title,company,contract_type,location,salary,remote_type,debut_date,require_experience,education,description,profil_experience
Consultant.e Data Engineer ExpÃ©rimentÃ©.e,"{'name': 'THE INFORMATION LAB', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '38 collaborateurs', 'creation_year': '2015', 'turnover': '5Mâ‚¬', 'mean_age': None}",CDI,Paris,45K Ã  60K â‚¬,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Qui sommes-nous ?
VÃ©ritables passionnÃ©s de data, nous avons construit The Information Lab autour des solutions Tableau, Alteryx et Snowflake. Nous sommes convaincus que ce sont les meilleures technologies pour accomplir la transformation digitale de nos clients.
Notre spÃ©cialisation nous permet dâ€™Ãªtre les premiers partenaires de ces Ã©diteurs et dâ€™Ãªtre les experts reconnus de ces solutions en France et en Europe.
En nous rejoignant vous pourrez partager votre passion avec vos pairs, travailler dans une ambiance dÃ©contractÃ©e pour remplir notre mission : ""Helping people make sense of dataâ€.
Description du poste
RattachÃ©(e) au pÃ´le Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous mÃ©tiers. Vos missions ont pour objet le traitement, lâ€™analyse, lâ€™enrichissement des donnÃ©es de nos clients et lâ€™adoption par nos clients des technologies que nous proposons. Au sein dâ€™une Ã©quipe de 5 Ã  8 personnes, vous rÃ©alisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre â€œpod leaderâ€ (chef dâ€™Ã©quipe).
Votre rÃ´le consiste Ã  :
Intervenir en avant-vente et cadrer vos missions
Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours Ã  quelques mois
Mener des projets de bout en bout, en mÃ©thode classique ou agile, en coordination avec les Ã©quipes de nos clients, nos Ã©quipes internes et les Ã©diteurs partenaires
PrÃ©senter les livrables de vos missions et mettre en avant leur ROI
Former nos clients Ã  nos technologies
Mettre vos compÃ©tences au service de vos collÃ¨gues au-delÃ  des missions dont vous avez la charge et participer au dÃ©veloppement des compÃ©tences en partageant vos retours dâ€™expÃ©rience
Participer aux activitÃ©s dâ€™Ã©vangÃ©lisation, par exemple : rÃ©daction de posts de blogs, participation aux communautÃ©s des Ã©diteurs, interventions lors dâ€™Ã©vÃ©nements (salons, confÃ©rences, webinaires)
Participer aux projets internes (BI interne, mÃ©thodes & qualitÃ©s)
Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires.
Vos principales qualitÃ©s :
Excellentes facultÃ©s dâ€™Ã©coute et de communication, orale et Ã©crite
Aptitude Ã  travailler sur plusieurs sujets en parallÃ¨le, Ã  prioriser
HumilitÃ© et capacitÃ© Ã  apprendre ainsi quâ€™Ã  transmettre ses connaissances
Sens du service, un bon relationnel avec les clients et la rigueur nÃ©cessaire au succÃ¨s de leurs projets
Team player
CompÃ©tences mÃ©thodologiques :
Analyse du besoin et cadrage de mission
Construction dâ€™indicateurs mÃ©tiers Ã  partir de donnÃ©es brutes
IdÃ©alement connaissance dâ€™un ou plusieurs mÃ©tiers et de leurs indicateurs clÃ©s
PrÃ©paration de donnÃ©es complexes Ã  des fins dâ€™analyse
MÃ©thodes de gestion de projet (classique et agile)
CapacitÃ© prouvÃ©e Ã  rÃ©aliser des dÃ©monstrations dâ€™outils
CompÃ©tences techniques :
Connaissance dâ€™au moins Alteryx Designer ou Tableau Prep (idÃ©alement vous avez dÃ©jÃ  une expÃ©rience solide sur ces outils)
MaÃ®trise dâ€™autres outils dâ€™analyse de donnÃ©es
Connaissance de la modÃ©lisation de donnÃ©es Ã  des fins dâ€™analyse
ExpÃ©rience professionnelle : vous bÃ©nÃ©ficiez dâ€™au moins 5 ans dâ€™expÃ©rience professionnelle, dont 3 ans sur un poste similaire ou dans un poste qui vous aura permis dâ€™utiliser les technologies similaires aux nÃ´tres. IdÃ©alement, vous avez dÃ©jÃ  une expÃ©rience dans un cabinet de conseil ou une ESN.
Langues : FranÃ§ais, Anglais professionnel
Quoi dâ€™autre ?
Situation gÃ©ographique : Ile-de-France. DÃ©placements en France Ã  prÃ©voir.
RÃ©munÃ©ration : 45 Ã  60 kâ‚¬, selon expÃ©rience.
Voir moins",
Alternance (Bac +5) - Data Engineer (F/H/X),"{'name': 'IADVIZE', 'sector': 'IT / Digital, Ã‰conomie collaborative, E-commerce', 'employees': '220 collaborateurs', 'creation_year': '2010', 'turnover': None, 'mean_age': '33 ans'}",Alternance,Nantes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 6 mois,,"Descriptif du poste
Vous rejoindrez l'Ã©quipe Data (4 personnes) au sein du dÃ©partement Product & Engineering. Vous serez sous la responsabilitÃ© du Senior Data Engineer et l'aiderez Ã  concevoir, construire, amÃ©liorer et maintenir la stack Data.
Vous aurez l'opportunitÃ© de participer Ã  une gamme Ã©tendue de tÃ¢ches, allant de la surveillance de l'infrastructure de donnÃ©es Ã  la mise en Å“uvre de changements critiques, ainsi que de la collecte de donnÃ©es pour rÃ©pondre aux dÃ©fis business.
Votre travail implique des actions Ã  plus long terme ainsi que des interventions opÃ©rationnelles quotidiennes, vous offrant ainsi une expÃ©rience rÃ©aliste du rÃ´le de Data Engineer.
Vous collaborez avec des Data Scientists et des Analystes, ainsi qu'avec l'Ã©quipe Engineering Platform et Ã©ventuellement avec des parties prenantes commerciales.
Vous acquerrez de l'expÃ©rience dans un environnement technique riche, notamment sur Google Big Query, Apache Airflow, Amazon Athena, Elasticsearch, Tableauâ€¦
Vos missions :
Surveiller l'exÃ©cution des pipelines de donnÃ©es.
Participer Ã  la migration des processus ETL.
ImplÃ©menter des Ã©volutions dans la stack d'ingÃ©nierie des donnÃ©es (par exemple, automatisations, systÃ¨mes d'alerte, traÃ§abilitÃ©, documentation).
Contribuer Ã  la mise Ã  jour ou Ã  la configuration de nouveaux pipelines de collecte.
Effectuer des extractions ad hoc et/ou des corrections BI pour rÃ©pondre aux besoins urgents de l'entreprise.
Voir moins","Profil recherchÃ©
Profil recherchÃ©
En derniÃ¨re annÃ©e d'Ã©tudes (Bac +5), vous recherchez pour 2024/2025 un terrain propice pour vous forger une expÃ©rience valorisante.
Vous disposez dâ€™au moins une premiÃ¨re expÃ©rience en programmation, de compÃ©tences en manipulation de donnÃ©es ainsi que de connaissances de base des environnements cloud. Enfin, vous Ãªtes Ã  l'aise avec la gestion de plusieurs tÃ¢ches et des dÃ©lais.
 CompÃ©tences techniques
Bonne connaissance de Python (usage gÃ©nÃ©ral, avec un accent sur la manipulation de structures de donnÃ©es).
Bonne connaissance de SQL.
FamiliaritÃ© avec les environnements Linux et la ligne de commande (CLI).
ComprÃ©hension des processus et de l'orchestration ELT/ETL.
Bonus 1 : ExpÃ©rience avec au moins un fournisseur de Cloud majeur (AWS, GCP, Azure, â€¦).
Bonus 2 : Connaissance d'Airflow, Docker, Terraform, Big Query.
Voir plus"
Margo Analytics - Data Engineer - H/F,"{'name': 'MARGO', 'sector': 'Logiciels, IT / Digital', 'employees': '400 collaborateurs', 'creation_year': '2005', 'turnover': '43M', 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
Margo Analytics est l'entitÃ© experte de Margo Group des problÃ©matiques Data, Cloud et DevOps crÃ©Ã©e en 2020 par leurs fondateurs RaphaÃ«l et Mounir. Aujourdâ€™hui 60 consultants ont intÃ©grÃ© l'entitÃ© et nous avons commencÃ© Ã  travailler avec 18 nouveaux clients (Banque, Industrie, Assurance, Ã‰nergie, E commerce, SantÃ©). A leurs cÃ´tÃ©s, vous pourrez Ã©voluer rapidement et dÃ©velopper de nouvelles compÃ©tences. 
Deux ADN fondateurs forts et spÃ©cifiques Ã  Margo Analytics Ã  lâ€™origine de lâ€™entitÃ© :
- Toujours se positionner sur les plus beaux sujets et sur les missions Ã  fortes valeurs ajoutÃ©es
- Recruter des consultants passionnÃ©s et curieux qui cherchent Ã  Ãªtre challengÃ©s
Aujourdâ€™hui, Margo Analytics possÃ¨de 4 communautÃ©s de compÃ©tences : 
- Data engineer 
- Data Science/ IA 
- Galaxy OPS (devOps, dataOps, cloudOps)
- Architecte Big Data 
Ainsi en rejoignant Margo Analytics vous aurez le choix des missions (#consultantfirst) sur lesquelles vous souhaitez travailler. Vous serez accompagnÃ© par les deux fondateurs ainsi que par le leader de votre communautÃ©, dont les rÃ´les sont de rechercher le projet qui correspondra le plus Ã  vos attentes et de vous accompagner dans votre carriÃ¨re.
ğŸ¯Les missions Margo Analytics : 
Au sein de la communautÃ© Data Engineer vos missions seront : 
- DÃ©velopper en mode agile les cas dâ€™usages mÃ©tier 
- Mettre en place des processus de collecte, dâ€™organisation, de stockage et de modÃ©lisation des donnÃ©es 
- DÃ©velopper des traitements de transformation et de production de donnÃ©es
- Assurer la mise en production des modÃ¨les de prÃ©diction crÃ©Ã©s par les Data Scientists
- Participer Ã  lâ€™amÃ©lioration continue et au refactoring de code
Besoin de projection ? Voici un exemple de mission : 
Camille accompagne un grand compte dans le domaine de lâ€™industrie sur son projet de mise en place dâ€™un nouveau datalake en Azure databricks. Lâ€™objectif de cette mission est dâ€™assurer la distribution de la donnÃ©e de maniÃ¨re optimisÃ©e pour crÃ©er une couche de distribution et permettre aux Data Scientists dâ€™implÃ©menter les use cases. Camille apporte son expertise sur les technologies suivantes : Spark, Scala, Azure, Databricks.
Nos stack Technique : 
- Langage : Python/Scala/Java
- Framework : Spark/Hadoop
- Cloud: Azure/ AWS/ GCP 
ğŸ™Œ Les avantages : 
- Tickets restaurants Swile
- Mutuelle Alan prise en charge Ã  100%
- Pass Navigo pris en charge Ã  100%
- TÃ©lÃ©travail
- Formations illimitÃ©es
- Locaux en plein coeur de Paris
- Places en crÃ¨ches
ğŸ¤Notre processus de recrutement : 
Notre processus de recrutement se fait en 3 Ã©tapes, rÃ©parties sur 7 Ã  15 jours maximum :
- PremiÃ¨re rencontre ! Vous Ã©changez avec un RH et un dirigeant sur votre parcours, vos aspirations professionnelles ainsi que sur Margo Analytics et les opportunitÃ©s que nous proposons
- Challengez-vous dans le cadre dâ€™un entretien technique avec lâ€™un de nos experts. Câ€™est Ã©galement lâ€™occasion pour vous dâ€™avoir son retour dâ€™expÃ©rience
- Dernier entretien de motivation : pour finir, vous rencontrez un membre du board de Margo Analytics pour un entretien final
ğŸ” Vous Ãªtes un(e) futur(e) Margo Analytics si : 
Must-Have
Vous Ãªtes issu(e) dâ€™une Ã©cole dâ€™ingÃ©nieur ou dâ€™un cursus universitaire Ã©quivalent niveau Bac + 5 / Master
Vous aimez coder et vous Ãªtes passionnÃ©(e) dâ€™informatique et de Data
Vous Ãªtes curieux(se) et vous vous intÃ©ressez aux derniÃ¨res technologies du marchÃ©
Vous justifiez dâ€™une premiÃ¨re expÃ©rience en tant que Data Engineer
Nice to Have
Vous Ãªtes ambitieux(se) et nâ€™avez pas peur de travailler sur des projets challengeants dans des environnements Ã  fortes contraintes techniques . Vous parlez et comprenez lâ€™anglais. 
Voir moins",
Data Engineer Junior H/F,"{'name': 'MEILLEURTAUX', 'sector': 'FinTech / InsurTech, Immobilier commercial, Immobilier particulier', 'employees': '2000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Vous souhaitez rejoindre la fintech leader en crÃ©dit et en assurance, en forte croissance, innovante, dynamique et dÃ©bordante de projets ? Ce qui suit va vous intÃ©resser !
Nous sommes engagÃ©s dans le dÃ©veloppement de la plateforme Data du Groupe incluant notamment des problÃ©matiques mÃ©tiers clefs telles que la Customer Data Platform.â€¯ 
Cette plateforme de donnÃ©es est au cÅ“ur de la stratÃ©gie de croissance de lâ€™entreprise et va nous permettre de : 
- Augmenter la Customer Lifetime Value (CLTV) de nos clients, 
- D'intÃ©grer dans tous nos produits des composants IA innovants,â€¯ 
- RÃ©duire nos coÃ»ts dâ€™acquisition, 
- Faciliter le pilotage du business Ã  travers une optimisation de nos outils de BI. 
Au sein de lâ€™Ã©quipe Data, vous vous Ã©panouirez dans notre environnement en Ã©volution rapide, oÃ¹ l'adaptabilitÃ© est essentielle. Au-delÃ  de la rÃ©solution de dÃ©fis techniques, nous souhaitons que vous contribuiez activement Ã  la construction de la culture d'ingÃ©nierie de Meilleurtaux, Ã  l'amÃ©lioration des pratiques et Ã  la promotion d'un environnement collaboratif et innovant. Lâ€™Ã©quipe est en pleine construction donc nous nâ€™attendons plus que vous pour participer Ã  cette belle aventure. 
Vos missions ğŸ“
CrÃ©er et maintenir une infrastructure de donnÃ©es de pointe en permettant aux utilisateurs finaux d'accÃ©der Ã  de la donnÃ©e prÃ©cise et de qualitÃ© ; 
DÃ©velopper de nouveaux modÃ¨les de donnÃ©es et des pipelines ; 
Ils auront pour objectif de prendre en charge une grande variÃ©tÃ© de cas d'utilisation (de l'analyse et du reporting Ã  l'apprentissage automatique et Ã  l'innovation de produits) ; 
Explorer en permanence de nouvelles technologies de donnÃ©es ; 
Tester les solutions les plus innovantes et prometteuses du marchÃ© en vue de pouvoir amÃ©liorer nos capacitÃ©s en matiÃ¨re de donnÃ©es.
Notre stack technique  
DÃ©veloppementâ€¯: Python, java, Salesforce.
CI-CDâ€¯:â€¯ Git, Docker.
Infrastructure cloudâ€¯: GCP et Azure. 
Bases de donnÃ©esâ€¯: Google BigQuery, SQL Server.
BIâ€¯: Qlik Sense. 
Ce poste nÃ©cessite d'interagir avec de nombreuses Ã©quipes au sein de Meilleurtaux que ce soit sur le plan technique (Ã©quipes IT, Data Scientist et BI) et/ou fonctionnel (Product Managers). 
Ceci nâ€™est quâ€™un avant-goÃ»t de la superbe aventure que vous vous apprÃªtez Ã  rejoindre, le poste Ã©tant Ã©videmment amenÃ© Ã  Ã©voluer en fonction de vous et vos propositions.
Voir moins","Profil recherchÃ©
Pourquoi Ãªtes-vous notre TOP candidat ? ğŸ§
Une premiÃ¨re expÃ©rience rÃ©ussie sur des sujets Data, idÃ©alement de 2 ans.  
Vous savez modÃ©liser la donnÃ©e et monitorer sa qualitÃ©. 
Bien entendu, il est important que vous ayez de trÃ¨s bonnes bases dans les compÃ©tences techniques nÃ©cessaires pour une plateforme data, que ce soit en Python, SQL ou les technologies du Cloud. 
Vous avez dÃ©jÃ  utilisÃ© des plateformes data. 
Vous vous tenez au fait des derniÃ¨res actualitÃ©s et suivez les communautÃ©s data. 
Le must : vous avez dÃ©jÃ  des connaissances sur l'industrie Fintech / Assurtech ou secteur Ã©quivalent.â€¯ 
Les soft-skills attendus pour rÃ©ussir chez Meilleurtaux ? 
De la curiositÃ© et de l'apprentissage continu : dans un domaine en constante Ã©volution, nous recherchons une personne connectÃ©e aux nouvelles technologies et aux derniÃ¨res innovations. 
Lâ€™esprit dâ€™Ã©quipe : travailler chez Meilleurtaux câ€™est pratiquer un sport dâ€™Ã©quipe, chacun collabore avec ses collÃ¨gues pour aller jusquâ€™Ã  une victoire collective. 
Voir plus"
Data Engineer,"{'name': 'ADVANCED SCHEMA', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '220 collaborateurs', 'creation_year': '2001', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 1 an,Bac +3,,
Data Engineer - Banque Data Factory - Nantes,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Nantes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Votre environnement de travail :
La division Â« Services Financiers Â» sâ€™est dÃ©veloppÃ©e autour des mÃ©tiers de la banque de dÃ©tail, de la banque privÃ©e et des services financiers spÃ©cialisÃ©s. Nous participons Ã  la rÃ©volution digitale grÃ¢ce Ã  notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compÃ©tences dans les domaines fonctionnels des CrÃ©dits, des Risques/ConformitÃ© et des Moyens de Paiement.
Si vous Ãªtes passionnÃ©(e) par la valorisation de la donnÃ©e, rejoignez notre Data Factory localisÃ©e Ã  Nantes et les quelques 100 Data IngÃ©nieurs qui la composent. Vous y rencontrerez des experts de la mise en Å“uvre de Plateforme de DonnÃ©es, des Data Architectes ou autres experts solution autour des problÃ©matiques de valorisation de la donnÃ©e.
Vous Ãªtes accompagnÃ©(e) au dÃ©veloppement de vos connaissances aux travers de diffÃ©rents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnÃ©e, la modÃ©lisation et mise Ã  disposition.
Rejoindre la Data Factory Sopra Steria, c'est rejoindre une communautÃ© de Data IngÃ©nieurs fiers de partager leur savoir et ouverts aux nouvelles expÃ©riences et expÃ©rimentations de la donnÃ©e.
Votre rÃ´le et vos missions :
Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expÃ©rience et votre appÃ©tence pour l'un de nos chapitres Data ci-dessous, vous participez Ã  :
La comprÃ©hension des besoins mÃ©tiers et la traduction solution de data ingÃ©nierie et ou data analysis ;
La mise en Å“uvre de solution d'ingestion des donnÃ©es quelles soit en batch et/ou en streaming dans un contexte Cloud ;
La structuration du DataLake, la mise en place des processus de gouvernance et de sÃ©curisation des donnÃ©es ;
Le traitement de la donnÃ©e jusqu'Ã  l'exposition au mÃ©tier ;
La mise en place de la chaine CI/CD et de sa supervision ;
La veille technologie avec nos partenaires Ã©diteurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idÃ©ation pour nos clients.
Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, R
Informations supplÃ©mentaires
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions. 
Un package avantages intÃ©ressant : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 30 familles de mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â».
L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encoreâ€¦).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
> 
Voir moins","Profil recherchÃ©
Votre profil :
DiplÃ´mÃ©(e) d'une Ecole d'ingÃ©nieur ou formation Ã©quivalente, vous avez dÃ©jÃ  participÃ© Ã  un projet Data (Big Data, BI) et vous avez une expÃ©rience de minimum 2 ans.
Vous accordez une importance particuliÃ¨re au dÃ©veloppement de vos compÃ©tences sur plusieurs technologies. Vous souhaitez une Ã©volution rÃ©elle de carriÃ¨re Ã  travers l'expÃ©rience projet. Vous Ãªtes soucieux de l'apport de valeur pour vos clients. Et vous voulez transmettre votre savoir auprÃ¨s de collaborateurs moins expÃ©rimentÃ©s. Alors, n'attendez-plus, ce poste est fait pour vous !"
Data Engineer Talend F/H,"{'name': 'ORANGE', 'sector': 'Objets connectÃ©s, Big Data, Electronique / TÃ©lÃ©communications', 'employees': '136000 collaborateurs', 'creation_year': '1994', 'turnover': '43,5 milliards â‚¬', 'mean_age': '44 ans'}",CDI,Villeneuve-d'Ascq,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Afin de dÃ©velopper notre Ã©quipe lilloise, nous recherchons aujourdâ€™hui, un IngÃ©nieur DATA Ã  mÃªme dâ€™accompagner nos clients dans la structuration de leurs SI autour de la donnÃ©e.

Vos principales missions seront les suivantes :

- Concevoir des solutions de traitement et collecter des volumes importants de donnÃ©es.
- Participer Ã  des Ã©tudes de cadrage pour collecter le besoin mÃ©tier et concevoir les solutions qui rÃ©pondent au besoin du client.
- Apporter son expertise sur des problÃ©matiques prÃ©cises rencontrÃ©es chez les clients.
- Participer Ã  la veille techno
- Rester informer et former sur les nouvelles solutions DATA
- Contribuer aux phases dâ€™avant-vente et au dÃ©veloppement business.
- Participer Ã  la conception, lâ€™Ã©volution et la prÃ©sentation de nos offres DATA.","Profil recherchÃ©
Vous :
- ÃŠtes issu(e) de formation bac+5
- Vous justifiez dâ€™au moins 4 ans dâ€™expÃ©riences en qualitÃ© dâ€™IngÃ©nieur DATA sur la solution TALEND Enterprise (Data Integration) et avez idÃ©alement une connaissance des solutions Cloud dâ€™AWS et dâ€™AZURE
- Vous Ãªtes intervenus sur des projets intÃ©grant des pratiques DevOps et AGILE
Alors postulez, ce poste est fait pour vous !
 
Vos compÃ©tences clÃ©s :
- Expertise sur lâ€™outil ETL TALEND Enterprise (administration et dÃ©veloppement)
- Fortes connaissances des solutions de bases de donnÃ©es (SQL, NoSQLâ€¦)
- Connaissances en langages objets ou scripts (notamment Java mais aussi Javascript, Scala, Pythonâ€¦)
- Divers systÃ¨mes dâ€™exploitation : UNIX, Windows
 
Autonomie, rigueur, curiositÃ©, dynamisme et sens du service sont des qualitÃ©s nÃ©cessaires pour ce poste.
 
Les compÃ©tences complÃ©mentaires qui seraient apprÃ©ciÃ©es :

- Connaissances dâ€™autres modules Talend (MDM, ESB, Data Quality, Cloudâ€¦)
- MaÃ®trise des technologies du Big Data (Hadoop, Spark, Kafkaâ€¦)
- Expertise sur dâ€™autres outils ETL (Informatica, SSIS, DataStageâ€¦)
- Notions en architecture des SystÃ¨mes dâ€™Information
- MaÃ®trise de lâ€™anglais (oral et Ã©crit)
Voir plus"
Data Engineer (H/F),"{'name': 'MELTONE ADVISORY', 'sector': 'Logiciels, IT / Digital, Transformation', 'employees': '150 collaborateurs', 'creation_year': '2014', 'turnover': '17Mâ‚¬', 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
Chez MeltOne Advisory, il nâ€™y a pas les fonctions mÃ©tiers dâ€™un cÃ´tÃ© et la technologie de lâ€™autre. Tous les consultants sont polyvalents et ont un parcours qui leur confÃ¨re une expertise indÃ©niable Ã  la fois sur vos problÃ©matiques mÃ©tiers mais aussi sur la dimension IT.
Tu interviendras en collaboration Ã©troite avec nos managers et sur diffÃ©rents types de projet :
Transformations digitales,
Optimisation des processus,
AmÃ©lioration de la qualitÃ© de lâ€™information,
Mise en oeuvre et Ã©volution de systÃ¨mes dâ€™information,
Assistance Ã  la gestion de projet
Tes missions seront :
Concevoir des solutions pertinentes et innovantes en tenant compte de tous les enjeux du contexte client
ImplÃ©menter et optimiser ces solutions dans les rÃ¨gles de lâ€™art
Conseiller les clients dans leurs choix
Transmettre ton savoir-faire et participer Ã  la capitalisation de connaissance des utilisateurs
Notre structure Ã  taille humaine est un cadre parfait pour te permettre dâ€™Ã©voluer rapidement en tâ€™offrant lâ€™opportunitÃ© dâ€™intervenir Ã  la fois sur les diffÃ©rentes phases dâ€™un projet : cadrage / conception et mise en oeuvre / conduite de projet et encadrement dâ€™Ã©quipe, mais Ã©galement sur des activitÃ©s Ã  dominante commerciale : conception dâ€™offres / rÃ©daction de proposition / soutenance en clientÃ¨le.
Voir moins","Profil recherchÃ©
Tu as une expÃ©rience projets avec Snowflake
Tu maitrises le domaine fonctionnel de la finance ou de la logistique
Tu souhaites intervenir sur des projets Ã  forte valeur ajoutÃ©e
Tu as un goÃ»t prononcÃ© pour les nouvelles technologies
Tu as un fort esprit dâ€™Ã©quipe, et aime partager des moments conviviaux avec tes collÃ¨gues
Tu es dotÃ©(e) dâ€™un bon relationnel et tu maÃ®trises lâ€™anglais
Tu recherches une entreprise Ã  taille humaine avec un management de proximitÃ© pour accompagner ton dÃ©veloppement de carriÃ¨re, et un environnement oÃ¹ lâ€™autonomie et lâ€™esprit dâ€™initiative sont mis en avant.
Si en lisant cela, tu te dis que câ€™est tout toi (ou presque), câ€™est que tu as lâ€™Ã©toffe dâ€™un futur MeltOner et que tu dois postuler Ã  cette offre."
Data Engineer,"{'name': 'ADVANCED SCHEMA', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '220 collaborateurs', 'creation_year': '2001', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,Bac +3,,
Data Engineer (H/F) - CDI - Paris,"{'name': 'LE COLLECTIONIST', 'sector': 'HÃ´tellerie, Tourisme, Immobilier particulier', 'employees': '330 collaborateurs', 'creation_year': '2012', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 6 mois,Bac +5 / Master,"Descriptif du poste
At LC, The Data team is composed of 2 Data Analysts (1 Lead and 1 IC) and 1 Lead Data Engineer reporting to the CTPO, and is thus part of the Tech & Product team.
The goal of the Data team is to unlock and democratize the usage of data in other teamsâ€™ everyday activity and decision making process.
The Data Engineer is responsible for the companyâ€™s Data Platform: from the infrastructure setup to the release and management of the Warehouse trusted data model.
As of today, this Data Platform is mainly used for BI & Analytics use cases to help teams work more efficiently and make better decisions by providing a consolidated view of LC business performance through dashboards, data extractions and analysis.
In 2024, we will work on building a more Self-service oriented Data platform for business users to be less dependent on the central Data team AND why not, explore some Machine Learning use cases later.
By joining us, you will be part of a Data team that, while still in its early stages of development, made the effort of building a strong basis and setting up a lot of best practices.
It will be the opportunity for you to grow and develop your Data Engineering skills on a Modern Data Stack, be mentored by an experienced Data Engineer and have a lot of impact on the Data Platform and team development.
ğŸš€ Key missions
As a Data Engineer, you will report directly to the Lead Data Engineer and will:
Build and maintain data ingestion and processing pipelines (cleaning, curation, data quality checks, etc.)
Provide and maintain consumption-ready trusted data for Data Analyst or Business users
Deploy, monitor and optimize components of the Data Platform
Provide and maintain tools for Data Analysts
Write and maintain the Data Platform documentation
At LC, the Data Engineer role has a mix of Data Platform Engineer and Analytics Engineer responsibilities.
ğŸ­ Our technical stack
Cloud provider : Google Cloud Platform
Data Warehouse : BigQuery
Ingestion tool : Airbyte (self-hosted, on Kubernetes)
Orchestration & Transformation : Cloud Composer (Apache Airflow), Dataform
BI tool : Looker Studio
Infra-as-Code : Terraform, Terragrunt
Main coding language : Python, SQL
Perks :
ğŸšŒ 50% reimbursement of the transportation passğŸ‚ 1 day off for your birthday (excluding weekends and public holidays)
ğŸ½ï¸ Meal vouchers up to â‚¬8
ğŸ’» A laptop
ğŸŠ Year-round events (Christmas Party, Raclette Party, Summer Partyâ€¦)
ğŸ’µ Unlimited referrals (up to â‚¬1000 for a permanent position)
â˜€ï¸ A surprise experience worth â‚¬150 to be won every quarter
ğŸ¡ 2 remote days per week
ğŸ‹ğŸ½ Gymlib subscription (activities and sports in France)
âœ¨ Happypal account for cultural activities
Voir moins","Profil recherchÃ©
Preferred background/experience
Bac+5 with specialization in Data
Internship and/or 1st experience as Data/Analytics/BI Engineer in a startup/scaleup company is preferred
Hard skills
Basic knowledge of Software and Data Engineering principles
Experience with any RDBMS (PostgreSQL, MySQL, SQL Server, etc.)
Experience with git
Good experience with SQL 
Knowledge of Python and CLI
Soft skills
Team player 
Strong interest in using best practices 
Not afraid to talk to business people"
Data Engineer - Madonne Core (H/F),"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards â‚¬ de PNB', 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous rejoignez l'Ã©quipe Core en charge de la maintenance Ã©volutive des applications Madonne (RÃ©colte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiÃ©e au coeur de l'IT Risque).

Au quotidien vous avez pour missions de :

Participer Ã  l'adaptation de nos applications en adÃ©quation avec les besoins mÃ©tiers (nouveaux produits, nouvelles rÃ¨glementations, nouveaux SI Front) ;
Participer activement Ã  la modernisation de nos outils, modernisation de notre chaÃ®ne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;
Monter en compÃ©tences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous dÃ©velopperez une comprÃ©hension globale des chaÃ®nes de traitements ;
Participer Ã  tous les travaux de modernisation de notre SI, et Ãªtre donc engagÃ© dans la migration de nombreux process vers le DataLake Risk.





#TransformativeFinance
Ce poste est basÃ© Ã  Paris avec la possibilitÃ© de tÃ©lÃ©travailler.
En tant que Top Employer, nous plaÃ§ons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilitÃ© interne, dÃ©veloppement de carriÃ¨re et de formation vous permettent de grandir et de vous Ã©panouir tout au long de votre parcours.
Vous Ã©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.
Vous avez Ã©galement la possibilitÃ© de vous engager en faveur de la sociÃ©tÃ© et de causes qui vous tiennent Ã  cÅ“ur via notre fondation d'entreprise.
A propos du processus de recrutement
Vous serez contactÃ© par l'un de nos recruteurs avant de rencontrer nos experts mÃ©tier (manager, membre de l'Ã©quipe ou de la filiÃ¨re mÃ©tier).
Voir moins","Profil recherchÃ©
Qui Ãªtes-vous ? Si vous vous reconnaissez dans la description suivante vous Ãªtes fait pour travailler avec nous : Vous souhaitez bÃ©nÃ©ficier d'une premiÃ¨re expÃ©rience significative en dÃ©veloppement Spark et Scala. Vous maitrisez : * Les mÃ©thodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appÃ©tence pour la manipulation de la data. Vous Ãªtes : * Reconnu par votre esprit d'Ã©quipe ; * Capable de communiquer avec des publics diffÃ©rents, notamment avec le mÃ©tier ; * Autonome et ntÃ©ressÃ© par l'environnement finance de marchÃ©. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous Ãªtes intÃ©ressÃ© en rÃ©pondant Ã  cette annonce."
"Senior Data Engineer - Paris, Toulouse, Montpellier - F/H/N","{'name': 'SWILE', 'sector': 'Application mobile, Restauration, FoodTech', 'employees': '1000 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '35 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©",TÃ©lÃ©travail frÃ©quent,,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Notre Ã©quipe Analytics sâ€™agrandit et nous recherchons un.e Data Engineer Senior pour dÃ©velopper notre plateforme dâ€™Analytics globale.
ğŸ˜ Tes futures missions :
DÃ©velopper et maintenir une Data Platform robuste qui permet lâ€™ingestion et la mise Ã  disposition dâ€™une grande variÃ©tÃ© de donnÃ©es
GÃ©rer nos outils SaaS (Stitch, Snowflake, â€¦) et contribuer sur notre infrastructure K8S auto-hebergÃ©e (Airflow, Kafka, â€¦)
ModÃ©liser les donnÃ©es pour les traitements Analytics
DÃ©finir avec lâ€™Ã©quipe les bonnes pratiques afin dâ€™industrialiser nos modÃ¨les dâ€™Analytics
Assurer la chaÃ®ne de traitement des donnÃ©es
Appliquer les bonnes pratiques de code pour permettre une croissance de la base de code sans augmenter notre dette technique (version control, testing, refactoring, â€¦)
Participer aux choix techniques
Documenter le code et les process pour le partage de connaissance au sein de lâ€™Ã©quipe Innovation","Profil recherchÃ©
âœ¨Ce sera un match parfait si tu as â€¦
Au moins 3 ans dâ€™expÃ©rience sur un poste en Data Engineering avec un background en Software Engineering
Bon niveau de maitrise sur notre stack technique Analytics : Stitch/Airflow, AWS S3/ Snowflake, DBT, Github, Docker/Terraform
Bon niveau de maitrise en SQL
Excellente communication et capacitÃ© Ã  prÃ©senter des sujets complexes de maniÃ¨re simple
Bonne capacitÃ© dâ€™ownership et de priorisation
Anglais courant"
Cloud Data Engineer H/F,"{'name': 'HARDIS GROUP', 'sector': 'IT / Digital, Supply Chain, SaaS / Cloud Services', 'employees': '1500 collaborateurs', 'creation_year': '1984', 'turnover': ""156 millions d'euros en 2022"", 'mean_age': '38 ans'}",CDI,Saint Herblain,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,01 novembre 2021,> 3 ans,Bac +5 / Master,"Descriptif du poste
Au sein de notre entitÃ© Business Applications nantaise et intÃ©grÃ© au sein dâ€™une Ã©quipe projet, vous contribuez Ã  lâ€™Ã©laboration et lâ€™Ã©volution des couches mÃ©tiers des applications que nous rÃ©alisons pour nos clients.
En tant que Cloud Data Engineer, vous participez Ã  des projets innovants Ã  forte valeur ajoutÃ©e pour nos clients, Ã  la fois technologique et mÃ©tier. EntourÃ© de dÃ©veloppeurs, lead dÃ©veloppeur, architecte et Scrummaster, vous travaillez en mÃ©thode agile (Scrum). Notre vision du Cloud Data Engineer :
Vous Ãªtes capable dâ€™apprÃ©hender un contexte client et dâ€™implÃ©menter une plateforme pour valoriser sa donnÃ©e
Vous avez dÃ©jÃ  une expÃ©rience sur GCP ou AWS
Vous Ãªtes Ã  lâ€™aise sur lâ€™un des langages suivants (Python, Java, JavaScript)
Vous avez dÃ©jÃ  utilisÃ© un framework de calculs distribuÃ© (Spark, Beam, â€¦)
Vous connaissez et utilisez les diffÃ©rentes solutions de stockage (SQL, NoSQL, Search Engineâ€¦)
Vous maitrisez les principes du dÃ©veloppement Cloud
Vous avez des connaissances en machine learning","Profil recherchÃ©
De formation Bac + 5, issu dâ€™une Ã©cole dâ€™ingÃ©nieur ou Ã©quivalent, vous justifiez dâ€™au moins 3 ans dâ€™expÃ©rience professionnelle rÃ©ussie dans les domaines de la Data et du Cloud en contexte agile.
Vous Ãªtes Ã  lâ€™aise avec un ou plusieurs des sujets suivants : Python, Java, JavaScript, GCP, AWS, Spark, Beam, Kafka, Airflow, ELK.
Vous Ãªtes Ã  la fois autonome et force de proposition.
Vous aimez partager vos connaissances et souhaitez Ã©voluer au sein dâ€™une Ã©quipe technophile et riche en expertises. Vous Ãªtes organisÃ©, mÃ©thodique et avez une excellente capacitÃ© dâ€™analyse. La curiositÃ©, lâ€™esprit dâ€™Ã©quipe et la bonne humeur sont indispensables pour intÃ©grer lâ€™Ã©quipe Business Applications Nantes.
Nous pouvons accompagner votre mobilitÃ© grÃ¢ce Ã  une offre globale (de la recherche de logement Ã  lâ€™accompagnement administratif, en passant par lâ€™intÃ©gration de lâ€™ensemble de la famille dans le nouvel environnement de vie) - sous condition dâ€™Ã©ligibilitÃ©"
Data Engineer,"{'name': 'SOCIÃ‰TÃ‰ GÃ‰NÃ‰RALE', 'sector': 'Banque, FinTech / InsurTech, Finance', 'employees': '117000 collaborateurs', 'creation_year': '1864', 'turnover': None, 'mean_age': None}",CDI,Fontenay-sous-Bois,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Au sein de la Direction des SystÃ¨mes d'Information de la Banque de DÃ©tail France de SociÃ©tÃ© GÃ©nÃ©rale, vous :

BÃ©nÃ©ficierez d'un cadre de travail agrÃ©able facilitant l'Ã©quilibre vie pro/vie perso notamment en permettant jusqu'Ã  3 jours de tÃ©lÃ©travail par semaine.

Evoluerez dans un environnement stimulant : intÃ©grez nos Ã©quipes afin de relever les dÃ©fis innovants qui nous animent au quotidien autour des pratiques de dÃ©veloppement green, du cloud, de la data ou encore de la CybersÃ©curitÃ©.

Baignerez dans une culture bienveillante : notre proximitÃ© avec le mÃ©tier, l'entraide et l'Ã©coute entre management et la communautÃ© des experts font notre force. Un collectif plÃ©biscitÃ© par 85% de nos collaborateurs.

Les missions seront les suivantes :
Suivre et dÃ©panner la production pour son maintien en conditions opÃ©rationnelles
Concevoir des solutions pour collecter, transformer et exploiter de gros volumes de donnÃ©es
Analyser les donnÃ©es provenant de multiples sources (exemple : croisement simple de donnÃ©es jusqu'Ã  l'analyse prÃ©dictive)
Industrialiser des traitements et participer Ã  leur amÃ©lioration continue pour qu'ils soient fiables, robustes, performants et rÃ©silients afin de rÃ©pondre aux exigences des partenaires mÃ©tiers
Travailler en Ã©troite collaboration avec les Data Architectes et Data Scientists pour industrialiser le procÃ©dÃ© et produire des analyses opÃ©rationnelles => ajouter les autres transverses + PO mÃ©tier
Tester de nouvelles fonctionnalitÃ©s, nouveaux outils et participer Ã  des confÃ©rences internationales (Flink Forward, Spark Summit)
Documenter ses travaux
Contribuer Ã  l'acculturation et Ã  la vulgarisation des sujets Big Data auprÃ¨s de ses principaux interlocuteurs


Et si câ€™Ã©tait vous ?


Vous possÃ©dez les compÃ©tences suivantes :
Connaissances des outils liÃ©s au Big Data : Spark, Hive, Hadoop, NiFi, Kafka, Elastic, Kibana
DÃ©veloppement informatique : Scala, Python, Java, Devops, Big Data, outils CI/CD, microservice, API
ModÃ©lisation des donnÃ©es ModÃ¨les de donnÃ©es : modÃ¨le en Ã©toile, modÃ¨le Data Vault
Connaissances en architecture technique Big Data
Relationnel et esprit d'Ã©quipe sens du service, capacitÃ© Ã  collaborer, Ã  communiquer et Ã  s'adapter Ã  ses interlocuteurs
Autonomie
Savoir s'adapter aux diffÃ©rentes mÃ©thodologies (prÃ©dictives, agiles, hybrides)
Forte transversalitÃ© (interactions avec des Ã©quipes variÃ©es) : Admin plate-forme, Ã©quipe DevOps, support, Expert IT : Architecte Big Data, IT Data Designer, Experts Data : Data Scientist, Data Quality Manager, Business Data Designer, MÃ©tiers, Chef de Projet

Plus qu'un poste, un tremplin


Notre vision est de jouer un rÃ´le moteur dans les transformations positives du monde et de contribuer Ã  un avenir plus Ã©cologique, respectueux de la planÃ¨te !

Choisir SociÃ©tÃ© GÃ©nÃ©rale, c'est intÃ©grer un Groupe oÃ¹ la culture d'entreprise est tournÃ©e vers l'inclusion, la diversitÃ© et l'esprit d'Ã©quipe !

C'est construire une carriÃ¨re dynamique avec la possibilitÃ© de changer de poste en moyenne tous les 4 ans, en France et Ã  l'international tout en bÃ©nÃ©ficiant de formations rÃ©guliÃ¨res !

Au regard de vos compÃ©tences, une rÃ©munÃ©ration attractive revue annuellement, composÃ©e d'un salaire fixe, d'une part variable individuelle et d'une prime d'intÃ©ressement et de participation vous sera proposÃ©e.

Vous bÃ©nÃ©ficiez Ã©galement de tarifs prÃ©fÃ©rentiels sur vos services bancaires, d'un compte Ã©pargne temps monÃ©tisable et d'un Plan d'Epargne Entreprise abondÃ©.

Attentif Ã  votre qualitÃ© de vie et conditions de travail, vous bÃ©nÃ©ficiez de nombreux avantages complÃ©mentaires :
Ã€ minima 2 jours de tÃ©lÃ©travail par semaine
26 Ã  28 jours de congÃ©s payÃ©s par an et 14 Ã  18 jours de RTT (suivant les annÃ©es), des congÃ©s liÃ©s aux Ã©vÃ©nements de la vie
Un ComitÃ© d'Entreprise (billetterie Ã©vÃ©nements sportifs & culturels, primes et subventions vacances, garde d'enfants, chÃ¨que cadeaux Ã  Noel)
Une offre variÃ©e de restaurants d'entreprise et de cafÃ©tÃ©rias Ã  tarifs compÃ©titifs ainsi que des titres restaurants dÃ©matÃ©rialisÃ©s quand vous Ãªtes en tÃ©lÃ©travail

Pourquoi nous choisir ?


Chez SociÃ©tÃ© GÃ©nÃ©rale, nous sommes convaincus que vous Ãªtes le moteur du changement et que le monde de demain sera fait de toutes vos initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques annÃ©es ou toute votre carriÃ¨re, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. CrÃ©er, oser, innover, entreprendre font partie de notre ADN.

Si vous aussi vous souhaitez Ãªtre dans l'action, Ã©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et dÃ©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !

Vous hÃ©sitez encore ?

Sachez que nos collaborateurs peuvent s'engager quelques jours par an pour des actions de solidaritÃ© sur leur temps de travail : parrainer des personnes en difficultÃ© dans leur orientation ou leur insertion professionnelle, participer Ã  l'Ã©ducation financiÃ¨re de jeunes en apprentissage ou encore partager leurs compÃ©tences avec une association. Les formats d'engagement sont multiples.

Nous sommes un employeur garantissant l'Ã©galitÃ© des chances et nous sommes fiers de faire de la diversitÃ© une force pour notre entreprise. Le groupe s'engage Ã  reconnaÃ®tre et Ã  promouvoir tous les talents, quels que soient leurs croyances, Ã¢ge, handicap, parentalitÃ©, origine ethnique, nationalitÃ©, identitÃ© de genre, orientation sexuelle, appartenance Ã  une organisation politique, religieuse, syndicale ou Ã  une minoritÃ©, ou toute autre caractÃ©ristique qui pourrait faire l'objet d'une discrimination.

RÃ©fÃ©rence: 240003CI
EntitÃ©: Banque de dÃ©tail France
Date de dÃ©but: 01/04/2024

Date de publication: 08/02/2024
Voir moins",
Data Engineer,"{'name': 'SOCIÃ‰TÃ‰ GÃ‰NÃ‰RALE', 'sector': 'Banque, FinTech / InsurTech, Finance', 'employees': '117000 collaborateurs', 'creation_year': '1864', 'turnover': None, 'mean_age': None}",Stage,Fontenay-sous-Bois,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Au sein de la Direction des SystÃ¨mes d'Information de la banque de dÃ©tail France de SociÃ©tÃ© GÃ©nÃ©rale, vous ...
BÃ©nÃ©ficierez d'un cadre de travail agrÃ©able facilitant l'Ã©quilibre vie pro/vie perso notamment en permettant jusqu'Ã  3 jours de tÃ©lÃ©travail par semaine.
Evoluerez dans un environnement stimulant : intÃ©grez nos Ã©quipes afin de relever les dÃ©fis innovants qui nous animent au quotidien autour des pratiques de dÃ©veloppement green, du cloud, de la data ou encore de la cybersÃ©curitÃ©.
Baignerez dans une culture bienveillante : notre proximitÃ© avec le mÃ©tier, l'entraide et l'Ã©coute entre management et la communautÃ© des experts font notre force. Un collectif plÃ©biscitÃ© par 85% de nos collaborateurs*.

En tant que Data Engineer, vous serez rattachÃ©(e) Ã  une Feature Team agile dÃ©diÃ©e Ã  la banque de de dÃ©tail en France.

Vous participerez au dÃ©veloppement des applications big data en Ã©quipe avec l'aide de nos meilleurs experts, rÃ©aliser des traitements data lake sur des milliards d'indicateurs quotidiens pour garantir la bonne gestion des risques de la banque ou manipuler des millions de contrats financiers pour rÃ©pondre aux demandes de nos rÃ©gulateurs, bref, devenir un(e) vrai(e) maestro de la data !

ConcrÃ¨tement, vous serez amenÃ©(e) Ã  :
Travailler sur des applications de traitement de donnÃ©es basÃ©es sur des technologies Big Data (Hadoop, Spark, Kafka) mises en place pour stocker et distribuer l'ensemble des transactions ainsi que leurs indicateurs de risques associÃ©s. Les donnÃ©es et traitements sont progressivement migrÃ© sur le cloud public Azure.
Participer aux nouveaux dÃ©veloppements requis sur l'application (ajout de nouvelles fonctionnalitÃ©s aux jobs existants, implÃ©mentation de nouveaux jobs, d'outils de non-rÃ©gression, de data quality, de continuous delivery, ou bien la conduite de tests de performances)
Concevoir des solutions pour collecter, nettoyer, organiser et synthÃ©tiser de trÃ¨s gros volumes de donnÃ©es (pour alimenter bases de donnÃ©es, datalakes et projets Big Data)
Participer Ã  l'analyse complexe de donnÃ©es provenant de diffÃ©rentes sources
Assurer une veille technologique permettant de tester de nouvelles fonctionnalitÃ©s et nouveaux outils

* RÃ©sultats enquÃªte collaborateurs IPSOS (DÃ©cembre 2021)

Et si câ€™Ã©tait vous ?


Etudiant(e) de niveau Bac +4/5 en Ecole d'ingÃ©nieur ou UniversitÃ©, avec une spÃ©cialisation en Data, Informatique
PassionnÃ©(e) de data, vous aimez travailler en mode collaboratif, partager votre savoir-faire et proposer des amÃ©liorations qui donneront du sens Ã  l'activitÃ©
Vous Ãªtes curieux(se), avec un bon esprit d'analyse et vous aimez communiquer
Incollable sur Spark et Java, vous apprÃ©ciez le code propre et appliquez les bonnes pratique du crafmanship
You're fluent in english ! Vous Ãªtes notre candidat(e) idÃ©al(e) !

Plus qu'un poste, un tremplin


DÃ¨s votre arrivÃ©e, vous serez intÃ©grÃ©(e) dans nos Ã©quipes et apprendrez chaque jour aux cÃ´tÃ©s de nos experts qui vous accompagneront dans vos missions. Progressivement, vous gagnerez en autonomie sur vos projets pour faire de cette expÃ©rience un vrai accÃ©lÃ©rateur de carriÃ¨re. Vous dÃ©couvrirez Ã©galement toute la diversitÃ© de nos mÃ©tiers, dans un secteur qui Ã©volue et innove en permanence.

A la fin de vos Ã©tudes ou de votre VIE, diverses opportunitÃ©s pourront s'offrir Ã  vous, en France et Ã  l'international.

En tant que stagiaire, vous pourrez bÃ©nÃ©ficier de jours de tÃ©lÃ©travail (pour tout stage de longue durÃ©e et selon le rythme de votre service), d'une prise en charge de 50% de votre titre de transport et de la billetterie Ã  prix rÃ©duits de notre ComitÃ© d'Entreprise (concerts, cinÃ©ma, sport...). Lors de votre prÃ©sence sur site, vous accÃ©derez Ã  une offre variÃ©e de restaurants d'entreprise et de cafÃ©terias Ã  un tarif trÃ¨s compÃ©titif.

Pourquoi nous choisir ?


Chez SociÃ©tÃ© GÃ©nÃ©rale, nous sommes convaincus que vous Ãªtes le moteur du changement et que le monde de demain sera fait de toutes vos initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques annÃ©es ou toute votre carriÃ¨re, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. CrÃ©er, oser, innover, entreprendre font partie de notre ADN.

Si vous aussi vous souhaitez Ãªtre dans l'action, Ã©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et dÃ©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !

Vous hÃ©sitez encore ?

Sachez que nos collaborateurs peuvent s'engager quelques jours par an pour des actions de solidaritÃ© sur leur temps de travail : parrainer des personnes en difficultÃ© dans leur orientation ou leur insertion professionnelle, participer Ã  l'Ã©ducation financiÃ¨re de jeunes en apprentissage ou encore partager leurs compÃ©tences avec une association. Les formats d'engagement sont multiples.

Nous sommes un employeur garantissant l'Ã©galitÃ© des chances et nous sommes fiers de faire de la diversitÃ© une force pour notre entreprise. Le groupe s'engage Ã  reconnaÃ®tre et Ã  promouvoir tous les talents, quels que soient leurs croyances, Ã¢ge, handicap, parentalitÃ©, origine ethnique, nationalitÃ©, identitÃ© de genre, orientation sexuelle, appartenance Ã  une organisation politique, religieuse, syndicale ou Ã  une minoritÃ©, ou toute autre caractÃ©ristique qui pourrait faire l'objet d'une discrimination.

RÃ©fÃ©rence: 240001R7
EntitÃ©: Banque de dÃ©tail France
Date de dÃ©but: 11/03/2024

Date de publication: 02/02/2024
Voir moins",
Data Engineer - Equipements BiomÃ©dicaux connectÃ©s,"{'name': 'APHP DSI', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, SantÃ©', 'employees': '495 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '46 ans'}","CDD / Temporaire
(12 Ã  36 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
La mission de votre Ã©quipe
Afin de permettre le dÃ©veloppement de projets de recherche innovants, en particulier dans le domaine de lâ€™intelligence artificielle, lâ€™APâ€“HP a mis en place une plateforme Big Data, infrastructure informatique propre, intÃ©grant des capacitÃ©s de stockage et de calcul pour lâ€™exploitation sÃ©curisÃ©e et performante des donnÃ©es de santÃ© dont elle est dÃ©positaire. Cette plateforme hÃ©berge notamment lâ€™entrepÃ´t de donnÃ©es de santÃ© (EDS) de lâ€™AP-HP.

Lâ€™EntrepÃ´t de DonnÃ©es de SantÃ© (EDS) de lâ€™AP-HP intÃ¨gre des donnÃ©es administratives et mÃ©dicales de plus de 8 millions de patients hospitalisÃ©s ou venus en consultation au sein des 39 Ã©tablissements de lâ€™AP-HP (20 millions de dossiers mÃ©dicaux, plus de 10 millions de diagnostics, 181 millions de rÃ©sultats de laboratoiresâ€¦). Cet entrepÃ´t permet dâ€™amÃ©liorer le pilotage de lâ€™activitÃ© hospitaliÃ¨re et de faire avancer la recherche scientifique dans le domaine de la santÃ© en favorisant la rÃ©alisation dâ€™Ã©tudes sur donnÃ©es, la mise en place dâ€™essais cliniques et le dÃ©veloppement dâ€™algorithmes dâ€™aide Ã  la dÃ©cision.

La Plateforme Big Data de lâ€™AP-HP compte actuellement +30 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po dâ€™espace disque), de machines GPU (48 Nvidia P40 / V100), de 20 machines dÃ©diÃ©es aux environnements Jupyter pour lâ€™analyse de donnÃ©es, et de nombreuses autres machines applicatives.

Votre Ã©quipe, le domaine Â« Plateforme Big Data Â», a pour mission lâ€™intÃ©gration des donnÃ©es de santÃ© massives et complexes (donnÃ©es structurÃ©s, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation Ã  grande Ã©chelle, de maniÃ¨re performante, ergonomique et sÃ©curisÃ©e dans le respect des principes et rÃ¨gles de gouvernance des donnÃ©es dÃ©finis par lâ€™AP-HP. Les donnÃ©es issues des Ã©quipements biomÃ©dicaux connectÃ©s proviennent globalement de lâ€™ensemble des services de lâ€™APHP et en particulier dans les services de soins intensifs. Selon le contexte, la frÃ©quence dâ€™acquisition et la durÃ©e dâ€™enregistrement des signaux varient dans des proportoins importantes (de quelques secondes Ã  plusieurs jours et de 0.02Hz Ã  3kHz).
Vos missions
Au sein de lâ€™Ã©quipe en charge de la Plateforme Big Data de lâ€™APHP, vous prenez en charge le dÃ©veloppement des outils ou composants rÃ©pondant aux attentes des mÃ©decins et chercheurs pour le stockage et lâ€™exploitation des donnÃ©es de type signaux physiologiques (ECG, EEG, EMG, courbes respiratoires, â€¦) collectÃ©es dans le cadre de leurs projets de recherche.
La plateforme big data cherche a se doter dâ€™une solution technique spÃ©cifique pour le stockage, le traitement et lâ€™exploitation de ces donnÃ©es sous forme de sÃ©ries temporelles. Vous serez amenÃ© Ã  analyser, Ã  proposer et Ã  mettre en oeuvre une architecture et des solutions adaptÃ©es aux diffÃ©rents besoins des projets de recherche et vous participerez Ã©galement Ã  la mise en place dâ€™un certain nombre dâ€™outils de base (visualisation, annotation, etc.) pour faciliter lâ€™exploitation et lâ€™enrichissement des donnÃ©es physiologiques par les utilisateurs de la plateforme.
En tant que data engineer spÃ©cialisÃ© en traitement du signal et idÃ©alement en systÃ¨mes biomÃ©dicaux, vous :
RÃ©aliserez la dÃ©finition des besoins et lâ€™accompagnement des mÃ©decins pour la rÃ©alisation dâ€™un projet de recherche
Analyserez les diffÃ©rents Ã©quipements biomÃ©dicaux, signaux et protocoles de communication
DÃ©velopperez, industrialiserez et maintiendrez les flux dâ€™intÃ©gration des signaux physiologiques pour permettre leur collecte au sein de la plateforme big data
Contribuerez Ã  lâ€™utilisation de ces nouvelles typologies de donnÃ©es (extraction, sÃ©lection, collecte et intÃ©gration) via des connecteurs spÃ©cifiques dÃ©veloppÃ©s en java, python ou dâ€™autres langages
Industrialiserez le code de gÃ©nÃ©ration du flux de donnÃ©es et assurer sa performance globale
Aiderez Ã  lâ€™implÃ©mentation de standards et normes de mise Ã  disposition des donnÃ©es
Mettrez en place des outils permettant lâ€™enrichissement des donnÃ©es (analyse, annotation, etc)
Travaillerez en collaboration avec des partenaires industriels dans le cadre des diffÃ©rents projets de recherche
Voir moins","Profil recherchÃ©
IdÃ©alement, vous..
Avez un diplÃ´me dâ€™ingÃ©nieur ou Ã©quivalent (bac+4/5, master2) en informatique ou sciences avec formation complÃ©mentaire en informatique
Avez une expÃ©rience de dÃ©veloppement sous Linux, des langagage Java et/ou Python et des outils EAI (Mirth, â€¦) et ETL (Talend ou autre)
Avez une expÃ©rience dans la manipulation de donnÃ©es avec le langage SQL
Connaissez les standards en informatique de santÃ© (HL7 v2, DICOM, HL7-FHIR, OMOP, â€¦)
Avez le goÃ»t de lâ€™intÃ©gration de systÃ¨mes informatiques hÃ©tÃ©rogÃ¨nes
Avez des connaissances des bonnes pratiques de sÃ©curitÃ© informatique et de la rÃ©glementation informatique et libertÃ©s
AdhÃ©rez aux valeurs du service public et vous avez un intÃ©rÃªt prononcÃ© pour le domaine de la santÃ©
Avez un niveau dâ€™anglais courant
Vous avez un savoir faire dans un de ces domaines :
Bonne maitrise du langage Python et de bash
Voir plus"
Data Engineer,"{'name': 'PICTARINE', 'sector': 'Application mobile, Logiciels, E-commerce', 'employees': '50 collaborateurs', 'creation_year': '2009', 'turnover': '14M$', 'mean_age': '32 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,> 3 ans,,"Descriptif du poste
Mission and challenges ğŸ¯
Si tu es enthousiaste Ã  embarquer dans la nouvelle Ã©quipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors câ€™est lâ€™aventure quâ€™il te faut! ğŸ”ï¸
Avec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les Ã©quipes de Pictarine ne sont jamais Ã  court dâ€™idÃ©es pour explorer de nouveaux horizons. ğŸš€
En tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toute ta crÃ©ativitÃ© pour garantir la qualitÃ© de la data, accompagner et challenger les besoins data.
Tu Ã©volueras au sein de lâ€™Ã©quipe Engineering, composÃ©e des pÃ´les dev & data. Tu rejoindras une Ã©quipe data dÃ©jÃ  composÃ©e dâ€™une data analyste, Romane, et de la data manager, Marie !
Ton rÃ´le comprendra les aspects suivants ğŸ‘‡ğŸ»
Tu es garant de la qualitÃ© de la data !
En simplifiant la structure de la data et rÃ©duisant le nombre de tables
En transformant les donnÃ©es pour les rendre facilement utilisables
En orchestrant le flux des donnÃ©es de maniÃ¨re continue et automatique
Tu accompagnes et challenges les Ã©quipes de Pictarine !
En co-construisant des solutions data appropriÃ©es
En Ã©levant le niveau de jeu des mÃ©thodes data existantes
En faisant rayonner la data autour de bonnes pratiques et dâ€™outillages adÃ©quates
Voir moins","Profil recherchÃ©
About you ğŸ’
Tu as au moins 3 ans dâ€™expÃ©rience sur un poste similaire
Tu as de bonnes connaissances dans la transformation des donnÃ©es (ETL), la conception de modÃ¨les de donnÃ©es et les stratÃ©gies dâ€™optimisation des requÃªtes
Tu as des compÃ©tences en DevOps pour le dÃ©ploiement et la gestion efficace des pipelines de donnÃ©es
Tu as une bonne maÃ®trise de Python, SQL & Github
Tu maÃ®trises lâ€™un des data warehouse suivants : BigQuery, Refshift, Snowflake, Synapse Analytics
Tu as une passion pour rÃ©soudre des problÃ¨mes business avec la programmation
Tu es curieux de tester des nouvelles technologies
Tu es organisÃ©, rigoureux et portes une grande attention aux dÃ©tails
Tu es dotÃ© dâ€™excellentes qualitÃ©s relationnelles, de communication et de vulgarisation
Tu es un team player et toujours Ã  lâ€™affÃ»t de nouvelles idÃ©es
Work @ Pictarineâœ¨
Un environnement de travail agile, collaboratif, international et multiculturel
Voir plus"
Data engineer intern,"{'name': 'EQUATIV', 'sector': 'AdTech / MarTech', 'employees': '600 collaborateurs', 'creation_year': '2001', 'turnover': None, 'mean_age': '33 ans'}",Stage,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,Bac +5 / Master,"Descriptif du poste
ğŸ‘« About the team
At Equativ, weâ€™re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.
Our innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.
At Equativ, weâ€™re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 100 billions requests per day and above 40 Gbps of network traffic. 
Our data engineering team is composed of 8 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 120+ engineers spread across Paris, Nantes, Limoges, Krakow and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.
The data engineers are split in two sub-teams working in close collaboration:
Pipeline team: Maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIs.
Feature team: Apply best in class data modeling and orchestrating data transformations in our warehouses, leading the day-to-day management of these warehouses.
Our Mission
Our Data Engineering team is central to Equativâ€™s data centric business and is responsible to ingest, transform, model and redistribute all data coming from our ad tech platform.
We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle huge volumes (15 Tb per day), short & long term data storage, complex data modeling, real-time and batch ELT as well as providing external access through dedicated APIs.
We enhance and deliver Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science models feeding, customer reporting, invoicing and more.
We rely on a top tier on-premise & cloud stack (Kafka, Flink, ClickHouse, Bigquery, Dataflow, Airflow, DBTâ€¦) and work hard to increase reporting capabilities, lower maintenance time, improve performances and simplify the access to our raw data.
What you will do
As a data engineer intern, you will be supporting one of the two sub-team (pipeline or feature) in their tasks and projects:
Take a leading part on a data engineering project such as but not limited to:
Proof of Concept of Clickhouse Cloud
Improvement of the data transformation process with DBT, BigQuery and Airflow
Development of new functionalities on our internal tools (APIs, software applications)
Setup a data lineage application (castor doc) 
Support the data engineering team in their day-to-day activities
Enhance our DevOps process with CI/CD and testing framework.
Monitor performances and workflow of our applications using reporting tool (Grafana)
Take part in improving and deploying data engineering standards, documentation and operational guidelines around data usage at Equativ
About you
Master degree in Computer Science or similar technical field of study.
Prior experience in data or software development related environment is desired.
Experience with a cloud datawarehouse (BigQuery, Snowflake, Databrick,..) is a plus.
Good knowledge of SQL and one other data programming language (Java preferred, Python, Scala..). 
Knowledge on the software development process (Git, CI/CD, test, scrum)
Working proficiency and communication skills in verbal and written English
Strong interest in big data and cloud computing technologies. 
ğŸ‘‹ About us 
Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus â€” four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.
Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.
The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Timesâ€™ FT 1000: Europeâ€™s Fastest-Growing Companies.
Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.
Come and lead the charge with us in building a transparent ecosystem based on quality!
----------------------
Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com
Voir moins",
Data Engineer,"{'name': 'NIELSENIQ GROUP INCL DATA IMPACT AND GFK', 'sector': 'Big Data, E-commerce', 'employees': '40000 collaborateurs', 'creation_year': '1923', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Weâ€™re looking for an experienced Data Engineer to join our growing Machine Learning team.Your work will entail the following :
Creating data flows
Working on data versioning
Launching flows in orchestration tools
Improve CI/CD pipelines
Dependencies management (poetry)
Deploying scripts/models created by data scientists on Notebooks
Contrat : CDI
Localisation : Paris 10e
#LI-DAIM
About NIQ
NIQ is the worldâ€™s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insightsâ€”delivered with advanced analytics through state-of-the-art platformsâ€”NIQ delivers the Full Viewâ„¢.
NIQ, is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the worldâ€™s population. For more information, visit NIQ.com.
Want to keep up with our latest updates?
Follow us on: LinkedIn | Instagram | Twitter | Facebook
  Our commitment to Diversity, Equity, and Inclusion
NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us.
We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide.
Learn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion/
NIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process.
Voir moins","Profil recherchÃ©
1-2 years of experience
Proficiency with Python
Experience with distributed systems to manipulate big data (Dask, Spark)
Experience with ML datasets is a plus
Experience creating ETL pipelines
Experience working with GCP (Google Cloud Platform) on main data services (cloud storage, bigquery, cloud build, GKE..)
Experience using orchestrators (airflow, dagster...)
Work environment (Linux, Jupyter, Python, Git, Docker, SQL, NoSQL, ...)
Significant experience with Pandas, SQL technologies and writing Dockerfiles
Professional level of French and English"
Senior Data Engineer (H/F),"{'name': 'STUDI - DIGITAL EDUCATION FOR LIFE', 'sector': 'Education, EdTech, Formation', 'employees': '1000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,PÃ©rols,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Avec plus de 1000 collaborateurs, Studi est LA grande Ã©cole en ligne franÃ§aise, acteur incontournable de lâ€™edtech et leader sur son marchÃ© de la formation en ligne et lâ€™alternance.
Filiale Edtech de Galileo Global Education - NÂ°1 groupe mondial de lâ€™enseignement supÃ©rieur privÃ© - Studi propose plus de 200 formations reconnues par lâ€™Ã‰tat du niveau CAP au BAC+5 et forme plus de 70 000 apprenants chaque jour. 
Pour y parvenir, Studi accÃ©lÃ¨re son dÃ©veloppement en France et Ã  lâ€™international ğŸŒ, et souhaite renforcer ses effectifs.
Nous recrutons continuellement de nouveaux talents passionnÃ©s qui souhaitent grandir et prendre part Ã  une belle aventure.
Join us ! ğŸ˜
 Vos missions
Sous la responsabilitÃ© du Head of Data, le Senior Data Engineer est chargÃ© de collecter, transformer et activer la data afin dâ€™accompagner la prise de dÃ©cision. Il est chargÃ© de la conception de solutions robustes, permettant le traitement de volumes importants de pipelines donnÃ©es. Par ailleurs, les solutions choisies doivent Ãªtre suffisamment sÃ©curisÃ©es et lisibles pour les Data Analysts et Data Scientists qui seront les premiers consommateurs de ces donnÃ©es stockÃ©es, nÃ©cessaires aux besoins opÃ©rationnels et dÃ©cisionnels de lâ€™entreprise.
Vous concevez, dÃ©veloppez et maintenez des pipelines de donnÃ©es robustes, Ã©volutifs et fiables pour le recueil, le traitement et la distribution des donnÃ©es. 
Vous assurez la qualitÃ© des donnÃ©es en mettant en place des processus de nettoyage, de transformation et de validation et mettez en Å“uvre des solutions de stockage adaptÃ©es et performantes. 
Vous optimisez les performances des requÃªtes et des processus liÃ©s aux donnÃ©es pour garantir une rÃ©ponse rapide aux besoins des Data Analysts. 
Vous participez Ã  la documentation des architectures, des processus et des flux de donnÃ©es et collaborez avec les Ã©quipes de sÃ©curitÃ© afin d'en garantir la confidentialitÃ© et leur conformitÃ©. 
Vous disposez d'une expÃ©rience significative en ingÃ©nierie des donnÃ©es et une solide connaissance des technologies ETC (Extract, Transform, Load).
Vous maitrisez les langages de programmation tels que Python ou autre. 
Vous avez des compÃ©tences avancÃ©es en SQLet une connaissance approfondie des concepts e modÃ©lisation de donnÃ©es et de normalisation. 
Vous avez une expÃ©rience en dans la conception et la mise en Å“uvre d'architectures de donnÃ©es distribuÃ©es. 
Vous Ãªtes force de proposition, rigoureux et disposez d'un esprit analytique et de synthÃ¨se. 
Vous aves l'esprit d'Ã©quipe et un excellent relationnel. 
Vous avez le sens de l'organisation et de la qualitÃ©. 
AUDACE : Try it! Shake it! Chez Studi nous sommes curieux, nous proposons de nouvelles solutions et sortons de notre zone de confort.
ENERGIE: Go for it! Do It! Nous donnons le meilleur de nous-mÃªme pour avancer.
SOLIDARITE: Share it! Nous favorisons la collaboration, l'entraide et la bienveillance.
RESPONSABILITE:Own it! Nous assumons une mission qui a du sens : moderniser et dÃ©mocratiser lâ€™Ã©ducation. 
Vous vous reconnaissez ?
Nous sommes impatient(e)s de vous rencontrer !
 Et puis Studi c'est aussi...
De superbes nouveaux locaux de 10 000m2
Une carte tickets restaurant SWILE
Une prime dâ€™intÃ©ressement et participation
Des jours de congÃ© conventionnels
Un CE
Une charte de 2 jours de TÃ©lÃ©travail par semaine
Une mutuelle et une prÃ©voyance dâ€™entreprise
Petit plus, vous pouvez bÃ©nÃ©ficier au cours de votre carriÃ¨re de contenus de formation Studi!
 Adressez-nous votre candidature !
 Type de contrat : CDI
Lieu : Montpellier (34 000)
Cette opportunitÃ© est ouverte aux personnes en situation de handicap.
STUDI_SJ+
Voir moins",
Alternance - Cloud Data Engineer (H/F),"{'name': 'EPSILON FRANCE', 'sector': 'Digital Marketing / Data Marketing, Big Data, AdTech / MarTech', 'employees': '600 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '38 ans'}",Alternance,Wasquehal,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 6 mois,,"Descriptif du poste
Lâ€™ambition du PÃ´le Data Management est d'offrir la meilleure expÃ©rience Ã  nos clients grÃ¢ce Ã  des solutions data-driven et cloud.
Nous les accompagnons sur des projets innovants et la crÃ©ation de modÃ¨les s'appuyant sur les nouvelles technologies.
 En tant que Cloud Data Engineer Azure et/ou Google voici vos missions : 
Contribuer Ã  la rÃ©alisation de projets Data Client, Data Lake, Data services dans un contexte de plus en plus DevOps et Agile,
Assurer la veille technologique sur les composants dâ€™une plateforme Data,  Datalake, Cloud,
RÃ©diger des documents projets (design, rÃ©alisation, dÃ©ploiement, â€¦),
GÃ©rer lâ€™Ã©volution des solutions proposÃ©es, et possiblement en assurer la TMA,
Participer aux initiatives projets et Ã  lâ€™Ã©volution de nos assets data internes.
C'est un travail passionnant et enrichissant pour nos collaborateurs qui sont amenÃ©s Ã  collaborer avec le marketing, le digital et la crÃ©ation.","Profil recherchÃ©
Vous avez une premiÃ¨re expÃ©rience sur des projets data en environnement cloud (GCP, Azure), ou une connaissance des DWH (sur technologie traditionnelle et/ou cloud), voire du DataOps.
Vous souhaitez Ã©voluer sur les technologies Big Data Hadoop/HDFS, Hive, Python et le requÃªtage de donnÃ©es (Impala, Hive, ...).
Votre expÃ©rience dans le traitement de la data, sa valorisation et sa production est un atout considÃ©rable. 
Une connaissance dâ€™un ETL (Stambia, Talendâ€¦) est un plus.
 Localisation : Campus 5.9 (Wasquehal)
RÃ©munÃ©ration : Nous savons que le salaire est un Ã©lÃ©ment essentiel pour vous ! Câ€™est pourquoi nous en parlerons sans tabou dÃ¨s les premiers Ã©changes.
Les + EPSILON France :
AccÃ¨s au Restaurant d'entreprise 
Travail Hybride grÃ¢ce Ã  notre Accord TÃ©lÃ©travail qui autorise jusquâ€™Ã  2 jours par semaine
EngagÃ© avec le Forfait MobilitÃ© Durable
Voir plus"
Data Engineer confirmÃ© - Banque - Lille,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Villeneuve-d'Ascq,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail :
Au sein dâ€™une Data Factory, vous Ãªtes pleinement impliquÃ©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi Ã  leur succÃ¨s.
Vous avez l'occasion de dÃ©velopper vos compÃ©tences techniques et fonctionnelles de maniÃ¨re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.
C'est tentant non ? Alors embarquez pour une nouvelle aventure professionnelle !
 Vos missions :
RattachÃ©(e) Ã  la division  Â« Banque Â», vous Ã©voluez dans un environnement challengeant et convivial, entourÃ©(e) de passionnÃ©s dotÃ©s d'expertises dans leurs domaines.
En tant que Data Engineer, vous Ã©voluez sur des projets IT Ã  forte valeur ajoutÃ©e et avez pour rÃ´le la mise en place de pipelines de donnÃ©es fiables, sÃ©curisÃ©s et Ã  lâ€™Ã©chelle pour soutenir la mise Ã  disposition des donnÃ©es aux cas dâ€™usage mÃ©tier qui en ont besoin.
Vos activitÃ©s principales sont les suivantes :
Vous travaillez avec le client pour Ã©valuer, concevoir, dÃ©ployer, amÃ©liorer et maintenir les pipelines de donnÃ©es 
Vous vous assurez que les pipelines de donnÃ©es crÃ©Ã©s sont rÃ©silients, sÃ©curisÃ©s et accessibles 
Vous dÃ©finissez le modÃ¨le opÃ©rationnel pour monitorer et supporter les pipelines de donnÃ©es 
Vous fournissez une expertise Ã  nos clients sur leurs donnÃ©es pour assurer leur optimisation et leur sÃ©curitÃ© par rapport Ã  leurs besoins 
Vous apportez un savoir en gestion de la qualitÃ© et la gouvernance de la donnÃ©e pour assurer le suivi de la conformitÃ© Ã  la gouvernance de la donnÃ©e 
Vous faites de la veille technologique dans le domaine afin dâ€™enrichir les roadmaps technologiques et fournir des solutions modernes Ã  nos clients.
  En parallÃ¨le de votre mission, vous pouvez Ã©galement intervenir sur des sujets transverses, tels que devenir formateur sur les sujets qui vous animent ou encore participer Ã  des challenges autour de l'innovation et du digital par le biais de notre communautÃ© d'experts. Vous pourrez prendre part Ã  l'accompagnement de vos collÃ¨gues dans leur montÃ©e en compÃ©tences ou encore partagez vos expertises pour enrichir nos savoir-faire.
EpaulÃ©(e) par votre manager projet et votre mentor (que vous avez choisi), vous construisez votre carriÃ¨re de maniÃ¨re active : vous pouvez par exemple vous former via notre Academy interne, ou encore Ã©voluer professionnellement par des mises en situation sur le terrain.
 Ce que nous vous proposons :
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressants : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor. Des opportunitÃ©s de carriÃ¨res multiples : plus de 50 mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â». - L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encore).
Informations supplÃ©mentaires
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
> 
Voir moins","Profil recherchÃ©
Votre profil :
DiplÃ´mÃ©(e) d'une formation supÃ©rieur en informatique type Bac + 5 (Ã©cole ingÃ©nieur, universitÃ© ou Ã©quivalent), vous avez dÃ©jÃ  acquis une expÃ©rience significative en data engineer.
Vous avez au moins l'une de ces compÃ©tences requises :
MaÃ®trise des technologies de bases de donnÃ©es Relationnelles et NoSQL
MaÃ®trise dâ€™au moins un outil dâ€™ETL/ELT (Semarchy, Informatica, Datastage, etc.)
MaÃ®trise des technologies de traitement distribuÃ© de donnÃ©es (Spark, Hadoop)
MaÃ®trise dâ€™au moins un framework de streaming de donnÃ©es (Kafka, RabbitMQ, etc.)
MaÃ®trise de chaines CI/CD et de des bonnes pratiques de DataOps
MaÃ®trise de solution de Virutualisation de donnÃ©es (Denodo, Dremio, etc.)
MaÃ®trise dâ€™au moins un environnement cloud public ou privÃ© (Azure, AWS, Outscale, etc.)
 Vous avez dÃ©veloppÃ© de solides compÃ©tences en matiÃ¨re d'autonomie, d'adaptabilitÃ© et de communication."
Data Engineer H/F/X,"{'name': 'ELEVEN LABS', 'sector': 'Logiciels, IT / Digital, Audit', 'employees': '100 collaborateurs', 'creation_year': '2011', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,,"Descriptif du poste
Seras-tu notre furtur.e Data Engineer !
Un peu de contexte
â˜ï¸ De plus en plus de nos consultants sâ€™intÃ©ressent de prÃ¨s au sujet de la Data, ce qui nous a poussÃ© Ã  explorer ces problÃ©matiques chez nos clients et de constater un besoin fort dâ€™accompagnement de leur part.
Nous recherchons donc la personne qui ouvrira la voie Ã  cette expertise chez Eleven Labs et qui accompagnera la crÃ©ation de lâ€™escouade Data !","Profil recherchÃ©
Nos attentes
ğŸ§  Nous recherchons quelquâ€™un dâ€™expÃ©rimentÃ©/e dans la mise en place de pipeline ETL/ELT et data lake / data hub, capable de rÃ©pondre au mieux aux problÃ©matiques qui lui seront soumises, pour qui les requÃªtes SQL, NoSQL sur BDD nâ€™ont aucun secret, et qui maÃ®trise dÃ©jÃ  une ou plusieurs solutions de Data Warehouse (de type BigQuery ou SnowFlake).
ğŸ’ Cerise sur le gÃ¢teau : on cherche aussi un profil maÃ®trisant les langages type Python, Java ou Scala pour customiser les steps, avec bien entendu des connaissances solides sur des outils comme Spark, Jupyter ou encore Cloud Run comme outils de calcul distribuÃ©. Des connaissances dans lâ€™utilisation dâ€™outils ML et dâ€™environnement Cloud en gÃ©nÃ©ral sont un vrai plus.
ğŸ­ CÃ´tÃ© personnalitÃ©, et outre cet aspect expÃ©rimentÃ© et â€œouvreur de voieâ€, on cherche quelquâ€™un de moteur, avec un rÃ©el enthousiasme Ã  transmettre ses connaissances, former et Ã©changer.
Les missions
ğŸ•µï¸ Les missions proposÃ©es te feront intervenir dans des secteurs divers, avec des cas dâ€™usage variÃ©s souvent en lien avec le marketing et impliqueront principalement :
dâ€™Ãªtre force de proposition quant au choix des outils et pratiques ;
Voir plus"
STAGE / ALTERNANCE - Data Engineer @ Startup Juno,"{'name': 'OSS VENTURES', 'sector': 'SaaS / Cloud Services', 'employees': '20 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '32 ans'}","Stage
(4 Ã  12 mois)",Paris,"1,3K â‚¬ par mois",TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
Mission et objectifs
En tant que data engineer, tu seras responsable de la conception, du dÃ©veloppement, de la mise en Å“uvre de stream dâ€™intÃ©gration et de transformation de donnÃ©es (ETL) et de crÃ©ation de dashboard analytics
Nous voulons faire de ton stage une vraie rÃ©ussite, que tu puisses Ã  la fois tâ€™Ã©panouir et devenir un rÃ©el pilier dans notre organisation, lâ€™objectif est de te proposer un CDI Ã  lâ€™issue de ton stage.
Tes missions
Travailler en Ã©troite collaboration avec les dÃ©veloppeurs et les Operations managers pour identifier les problÃ¨mes Ã  rÃ©soudre et concevoir des solutions de data engineering appropriÃ©.
Conception et mise en Å“uvre de pipelines de donnÃ©es robustes pour lâ€™extraction, la transformation et lâ€™ingestion des donnÃ©es (ETL).
DÃ©veloppement de solutions de stockage de donnÃ©es optimisÃ©es pour garantir lâ€™intÃ©gritÃ© et lâ€™accessibilitÃ© des donnÃ©es.
Collaboration Ã©troite avec les Ã©quipe pour dÃ©velopper des stratÃ©gies de visualisation des donnÃ©es qui traduisent les donnÃ©es complexes en insights actionnables.
Assurer la qualitÃ© et la cohÃ©rence des donnÃ©es Ã  travers des tests rigoureux et un suivi continu.
Suivre les derniÃ¨res tendances et technologies en matiÃ¨re de data engineering
Voir moins","Profil recherchÃ©
DiplÃ´me en informatique, en mathÃ©matiques, en statistiques ou dans un domaine connexe.
Tu es polyvalent(e), crÃ©atif(ve) et autonome, avec une bonne capacitÃ© dâ€™adaptation
MaÃ®trise poussÃ©e du SQL exigÃ©e (Postgres, MySql oÃ¹ autre)
MaÃ®trise dâ€™un des langages de programmation tels que Python, NodeJs, etc.
ExpÃ©rience en intÃ©gration de donnÃ©es pour les bases de donnÃ©es relationnelles et non relationnelles avec des ETLs
CapacitÃ© Ã  travailler en Ã©quipe, Ã  communiquer efficacement et Ã  gÃ©rer plusieurs tÃ¢ches simultanÃ©ment.
Tu es passionnÃ©(e) par les nouvelles technologies et/ou par lâ€™industrie"
Stagiaire / Intern Data Engineer,"{'name': 'QUANTCUBE TECHNOLOGY', 'sector': 'Intelligence artificielle / Machine Learning, FinTech / InsurTech, Big Data', 'employees': '55 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '28 ans'}","Stage
(6 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,< 6 mois,Bac +5 / Master,"Descriptif du poste
At the forefront of AI innovation and investment strategies, weâ€™re a leading company on the lookout for a passionate Junior Data Engineer to join our dynamic and rapidly expanding quantitative team. Our mission revolves around setting up cutting-edge technology, fortified infrastructure, and ingenious quantitative methodologies to drive our business and sustain a competitive advantage in the market.
Your primary responsibility will manage the freshly installed infrastructure and systems that lie at the heart of our quant desk. Picture yourself in charge of architecting ingenious trading systems, managing our databases, and maintaining seamless communication with our full-stack developers to continuously enhance and elevate our existing dashboards.
Missions:
You will be a pivotal and essential member of our team. Your assignments will immerse you in the heart of our current projects, providing you with unparalleled opportunities for growth and impact. Your daily tasks will include:
Pioneering the development, rigorous testing, and deployment of quantitative trading systems, databases, and other mission-critical software.
Playing a pivotal role in the architectural decision-making process, architecting scalable solutions to the most intricate challenges that come our way.
Coordinating role between the Quant team and the IT team (full-stack developers and DevOps engineers), ensuring the meticulous management and real-time monitoring of our trading desk dashboard.
Maintaining the pulse of our database, meticulously safeguarding its performance, availability, scalability, and security to ensure it runs like clockwork.
What we offer
At the heart of these assignments lies the opportunity to drive innovation forward in the world of AI and finance. You will have the opportunity to take part to challenging and valuable projects, to communicate directly with our IT, Product and Data Science teams, at the forefront of AI forâ€¯economics and finance.
Youâ€™ll also be joining a multicultural, warm and close-knit team that loves to organise events and activities after work.
A la pointe de lâ€™innovation en matiÃ¨re dâ€™IA et de stratÃ©gies dâ€™investissement, nous sommes une entreprise de premier plan Ã  la recherche dâ€™un ingÃ©nieur de donnÃ©es passionnÃ© pour rejoindre notre Ã©quipe dynamique dâ€™analyst quantitatifs et en pleine expansion. Notre mission consiste Ã  mettre en place une technologie de pointe, une infrastructure fortifiÃ©e et des mÃ©thodologies quantitatives ingÃ©nieuses pour stimuler notre activitÃ© et maintenir un avantage concurrentiel sur le marchÃ©.
Votre principale responsabilitÃ© sera de gÃ©rer lâ€™infrastructure nouvellement mise en place et les systÃ¨mes qui sont au cÅ“ur de notre desk quantitatif. Vous vous imaginez en charge de lâ€™architecture de systÃ¨mes de trading ingÃ©nieux, de la gestion de nos bases de donnÃ©es et du maintien dâ€™une communication transparente avec nos dÃ©veloppeurs full-stack afin dâ€™amÃ©liorer et de rehausser continuellement nos tableaux de bord existants.
Missions :
Vous serez un membre essentiel de notre Ã©quipe. Vos missions vous plongeront au cÅ“ur de nos projets actuels, vous offrant des opportunitÃ©s de croissance et dâ€™impact inÃ©galÃ©es. Vos tÃ¢ches quotidiennes consisteront notamment Ã 
ÃŠtre pionnier dans le dÃ©veloppement, les tests rigoureux et le dÃ©ploiement de systÃ¨mes de nÃ©gociation quantitative, de bases de donnÃ©es et dâ€™autres logiciels critiques.
Jouer un rÃ´le central dans le processus de prise de dÃ©cision en matiÃ¨re dâ€™architecture, en Ã©laborant des solutions Ã©volutives pour relever les dÃ©fis les plus complexes qui se prÃ©sentent Ã  nous.
RÃ´le de coordination entre lâ€™Ã©quipe Quant et lâ€™Ã©quipe IT (dÃ©veloppeurs Full-Stack et ingÃ©nieurs DevOps), assurant la gestion mÃ©ticuleuse et le suivi en temps rÃ©el du tableau de bord de notre trading desk.
Prendre le pouls de notre base de donnÃ©es, en protÃ©geant mÃ©ticuleusement ses performances, sa disponibilitÃ©, son Ã©volutivitÃ© et sa sÃ©curitÃ© afin de sâ€™assurer quâ€™elle fonctionne comme une horloge.
Ce que nous proposons
Au cÅ“ur de ces missions se trouve lâ€™opportunitÃ© de faire avancer lâ€™innovation dans le monde de lâ€™IA et de la finance. Vous aurez lâ€™occasion de participer Ã  des projets stimulants et utiles, de communiquer directement avec nos Ã©quipes IT, Produit et Data Science, Ã  la pointe de lâ€™IA pour lâ€™Ã©conomie et la finance.
Vous rejoindrez Ã©galement une Ã©quipe multiculturelle, chaleureuse et soudÃ©e qui aime organiser des Ã©vÃ©nements et des activitÃ©s aprÃ¨s le travail.
Voir moins","Profil recherchÃ©
Degree in Computer Science, Engineering, Mathematics, or a related quantitative discipline
Knowledge of python packages (requests, beautiful soup, selenium) and SQL database management systems
Strong knowledge of data structures, algorithms, and object-oriented programming
Proficiency in UNIX commands and Linux development
Good development practices: version control, testing
What is a plus :
First experience in Quantitative trading environment
Interest in Finance, trading systems and relevant technology
Strong problem-solving abilities, with an analytical mind and a keen attention to detail
Excellent written and verbal communication skills
QuantCube recruits and recognises all talents.
DiplÃ´me en informatique, ingÃ©nierie, mathÃ©matiques ou dans une discipline quantitative similaire
Connaissance des paquets Python (requests, beautiful soup, selenium) et des systÃ¨mes de gestion de bases de donnÃ©es SQL
Voir plus"
Senior Data Engineer H/F,"{'name': 'QANTEV', 'sector': 'Intelligence artificielle / Machine Learning, FinTech / InsurTech, SaaS / Cloud Services', 'employees': '46 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '29 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
What you will be doing
As a member of the data science and engineering team, alongside our technical experts, you will be able to:
Improve our OCR pipeline deployed on insurance claims data.
Work on our NLP pipelines for medical coding inference and sentiment analysis on hospital reviews.
Enhance our fraud detection machine learning models.
Scale our proprietary patient journey optimizer based on state-of-the-art optimal transport.
Implement and optimize the associated algorithms.
Integrate your contribution in our python/postgresql/elasticsearch stack.
Develop test framework for the models.
Think about the best ways to deploy our machine learning models at scale.
Continuously provide ideas to improve the solution.","Profil recherchÃ©
Preferred Experience
What you need to succeed
3+ years of experience in the field of data engineering and machine learning.
Advanced technical skills in Applied Mathematics, preferably in machine learning,
probabilistic modeling, computer sciences, statistics and/or operations research
Strong analysis and synthesis abilities, not afraid to deal with details.
Proficient knowledge of Python and Deep Learning Frameworks.
Ability to read, understand and implement research papers.
Able to write quality production code and provide coding review to improve the skills of the team.
Fluent in English.
Bonus skills
Working on production-grade projects with good software engineering insights.
Previous experience working within an agile framework.
Previous startup or health insurance experience.
Fluency in a language other than English or French.
Voir plus"
Data Engineer,"{'name': 'THE PRODUCT CREW', 'sector': 'Recrutement', 'employees': '10 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,,
Data Engineer GCP Senior (F/H),"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, CybersÃ©curitÃ©', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232Mâ‚¬', 'mean_age': None}",CDI,La DÃ©fense,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
ğŸ’¥ DÃ©couvrez la Vie Apsidienne ğŸ“¹ et vous aussi, devenez Apsidien
On aurait pu demander Ã  Chat GPT de vous dÃ©montrer en quoi Apside est lâ€™ESN quâ€™il vous faut, mais on prÃ©fÃ¨re que vous le dÃ©couvriez vous-mÃªmes ğŸ‘‡ğŸ˜
ğŸ”¥ DÃ©couvrez votre future mission
ğŸ‘‰ Contexte
Rejoignez notre Practise Cloud/Data, afin dâ€™intervenir sur des sujets Ã  haute valeur ajoutÃ©e !
Secteur â€¯: TÃ©lÃ©com
MÃ©thode de travailâ€¯: Agile Safe
Notre client a besoin dâ€™un accompagnement sur leurs projets mÃ©tiers Data/IA accostant sur un cloud public et Ã  la construction d'outils pour accÃ©lÃ©rer et faciliter cet accostage.
Cela sera rÃ©alisÃ© dans un environnement GCP et en grande majoritÃ© sur des technologies innovantes pour des services Data & IA. La mission sera partagÃ© entre le ""build"" des cas d'usage et outils, et le ""run"" de ces derniers.
ğŸ˜ Mission
Etude et dÃ©finition des architectures GCP, ainsi que leur implÃ©mentation
Mise en application des exigences opÃ©rationnelles (sÃ©curitÃ©, exploitabilitÃ© et industrialisation)
Aiguillage sur nos outils transverse et prÃ©conisations Ã  l'usage du cloud public
Construction d'outillages facilitant l'accostage de ces des projets mÃ©tiers DATA-IA
â€¦
Environnement techniqueâ€¯:
GCP
Git
Gitlab
Bash
Docker
Kubernetes
GitlabCI
ğŸ’° Le package salarial que nous vous proposons
Contratâ€¯: CDI
Avantages groupeâ€¯: carte ticket restaurant Swile, prime de mobilitÃ©, RTT, accord tÃ©lÃ©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle Ã  100% etcâ€¦
Avantages agenceâ€¯: intÃ©gration de la Practise Cloud/Data, afterworks, communautÃ© techlead...
Formationâ€¯: certifications techniques, cours particuliers dâ€™anglais en interne, accÃ¨s Ã  un catalogue de formations grÃ¢ce Ã  notre plateforme e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherchÃ©
ğŸ”® Ã” vous futur Apsidien, qui Ãªtes-vousâ€¯?
Au moins 5 ans d'expÃ©rience en tant que Data Engineer
Maitrise de lâ€™environnement cloud GCP
Force de proposition, bon relationnel et autonome
ğŸ˜ Apside a suscitÃ© votre curiositÃ©â€¯?
Dans un environnement marquÃ© par une accÃ©lÃ©ration des Ã©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients Ã  crÃ©er de la valeur et Ã  adresser leurs enjeux stratÃ©giques en leur mettant Ã  disposition des expertises technologiques (Data / IA, Cloud, Cyber) et une expÃ©rience sectorielle (Industrie, Banque, Assurance, Service, Secteur Public). Pour un accompagnement global, le groupe propose des offres transverses autour du Handicap (Apsidâ€™EA), du Digital Learning, et du Conseil.
ğŸ¤” Et votre place dans tout Ã§aâ€¯?
ğŸ‘‰ Notre volontÃ© est de vous accompagner dans la construction et lâ€™Ã©panouissement de votre carriÃ¨re en nous appuyant notamment sur 3 piliers :
Une rÃ©munÃ©ration Ã  hauteur de vos investissements et de vos compÃ©tences
Voir plus"
Data Engineer AWS Senior (F/H),"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, CybersÃ©curitÃ©', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232Mâ‚¬', 'mean_age': None}",CDI,La DÃ©fense,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
ğŸ’¥ DÃ©couvrez la Vie Apsidienne ğŸ“¹ et vous aussi, devenez Apsidien
On aurait pu demander Ã  Chat GPT de vous dÃ©montrer en quoi Apside est lâ€™ESN quâ€™il vous faut, mais on prÃ©fÃ¨re que vous le dÃ©couvriez vous-mÃªmes ğŸ‘‡ğŸ˜
ğŸ”¥ DÃ©couvrez votre future mission
ğŸ‘‰ Contexte
Rejoignez notre Practise Cloud/Data, afin dâ€™intervenir sur des sujets Ã  haute valeur ajoutÃ©e !
Dans le cadre du renforcement de leur Ã©quipe data, notre client recherche un data ingÃ©nieur qui sera amenÃ© Ã  travailler sur la mise en oeuvre de plusieurs produits data visant Ã  l'exposition et la mise en qualitÃ© des donnÃ©es de rÃ©fÃ©rences.
L'environnement de travail est sur le cloud AWS avec terraform en infra as code
Secteur â€¯: culture/mÃ©dia
MÃ©thode de travailâ€¯: Agile / Scrum
ğŸ˜ Mission
Ingestion et traitement des sources de donnÃ©es
PrÃ©paration des donnÃ©es (transformation fonctionnelle et technique)
Elaboration de systÃ¨me avancÃ© de gestion de qualitÃ© de donnÃ©es
Elaboration d'API/workflow
Exposition des donnÃ©es (Elasticsearch, RDS) via des API pour les applications front
PrÃ©paration des package de livraison en Infra as code
Gestion du cycle de livraison en production
MCO
RÃ©daction des documentations techniques
â€¦
Environnement techniqueâ€¯:
AWS (lambda, EMR, APIGateway, cognito ...)
Python
TerraForm
Git CI/CD
Elasticsearch
PySpark
JSON
SQL (PostgreSQL)
ğŸ“ Localisation
     La DÃ©fense
ğŸ’° Le package salarial que nous vous proposons
Contratâ€¯: CDI
Avantages groupeâ€¯: carte ticket restaurant Swile, prime de mobilitÃ©, RTT, accord tÃ©lÃ©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle Ã  100% etcâ€¦
Avantages agenceâ€¯: intÃ©gration de la Practise Cloud/Data, afterworks, communautÃ© techlead...
Formationâ€¯: certifications techniques, cours particuliers dâ€™anglais en interne, accÃ¨s Ã  un catalogue de formations grÃ¢ce Ã  notre plateforme e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherchÃ©
ğŸ”® Ã” vous futur Apsidien, qui Ãªtes-vousâ€¯?
Au moins 5 ans d'expÃ©rience en tant que Data Engineer
Maitrise de lâ€™environnement cloud AWS
Force de proposition, bon relationnel et autonome
ğŸ˜ Apside a suscitÃ© votre curiositÃ©â€¯?
Dans un environnement marquÃ© par une accÃ©lÃ©ration des Ã©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients Ã  crÃ©er de la valeur et Ã  adresser leurs enjeux stratÃ©giques en leur mettant Ã  disposition des expertises technologiques (Data / IA, Cloud, Cyber) et une expÃ©rience sectorielle (Industrie, Banque, Assurance, Service, Secteur Public). Pour un accompagnement global, le groupe propose des offres transverses autour du Handicap (Apsidâ€™EA), du Digital Learning, et du Conseil.
ğŸ¤” Et votre place dans tout Ã§aâ€¯?
ğŸ‘‰ Notre volontÃ© est de vous accompagner dans la construction et lâ€™Ã©panouissement de votre carriÃ¨re en nous appuyant notamment sur 3 piliers :
Une rÃ©munÃ©ration Ã  hauteur de vos investissements et de vos compÃ©tences
Voir plus"
Senior Data Engineer M/F,"{'name': 'SPLIO', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Marketing / Communication', 'employees': '250 collaborateurs', 'creation_year': '2001', 'turnover': '26Mâ‚¬', 'mean_age': '33 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
About Splio
Splio is a scale-up in the Martech industry with around 30 million ARR. It is headquartered in Paris and employs 220 people (with 90 within the Product and Tech department and across 4 offices (France, Spain, Italy, Tunisia).
In 2023, Splio acquired Tinyclues to integrate their predictive marketing into Splio's CRM and become the European leader in intelligent CRM, allowing brands to easily orchestrate highly personalized marketing at scale through AI.
We are proud to include Longchamp, 3 Suisses, Cojean, Micromania, FNAC, SNCF Connect, Orange, and Samsung among a portfolio of 500 client companies from SME to larger companies across various industries (retail, catering, telecoms, etc.).
To support our growth, we are looking for a Senior Data Engineer to join our R&D team.
Your missions
Build, manage & improve several hundred data pipelines
You are a SQL guru : you are able to find the most cost-effective way to create an asset in our data layer
You are a practitioner of orchestration technologies (Airflow, Kubeflow)
Focus on :
Multi Tenancy : every client has its own data schema, ability to build flexible and configurable KPIs
Scalability : Clientâ€™s data can be big but the computation and scoring we process for our clients are even bigger
Cost efficiency : linked to the amount of data to process for each client, we maintain the cost low to make profit
Stack :
Languages : SQL, Python
Framework/Lib : dbt
Dev Env : GCP, Airflow 
Your responsibilities
Tech (80%)
Contribute to the overall engineering at Splio
Contribute to the development with your team
Proactively ensure that security, reliability, performance and cost-efficiency are included in technical and architectural discussions
Keep up to date with the latest relevant technologies, continually evaluating their use for Splio
Leadership (20%)
As a Senior Data Engineer, you provide guidance, allow teams to discover and learn independently.
You can handle high level of complexity and bring clarity on those complex problems
Actively question decisions and provide guidance and own experience to ensure no stone is left unturned and risks are identified and highlighted
Collaborate with other teams when necessary for the product youâ€™re building
Your Profile
ğŸ› Good technical architectural skills, you are Python fluent with a knowledge of Google Cloud Platform and an experience of BigQuery
ğŸ“£Excellent communication skills to build relationships, trust, and respect
âš™ï¸ A solid background in technology allowing you to handle new technologies & to challenge technical choices
âœ… A strong interest for engineering practices
ğŸ§‘ğŸ»â€ğŸ« Able to lead by example, hands-on and ownership
ğŸ” Comfortable in dealing with change and uncertainty during the software development lifecycle
ğŸ¤¸â€â™‚ï¸ Good knowledge about Agile development practices
ğŸ‡¬ğŸ‡§ Good english skills (speaking and writing)
Perks & Benefits
ğŸŒ´ 12 Splio days (days off), in addition to the 25 legal days off
ğŸ›‹ï¸ Friendly remote policy (5 days on site in one of the cities where thereâ€™s a Splio office)
ğŸ˜‹ A Swile card that you can use for lunch (10â‚¬ per worked day)
ğŸ‘¨â€ğŸ‘©â€ğŸ‘¦â€ğŸ‘¦ Possibility to attend or participate to conferences once or twice a year
Interested in joining Splio ?
30 min video-call with FranÃ§ois Bonicel, VP engineering to get to know you, present the job position and exchange on your qualifications & motivations to join Splio
1 hour technical case in our Paris office to evaluate your hard skills and deep dive into the role
30 min video-call with a member of the HR team to assess your interpersonal skills and give you more information about the company culture & benefits
30 min video-call with our CPTO or CTO for final validation
Voir moins",
Stagiaire Data Engineer,"{'name': 'NAMR', 'sector': 'Big Data', 'employees': '48 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '31 ans'}","Stage
(6 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,04 mars 2024,< 6 mois,,"Descriptif du poste
En rejoignant notre Ã©quipe Data Engineering, tu auras les missions suivantes :
ImplÃ©menter et gÃ©rer CI/CD pipelines
Sourcer, analyser, nettoyer, intÃ©grer et documenter les datasets du datalake
Extraire les donnÃ©es issues de ces datasets pour construire les donnÃ©es de notre base de donnÃ©es (attributs)
Maintenir les scripts de mise Ã  jour des flux de donnÃ©es (airflow)
DÃ©velopper lâ€™outil interne de gestion et administration de nos donnÃ©es et mÃ©tadonnÃ©es (Python, SQL)
Contribuer Ã  lâ€™Ã©volution de notre infrastructure de donnÃ©es vers des technologies scalables (Postgresql, BigQuery, Kubernetes) intÃ©grant plusieurs types de donnÃ©es (structurÃ©es, gÃ©olocalisÃ©es, imagerie, texte, etc.)
maintenance de la code base + maitrise des bonnes pratiques de code (Tests unitaires, Ci/CD etc)
Effectuer une veille systÃ©matique des technos, outils et mÃ©thodes de gestion des bases de donnÃ©es","Profil recherchÃ©
Ton parcours : Tu es en Master Computer Science ou en formation dâ€™IngÃ©nieur en Informatique et recherches un stage de fin dâ€™Ã©tudes.
Ta stack technique :
Python, SQL ;
Traitement/nettoyage de donnÃ©e.
Les technologies souhaitables :
Cloud (OVH, AWS, GCS, Azur, Scaleway) ;
Docker ;
QGIS ;
Dataiku ;
Git ;
NoSQL ;
PostgreSQL, PostGIS ;
Airflow
Tes qualitÃ©s humaines :
Voir plus"
Consultant.e Data Engineer ExpÃ©rimentÃ©.e,"{'name': 'THE INFORMATION LAB', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '38 collaborateurs', 'creation_year': '2015', 'turnover': '5Mâ‚¬', 'mean_age': None}",CDI,Paris,45 Ã  60 â‚¬,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Qui sommes-nous ?
VÃ©ritables passionnÃ©s de data, nous avons construit The Information Lab autour des solutions Tableau, Alteryx et Snowflake. Nous sommes convaincus que ce sont les meilleures technologies pour accomplir la transformation digitale de nos clients.
Notre spÃ©cialisation nous permet dâ€™Ãªtre les premiers partenaires de ces Ã©diteurs et dâ€™Ãªtre les experts reconnus de ces solutions en France et en Europe.
En nous rejoignant vous pourrez partager votre passion avec vos pairs, travailler dans une ambiance dÃ©contractÃ©e pour remplir notre mission : ""Helping people make sense of dataâ€.
Description du poste
RattachÃ©(e) au pÃ´le Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous mÃ©tiers. Vos missions ont pour objet le traitement, lâ€™analyse, lâ€™enrichissement des donnÃ©es de nos clients et lâ€™adoption par nos clients des technologies que nous proposons. Au sein dâ€™une Ã©quipe de 5 Ã  8 personnes, vous rÃ©alisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre â€œpod leaderâ€ (chef dâ€™Ã©quipe).
Votre rÃ´le consiste Ã  :
Intervenir en avant-vente et cadrer vos missions
Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours Ã  quelques mois
Mener des projets de bout en bout, en mÃ©thode classique ou agile, en coordination avec les Ã©quipes de nos clients, nos Ã©quipes internes et les Ã©diteurs partenaires
PrÃ©senter les livrables de vos missions et mettre en avant leur ROI
Former nos clients Ã  nos technologies
Mettre vos compÃ©tences au service de vos collÃ¨gues au-delÃ  des missions dont vous avez la charge et participer au dÃ©veloppement des compÃ©tences en partageant vos retours dâ€™expÃ©rience
Participer aux activitÃ©s dâ€™Ã©vangÃ©lisation, par exemple : rÃ©daction de posts de blogs, participation aux communautÃ©s des Ã©diteurs, interventions lors dâ€™Ã©vÃ©nements (salons, confÃ©rences, webinaires)
Participer aux projets internes (BI interne, mÃ©thodes & qualitÃ©s)
Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires.
Voir moins","Profil recherchÃ©
Vos principales qualitÃ©s :
Excellentes facultÃ©s dâ€™Ã©coute et de communication, orale et Ã©crite
Aptitude Ã  travailler sur plusieurs sujets en parallÃ¨le, Ã  prioriser
HumilitÃ© et capacitÃ© Ã  apprendre ainsi quâ€™Ã  transmettre ses connaissances
Sens du service, un bon relationnel avec les clients et la rigueur nÃ©cessaire au succÃ¨s de leurs projets
Team player
CompÃ©tences mÃ©thodologiques :
Analyse du besoin et cadrage de mission
Construction dâ€™indicateurs mÃ©tiers Ã  partir de donnÃ©es brutes
IdÃ©alement connaissance dâ€™un ou plusieurs mÃ©tiers et de leurs indicateurs clÃ©s
PrÃ©paration de donnÃ©es complexes Ã  des fins dâ€™analyse
MÃ©thodes de gestion de projet (classique et agile)
CapacitÃ© prouvÃ©e Ã  rÃ©aliser des dÃ©monstrations dâ€™outils
CompÃ©tences techniques :
Voir plus"
Lead Data Engineer - Scala (F/H/X),"{'name': 'AVIV GROUP', 'sector': 'Immobilier commercial, Immobilier particulier', 'employees': '1800 collaborateurs', 'creation_year': '2015', 'turnover': '500Mâ‚¬', 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
Rejoignez lâ€™Ã©quipe Marketplace Design AVIV
La marketplace AVIV est le lieu de rencontre privilÃ©giÃ© de tous les acteurs de lâ€™annonce immobiliÃ¨re: potentiels acquÃ©reurs ou locataires, propriÃ©taires ou agents, â€¦ Afin de garder notre position, nous devons fournir la meilleure qualitÃ© de service possible en termes de sÃ©curitÃ©,  de confiance, dâ€™efficacitÃ© et de pertinence des Ã©changes entre ces acteurs. Plusieurs facteurs entrent en ligne de compte: qualitÃ© et sÃ©rieux des prospects et des agents  ainsi que la qualitÃ© des informations affichÃ©es.
Le rÃ´le de lâ€™Ã©quipe Marketplace design est de concevoir et exÃ©cuter toutes les actions nÃ©cessaires pour assurer la satisfaction de nos utilisateurs : qualitÃ© et correction des donnÃ©es, scoring, matching, gamification, et amÃ©lioration continue. Ces actions requiÃ¨rent un usage important des donnÃ©es, lâ€™Ã©quipe Data Operations est responsable de la gouvernance, la modÃ©lisation et  la qualitÃ© des donnÃ©es ainsi que de fournir les data-sets clÃ©s et maintenir une data platform robuste et efficace pour tout le groupe AVIV.
Vos responsabilitÃ©s :
En tant que Lead Data Engineer au sein de lâ€™Ã©quipe Data Operations, vous travaillez en Ã©troite collaboration avec un Product Manager et votre Engineering Manager. Vos dÃ©veloppements respectent les bonnes pratiques en place et sont alignÃ©s avec lâ€™architecture dâ€™entreprise AVIV. Vous apportez votre expertise technique Ã  votre Ã©quipe, vous crÃ©ez, adaptez et amÃ©liorez la qualitÃ© des data-sets et des outils largement utilisÃ©s chez AVIV.
Lâ€™Ã©quipe Data Operations
Lâ€™Ã©quipe est constituÃ©e dâ€™environ 40 personnes, avec notamment:
Coach Agile
Data Engineers
Data Quality Engineers
Data Analysts & Modelers
Devops Engineers
Enterprise & Solution Architects
Product Managers
Les projets
DÃ©centraliser la data et Mettre en place le Data Mesh au sein du groupe Aviv
Fournir les insights sur les usages des diffÃ©rents sites et apps mobiles europÃ©ens  
Notre Stack Technique data
AWS (CloudFormation, EMR, S3, Glue, Athena, Redshift, SNS/SQS)
Spark
Git, CircleCI, Datadog
Scala, Java
Vous avez idÃ©alement des connaissances complÃ©mentaires telles que :
Python 
Apache Airflow, Kubernetes
Jenkins, Argo CD, Grafana, VictoriaMetrics
Voir moins","Profil recherchÃ©
Nous recherchons une personne capable de:
CrÃ©er et maintenir des datasets complexes et Ã  gros volumes selon des spÃ©cifications fonctionnelles prÃ©cises.
Participer Ã  la crÃ©ation dâ€™une infrastructure solide et optimale pour lâ€™extraction, la transformation et le chargement (ETL) de donnÃ©es Ã  partir de nombreuses sources. Utilisation de SQL et de technologies big data cloud.
Identifier, concevoir et implÃ©menter les processus internes dâ€™amÃ©lioration: automatisation, optimisation du delivery, scalabilitÃ©, etcâ€¦
Travailler avec des experts data et donnÃ©es analytiques au dÃ©veloppement de nouvelles fonctionnalitÃ©s 
Maitriser la mÃ©thodologie Agile: communication directe, adaptation, fail fast, amÃ©lioration continue et Software Craftsman
MaÃ®triser le produit et le business, impactant lâ€™amÃ©lioration du service aux clients, du produit et de lâ€™architecture
Rigueur, curiositÃ©, autonomie et Ã©tat dâ€™esprit positif 
Voir plus"
Stage - Data Engineer - Services Financiers - Ãle de France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",Stage,La DÃ©fense,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Votre futur environnement de travail : 
IntÃ©grÃ©(e) au sein dâ€™une Ã©quipe Data dâ€™une grande banque franÃ§aise, vous Ãªtes amenÃ©(e) Ã  travailler sur des projets dâ€™intelligence artificielle et de nouveaux projets data. 
Vous intÃ©grez une Ã©quipe composÃ©e de 1 responsable de patrimoine ou CP, 1 testeur, 4 profils techniques dont le tuteur du stage et 1 alternant. 
Votre rÃ´le et vos missionsâ€¯:  
Au sein du projet, vous participez Ã â€¯lâ€™ensemble des Ã©tapes clefsâ€¯du projet : 
RÃ©alisation de dossiers de conception, 
Mise en place dâ€™architecture, 
DÃ©veloppement dâ€™algorithmes en java/Angular et/ou Spark/Scala 
RÃ©alisation et automatisation des tests unitaires, 
Phases de qualification. 
Vous intervenez sur Dataiku 
Vous faites partie intÃ©grante de lâ€™Ã©quipe projet Sopra Steria, vous participez aux rÃ©unions dâ€™Ã©quipe projet et vous Ãªtes impliquÃ©(e) dans lâ€™atteinte des objectifs pour rÃ©pondre aux besoins exprimÃ©s par le client.
Les apports du stageâ€¯: 
Participation Ã  un projet de dÃ©veloppement spÃ©cifique. 
Approfondissement de vos compÃ©tences en dÃ©veloppement sur les technologies de lâ€™application.
DÃ©couverte des outils de mÃ©thodologie industrielle dâ€™un grand groupe.
Collaboration avec diffÃ©rents acteurs : Directeurs de projets, Architectes, Consultants, DÃ©veloppeurs.â€¯ 
Encadrement par des experts techniques. 
DÃ©couverte de lâ€™Ã©cosystÃ¨me technique dâ€™un grand compte. 
DÃ©couverte dâ€™un secteur dâ€™activitÃ© en pleine mutation 
Ce que nous vous proposonsâ€¯: 
Progresser et de dÃ©velopper ses compÃ©tencesâ€¯: vous Ã©voluez Ã  travers des expÃ©riences variÃ©es auprÃ¨s des plus grandes entreprises europÃ©ennes. 
Construire un avenir positif en mettant le digital au service de lâ€™humain : grÃ¢ce Ã  la puissance du collectif, nous construisons des solutions sur-mesure ayant un impact rÃ©el.
Evoluer dans une entreprise qui encourage lâ€™audace, la curiositÃ© et la prise de responsabilitÃ©s : explorer de nouvelles voies et exploiter les technologies innovantes qui permettront de mener des transformations au bÃ©nÃ©fice de tous. 
Informations supplÃ©mentaires
Les avantages Ã  nous rejoindre :
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressants : des titres restaurants, accÃ¨s aux subventions des activitÃ©s sociales & culturelles.
PossibilitÃ© de rejoindre la communautÃ© des stagiaires et alternants SPEAK UP pour booster son rÃ©seau.
De trÃ¨s nombreuses opportunitÃ©s en CDI peuvent vous attendre Ã  lâ€™issue du stage !
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherchÃ©
Votre profil :
Vous Ãªtes Ã©tudiant(e) en Ã©cole dâ€™IngÃ©nieur, en Master 2 dâ€™informatique ou Ã©quivalent, et vous recherchez un stage qui allie dÃ©veloppement, intelligence artificielle et relation client.
Vous avez des connaissances dans les langages orientÃ©s objets (Java, C++, C#,...), ou plus largement Devops, Jenkins, Dataiku et les process dâ€™automatisation.
Envie de construire avec nous et nos clients ? Lâ€™esprit dâ€™entreprendre est en vous ? Le dÃ©fi vous motive ? Alors, nâ€™hÃ©sitez plus, rejoignez sans plus attendre les Ã©quipes digitales de Banque Paris !"
Data Engineer H/F,"{'name': 'CAPGEMINI', 'sector': 'IT / Digital, Organisation / Management, StratÃ©gie, Transformation', 'employees': '360000 collaborateurs', 'creation_year': '1967', 'turnover': '18 Mds â‚¬', 'mean_age': '37 ans'}",CDI,Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,Bac +5 / Master,"Descriptif du poste
  Vous Ãªtes passionnÃ© par le domaine de la Data, vous souhaitez prendre part Ã  des projets d'envergure, concevoir des solutions, les implÃ©menter et les faire Ã©voluer?
Alors rejoignez notre Ã©quipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.
Vous avez acquis une expÃ©rience solide dans le dÃ©veloppement, la mise en Å“uvre et lâ€™optimisation de solutions pour le traitement d'un grand volume de donnÃ©es, vous Ãªtes capable de crÃ©er des solutions qui rÃ©pondent aux besoins mÃ©tiers et IT, alors rejoignez notre Ã©quipe dâ€™experts.
 En qualitÃ© de Data engineer, vos missions sont les suivantes :
â–ª Concevoir et dÃ©velopper des solutions Data/IA.
â–ª Accompagner les MÃ©tier dans la comprÃ©hension et la mise en Å“uvre de solution orientÃ©es donnÃ©es.
â–ª Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et dâ€™infrastructures axÃ©es sur les donnÃ©es.
â–ª GÃ©rer un Ã©cosystÃ¨me de partenaires data et assurer un haut niveau d'expertise
â–ª Assurer un rÃ´le de veille technologique sur tous les outils autours de la data, de lâ€™IA et de la BI.
  Avec nous, votre futur ressemblera Ã  :
Des projets dâ€™envergure, variÃ©s et passionnants
Des clients grands comptes de tous secteurs
Des Ã©volutions avec une offre de formation solide
Des Ã©changes avec une communautÃ© dâ€™experts trÃ¨s actives
Un accompagnement de proximitÃ©.
 Voir moins","Profil recherchÃ©
Description du profil :

Vous Ãªtes issu dâ€™une formation ingÃ©nieur ou Ã©quivalent bac+5 informatique spÃ©cialisÃ©e en DATA et vous justifiez dâ€™une expÃ©rience dâ€™au moins 5 ans dans un rÃ´le similaire. Expert dans une technologie de base de donnÃ©es relationnelle (PostgreSQL, Oracleâ€¦)
Expert dans une technologie de base NoSQL (MongoDB, Cassandraâ€¦)
Vous maitrisez un framework de manipulation de donnÃ©es (Hadoop, Spark, Kafkaâ€¦)
Vous maitrisez les concepts DevOps et avez de bonnes notions en scripting et dÃ©veloppement
Vous avez une expÃ©rience des outils BI et de data visualisation (Kibana, PowerBIâ€¦)
La maitrise de lâ€™anglais est nÃ©cessaire. 


Nous proposons :

Et pour (finir de) vous convaincre, on vous en dit un peu plus sur nous :
Les avantages aussi nombreux que variÃ©s :
Voir plus"
Data Engineer Senior - CDI - Paris ou Caen,"{'name': 'JAKALA', 'sector': 'Digital Marketing / Data Marketing, Big Data, E-commerce', 'employees': '150 collaborateurs', 'creation_year': '2023', 'turnover': '15Mâ‚¬', 'mean_age': '31 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©",TÃ©lÃ©travail frÃ©quent,,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Au sein de notre Data Lab, vous travaillerez conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer dÃ©jÃ  en poste et vous serez impliquÃ©.e dans la prise de dÃ©cisions liÃ©e Ã  notre solution Data et Ã  son Ã©volution.
A cet effet, vous Ãªtes en charge de :
Contribuer au dÃ©veloppement de notre offre Data et Ã  lâ€™industrialisation de plateformes data pour nos clients
Comprendre, analyser et proposer des solutions techniques rÃ©pondant aux besoins des Plateformes digitales et des projets internes,
DÃ©finir lâ€™architecture logiciel ETL / ELT en collaboration avec vos pairs
Travailler la donnÃ©e sous toutes ses formes (stockage, Ã©laboration de modÃ¨les, structuration, nettoyage),
RÃ©diger de la documentation technique (diagrammes UML, documentation dâ€™API, â€¦),
Partager votre savoir-faire entre les diffÃ©rents membres de lâ€™Ã©quipe,
Concevoir et dÃ©velopper des connecteurs entre les sources de donnÃ©es (internes et/ou externes) et la plateforme,
Concevoir et dÃ©velopper des pipelines de traitements de donnÃ©es (batch et/ou temps rÃ©el) dans un environnement Big Data,
Assurer une veille technologique et savoir mener Ã  bien un projet de R&D.
Vous assurez en autonomie les missions suivantes en interne ou auprÃ¨s de nos clients grands comptes :
Cartographier des donnÃ©es et des flux de donnÃ©es
ImplÃ©menter des algorithmes dâ€™analyse de donnÃ©es pour lâ€™industrialisation
Collecter, consolider et modÃ©liser de gros volumes de donnÃ©es (Big Data, Data Warehouses, Data Lakes)
DÃ©velopper et automatiser des flux de donnÃ©es et leurs visualisations en dashboards, reporting
Sâ€™assurer de la scalabilitÃ©, sÃ©curitÃ©, stabilitÃ© et disponibilitÃ© des donnÃ©es de la plateforme
Analyser les donnÃ©es web pour rÃ©pondre aux questions mÃ©tiers et participer Ã  la construction de lâ€™architecture Big Data
Mettre en place du sÃ©quencement et de la supervision des flux prÃ©citÃ©es en gÃ©rant les cas limites
CompÃ©tences attendues :
Bon niveau en dÃ©veloppement :
De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)
De script ELT : DBT (ex. Snowflake, PostgreSQL)
Connaissance conception et administration dâ€™entrepÃ´t de donnÃ©es : Snowflake, Big Query, PostgreSQL
LakeHouse: Delta LakeConnaissance message broker : RabbitMQ, Kafka
CompÃ©tences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)
ExpÃ©rience dâ€™architecture et de dimensionnement dâ€™une architecture cloud via des services managÃ©s
Cartographie des donnÃ©es
Voir moins","Profil recherchÃ©
DiplÃ´mÃ©Â·e dâ€™Ã©tudes supÃ©rieures dans le systÃ¨me dâ€™information, computer sciences, big data (Ã©cole dâ€™ingÃ©nieurs, Ã©cole spÃ©cialisÃ©e ou Ã©quivalent universitaire), vous justifiez dâ€™au moins 5 ans en Data engineering.
Vous avez une expertise reconnue sur la mise en place de pipelines complets de valorisation de donnÃ©es massives, de la collecte Ã  la mise Ã  disposition dâ€™applications en passant par le traitement.
La maÃ®trise de lâ€™anglais est apprÃ©ciÃ©e.
CertificationÂ·s indispensableÂ·s : GCP Professionnal Data Engineer OU Azure Data Engineer Associate OU AWS Solution Architect.
Vous Ãªtes passionnÃ©Â·e par votre mÃ©tier, aimez le faire partager."
Data Architect / Data Engineer - CDI - Paris,"{'name': 'JAKALA', 'sector': 'Digital Marketing / Data Marketing, Big Data, E-commerce', 'employees': '150 collaborateurs', 'creation_year': '2023', 'turnover': '15Mâ‚¬', 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
SOYHUCE est Ã  la recherche dâ€™unÂ·e Data architect / Data Engineer afin dâ€™accompagner techniquement et opÃ©rationnellement le Data Lab (Data Scientist, Data Engineer, Data Analystes, MLOps â€¦) et travailler Ã©troitement avec les Ã©quipes IT pour le dÃ©veloppement des projets.
Vous contribuez ainsi aux grands programmes innovants et stratÃ©gique du groupe.
Vos missions au quotidien :
GÃ©rer lâ€™environnement Big Data (GCP) et dâ€™en assurer la stabilitÃ© et  lâ€™optimisation dans le cadre des projets DATA inscrits dans la Roadmap
ImplÃ©menter des flux de collecte, de transformation et de stockage des donnÃ©es multi- sources
Automatiser le processus de structuration de la DATA en amont de lâ€™intervention dâ€™un Data Scientist (crÃ©ation et maintenance du code)
Concevoir et automatiser le processus de structuration de la DATA et des outils nÃ©cessaires permettant aux experts de lâ€™Ã©quipe un accÃ¨s facile aux donnÃ©es pour dÃ©velopper les cas dâ€™usage mÃ©tier (Data science/IA, Reporting, Analytics, Activation mÃ©dia, â€¦)
ÃŠtre lâ€™interlocuteur privilÃ©giÃ©  de lâ€™Ã©quipe Architecture IT pour assurer un avancement conjoint sur les sujets Data prioritaires
Assurer avec lâ€™IT le processus de qualitÃ© et la fiabilitÃ© des flux de donnÃ©es (scalabilitÃ©, sÃ©curitÃ©, performance, recovery) en conformitÃ© avec les standards dÃ©finis par la sÃ©curitÃ© du groupe
Assurer la rÃ©daction et la maintenance  dâ€™une documentation claire sur les diffÃ©rents projets dÃ©veloppÃ©s
Assurer la mise en production des projets DATA
Ã‰valuer lâ€™architecture et lâ€™environnement DATA actuels et prÃ©voir des mises Ã  jour nÃ©cessaires selon les besoins de lâ€™Ã©quipe. (ex. intÃ©gration nouveaux outils de Data Prep)
DÃ©velopper les APIs/ connecteurs nÃ©cessaires pour intÃ©grer notre DATA dans les plateformes AdTech 3rd (ex DSP/SSP MÃ©dia)
CompÃ©tences techniques :
MaÃ®trise des solutions Cloud GCP (BigQuery, DataProcâ€¦) et AWS (RDS, EMRâ€¦)
Langages SQL, NoSQL, Python, Râ€¦
ModÃ©lisation, traitement et transformation des donnÃ©es complexes et multi-sources
Conception et dÃ©ploiement dâ€™une architecture distribuÃ©e pour le traitement de donnÃ©es
Maitrise des aspects dâ€™authentification, de sÃ©curitÃ©, de containerisation et dâ€™orchestration
Maitrise des technologies: Spark, Kafka, Couchbase, Cassandra, Solr, Suite ELK, Redis, SQL Server, PostgreSQL, Docker, Kubernetes
Outils : Tableau et PowerBI
Voir moins","Profil recherchÃ©
DiplÃ´me Bac + 5, ingÃ©nieur ou Ã©quivalent universitaire ou ayant dÃ©montrÃ© ses compÃ©tences dans lâ€™architecture DATA.
PassionnÃ©Â·e de la data avec au moins 5 ans dâ€™expÃ©rience dans des rÃ´les Data Architect, Architecture ou similaire, vous possÃ©dez les qualitÃ©s suivantes :
Esprit dâ€™Ã©quipe et sens de lâ€™Ã©coute
Autonomie et proactivitÃ©
CuriositÃ© et crÃ©ativitÃ©
Sens relationnel et capacitÃ© dâ€™adaptation
Rigueur
Esprit dâ€™analyse"
Data Engineer GCP (H/F),"{'name': 'THALES', 'sector': 'Logiciels, CybersÃ©curitÃ©, AÃ©ronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mdsâ‚¬', 'mean_age': None}",CDI,Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Nos Ã©quipes de lâ€™activitÃ© SystÃ¨mes dâ€™information critiques et cybersÃ©curitÃ© fournissent des services et des solutions globales optimisant la performance, la rÃ©silience et la sÃ©curitÃ© des systÃ¨mes dâ€™information afin de faire face aux ruptures technologiques et aux cybermenaces.
THALES Bordeaux recherche un IngÃ©nieur Data / GCP (H/F) :
CDI (pas de full-remote ni freelance)
2 jours de tÃ©lÃ©travail par semaine
Site : MÃ©rignac (33700)
QUI ETES-VOUS ?
De formation supÃ©rieure en Informatique/Data (Bac+5 ou supÃ©rieur), vous disposez d'une expÃ©rience professionnelle dâ€™au moins 3 ans dans lâ€™utilisation de technologies cloud, et notamment GCP. Vous avez gÃ©rÃ© des projets industrialisÃ©s en data engineering et/ou IA, et souhaitez continuer Ã  Ã©voluer dans ces deux domaines.
Vous maÃ®trisez les outils de cloud, Data Analytics et les techniques de traitement de donnÃ©es. Vous avez une expÃ©rience du travail DevOps, de l'automatisation et la surveillance continues tout au long du cycle de vie des applications (approche CI/CD).
Vous connaissez au moins le langage de programmation PYTHON ainsi que les bases de donnÃ©es (postgreSQL) et leur langage associÃ© (SQL...). Vous savez vous adapter Ã  diverses technologies et outils, et tirer parti de la meilleure solution pour rÃ©pondre aux exigences du client.
Votre rigueur, votre esprit d'Ã©quipe et vos qualitÃ©s relationnelles sont autant d'atouts qui vous permettront de rÃ©ussir dans vos missions.
CE QUE NOUS POUVONS FAIRE ENSEMBLE :
Au sein de projets Agile, vous aurez pour mission de :
Concevoir et dÃ©velopper des pipelines de traitements de la donnÃ©e
Collaborer avec lâ€™Ã©quipe pour le respect des dÃ©lais de livraisons dans une organisation en mode Agile
Utiliser des outils comme Google Cloud Platform (GCP) pour rÃ©aliser des traitements IA et Data
RÃ©flÃ©chir Ã  la sÃ©curisation des donnÃ©es confidentielles
Contribuer au dÃ©veloppement des cas dâ€™usage mÃ©tier, apporter de la valeur et de lâ€™innovation en utilisant les outils Ã  disposition
Participer aux projets dâ€™Ã©volutions en apportant votre analyse technique et fonctionnelle
Innovation, passion, ambition : rejoignez Thales et crÃ©ez le monde de demain, dÃ¨s aujourdâ€™hui.
Voir moins",
STAGE - Data Engineer,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",Stage,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
La mission dâ€™AXA est de Â« donner Ã  chacun les moyens de vivre une vie meilleure Â». Nous souhaitons alors passer du rÃ´le de payeur Ã  celui de partenaire. La mission de notre division, AXA Group Operations (GO), est de soutenir et responsabiliser lâ€™ensemble des Ã©quipes dâ€™AXA afin de concrÃ©tiser cette ambition commune.
Lâ€™innovation et lâ€™exÃ©cution sont nos principaux leviers pour atteindre cet objectif. Ils guident lâ€™ensemble des Ã©quipes de GO au quotidien : Innovation : crÃ©er et fournir les bases et opportunitÃ©s aux Ã©quipes dâ€™AXA qui dÃ©velopperont des solutions innovantes afin de rÃ©pondre aux besoins de nos clients actuels et futurs ;
ExÃ©cution : crÃ©er lâ€™environnement qui permettra Ã  nos Ã©quipes Ã  travers le monde, de donner vie Ã  leurs idÃ©es et de tenir les promesses faites Ã  nos clients.
Nos objectifs concrets sont de :- Renforcer la crÃ©ation de valeur pour lâ€™ensemble du groupe AXA ;- Soutenir et encourager l'innovation au sein d'AXA, en collaboration avec la division Group Business Innovation ;- Automatiser et intÃ©grer la simplicitÃ© dans notre travail quotidien, en nous assurant de contribuer efficacement Ã  la mission et stratÃ©gie dâ€™AXA.
Les Ã©quipes de Group Operations sont alors composÃ©es de :
Group IT : dÃ©finit la stratÃ©gie IT globale dâ€™AXA ; favorise la convergence de lâ€™IT au sein des entitÃ©s et leur fournit des services partagÃ©s ;
Group Security : protÃ¨ge les salariÃ©s, nos parties prenantes et la marque AXA en sÃ©curisant les informations et gÃ©rant les cyber sÃ©curitÃ©, la sÃ©curitÃ© physique ainsi que la rÃ©silience des opÃ©rations ;
REV: dÃ©finit les ambitions concernant la maturitÃ© des donnÃ©es du Groupe ; construit et gÃ¨re la communautÃ© ; conduit la recherche et lâ€™expertise ; assiste les entitÃ©s les moins matures en termes de donnÃ©es ;
Technology Innovation : identifie les technologies de pointe et en dÃ©veloppe des disruptives pour les entitÃ©s ; crÃ©e des cas dâ€™usage sur des technologies spÃ©cifiques avec les entitÃ©s ;
Group Procurement : dÃ©finit la stratÃ©gie dâ€™achats dâ€™AXA, ses lignes directrices et les normes du Groupe ; gÃ¨re les relations avec nos fournisseurs stratÃ©giques et accÃ©lÃ¨re les achats mÃ©tiers ;
Group Strategic Program Management : sâ€™assure de la cohÃ©rence des projets globaux avec la stratÃ©gie du Groupe ; veille Ã  la mise en Å“uvre et performance des projets stratÃ©giques ;
AXA Business Services : offre des services partagÃ©s alignÃ©s aux prioritÃ©s commerciales dâ€™AXA ;
Group Operations Transformation : accÃ©lÃ¨re la transformation agile au sein de Group Operations ; Ã©tablit et met en Å“uvre une communication et stratÃ©gie RH commune Ã  notre division.
Dans ce contexte, vous intÃ©grerez le dÃ©partement  Data, BI and Analytics pour rejoindre une Ã©quipe projets en charge du dÃ©veloppement de solutions data pour les entitÃ©s. Le dÃ©partement Data, BI & Analytics propose des produits aux entitÃ©s du Groupe AXA pour stocker la donnÃ©e (datalake), la transformer, lâ€™agrÃ©ger et la visualiser. Notre catalogue de services sâ€™appuie sur 3 piliers :
Le CoE (Center of Excellence) qui joue un rÃ´le dâ€™expertise et de conseil vis-Ã -vis des entitÃ©s (formation, R&D, expertise fonctionnelle et technique, UXâ€¦)
Le Delivery - projet et BAU â€“ qui implÃ©mente et maintient les produits (IT Services, qualitÃ© de service, support, Ã©volutionsâ€¦)
La Factory qui implÃ©mente et maintient les couches techniques des applications (CI/CD, monitoring de plateforme, capacity managementâ€¦).
Dans ce contexte, le dÃ©partement Data, BI & Analytics prend en charge le cycle complet des produits et services : avant-vente, delivery du projet, exploitation et maintenance des solutions.
VOS MISSIONS : 
Construire et maintenir des composents Microsoft BigData & BI
DÃ©velopper des rapports BI
Interagir avec une Ã©quipe et le tech lead
Ecrire et maintenir la document technique autour dâ€™une application
Mener de courtes missions en autonomie autour des besoins dâ€™une application (rÃ©soudre les incidents techniques)
Nous cÃ©lÃ©brons l'expertise, la diversitÃ© culturelle et la crÃ©ativitÃ© de plus de 8 000 employÃ©s de par le monde.  Nous nous engageons Ã  assurer l'Ã©galitÃ© des chances en matiÃ¨re d'emploi (paritÃ© hommes-femmes, communautÃ© LGBT+, personnes handicapÃ©es ou personnes d'origines diverses) et Ã  promouvoir la diversitÃ© et l'inclusion en crÃ©ant un environnement de travail oÃ¹ tous les employÃ©s sont traitÃ©s avec dignitÃ© et respect, et oÃ¹ les diffÃ©rences individuelles sont valorisÃ©es.
Voir moins","Profil recherchÃ©
PROFIL : Etudiant en Ã©cole d'ingÃ©nierie Ã  la recherche d'un stage de 4-6 mois.
Vous dÃ©velopperez vos compÃ©tences sur :
Le travail dans un contexte internationnal (anglais)
Vos connaissances en traitement de donnÃ©es et les bonnes pratiques
Vos capacitÃ©s Ã  travailler en Ã©quipe
Vos capacitÃ©s Ã  rÃ©soudre les problÃ¨mes et incidents techniques 
CompÃ©tences techniques / Hard skills:
Python
SQL Server
DAX (serait un plus)
Langues : FranÃ§ais (bilingue), anglais(opÃ©rationnel)
Outils informatiques :
Office 365 (EXCEL)
PowerBI
Plateforme Cloud Azure"
Data Engineer,"{'name': 'WEWYSE', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Transformation', 'employees': '60 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 1 an,Bac +5 / Master,,
Data Engineer (H/F),"{'name': 'MOONCARD', 'sector': 'Banque, IT / Digital, Big Data', 'employees': '125 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '28 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,12 mars 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
Fintech fondÃ©e en mars 2016, Mooncard est un leader franÃ§ais de lâ€™automatisation des dÃ©penses en entreprise, proposant une solution intÃ©grÃ©e avec une carte entiÃ¨rement sÃ©curisÃ©e et paramÃ©trable, une application de gestion et un moteur comptable. Mooncard est une solution SaaS et a dÃ©jÃ  sÃ©duit plus de 4000 entreprises.
LibÃ©rer les collaborateurs de la gestion chronophage des notes de frais, câ€™est gagner en productivitÃ© sur des tÃ¢ches Ã  plus forte valeur ajoutÃ©e.
PortÃ©e par une Ã©quipe jeune et passionnÃ©e, Mooncard est une scale-up en forte croissance, offrant de rapides perspectives dâ€™Ã©volution.
Vous allez rencontrer des Ã©quipes soudÃ©es, enthousiastes et passionnÃ©es qui ont un but commun : faire grandir notre projet.

Nos valeurs :
Lâ€™empathie
La curiositÃ©
Lâ€™ambition
La collaboration
 Nous recherchons notre futur(e) Data Engineer, qui sera plongÃ©.e au coeur de la stratÃ©gie commerciale et opÃ©rationnelle de Mooncard.
 Votre rÃ´le au sein de l'Ã©quipe :
En tant que sociÃ©tÃ© technologique et financiÃ¨re, Mooncard dispose dâ€™un patrimoine de donnÃ©es particuliÃ¨rement riche et dont lâ€™exploitation est clÃ© pour lâ€™excellence opÃ©rationnelle de lâ€™entreprise.
Au sein de l'Ã©quipe Data & Business Operations (6 collaborateurs), vous serez en charge de construire, maintenir et documenter les flux de donnÃ©es entre les systÃ¨mes de Mooncard et de fournir des datamarts pertinents pour les Ã©quipes business.

Vos missions au quotidien :
IntÃ©gration de DonnÃ©es
Ã‰tablir des pipelines de donnÃ©es robustes pour fusionner des bases de donnÃ©es multiples, notamment l'application de production, nos outils Salesforce, Stripe..
Data Lake / Data Warehouse
DÃ©velopper et maintenir notre Data lake / Data warehouse centralisÃ© pour les Ã©quipes BI, Produit, et machine learning.
Automatisation et Monitoring
Automatiser les processus rÃ©currents et mettre en place des alertes pour surveiller la santÃ© des pipelines de donnÃ©es.
Optimisation de CoÃ»ts AWS
Analyser et ajuster l'utilisation des ressources AWS pour optimiser les coÃ»ts tout en maintenant la qualitÃ© de service.
Support aux Ã‰quipes Data ""Front""
Fournir des jeux de donnÃ©es exploitables et des outils aux data analysts/scientists et autres Data champions de Mooncard.
Documentation et Best Practices
Documenter les architectures de donnÃ©es, les configurations, et les best practices pour assurer une maintenance aisÃ©e et la formation des nouveaux membres de l'Ã©quipe.
Collaboration Inter-Ã‰quipes
- Travailler en Ã©troite collaboration avec les Ã©quipes BI, ML, Produit et DevOps pour assurer que les besoins en donnÃ©es sont bien compris et satisfaits.
- Faire lâ€™intermÃ©diaire entre les dÃ©veloppeurs et les analystes pour trouver des quick wins qui faciliteront le travail des Ã©quipes BI et la scalabilitÃ© de lâ€™infrastructure. DÃ©velopper et prendre lâ€™ownership dâ€™une logique de Data Contracts.
Gestion des DonnÃ©es Sensibles
Mettre en Å“uvre des mesures de sÃ©curitÃ© pour protÃ©ger les donnÃ©es sensibles et garantir la conformitÃ© aux rÃ©gulations (GDPR, etc.).
Est-ce que Ã§a vous ressemble ?
ExpÃ©rience professionnelle avÃ©rÃ©e en tant que Data Engineer (3 ans d'expÃ©rience)
Forte capacitÃ© Ã  analyser et Ã  manipuler des donnÃ©es
Connaissance avancÃ©e du langage SQL et expÃ©rience en Python
Connaissance de Databricks
MaÃ®trise dâ€™un ou plusieurs ETL du marchÃ©
Connaissance dâ€™outils BI tels que Tableau.
Nice to have : Connaissance du modÃ¨le de donnÃ©es Salesforce
Anglais courant : lu, Ã©crit, parlÃ©

Ce que nous vous offrons :
Contrat CDI : CP + RTT
Team buildings et sÃ©minaires d'Ã©quipe rÃ©guliers
We Work situÃ© dans le 9Ã¨me arrondissement Ã  Paris
Mutuelle Generalli (50%)
Tickets restaurant Up (9â‚¬/jour)
TÃ©lÃ©travail jusqu'a 3 jours par semaine
Voir moins",
Senior Data Engineer,"{'name': 'ECHO ANALYTICS', 'sector': 'Intelligence artificielle / Machine Learning, Big Data', 'employees': '70 collaborateurs', 'creation_year': '2021', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,19 fÃ©vrier 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
ğŸš€ Founded in 2021, Echo's narrative is one of relentless growth, ambition, and promise. A cutting-edge startup at the forefront of Geospatial Data and Gen AI technologies, we have skyrocketed from 0 to 50+ employees in just two years!
Specialists in the location intelligence industry, we empower innovation by helping companies better understand the world around them.
In a world inundated with data, quality is crucial. We use data science, machine learning, and human feedback to build Europe's most comprehensive, high-quality datasets, enriched with differentiating attributes that outmaneuver the competition.
We arenâ€™t just about reliable data (read: unmatched quality) though.
Life at Echo is about individual growth, collective ambition, and a culture that values and celebrates diversity; With a ""people first"" philosophy guiding everything we do.
You'll be at the heart of innovation, tackling projects that shape our future, with the best people possible!
Your Role at Echo
As a Senior Data Engineer on our R&D team, you'll be a key player in shaping data flows within our Google Cloud Platform (GCP) environment. Your role involves designing and managing intricate data processes using technologies like BigQuery, Pub/Sub, Data flow, Airflow, Terraform, and GCP. Beyond design, you'll actively contribute to data modeling, overseeing data flows from concept to production support. Join us in a unique opportunity to be part of a successful startup, leading its market from the early stages.
As such, your main responsibilities will be
Be the driving force behind the development and maintenance of the team's products. This can take many forms, here are a few examples:
Ensure data is reliable, consistent, and available.
Expose the data through APIs, flat files, etc., for internal and external use.
Design geographical datasets for external consumers for speed, consistency, cost, and efficiency.
Be the technical mentor for a team of 2 to 5 Data/Software Engineers:
Provide best practices and guidance for individual contributors.
Report to the R&D management team on progress and difficulties.
Be proactive in investigating and testing new tools, processes, and technologies on an ongoing basis.
Continuing learning new skills thanks to the Echo Analytics knowledge plan.
Proposing architecture and design changes based on internal audit.

What weâ€™re looking for
Fluent in English (French is a plus).
Minimum 5 years of data industry experience.
Proficient in Python programming.
Expertise in data engineering principles, ETL processes (Apache Airflow), and data warehousing.
Hands-on experience with Google Cloud Platform (or other providers) and cloud data processing frameworks
Proven experience with Apache Spark/Apache Beam.
Design and implementation of scalable and resilient data architectures in cloud environments.
Hands-on experience with Ops tools like GitHub Actions and Terraform.
Proven ability to provide ongoing support, monitor data processes, and optimize pipelines for stability and efficiency.

Why us?
ğŸŒ A great diverse and international team based in Paris (25+ nationalities!)
ğŸš€ Impact and ownership mindset: at Echo we encourage everyone to take ownership of their projects
ğŸ‡ People first company: without our people we have no business, we have dedicated a People Manifesto to them
ğŸŒ† A contemporary office space in central Paris with a rooftop to admire the view
ğŸ’» Remote-friendly policy
ğŸ¥˜ Free coffee, snacks on top of your lunch voucher card (Swile, 10â‚¬/ working day)
ğŸ¥ Healthcare insurance
Still hesitating or feeling like you donâ€™t check all the boxes? We encourage you to apply anyway! ğŸ™‚
Best case scenario: we start an incredible collaboration. If not, you only invest a few minutes towards your application. We promise, you wonâ€™t regret it!
We are committed to providing equal employment opportunities regardless of gender, sexual orientation, origin, disabilities, or any other traits that make you who you are.
Voir moins",
Data Engineer,"{'name': 'MEWS PARTNERS', 'sector': 'Organisation / Management, Transformation, Audit', 'employees': '300 collaborateurs', 'creation_year': '1992', 'turnover': '47Mâ‚¬', 'mean_age': '32 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,,
Consultant Senior Data Engineer H/F - CDI,"{'name': 'CONVERTEO', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, StratÃ©gie', 'employees': '400 collaborateurs', 'creation_year': '2007', 'turnover': '43M â‚¬', 'mean_age': '27 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,"Descriptif du poste
Description de l'entreprise

Converteo est un cabinet de conseil pure player de la data, au service du progrÃ¨s et de la performance des entreprises. Quâ€™il sâ€™agisse de dÃ©finir la stratÃ©gie ou de dÃ©ployer les projets, Converteo accompagne ses clients sur lâ€™ensemble de la chaÃ®ne de valeur de la donnÃ©e : collecte, modÃ©lisation, mesure, activation, gouvernance, conformitÃ©.
Avec plus de 420 consultants et plus de 200 clients dans tous les secteurs de lâ€™Ã©conomie, de la grande distribution au luxe en passant par lâ€™industrie, Converteo connaÃ®t une trÃ¨s forte croissance et voit ses besoins marketing croÃ®tre dâ€™annÃ©e en annÃ©e.

Description du poste
A la croisÃ©e des sujets data engineering, data science, IA et dÃ©veloppement, la Practice Data Technologies est Ã  lâ€™initiative de la construction et lâ€™Ã©volution des offres Data et Technologiques au sein de Converteo. La Practice couvre un champ dâ€™expertises trÃ¨s large et intervient notamment sur :
- les stratÃ©gies move to cloud (cadrage et implÃ©mentation) avec GCP, SF, AWS, Azure ;
- la conception de produits data : plateformes d'activation et de reporting in-house (Advanced Analytics / BI / Insights Sharing / Forecast / Activation Locale / CDP) ;
- la mise en place de squads data chez nos clients ;
- le cadrage et dÃ©ploiement de stratÃ©gies de gouvernance de la donnÃ©e ;
- le dÃ©ploiement de stratÃ©gies IA chez nos clients ;
- lâ€™implÃ©mentation d'outils partenaires sur nos sujets stratÃ©giques (CDP SaaS, PriceFX)
Nous recrutons un(e) Consultant Senior Data Engineer :

AprÃ¨s formation interne Ã  notre mÃ©thodologie et notre offre client, vous assurez, en autonomie, les missions suivantes en interne ou auprÃ¨s de grands comptes :
- Cartographie des donnÃ©es et des flux de donnÃ©es
- ImplÃ©menter des algorithmes dâ€™analyse de donnÃ©es pour l'industrialisation
- Collecter, consolider et modÃ©liser de gros volumes de donnÃ©es (Big Data, Data Warehouses, Data Lakes)
- DÃ©velopper et automatiser les flux de donnÃ©es et leurs visualisations en dashboards, reporting.
- S'assurer de la scalabilitÃ©, la sÃ©curitÃ©, la stabilitÃ© et la disponibilitÃ© des donnÃ©es de la plateforme.
- Analyser des donnÃ©es web pour rÃ©pondre aux questions mÃ©tiers et participer Ã  la construction de lâ€™architecture Big Data
- Mettre en place le sÃ©quencement et la supervision des flux prÃ©citÃ©es en gÃ©rant les cas limites.
Profil recherchÃ© 

De formation supÃ©rieure en Ã©cole dâ€™ingÃ©nieur/universitÃ© (niveau Bac+5 ou plus), vous justifiez d'au moins 3 ans d'expÃ©rience professionnelle en tant que Data Engineer, idÃ©alement dans un programme data en lien avec les mÃ©tiers marketing. 
Notre stack :
- GCP / Azure / AWS 
- Big Query, SQL-like, Dataflow, Dataproc & Looker Studio
- Python
- Une expÃ©rience et une certification SnowPro Core ou SnowPro Advanced sont requises
Vous disposez des qualitÃ©s suivantes : 
- Excellente qualitÃ© relationnelle et rÃ©dactionnelle 
- Autonomie / Sens de lâ€™initiative 
- Ethique et rigueur 
- Vous avez lâ€™esprit dâ€™Ã©quipe et Ãªtes impliquÃ©(e) dans votre travail au quotidien 
- Vous avez hÃ¢te de proposer des amÃ©liorations, les partager et les prioriser avec vos collÃ¨gues 
- Vous avez un niveau courant en Anglais 
Notre process de recrutement
Un entretien avec notre recruteur et un Manager Data Engineer (1h)
Un entretien technique avec deux Senior Manager Data (1h)
Un entretien Final avec nos deux Practice Leaders (45min)
Bienvenue chez nous ğŸ¤—

Conditions du poste 
Locaux situÃ©s Ã  Paris intramuros : 117 Quai de Valmy - 75010 Paris
Contrat en CDI, statut Cadre
Poste Ã  pourvoir dÃ¨s que possible

Notre petit + ? 

Et parce que le bien-Ãªtre de lâ€™Ã©quipe est au cÅ“ur de notre modÃ¨le, quelques infos sur le cadre de travail :
4,66 / 5 Ã  l'enquÃªte Happy at Work - 96% de taux de recommandation Ã  des proches
NÂ°1 au classement HappyIndexÂ®AtWork 2021, 2022 & 2023 des entreprises du secteur Conseil, nÂ°1 au classement HappyWomenAtWork 2023
Equilibre vie pro / vie perso (temps de travail maÃ®trisÃ©, mesures pour accompagner la parentalitÃ©)
Une politique de tÃ©lÃ©travail flexible, sans limitation de jours
Des bureaux spacieux tout confort au pied du Canal Saint-Martin
Ã‰quipement pour travailler en remote + participation aux frais du tÃ©lÃ©travail (allocation mensuelle)
Des sÃ©minaires d'Ã©quipe et des teambuilding pour se retrouver
Une multitude d'activitÃ©s sportives : via GymLib ou en rejoignant les Ã©quipes sportives de l'Ã©quipe (yoga, foot, basket, cross training, etc)
Valorisation des mobilitÃ©s douces (forfait mobilitÃ© durable pour les adeptes du vÃ©lo ou de la trottinette)
Une School interne pour se former et se certifier sur des outils continuellement

Nos collaborateurs tÃ©moignent sur Glassdoor

DÃ©couvrez l'aventure Converteo en vidÃ©o


ğŸŒŸ En 2021, 2022 et en 2023, Converteo occupe la 1Ã¨re place du classement HappyIndexÂ®AtWork des entreprises du secteur Conseil, rejoignez-nous !
ğŸ‘© En 2023, Converteo occupe la 1Ã¨re place du classement HappyWomenAtWork, classement des entreprises dans lesquelles les femmes sont les plus engagÃ©es et motivÃ©es ğŸ¤—
Voir moins","Profil recherchÃ©
."
Data Engineer - Databricks,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Paris,50K Ã  60K â‚¬,TÃ©lÃ©travail occasionnel,12 fÃ©vrier 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
MP DATA recrute un(e) Data Engineer (H/F) ayant une forte appÃ©tence databricks.
Dans le cadre de la transformation digitale industrielle de notre client, votre rÃ´le est dâ€™accompagner lâ€™Ã©quipe de data engineering en charge de lâ€™exploitation du Cluster Big Data.
En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des donnÃ©es, en veillant Ã  ce quâ€™elles soient prÃªtes pour lâ€™analyse.
Votre expertise dans la conception de pipelines ETL et la sÃ©curisation des donnÃ©es sera essentielle pour soutenir les activitÃ©s dâ€™analyse et de prise de dÃ©cision de lâ€™entreprise. Votre rÃ´le contribuera Ã  crÃ©er une base de donnÃ©es solide et sÃ©curisÃ©e pour des insights pertinents et en temps rÃ©el.
CrÃ©ation et dÃ©veloppement de flux et pipeline sous databricks !
Le vrai plus du poste, une vision end to end du cycle de la donnÃ©e, recueil, traitement et visualisation.
Nous recherchons un(e) collaborateur(trice) dynamique, bon communicant disposant dâ€™une bonne qualitÃ© de synthÃ¨se.
Vous travaillerez dans un environnement international auprÃ¨s dâ€™un acteur central de lâ€™Ã©nergie !","Profil recherchÃ©
Nous recrutons un(e) Data Engineer (H/F) afin de travailler pour un client secteur de lâ€™Ã©nergie, Vous interviendrez au sein du dÃ©partement en charge du pilotage des diffÃ©rentes business unit.
DiplÃ´mÃ©(e) dâ€™une Ã©cole dâ€™ingÃ©nieur, vous disposez dâ€™une premiÃ¨re expÃ©riences rÃ©ussie autour de la crÃ©ation de pipelines sous DataBricks.
Vous Ãªtes reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacitÃ© Ã  Ãªtre force de proposition, vous Ãªtes Ã  lâ€™aise dans un environnement challengeant.
Vous Ãªtes intÃ©ressÃ©(e)s pour vous dÃ©passer en data science & data engineering et vous avez des premiÃ¨res expÃ©riences dans ce domaine, comme par exemple :
Spark, PySpark
Cloud : Azure / AWS
SQL : Postgres / MongoDB /
Power BI
DATABRICKS
Palantir Foundry
AgilitÃ©
Voir plus"
Data Engineer - F/H,"{'name': 'CS', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, AÃ©ronautique / Spatiale, Energie', 'employees': '2700 collaborateurs', 'creation_year': '1968', 'turnover': '300 000 000â‚¬', 'mean_age': '40 ans'}",CDI,Fontaine,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Nous recrutons un.e Data Engineer pour rejoindre notre Business Unit INDUSTRIE au sein de la Business Line Data Intelligence.
Dans le cadre de son offre Â« Data Intelligence Â», CS GROUP accompagne ses clients sur lâ€™ensemble des Ã©tapes de valorisation de leurs donnÃ©es, incluant les dÃ©marches de Data Gouvernance. Ces projets dâ€™ampleur sont opÃ©rationnellement menÃ©s par des Â« Data Offices Â» accompagnant les experts mÃ©tiers dans lâ€™application de la stratÃ©gie Data de lâ€™entreprise.
Votre mission :
Concevoir et dÃ©velopper des outils de traitements et processing de donnÃ©es ;
DÃ©ployer, industrialiser et tester des solutions dÃ©veloppÃ©es ;
Monitoring et analyse de flux de donnÃ©es ;
Contribuer aux activitÃ©s de conseil (comprÃ©hension du besoin, proposition de solutions techniques - architectures, rÃ©alisation de missions dâ€™audit, industrialisation de modÃ¨les de donnÃ©esâ€¦).
Environnement technique : 
Spark, Hadoop
Environnement Cloud (AWS, GCP)
R, Python, Shiny
HTML, CSS, Javascript
DevOps
Voir moins","Profil recherchÃ©
Qui Ãªtes-vous ?
De formation supÃ©rieur (Bac+5), vous justifiez d'une premiÃ¨re expÃ©rience sur un projet de Data Engireening.
Vous apprÃ©ciez de travailler en Ã©quipe ? Vous possÃ©dez des qualitÃ©s en communication et Ãªtes rigoureux.se ? Alors vous Ãªtes la pÃ©pite que nous recherchons !
A compÃ©tences Ã©gales, ce poste est ouvert aux personnes en situation de handicap."
Data Engineer H/F,"{'name': 'NEXTON', 'sector': 'Design, IT / Digital, Digital', 'employees': '450 collaborateurs', 'creation_year': '2011', 'turnover': '31 millions', 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 1 an,Bac +5 / Master,"Descriptif du poste
NEXTON recrute un DATA ENGINEER H/F, en CDI, Ã  Paris !

Qui sommes-nous ?

NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBASâ€¦).

Nous sommes experts du digital aussi bien sur de l'accompagnement stratÃ©gique qu'opÃ©rationnel.

Fort du succÃ¨s, NEXTON connaÃ®t aujourd'hui un dÃ©veloppement significatif, autour de ses valeurs piliers : cohÃ©sion, confiance et performance.

Et pour toi ? Notre politique de dÃ©veloppement des compÃ©tences dynamique saura te sÃ©duire avec un programme de suivi de carriÃ¨re sur-mesure.

Contexte :

Nous recherchons pour notre client spÃ©cialisÃ© dans le secteur des TÃ©lÃ©com, un Data Engineer.

Les missions :

Tes principales missions sont :

de maÃ®triser les requÃªtes SQL pour effectuer des analyses avancÃ©es sur des ensembles de donnÃ©es complexes.
de concevoir, dÃ©velopper et mettre en Å“uvre des pipelines de donnÃ©es robustes en utilisant Python pour assurer la collecte, la transformation et l'intÃ©gration efficaces des donnÃ©es.
d'utiliser Power BI pour crÃ©er des tableaux de bord interactifs et des rapports visuels.
de travailler en Ã©troite collaboration avec les dÃ©veloppeurs de l'Ã©quipe afin de rÃ©pondre Ã  l'ensemble des pratiques en place (tests, relectures de code, industrialisation, cÃ©rÃ©monies agiles)


Voir moins","Profil recherchÃ©
Tu justifies d'une expÃ©rience de minimum 4 ans en tant que dÃ©veloppeur ou ingÃ©nieur data. Tu maÃ®trises Python, SQL, Power BI et un environnement Cloud serait un plus.
Enfin, tu es sensible aux problÃ©matiques techniques et best-practices pour la rÃ©alisation de projets DATA fiables et robustes. NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'annÃ©e :

- Des communautÃ©s : 2 Meet Up par mois pour partager et Ã©changer avec des experts

- De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'annÃ©e

- Des moments privilÃ©giÃ©s avec ton manager

PrÃªt Ã  nous rejoindre ? Rencontrons-nous !"
Data Engineer H/F- CDI,"{'name': 'ACHEEL', 'sector': 'Assurance, FinTech / InsurTech', 'employees': '75 collaborateurs', 'creation_year': '2020', 'turnover': '130 millions', 'mean_age': '33 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,17 juillet 2023,> 1 an,Bac +3,"Descriptif du poste
ğŸš€ Venez participer Ã  lâ€™essor de lâ€™Ã©quipe Data dâ€™Acheel ! Ce nouveau pÃ´le a pour rÃ´le de centraliser les outils de data science et data analyse de lâ€™entreprise, et a pour cela vocation de grandir rapidement. Son objectif est de construire une architecture de donnÃ©es robuste et documentÃ©e afin de proposer les meilleures solutions possibles et de fournir un outil dâ€™aide Ã  la prise de dÃ©cisions business aux Ã©quipes. Directement rattachÃ© au CEO, vos missions seront de :
Etudier, Formater, transformer et transfÃ©rer les donnÃ©es ingÃ©rÃ©es dans notre Data Warehouse provenant de nos diffÃ©rents domaines dâ€™activitÃ© avec Dagster, et Airbyte
Mettre en place les tests nÃ©cessaires pour vÃ©rifier leur cohÃ©rence avec DBT et BigQuery
Mettre en place les KPI, et tableaux de bord pour leur comprÃ©hension avec Metabase
Documenter les donnÃ©es dans DBT
Faire Ã©voluer ces modÃ¨les de donnÃ©es
Nous nous efforcerons de mettre en place les meilleurs pratiques afin de toujours nous amÃ©liorer et apprendre un maximum les uns des autres :
IntÃ©gration continue
DÃ©ploiement continu
Tests
Code review
Pair-programming
Voir moins","Profil recherchÃ©
Issu dâ€™un cursus dâ€™Ã©cole dâ€™ingÃ©nieur
Excellente connaissance de SQL et Python
Une premiÃ¨re expÃ©rience de 2 ans minimum dans un poste similaire
ExpÃ©rience avec Git
Une expÃ©rience avec DBT, GCP et Airbyte serait fortement apprÃ©ciÃ©e
Savoir lire et complÃ©ter de la documentation en Anglais
Un esprit entrepreneurial et un goÃ»t prononcÃ© pour les challenges.
Une volontÃ© de grandir vite et de gagner rapidement en autonomie"
Medical Data Engineer H/F,"{'name': 'GLEAMER', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, SantÃ©', 'employees': '68 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,> Bac +5 / Doctorat,"Descriptif du poste
Joining the Data Team means immersing yourself in an environment that fosters a profound grasp of the medical domain central to our mission.
You will have the opportunity to leverage a massive medical database of about ten million exams. Itâ€™s a formidable and rare context for creating Medical Devices that meet and exceed the performance of expert humans in the field, thus improving the care of millions of patients every month.
As a member of the Data Team, you will collaborate closely with Radiologists, Product Managers, AI Engineers and Software Developers to build and improve our medical products.
Working at Gleamer means bringing your enthusiasm for enhancing peopleâ€™s health and embracing the deep conviction that kindness is the cornerstone of a great work environment.
Missions:
Build and structure medically relevant and representative datasets.
Refine NLP techniques to unveil data insights.
Establish relevant annotation guidelines and training to ensure annotation quality.
Be a stakeholder in the ongoing overseeing and refinement of AI algorithm performance.
Contribute to clinical studies to scientifically assess the impact of our Medical Devices.","Profil recherchÃ©
PhD in the fields, but not limited to, Data & Computer Science, Bio-Informatics, Medical Physics
Hard Skills
Strong reasoning abilities and attention to detail.
Analytical and scientific mindset
Proficiency in a programming language
Soft Skills
Good communication skills
Driven to solve medical problems
Fluent in French. Proficient English level
Nice-to-have
Knowledge of medical imaging is a plus
Machine learning understanding is a plus"
Data Engineer Intern,"{'name': 'GLEAMER', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, SantÃ©', 'employees': '68 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '31 ans'}","Stage
(6 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,Bac +5 / Master,"Descriptif du poste
Au sein de lâ€™Ã©quipe Data, tu occuperas une position clef Ã  lâ€™interface de nombreux sujets. En charge de problÃ©matiques diversifiÃ©es et en Ã©troite collaboration avec les radiologues, lâ€™Ã©quipe IA et de dÃ©veloppement, tu contribueras Ã  concevoir des produits mÃ©dicaux innovants et ambitieux.
Ta mission principale sera de prendre en charge les problÃ©matiques Data de nos produits BoneView puis ChestView. Dans cette optique, tu seras amenÃ© Ã  :
Assurer la qualitÃ© et le suivi des annotations ;
Participer Ã  la rÃ©flexion sur les stratÃ©gies dâ€™annotation et les outils utilisÃ©s ;
Participer Ã  la crÃ©ation des datasets et Ã  la rÃ©flexion sur les performances des algorithmes dâ€™IA ;
Assurer les formations des labellisateurs ;
Enrichir les mÃ©thodes de traitement du langage afin dâ€™optimiser lâ€™annotation.
En tant que membre de lâ€™Ã©quipe Data, tu pourras aussi Ãªtre amenÃ© Ã  :
Mettre en place et suivre la qualitÃ© des imports de donnÃ©es ;
Assurer lâ€™intÃ©gritÃ© de la base de donnÃ©es ;
Participer Ã  des tÃ¢ches en lien avec les Ã©tudes cliniques.","Profil recherchÃ©
DerniÃ¨re annÃ©e dâ€™Ã©tude (Bac+5/Master)
Bonne maÃ®trise de langage de programmation Python et/ou Java ;
Rigueur scientifique et regard critique nÃ©cessaires ;
Bonnes capacitÃ©s de communication ;
Fort intÃ©rÃªt pour le domaine mÃ©dical (des connaissances en imagerie mÃ©dicale/norme Dicom sont un plus) ;
Connaissances en bases de donnÃ©es ;
Bon niveau dâ€™anglais."
Senior Data Engineer,"{'name': 'FABERNOVEL', 'sector': 'IT / Digital, StratÃ©gie, Transformation, Formation', 'employees': '350 collaborateurs', 'creation_year': '2003', 'turnover': None, 'mean_age': '29 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,> 5 ans,,"Descriptif du poste
Descriptif du poste
Tu rejoindra notre team Data ! Tu participeras Ã  la rÃ©alisation de solutions, en collaboration Ã©troite avec des machine learning engineer, software architect, designers, developers...
Force de proposition en interne, tu interviendras pour Ãªtre garant du dÃ©veloppement d'architecture Data, de la collecte multi-source de donnÃ©es, du pilotage et de la pertinence de ces derniÃ¨res.
Tu viendras complÃ©ter l'offre par tes connaissances techniques
ActivitÃ©s principales :
ComprÃ©hension des conceptions d'architecture data et des systÃ¨mes distribuÃ©s
Conception et modÃ©lisation des pipelines de donnÃ©es en assurant un stockage et une interrogation efficace
DÃ©veloppement des traitements de donnÃ©es et de leur exploitation
MaÃ®trise l'ensemble des techniques, technologies et concepts utilisÃ©s
Responsable de la qualitÃ© technique sur le pÃ©rimÃ¨tre confiÃ©
Contribuer Ã  la CI/CD avec TechLead et Ops
Accompagnement des juniors dans leur montÃ©e en compÃ©tence (pair programming, prÃ©sentation sur des sujets techs, management...)
Tu auras la chance d'arriver Ã  un moment charniÃ¨re pour les Ã©quipes Datas, tu pourras ainsi participer aux diffÃ©rents changements qui s'opÃ©rent et batir avec eux le nouveau socle Data de Fabernovel en s'appropriant des nouveaux sujets : Datawarehouse, Big Data ... Chez Fabernovel nous sommes des chimistes, nous experimentons et crÃ©ons !
Profil recherchÃ© :

Nous recherchons avant tout une personne avec des compÃ©tences en dÃ©veloppement logiciel ayant au moins 7 ans dâ€™expÃ©rience et qui a un attrait pour les problÃ©matiques data.
 Notre futur talent est :
En plus de tes compÃ©tences techniques, nous recherchons une personne curieuse, bienveillante, qui soit autonome et force de proposition.
Tu as un bon niveau en programmation fonctionnelle (ex : Scala, Rust)
Tu as dÃ©jÃ  collaborÃ© en workflows Git (One flow, Trunk based)
Tu es expert en base donnÃ©es SQL / NoSQL
Tu maitrise les systÃ¨mes et calcul distribuÃ©s
Tu as une expÃ©rience significative sur plusieurs projets de stream processing sur une ou plusieurs des technos suivantes : Akka, Kafka, Spark
Tu as dÃ©jÃ  travaillÃ© sur un Cloud Provider: AWS, GCP, Azure, IBM
Bonus : tu connais l'untilisation de Kubernetes, Docker ou Airflow.
Tu sais communiquer de faÃ§on claire et prÃ©cise et fait preuve dâ€™un esprit de synthÃ¨se.
 Ce que nous offrons Ã  tous nos talents
Des projets riches et impactants, chez Fabernovel nous transformons les environnements, les situations, avec nos propres mÃ©thodes et secrets de fabrication.
Une sociÃ©tÃ© apprenante ou nous avons conÃ§u notre propre Learning development factory pour un partage de connaissance et un apprentissage continue.
Un management fondÃ© sur la bienveillance, il nâ€™y a pas dâ€™Ã©chec, seulement des itÃ©rations et des occasions dâ€™apprendre.
De la libertÃ© dans ses choix : Flex office, horaires amÃ©nageables, possibilitÃ© de remote, culture de lâ€™intrapreunariat.
Des avantages toujours sympa, avec des locaux au coeur de Paris, des paniers fruits, du cafÃ©/thÃ©, des salles de jeux techs et low techs, ainsi que des salles de siestes.
Mais aussiâ€¦
Une Carte Swile prise en charge Ã  60% par Fabernovel
AccÃ¨s Ã  des offres privilÃ¨ges Gymlib
Remboursement de 50% des transports
RTT
PC ou MacBook
Ã€ propos de nous :
CrÃ©Ã© en 2003 au cÅ“ur de lâ€™Ã©cosystÃ¨me numÃ©rique franÃ§ais, Fabernovel naÃ®t dâ€™une conviction : celle que la technologie a le pouvoir de construire un futur plus vertueux pour les entreprises et le monde qui les entoure.
Aujourdâ€™hui, ce sont 350 talents, sur 3 continents, experts du conseil en transformation numÃ©rique et de la crÃ©ation de produits et de services numÃ©riques. Nous maÃ®trisons les expertises liÃ©es au design, aux technologies, au marketing et aux cultures nouvelles dans lâ€™entreprise et accompagnons de grandes entreprises de tous secteurs dâ€™activitÃ© dans leur projet de transformation digitale et culturelle.
Cette Talent Company rassemble Designers, Strategists, Project Analysts, Developers, Data Architects, Product Managers, Media Specialists, Finance Managers, Communication Managers, Business Developersâ€¦qui font naÃ®tre lâ€™innovation chez nos clients. Nous activons pour nos clients les meilleures combinatoires de talents individuels et de mÃ©thodologies Ã  la pointe, avec toujours lâ€™objectif de les rendre le plus autonome possible.
Voir moins",
Senior data engineer H/F,"{'name': 'INVIVO DIGITAL FACTORY', 'sector': 'IT / Digital, E-commerce', 'employees': '68 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '30 ans'}",CDI,Courbevoie,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,01 mars 2024,> 5 ans,Bac +4,"Descriptif du poste
Au sein des Ã©quipes Digital Factory du Groupe InVivo, vous prenez en charge la collecte des donnÃ©es issues de sources et de volumÃ©tries variÃ©es (systÃ¨mes dâ€™information traditionnel ou No SQL, systÃ¨mes de production, IoT, log, Events, â€¦). Vous assurez la connectivitÃ© vers les diffÃ©rentes sources, analysez le modÃ¨le des donnÃ©es sources et comprenez les problÃ©matiques mÃ©tier afin de dÃ©finir une modÃ©lisation adÃ©quate des DataSets.
Vous prenez en charge la transformation de ces donnÃ©es (nettoyage, normalisation, et prÃ©paration), pour y appliquer les traitements analytiques conÃ§us par les Data Scientists, ou les traitements dÃ©cisionnels conÃ§us par les Data Analysts.
En tant que sÃ©nior de lâ€™Ã©quipe Data Engineering, vous assurez la relation avec les PO et apportez, au reste de lâ€™Ã©quipe, votre maÃ®trise des architectures de flux de donnÃ©es, votre expÃ©rience sur la qualitÃ© des flux et des donnÃ©es ainsi que sur la sÃ©curitÃ©.
Vous participez activement Ã  lâ€™acculturation des mÃ©tiers.
Les locaux de la Digital Factory sont basÃ©s Ã  La DÃ©fense. TÃ©lÃ©travail Ã  hauteur de 60%.
ğŸ±â€ğŸLes missions
Recueillir les besoins en donnÃ©es (Data Product Owner, Data Analysts, Data Scientists) et analyser les sources de donnÃ©es, identifier de nouvelles sources de donnÃ©es pertinentes.
Coordonner la mise en place de lâ€™architecture Data & Analytics, conÃ§ue avec le data architect et en garantir le bon fonctionnement, la disponibilitÃ©, lâ€™Ã©volution et la performance technique des outils
DÃ©velopper les pipelines dâ€™intÃ©gration de donnÃ©es et la data quality en collaboration avec les Data Product Owner, Data Analysts et Data Scientists
Garantir lâ€™industrialisation et lâ€™automatisation de la chaÃ®ne de valeur de la donnÃ©e, en y intÃ©grant les algorithmes dÃ©cisionnels et les modÃ¨les de prÃ©diction des donnÃ©es
Effectuer une veille sur les nouvelles technologies et solutions et participer activement Ã  lâ€™effort R&D
Contribuer Ã  lâ€™Ã©volution des pratiques dans son domaine de compÃ©tences, en Ã©tant actif dans des rÃ©seaux de veille
Voir moins","Profil recherchÃ©
ğŸ‘¨â€ğŸ“ De formation Bac+5 Ã©cole dâ€™ingÃ©nieur orientÃ© dÃ©veloppement, ou master spÃ©cialisÃ© en data, avec une spÃ©cialisation Big Data, vous Ãªtes passionnÃ©.e par lâ€™innovation et les technologies liÃ©es aux domaines Data Analytics & AI. Vous avez une expÃ©rience dâ€™au moins 5 ans sur un poste similaire.
Vous faites preuve dâ€™une grande capacitÃ© dâ€™adaptation et capacitÃ© Ã  communiquer avec des interlocuteurs multiples.
Vous Ãªtes rigoureux.se, force de proposition, vous avez un bon esprit dâ€™analyse et de synthÃ¨se. Vous apprÃ©ciez le travail en Ã©quipe. Vous disposez dâ€™une bonne capacitÃ© dâ€™organisation, autonomie et sens de lâ€™initiative. MaÃ®trise de lâ€™anglais indispensable.
De fortes aptitudes en dÃ©veloppement, notamment Ã  travers une excellente maÃ®trise de langages de programmation comme : Python, C#, â€¦
Bonne connaissance de la conception, lâ€™audit et du dÃ©ploiement dâ€™architecture logicielle et technique autour des plateformes dÃ©cisionnelles et des plateformes Big Data (Spark, Hadoopâ€¦)
Une excellente maÃ®trise du langage SQL, des bases dans la programmation de quelques bases de donnÃ©es NoSQL (Neo4j, MongoDB, â€¦)
Excellente maÃ®trise des outils et techniques dâ€™analyses des donnÃ©es et des mÃ©thodologies statistiques.
Voir plus"
[Luxe] | Cloud Data Engineer ExpÃ©rimentÃ© (H/F) PARIS,"{'name': 'CENOVA', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Transformation', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '32 ans'}",CDI,Neuilly-sur-Seine,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
VOTRE FUTURE MISSION :
Vous travaillerez pour le compte de lâ€™un de nos clients, au sein de lâ€™Ã©quipe Data sur le dÃ©veloppement de solutions Data Analytics. Vos principales missions seront les suivantes :
Â·         Concevoir et mettre en Å“uvre des solutions de traitement de donnÃ©es dans un environnement #Cloud
Â·         Mener des Ã©tudes de faisabilitÃ© et prÃ©coniser les architectures data cibles
Â·         CrÃ©er, tester et dÃ©ployer des pipelines de donnÃ©es dâ€™extraction, de transformation et de chargement
Â·         Mettre en application les concepts de CI/CD via les outils dÃ©diÃ©s
Â·         Participer Ã  la mise en Å“uvre de produits de Data visualisation : dashboard, reportingâ€¦
Â·         Participer aux ateliers de collecte des besoins auprÃ¨s des Ã©quipes mÃ©tiers
Â·         RÃ©diger la documentation (spÃ©cification techniques, document dâ€™exploitation, dossier dâ€™architectureâ€¦) et analyser les solutions les plus adaptÃ©es
Â·         Assister les phases de recette utilisateurs (identification ou mise en place de jeux de tests, recueil et traitement des demandes de changements)
Â·         Accompagner et former les utilisateurs Ã  la prise en main des solutions
Environnement technique :
Â·         Cloud : #Azure, #GCP, #AWS
Â·         Langages : SQL, Python, Spark, Scala, Javascript
Â·         Base de donnÃ©es : SQL Server/SQL Cloud, Google BigQuery, Oracle, MySQL, MongoDB
Â·         Datamanagement : Azure Data Factory / Databricks/ Synapse (idÃ©alement), Google Cloud Data Fusion / Datafllow, DBT, Talend, SQL Server Integration Services.
Â·         Datavisualisation : Power BI (idÃ©alement), Tableau, Qlik, DataStudio/Looker
Â·         Repository : GIT, Azure DevOps, SVN
Â·         SystÃ¨mes dâ€™exploitation : Unix, Linux, Windows
Voir moins","Profil recherchÃ©
Vous avez une expÃ©rience minimale de 2 ans sur des missions de Data Engineering et vous disposez dâ€™une grande appÃ©tence technique.
Vous apprÃ©ciez comprendre le cycle de vie de la donnÃ©e et vous Ãªtes amateur de datavisualisation, notamment sur PowerBI.
Vous avez par ailleurs, le contact facile et vous comprenez les enjeux business et adaptez vos analyses en ce sens.
Vous Ãªtes proactif(ve), autonome, bon(ne) communiquant(e) et vous Ãªtes Ã  lâ€™aise en anglais."
Data Engineer,"{'name': 'CONSORTIA', 'sector': 'Big Data', 'employees': '515 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '35 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
LOCALISATION : Limay (78), 2 jours de tÃ©lÃ©travail
Accompagnement de lâ€™Ã©quipe Data en charge du dÃ©ploiement de la gouvernance Data
Â·â€ƒâ€ƒReprise et maintien du pÃ©rimÃ¨tre Data dâ€™une de nos filliales.
Â·â€ƒâ€ƒPrise en main et maintenance de lâ€™architecture Data Sarpi en cours de conception.
Â·â€ƒâ€ƒEvolution du modÃ¨le et intÃ©gration de nouvelles sources de donnÃ©es.
Â·â€ƒâ€ƒAccompagnement stratÃ©gique en termes dâ€™architecture auprÃ¨s du chef de projet.
Â·â€ƒâ€ƒPrise en main de lâ€™ETL Snaplogic pour le dÃ©veloppement et la documentation des flux dâ€™intÃ©gration de donnÃ©es.
Â·â€ƒâ€ƒUtilisation de lâ€™outil GCP BigQuery pour la construction des vues MÃ©tier et calcul dâ€™indicateurs.
Â·â€ƒâ€ƒMise en place et maintien de la sÃ©curitÃ© dâ€™accÃ¨s aux donnÃ©es et le support niveau 2 sur lâ€™outil Looker Studio.","Profil recherchÃ©
Une expÃ©rience significative (minimum 3 ans) sur des projets Data en tant que Data Engineer / Data Architect
CompÃ©tences requises : 
Â·â€ƒâ€ƒConnaissance des outils de la Google Cloud Platform (BigQuery, Looker Studio) avec les langages associÃ©s
Â·â€ƒâ€ƒUsage dâ€™ETL
CompÃ©tences comportementales :
Â·â€ƒâ€ƒCapacitÃ© dâ€™Ã©coute, dâ€™analyse et de synthÃ¨se
Â·â€ƒâ€ƒAptitude Ã  travailler en Ã©quipe
Â·â€ƒâ€ƒAptitude Ã  travailler de faÃ§on autonome avec un bon sens de lâ€™initiative."
(Senior) Data Engineer,"{'name': 'MIRAKL', 'sector': 'SaaS / Cloud Services, E-commerce', 'employees': '750 collaborateurs', 'creation_year': '2012', 'turnover': None, 'mean_age': '33 ans'}",CDI,Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail total,,> 4 ans,,"Descriptif du poste
Mirakl, leader et pionnier de lâ€™Ã©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accÃ©lÃ©rer de faÃ§on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancÃ©e, sÃ©curisÃ©e et Ã©volutive leur permettant de digitaliser leur activitÃ© et d'Ã©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacitÃ©, offrir une expÃ©rience d'achat personnalisÃ©e Ã  leurs clients, et augmenter leurs profits grÃ¢ce au retail media. BasÃ©e Ã  Paris et Boston, Mirakl est certifiÃ©e Great Place to Work.
A propos de Mirakl Labs
Nos Ã©quipes techniques et produits, nommÃ©es Mirakl Labs, sont principalement rÃ©parties entre nos 2 hubs situÃ©s Ã  Paris et Ã  Bordeaux. Elles collaborent au quotidien afin d'adresser les problÃ©matiques de nos clients et utilisateurs en rÃ©pondant Ã  diffÃ©rents challenges liÃ©s aux nouvelles fonctionnalitÃ©s, Ã  la scalabilitÃ©, la sÃ©curitÃ© et lâ€™ergonomieâ€¦
Elles opÃ¨rent en mode agile et s'organisent en Squads composÃ©es d'un Squad Lead, de 5 dÃ©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est spÃ©cialisÃ©e sur un scope fonctionnel afin de concevoir et rÃ©aliser de nouvelles features, leurs Ã©volutions et des APIs (avec un dÃ©coupage en micro-services). Nos Ã©quipes Infrastructure, Architecture, SÃ©curitÃ©, Documentation, Product Design, Data et Support opÃ¨rent en transverse en apportant leur expertise et de la cohÃ©rence sur lâ€™ensemble des produits.
Toutes les Ã©quipes sont responsables de leur pÃ©rimÃ¨tre et chacun des collaborateurs apporte son expÃ©rience et ses idÃ©es. Innovation, feedback et implication dans les prises de dÃ©cision sont au cÅ“ur de notre philosophie.
Et pour favoriser ce partage avec dâ€™autres passionnÃ©s, nous sommes sponsors, speakers, et hÃ´tes de diffÃ©rents Ã©vÃ©nements, meetups, et associations de la scÃ¨ne Tech en France. Au cours des derniÃ¨res annÃ©es, nous avons participÃ© Ã  des Ã©vÃ©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerÃ§ants Ã  travers le monde. Cette solution gÃ¨re et produit de gros volumes de donnÃ©es qui prÃ©sentent des challenges extrÃªmement intÃ©ressants pour les spÃ©cialistes de la donnÃ©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donnÃ©es de navigation, sÃ©ries temporelles, donnÃ©es gÃ©olocalisÃ©es etc.).
En tant que (Senior) Data Engineer au sein de lâ€™Ã©quipe Data Mirakl, vos principales missions seront de :
contribuer Ã  l'enrichissement de la Data Platform (ETL)
amÃ©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (infÃ©rence real time etc.)
IntÃ©grÃ©(e) dans une Ã©quipe de spÃ©cialistes de la donnÃ©e (data engineers, machine learning engineers, data scientists, data analysts), vous Ãªtes un des acteurs clÃ©s pour garantir la place de Mirakl comme solution dominante sur son marchÃ©.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer Ã  la dÃ©finition et Ã  lâ€™implÃ©mentation dâ€™une architecture performante, robuste, scalable et aux coÃ»ts maÃ®trisÃ©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (Ã©valuation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et amÃ©liorer la CI/CD de lâ€™Ã©quipe en collaboration avec lâ€™Ã©quipe SRE
Assurer la montÃ©e en compÃ©tence des membres de lâ€™Ã©quipe sur les sujets de MLOps et Data Engineering
RÃ©flÃ©chir Ã  la meilleure faÃ§on d'intÃ©grer les donnÃ©es Google Analytics dans la data platform
Partager ses connaissances et prÃ©senter les travaux devant toutes les Ã©quipes Labs
Ce quâ€™on peut vous apporter :
Des projets data driven, divers et variÃ©s (traitements massifs dâ€™images, de textes, time series etc.) pour des produits diffÃ©rents de Mirakl
Une culture orientÃ©e sur la veille technologique
Des projets qui ont un vrai impact business devant Ãªtre dÃ©ployÃ©s sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des donnÃ©es produit Ã  partir des images et des descriptions
ModÃ©ration automatique des produits
Mapping automatique des donnÃ©es produit
Identification des produits Ã  fort potentiels
DÃ©tection de comportements frauduleux
Sentiment analysis sur les messages Ã©changÃ©s entre clients et vendeurs et dans les Ã©valuations
DÃ©termination de prix optimaux
Monitoring de la qualitÃ© de service des vendeurs
Des applications dâ€™infÃ©rence en synchrone de nos modÃ¨les de ML
Vous aimerez ce job si :
Vous Ãªtes passionnÃ©(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous intÃ©ressez Ã  la data science et avez des connaissances gÃ©nÃ©rales sur les algorithmes de Machine Learning
Vous avez un background en dÃ©veloppement et avez Ã©voluÃ© dans un environnement Data
Vous avez a minima 4 ans dâ€™expÃ©rience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succÃ¨s des applications Big Data faisant appel Ã  du Machine Learning, du NLP, du traitement dâ€™images dans des projets d'envergure, Ã  fort volume de donnÃ©es
Votre maÃ®trisez Python, Ãªtes un pro des frameworks data de la fondation Apache et Ãªtes Ã  l'aise dans un environnement AWS
Vous maÃ®trisez au moins un outil dâ€™orchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous prÃ©sentez vos travaux de maniÃ¨re simple et accessible
Vous faÃ®tes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et franÃ§ais
Les plus pour le poste :
Vous avez une expÃ©rience significative dans le domaine du e-commerce
Vous avez dÃ©jÃ  mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez dÃ©ployÃ© des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de donnÃ©es avec une approche CDC Ã  l'aide de Debezium ou autre
Vous maÃ®trisez Java/Scala
Mirakl est engagÃ©e en faveur de la diversitÃ©, de lâ€™Ã©galitÃ© des chances et de lâ€™inclusion. Nous cÃ©lÃ©brons nos diffÃ©rences car nous sommes convaincus que les qualitÃ©s visibles et invisibles de chaque Mirakl Worker sont une source de force et dâ€™innovation. Dans le cadre de cet engagement, nous Ã©tudions toutes les candidatures sans distinction de : genre, ethnicitÃ©, religion, orientation sexuelle, handicap, Ã¢ge ou toute autre caractÃ©ristique protÃ©gÃ©e par la loi.
Voir moins",
(Senior) Data Engineer,"{'name': 'MIRAKL', 'sector': 'SaaS / Cloud Services, E-commerce', 'employees': '750 collaborateurs', 'creation_year': '2012', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 4 ans,,"Descriptif du poste
Mirakl, leader et pionnier de lâ€™Ã©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accÃ©lÃ©rer de faÃ§on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancÃ©e, sÃ©curisÃ©e et Ã©volutive leur permettant de digitaliser leur activitÃ© et d'Ã©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacitÃ©, offrir une expÃ©rience d'achat personnalisÃ©e Ã  leurs clients, et augmenter leurs profits grÃ¢ce au retail media. BasÃ©e Ã  Paris et Boston, Mirakl est certifiÃ©e Great Place to Work.
A propos de Mirakl Labs
Nos Ã©quipes techniques et produits, nommÃ©es Mirakl Labs, sont principalement rÃ©parties entre nos 2 hubs situÃ©s Ã  Paris et Ã  Bordeaux. Elles collaborent au quotidien afin d'adresser les problÃ©matiques de nos clients et utilisateurs en rÃ©pondant Ã  diffÃ©rents challenges liÃ©s aux nouvelles fonctionnalitÃ©s, Ã  la scalabilitÃ©, la sÃ©curitÃ© et lâ€™ergonomieâ€¦
Elles opÃ¨rent en mode agile et s'organisent en Squads composÃ©es d'un Squad Lead, de 5 dÃ©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est spÃ©cialisÃ©e sur un scope fonctionnel afin de concevoir et rÃ©aliser de nouvelles features, leurs Ã©volutions et des APIs (avec un dÃ©coupage en micro-services). Nos Ã©quipes Infrastructure, Architecture, SÃ©curitÃ©, Documentation, Product Design, Data et Support opÃ¨rent en transverse en apportant leur expertise et de la cohÃ©rence sur lâ€™ensemble des produits.
Toutes les Ã©quipes sont responsables de leur pÃ©rimÃ¨tre et chacun des collaborateurs apporte son expÃ©rience et ses idÃ©es. Innovation, feedback et implication dans les prises de dÃ©cision sont au cÅ“ur de notre philosophie.
Et pour favoriser ce partage avec dâ€™autres passionnÃ©s, nous sommes sponsors, speakers, et hÃ´tes de diffÃ©rents Ã©vÃ©nements, meetups, et associations de la scÃ¨ne Tech en France. Au cours des derniÃ¨res annÃ©es, nous avons participÃ© Ã  des Ã©vÃ©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerÃ§ants Ã  travers le monde. Cette solution gÃ¨re et produit de gros volumes de donnÃ©es qui prÃ©sentent des challenges extrÃªmement intÃ©ressants pour les spÃ©cialistes de la donnÃ©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donnÃ©es de navigation, sÃ©ries temporelles, donnÃ©es gÃ©olocalisÃ©es etc.).
En tant que (Senior) Data Engineer au sein de lâ€™Ã©quipe Data Mirakl, vos principales missions seront de :
contribuer Ã  l'enrichissement de la Data Platform (ETL)
amÃ©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (infÃ©rence real time etc.)
IntÃ©grÃ©(e) dans une Ã©quipe de spÃ©cialistes de la donnÃ©e (data engineers, machine learning engineers, data scientists, data analysts), vous Ãªtes un des acteurs clÃ©s pour garantir la place de Mirakl comme solution dominante sur son marchÃ©.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer Ã  la dÃ©finition et Ã  lâ€™implÃ©mentation dâ€™une architecture performante, robuste, scalable et aux coÃ»ts maÃ®trisÃ©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (Ã©valuation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et amÃ©liorer la CI/CD de lâ€™Ã©quipe en collaboration avec lâ€™Ã©quipe SRE
Assurer la montÃ©e en compÃ©tence des membres de lâ€™Ã©quipe sur les sujets de MLOps et Data Engineering
RÃ©flÃ©chir Ã  la meilleure faÃ§on d'intÃ©grer les donnÃ©es Google Analytics dans la data platform
Partager ses connaissances et prÃ©senter les travaux devant toutes les Ã©quipes Labs
Ce quâ€™on peut vous apporter :
Des projets data driven, divers et variÃ©s (traitements massifs dâ€™images, de textes, time series etc.) pour des produits diffÃ©rents de Mirakl
Une culture orientÃ©e sur la veille technologique
Des projets qui ont un vrai impact business devant Ãªtre dÃ©ployÃ©s sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des donnÃ©es produit Ã  partir des images et des descriptions
ModÃ©ration automatique des produits
Mapping automatique des donnÃ©es produit
Identification des produits Ã  fort potentiels
DÃ©tection de comportements frauduleux
Sentiment analysis sur les messages Ã©changÃ©s entre clients et vendeurs et dans les Ã©valuations
DÃ©termination de prix optimaux
Monitoring de la qualitÃ© de service des vendeurs
Des applications dâ€™infÃ©rence en synchrone de nos modÃ¨les de ML
Vous aimerez ce job si :
Vous Ãªtes passionnÃ©(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous intÃ©ressez Ã  la data science et avez des connaissances gÃ©nÃ©rales sur les algorithmes de Machine Learning
Vous avez un background en dÃ©veloppement et avez Ã©voluÃ© dans un environnement Data
Vous avez a minima 4 ans dâ€™expÃ©rience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succÃ¨s des applications Big Data faisant appel Ã  du Machine Learning, du NLP, du traitement dâ€™images dans des projets d'envergure, Ã  fort volume de donnÃ©es
Votre maÃ®trisez Python, Ãªtes un pro des frameworks data de la fondation Apache et Ãªtes Ã  l'aise dans un environnement AWS
Vous maÃ®trisez au moins un outil dâ€™orchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous prÃ©sentez vos travaux de maniÃ¨re simple et accessible
Vous faÃ®tes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et franÃ§ais
Les plus pour le poste :
Vous avez une expÃ©rience significative dans le domaine du e-commerce
Vous avez dÃ©jÃ  mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez dÃ©ployÃ© des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de donnÃ©es avec une approche CDC Ã  l'aide de Debezium ou autre
Vous maÃ®trisez Java/Scala
Mirakl est engagÃ©e en faveur de la diversitÃ©, de lâ€™Ã©galitÃ© des chances et de lâ€™inclusion. Nous cÃ©lÃ©brons nos diffÃ©rences car nous sommes convaincus que les qualitÃ©s visibles et invisibles de chaque Mirakl Worker sont une source de force et dâ€™innovation. Dans le cadre de cet engagement, nous Ã©tudions toutes les candidatures sans distinction de : genre, ethnicitÃ©, religion, orientation sexuelle, handicap, Ã¢ge ou toute autre caractÃ©ristique protÃ©gÃ©e par la loi.
Voir moins",
(Senior) Data Engineer,"{'name': 'MIRAKL', 'sector': 'SaaS / Cloud Services, E-commerce', 'employees': '750 collaborateurs', 'creation_year': '2012', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail total,,> 4 ans,,"Descriptif du poste
Mirakl, leader et pionnier de lâ€™Ã©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accÃ©lÃ©rer de faÃ§on durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancÃ©e, sÃ©curisÃ©e et Ã©volutive leur permettant de digitaliser leur activitÃ© et d'Ã©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacitÃ©, offrir une expÃ©rience d'achat personnalisÃ©e Ã  leurs clients, et augmenter leurs profits grÃ¢ce au retail media. BasÃ©e Ã  Paris et Boston, Mirakl est certifiÃ©e Great Place to Work.
A propos de Mirakl Labs
Nos Ã©quipes techniques et produits, nommÃ©es Mirakl Labs, sont principalement rÃ©parties entre nos 2 hubs situÃ©s Ã  Paris et Ã  Bordeaux. Elles collaborent au quotidien afin d'adresser les problÃ©matiques de nos clients et utilisateurs en rÃ©pondant Ã  diffÃ©rents challenges liÃ©s aux nouvelles fonctionnalitÃ©s, Ã  la scalabilitÃ©, la sÃ©curitÃ© et lâ€™ergonomieâ€¦
Elles opÃ¨rent en mode agile et s'organisent en Squads composÃ©es d'un Squad Lead, de 5 dÃ©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est spÃ©cialisÃ©e sur un scope fonctionnel afin de concevoir et rÃ©aliser de nouvelles features, leurs Ã©volutions et des APIs (avec un dÃ©coupage en micro-services). Nos Ã©quipes Infrastructure, Architecture, SÃ©curitÃ©, Documentation, Product Design, Data et Support opÃ¨rent en transverse en apportant leur expertise et de la cohÃ©rence sur lâ€™ensemble des produits.
Toutes les Ã©quipes sont responsables de leur pÃ©rimÃ¨tre et chacun des collaborateurs apporte son expÃ©rience et ses idÃ©es. Innovation, feedback et implication dans les prises de dÃ©cision sont au cÅ“ur de notre philosophie.
Et pour favoriser ce partage avec dâ€™autres passionnÃ©s, nous sommes sponsors, speakers, et hÃ´tes de diffÃ©rents Ã©vÃ©nements, meetups, et associations de la scÃ¨ne Tech en France. Au cours des derniÃ¨res annÃ©es, nous avons participÃ© Ã  des Ã©vÃ©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerÃ§ants Ã  travers le monde. Cette solution gÃ¨re et produit de gros volumes de donnÃ©es qui prÃ©sentent des challenges extrÃªmement intÃ©ressants pour les spÃ©cialistes de la donnÃ©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donnÃ©es de navigation, sÃ©ries temporelles, donnÃ©es gÃ©olocalisÃ©es etc.).
En tant que (Senior) Data Engineer au sein de lâ€™Ã©quipe Data Mirakl, vos principales missions seront de :
contribuer Ã  l'enrichissement de la Data Platform (ETL)
amÃ©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (infÃ©rence real time etc.)
IntÃ©grÃ©(e) dans une Ã©quipe de spÃ©cialistes de la donnÃ©e (data engineers, machine learning engineers, data scientists, data analysts), vous Ãªtes un des acteurs clÃ©s pour garantir la place de Mirakl comme solution dominante sur son marchÃ©.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer Ã  la dÃ©finition et Ã  lâ€™implÃ©mentation dâ€™une architecture performante, robuste, scalable et aux coÃ»ts maÃ®trisÃ©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (Ã©valuation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et amÃ©liorer la CI/CD de lâ€™Ã©quipe en collaboration avec lâ€™Ã©quipe SRE
Assurer la montÃ©e en compÃ©tence des membres de lâ€™Ã©quipe sur les sujets de MLOps et Data Engineering
RÃ©flÃ©chir Ã  la meilleure faÃ§on d'intÃ©grer les donnÃ©es Google Analytics dans la data platform
Partager ses connaissances et prÃ©senter les travaux devant toutes les Ã©quipes Labs
Ce quâ€™on peut vous apporter :
Des projets data driven, divers et variÃ©s (traitements massifs dâ€™images, de textes, time series etc.) pour des produits diffÃ©rents de Mirakl
Une culture orientÃ©e sur la veille technologique
Des projets qui ont un vrai impact business devant Ãªtre dÃ©ployÃ©s sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des donnÃ©es produit Ã  partir des images et des descriptions
ModÃ©ration automatique des produits
Mapping automatique des donnÃ©es produit
Identification des produits Ã  fort potentiels
DÃ©tection de comportements frauduleux
Sentiment analysis sur les messages Ã©changÃ©s entre clients et vendeurs et dans les Ã©valuations
DÃ©termination de prix optimaux
Monitoring de la qualitÃ© de service des vendeurs
Des applications dâ€™infÃ©rence en synchrone de nos modÃ¨les de ML
Vous aimerez ce job si :
Vous Ãªtes passionnÃ©(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous intÃ©ressez Ã  la data science et avez des connaissances gÃ©nÃ©rales sur les algorithmes de Machine Learning
Vous avez un background en dÃ©veloppement et avez Ã©voluÃ© dans un environnement Data
Vous avez a minima 4 ans dâ€™expÃ©rience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succÃ¨s des applications Big Data faisant appel Ã  du Machine Learning, du NLP, du traitement dâ€™images dans des projets d'envergure, Ã  fort volume de donnÃ©es
Votre maÃ®trisez Python, Ãªtes un pro des frameworks data de la fondation Apache et Ãªtes Ã  l'aise dans un environnement AWS
Vous maÃ®trisez au moins un outil dâ€™orchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous prÃ©sentez vos travaux de maniÃ¨re simple et accessible
Vous faÃ®tes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et franÃ§ais
Les plus pour le poste :
Vous avez une expÃ©rience significative dans le domaine du e-commerce
Vous avez dÃ©jÃ  mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez dÃ©ployÃ© des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de donnÃ©es avec une approche CDC Ã  l'aide de Debezium ou autre
Vous maÃ®trisez Java/Scala
Mirakl est engagÃ©e en faveur de la diversitÃ©, de lâ€™Ã©galitÃ© des chances et de lâ€™inclusion. Nous cÃ©lÃ©brons nos diffÃ©rences car nous sommes convaincus que les qualitÃ©s visibles et invisibles de chaque Mirakl Worker sont une source de force et dâ€™innovation. Dans le cadre de cet engagement, nous Ã©tudions toutes les candidatures sans distinction de : genre, ethnicitÃ©, religion, orientation sexuelle, handicap, Ã¢ge ou toute autre caractÃ©ristique protÃ©gÃ©e par la loi.
Voir moins",
Data Engineer - Industrie (H/F),"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,"Descriptif du poste
Vous Ãªtes motivÃ© par les enjeux de la mobilitÃ© et de son Ã©volution, MP DATA recrute un(e) Data Engineer - Industrie (H/F) mobile France afin de travailler sur des projets innovants et Ã  impact auprÃ¨s dâ€™un acteur majeur du secteur des mobilitÃ©s.
Votre mission principale consistera en la conception et le dÃ©veloppement de solutions Data permettant la collecte, lâ€™organisation, le stockage et la modÃ©lisation des donnÃ©es dans un environnement industriel. Les outils et donnÃ©es seront Ã  destination des Data Analysts et Data Scientists en charge de valoriser les donnÃ©es dans un contexte de transformation Usine 4.0. Plus prÃ©cisÃ©ment, votre rÃ´le sera clÃ© afin de :
Permettre la collecte des donnÃ©es usine directement sur les machines et automates et mettre en place les flux de remontÃ©e de donnÃ©es
Assurer lâ€™accÃ¨s fiable, efficace et sÃ©curisÃ© aux diffÃ©rentes sources de donnÃ©es mÃ©tier et processus
Mettre en place des outils et mÃ©thodes de contrÃ´le et validation de la qualitÃ© des donnÃ©es
Optimiser les processus de collecte, transfert et stockage de la donnÃ©es (ETL) en assurant lâ€™adÃ©quation avec les contraintes techniques et opÃ©rationnelles
Maintenir les outils, technologies et processus Ã  jour, en assurant une veille technique assidue et une supervision permanente de lâ€™environnement
AccompagnÃ© par les Ã©quipes internes MP DATA, vous monterez en compÃ©tences sur la mise en place et le management des flux de donnÃ©es industriel. Vous veillerez Ã  son traitement massif et qualitatif, ainsi quâ€™Ã  son stockage et sa mise Ã  disposition.
Voir moins","Profil recherchÃ©
IngÃ©nieur dâ€™une grande Ã©cole (Centrale, Mines, Supaero, Supelec, â€¦).Suite Ã  votre cursus ingÃ©nieur ou vos expÃ©riences professionnelles, vous disposez de appÃ©tences mÃ©tiers dans les domaines de lâ€™industrie.
Vous Ãªtes intÃ©ressÃ©s par lâ€™industrie en :
Etant familier avec les protocoles de communication ou standards (OPC UA / OPC DA)
Ayant la fibre Â« Usine 4.0 Â»
Ayant des notions dâ€™automatisme dans lâ€™automobile
Connaissant les systÃ¨mes de contrÃ´le type Scada
Connaissant des rÃ©seaux de tÃ©lÃ©communication sur sites industriels
Vous Ãªtes intÃ©ressÃ©s pour vous dÃ©passer en data engineering et vous avez des premiÃ¨res expÃ©riences dans ce domaine, comme par exemple :
 C/C++ / Java / Rust
Spark / PySpark
Kafka
Cloud : AWS / GCP / Azure
Voir plus"
Data Engineer - Transport,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,05 fÃ©vrier 2024,,,"Descriptif du poste
Lâ€™environnement data vous anime, vous Ãªtes sensibles par les enjeux de transitions Ã©nergÃ©tiques et environnementaux.
MP DATA recrute un(e) Data Engineer - Data visualisation (H/F) afin de travailler pour des projets auprÃ¨s dâ€™un acteur majeur du Transport.
Conception et dÃ©veloppement de solutions permettant la collecte, lâ€™organisation, le stockage et la modÃ©lisation des donnÃ©es. Ceux-ci doivent Ãªtre suffisamment sÃ©curisÃ©s et lisibles pour les Data Analysts et Data Scientists,
Mise Ã  jour permanente sur les technologies et les langages utilisÃ©s dans le but de partager ses connaissances et aider Ã  lâ€™avancement des projets,
Contribution, sous la responsabilitÃ© opÃ©rationnelle de notre Architecte, aux meilleures pratiques, normes, politiques, mÃ©thodes, outils et procÃ©dures sur le Cluster Big Data,
Assurer lâ€™accÃ¨s aux diffÃ©rentes sources de donnÃ©es, et veiller Ã  la qualitÃ© des donnÃ©es,
Donner un accÃ¨s facilitÃ© aux Data Analysts et Data Scientists afin exploiter les donnÃ©es dans des conditions optimales,
AccompagnÃ© par les Ã©quipes internes MP DATA, vous monterez en compÃ©tences sur le management des flux de donnÃ©es pour lâ€™ingÃ©nierie (prÃ© processing, feature engineeringâ€¦), la modÃ©lisation et enfin lâ€™industrialisation de vos modÃ¨les.
Voir moins","Profil recherchÃ©
IngÃ©nieur dâ€™une grande Ã©cole (Centrale, Mines, Supaero, Supelec, â€¦), vous avez des connaissances en modÃ©lisation et machine learning (deep learning, random forest, svmâ€¦) acquises lors de votre scolaritÃ© ou de vos expÃ©riences passÃ©es (stage ou cÃ©sure) vous avez de bonnes connaissances en Python pour coder ces algorithmes. Suite Ã  votre cursus ingÃ©nieur ou vos expÃ©riences professionnelles, vous disposez de appÃ©tences mÃ©tiers dans les domaines de lâ€™aÃ©ronautique, Ã©nergie, transport, etcâ€¦
Vous Ãªtes intÃ©ressÃ©s pour vous dÃ©passer en data science & data engineering et vous avez des premiÃ¨res expÃ©riences dans ce domaine, comme par exemple :
Spark / PySpark
Kafka
Cloud : AWS / GCP / Azure
Technologies de stockage : Snowflake / S3 / GCS / Azure Blob
Git Lab
SQL : Postgres / MongoDB
CI/CD.
Rencontrons-nous prochainement pour Ã©changer de nos opportunitÃ©s et vos projets !"
Data Engineer F/H - CDI,"{'name': 'GROUPE ODALYS', 'sector': 'HÃ´tellerie, Tourisme', 'employees': '1300 collaborateurs', 'creation_year': '1998', 'turnover': '300Mâ‚¬', 'mean_age': None}",CDI,Aix-en-Provence,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,< 6 mois,,"Descriptif du poste
Vous Ãªtes passionnÃ©(e) par la data et vous souhaitez participer Ã  la transformation digitale dâ€™une entreprise en pleine croissance ? Rejoignez-nous !
Nous recherchons un(e) data engineer pour intÃ©grer notre DSI composÃ©e dâ€™une quinzaine de personnes. Vous ferez partie de lâ€™Ã©quipe Data et Statistiques, en charge de la collecte, du traitement et de la mise Ã  disposition des donnÃ©es de lâ€™entreprise.
Vous participerez au projet de mise en place dâ€™une nouvelle data stack basÃ©e sur du cloud public, qui vise Ã  moderniser notre infrastructure, nos outils et nos processus data. Vous travaillerez en collaboration avec les chefs de projets et les autres membres de lâ€™Ã©quipe.
Vos missions principales seront :
DÃ©velopper et maintenir les pipelines de donnÃ©es en utilisant SAS, Airflow et Python
Participer Ã  la construction du datalake, en crÃ©ant de nouveaux pipelines de donnÃ©es, en choisissant les outils adaptÃ©s et en optimisant les performances et les coÃ»ts
Assurer la qualitÃ©, la fiabilitÃ© et la sÃ©curitÃ© des donnÃ©es
Tester et implÃ©menter de nouveaux outils de reporting et dâ€™analyse (Power BI, Tableau, etc.)
Accompagner la montÃ©e en compÃ©tences data de lâ€™entreprise en animant et formant les Ã©quipes
Veiller aux innovations technologiques dans le domaine de la data et proposer, tester et valider des solutions adaptÃ©es
Voir moins","Profil recherchÃ©
Vous Ãªtes titulaire dâ€™un diplÃ´me en informatique, mathÃ©matiques, statistiques ou Ã©quivalent
Vous avez une premiÃ¨re expÃ©rience rÃ©ussie dans le domaine de la data
Vous maÃ®trisez SQL et Python, et vous avez idÃ©alement des connaissances en SAS
Une expÃ©rience avec Docker, GIT et dâ€™autres outils de dÃ©veloppement serait Ã©galement apprÃ©ciÃ©e
Vous avez une appÃ©tence pour les technologies cloud, notamment AWS
Vous Ãªtes rigoureux(se), autonome et capable de vous adapter Ã  un environnement dynamique et Ã©volutif.
Vous avez un bon esprit dâ€™Ã©quipe et un bon sens relationnel

Informations complÃ©mentaires : 
Type de contrat de travail : CDI
Date dÃ©marrage souhaitÃ© : DÃ¨s que possible
Temps de travail : Cadre forfait jours
RÃ©munÃ©rations & avantages : A nÃ©gocier (incluant 13Ã¨me mois), RTT, tÃ©lÃ©travail possible 3 jours par semaine, mutuelle familiale, avantages CSE, sÃ©jours collaborateurs 
Voir plus"
Data Engineer,"{'name': 'AIVE', 'sector': 'Intelligence artificielle / Machine Learning, SaaS / Cloud Services', 'employees': '18 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 3 ans,,"Descriptif du poste
En temps que Data Engineer chez Aive, vos missions seront de :
Participer Ã  la conception et lâ€™implÃ©mentation de nouvelles fonctionnalitÃ©s reposant sur lâ€™analyse ou le traitement vidÃ©o, audio ou textuel.
Concevoir ou appliquer des modÃ¨les, algorithmes et mÃ©thodes pour mettre un oeuvres ces fonctionnalitÃ©s
Maintenir une veille technologique sur les sujets pertinents pour le produit
Collaborer avec les autres spÃ©cialitÃ©s de lâ€™Ã©quipe pour industrialiser le produit (qualitÃ©, performance, maintenance)
Lâ€™offre est ouverte pour toute la France, avec une prÃ©fÃ©rence pour les candidats en rÃ©gion Parisienne ayant la possibilitÃ© de venir rÃ©guliÃ¨rement dans les locaux.","Profil recherchÃ©
Une bonne connaissance des sujets et technologies suivants est apprÃ©ciÃ©e (exemples tirÃ©s de nos projets rÃ©cents ou Ã  venir):
Languages: Python, Golang
Frameworks de machine learning: Torch, ONNX
OpÃ©ration: Github CI, Docker, Kubernetes
Computer Vision (object/logo/face detection, shot/scene detection, feature extraction)
Signal Processing (automatic speech recognition, diarization)
Natural Language Processing (topic segmentation, summarization)
Les compÃ©tences et expÃ©riences suivantes seront fortement apprÃ©ciÃ©es :
3 ans dâ€™expÃ©rience prÃ©alable
Vous aimez travailler en Ã©quipe, partager vos connaissances et les approfondir au contact des autres
Recherchez lâ€™efficacitÃ© dans la crÃ©ation dâ€™algorithme Ã  grande Ã©chelle et Ã©volutifs
Si jamais vous ne remplissez pas tous ces critÃ¨res, nâ€™hÃ©sitez pas Ã  nous contacter quand mÃªme, nous Ã©tudierons tous les profils intÃ©ressants !
Voir plus"
Data engineer / Data scientist Flux Vision F/H,"{'name': 'ORANGE', 'sector': 'Objets connectÃ©s, Big Data, Electronique / TÃ©lÃ©communications', 'employees': '136000 collaborateurs', 'creation_year': '1994', 'turnover': '43,5 milliards â‚¬', 'mean_age': '44 ans'}",CDI,Cesson-SÃ©vignÃ©,35K Ã  45K â‚¬,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Votre mission consistera Ã  travailler sur les indicateurs mÃ©tier des clients de lâ€™offre Flux Vision, notamment dans les domaines du gÃ©omarketing, du transport et du tourisme.

Vous aurez en tant que data engineer / data scientist pour mission de travailler au sein dâ€™une Ã©quipe de data analyst/data scientist/data engineer sur les sujets suivants :
- Mise en place dâ€™algorithmes de data science pour la crÃ©ation et la qualification de nouveaux indicateurs statistiques,
- PrÃ©paration et qualification des donnÃ©es livrÃ©es aux clients,
- Participation Ã  lâ€™amÃ©lioration de lâ€™appareil de production,
- Vous participerez Ã©galement Ã  lâ€™Ã©laboration et Ã  lâ€™amÃ©lioration des livrables clients (rapport dâ€™analyse, tableaux de bord, intÃ©gration dans les outils de traitement de la donnÃ©e, â€¦),
- Vous travaillez en coordination avec les Ã©quipes de dÃ©veloppement et les Ã©quipes dâ€™exploitation.","Profil recherchÃ©
Vous Ãªtes titulaire dâ€™un Bac+5 master ou Ã©cole dâ€™ingÃ©nieur spÃ©cialisÃ© en mathÃ©matiques appliquÃ©es, en statistiques ou dans le domaine du transport, du gÃ©omarketing ou de lâ€™amÃ©nagement du territoire.

- Vous avez une expÃ©rience significative dans lâ€™utilisation des outils informatiques de datascience tel que Pandas, Keras/Scikit-Learn, SQL.
- Vous disposez de compÃ©tences dans les solutions de dataviz.
- Des connaissances dans les environnements cloud big data (Azure, AWS, GCP) est un plus.
- Dynamique, dotÃ© dâ€™un bon relationnel, vous avez le sens de lâ€™Ã©quipe, et vous aimez avoir de lâ€™autonomie pour mener une activitÃ© de maniÃ¨re longitudinale."
Senior Data Engineer,"{'name': 'VOODOO', 'sector': 'Jeux vidÃ©o, AdTech / MarTech', 'employees': '750 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Voodoo is a tech company that creates mobile games and apps. With 7 billion downloads and over 150 million monthly active users, Voodoo is the #3 mobile publisher worldwide in terms of downloads after Google and Meta.
The company is one of the most impressive examples of hypergrowth in the ecosystem, having raised over $1B and backed by Goldman Sachs, Tencent, and GBL.
Voodoo is now a team of over 750 employees worldwide, weâ€™re looking for talented individuals from across the globe to come and entertain the world with us.
Team
The Engineering & Data team builds innovative tech products and platforms to support the impressive growth of their gaming and consumer apps which allow Voodoo to stay at the forefront of the mobile industry. The Engineering & Data team plays a key role in Voodooâ€™s long-term strategy. It enables Voodoo to both accelerate product diversification and provide a state of the art growth-engine to distribute and scale our games. They create innovative solutions that drive growth with a pragmatic approach, ranging from simple searching to complex machine learning systems.
This position is hybrid and requires 2/3 days per week in the office based in Paris. 
Construct and manage robust data pipelines to align with ever-evolving business needs, ensuring optimal architecture support.
Contribute to the codebase, push and maintain your changes in production, and be an evangelist of good coding and data engineering practices
Take ownership of projects from initial discussions to release, including feature estimation & scoping, architecture design, benchmarking of new technologies, product feedback...
Work in a very agile environment with a fast decision process
Collaborate directly with people working on back-end development, data science, mobile games, broad audience mobile apps, product & marketing
Our Stack
Amazon Web Services â§« Python â§« Spark â§« Scala â§« Terraform â§« SQL â§« DBT â§« Airflow â§« Kubernetes
Profile
Extensive experience as a Data Engineer or another similar role.
A proven track record of building and optimizing data pipelines for massive amounts of data (at scale).
Strong experience in scalability, reliability, and security topics.
Strong analytical skills and ability to work with unstructured datasets.
Experience with Amazon Web Services.
Result-oriented and focused on the value created by your developments
Curious about business needs and keen to create innovative, agile solutions to help grow the business through data.
Excellent communication skills (you can speak & write English).
Understanding of ML concepts is a plus.
Working experience in a Gaming, Advertising, or successful company is a plus.
Familiarity with Voodoo's ecosystem: gaming, apps, advertising, analytics, etc
Voir moins",
Data Engineer (stage),"{'name': 'STORMSHIELD', 'sector': 'CybersÃ©curitÃ©', 'employees': '400 collaborateurs', 'creation_year': '2014', 'turnover': '60 Mâ‚¬', 'mean_age': '37 ans'}",Stage,Lyon,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,Bac +2,,
Lead Data Engineer / Architect H/F,"{'name': 'MEILLEURTAUX', 'sector': 'FinTech / InsurTech, Immobilier commercial, Immobilier particulier', 'employees': '2000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Vous souhaitez rejoindre la fintech leader en crÃ©dit et en assurance, en forte croissance, innovante, dynamique et dÃ©bordante de projets ? Ce qui suit va vous intÃ©resser !
Contexte de ce recrutement ğŸš€
Nous sommes engagÃ©s dans le dÃ©veloppement dâ€™une Customer Data Platform. 
Cette plateforme de donnÃ©es est au cÅ“ur de la stratÃ©gie de croissance de lâ€™entreprise va nous permettre de :
- Augmenter la Customer Lifetime Value (CLTV) de nos clients,
- D'intÃ©grer dans tous nos produits des composants IA innovants, 
- RÃ©duire nos coÃ»ts dâ€™acquisition,
- Faciliter le pilotage du business Ã  travers une optimisation de nos outils de BI.
Vous vous Ã©panouirez dans notre environnement en Ã©volution rapide, oÃ¹ l'adaptabilitÃ© est essentielle. Au-delÃ  de la rÃ©solution de dÃ©fis techniques, nous souhaitons que vous contribuiez activement Ã  la construction de la culture d'ingÃ©nierie de Meilleurtaux, Ã  l'amÃ©lioration des pratiques et Ã  la promotion d'un environnement collaboratif et innovant.
Vos missions ğŸ“
CrÃ©er et maintenir une infrastructure de donnÃ©es de pointe en permettant aux utilisateurs finaux d'accÃ©der Ã  de la donnÃ©e prÃ©cise et de qualitÃ© ;
DÃ©velopper de nouveaux modÃ¨les de donnÃ©es et des pipelines.
Ils ont auront pour objectif de prendre en charge une grande variÃ©tÃ© de cas d'utilisation (de l'analyse et du reporting Ã  l'apprentissage automatique et Ã  l'innovation de produits) ;
Explorer en permanence de nouvelles technologies de donnÃ©es ;
Tester les solutions les plus innovantes et prometteuses du marchÃ© en vue de pouvoir amÃ©liorer nos capacitÃ©s en matiÃ¨re de donnÃ©es ;
Recruter, encadrer et accompagner votre Ã©quipe de Data Engineers au quotidien ;
Partager et dÃ©fendre vos meilleures pratiques d'ingÃ©nierie de donnÃ©es au sein des principaux organes de dÃ©cision de l'entreprise.
Notre stack technique ğŸ›  
DÃ©veloppement : Python, React, java, Salesforce
CI-CD :  Git, Docker
Infrastructure cloud : GCP et Azure
Bases de donnÃ©es : Google BigQuery et Databricks
BI : Qliqsense
Ce poste nÃ©cessite d'interagir avec de nombreuses Ã©quipes au sein de Meilleurtaux que ce soit sur le plan technique (Ã©quipes IT, Data Scientist et BI) et/ou fonctionnel (Product Managers).
Ceci nâ€™est quâ€™un avant-goÃ»t de la superbe aventure que vous vous apprÃªtez Ã  rejoindre, le poste Ã©tant Ã©videmment amenÃ© Ã  Ã©voluer en fonction de vous et vos propositions.
Voir moins","Profil recherchÃ©
Pourquoi Ãªtes-vous notre TOP candidat ? ğŸ§
Avec une expÃ©rience d'au moins 8 ans dans la Data, vous aviez Ã©tÃ© amenÃ©(e) Ã  manager une petite Ã©quipe (entre 1 Ã  3 personnes) de Data Engineers.
Vous savez crÃ©er des architectures de donnÃ©es efficaces, Ã©volutives et robustes.
Vous concevez des systÃ¨mes adaptÃ©s au prÃ©sent mais Ã©galement Ã  l'avenir et qui rÃ©sistent Ã  l'Ã©preuve du temps.
Bien entendu, il est important que vous ayez de trÃ¨s bonnes compÃ©tences techniques que ce soit en Python ; SQL et les autres outils pouvant exister en ingÃ©nierie de donnÃ©es.
La Big Data n'a plus de secret pour vous. Spark & Hadoop sont vos plateformes de rÃ©fÃ©rence sur ce domaine.
Vous avez dÃ©jÃ  participÃ© au dÃ©ploiement d'infrastructure en Big Data.
IdÃ©alement, vous faÃ®tes partie d'une communautÃ© de professionnels de la Data vous permettant d'Ãªtre toujours au fait des derniÃ¨res actualitÃ©s.
Le must : cette expertise a Ã©tÃ© acquise au sein de l'industrie Fintech / Assurtech ou secteur Ã©quivalent. 
Voir plus"
Data Engineer - Energie - Ile-de-France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Courbevoie,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Description de lâ€™entreprise
Sopra Steria, lâ€™un des leaders europÃ©ens de la Tech reconnu pour ses activitÃ©s de conseil, de services numÃ©riques et dâ€™Ã©dition de logiciels, aide ses clients Ã  mener leur transformation digitale et Ã  obtenir des bÃ©nÃ©fices concrets et durables. Il apporte une rÃ©ponse globale aux enjeux de compÃ©titivitÃ© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs dâ€™activitÃ© et des technologies innovantes Ã  une approche rÃ©solument collaborative.
Sopra Steria place lâ€™humain au centre de son action et sâ€™engage auprÃ¨s de ses clients Ã  tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 50 000 collaborateurs dans prÃ¨s de 30 pays, le Groupe a rÃ©alisÃ© un chiffre dâ€™affaires de 5,1 milliards dâ€™euros en 2022.
The world is how we shape it
Description du poste
Votre futur environnement de travail :
La division Â« Energie Â» accompagne les grands acteurs du secteur en France dans les domaines de la production et de la distribution thermique, hydraulique et nuclÃ©aire. Dans un contexte agile, nos Ã©quipes dâ€™experts participent Ã  des projets autour de la transformation numÃ©rique pour conduire nos clients vers une transition Ã©cologique.
Le dÃ©fi que nous vous proposons de relever ? Mettre lâ€™Ã©nergie au service des Smart Grid & Cities !
Sous la responsabilitÃ© dâ€™un directeur de la Business Unit Energie, vous participez aux principaux grands projets de transformation numÃ©rique de ses secteurs.
Acteur majeur de lâ€™avant-vente jusquâ€™Ã  la livraison du produit final, vous intervenez sur un pÃ©rimÃ¨tre large, au sein dâ€™un environnement technique innovant
Votre rÃ´le et missions :
Au sein dâ€™une Ã©quipe Agile, accompagnÃ© par un chef de projet, en tant que Data Engineer et dans le cadre de nos projets de data management dans le secteur de lâ€™Ã©nergie, vous intervenez dans le cadre de dÃ©veloppement de projet BI (incluant la rÃ©alisation de datamarts, cubes ou rapports) complexes et Ã  forte valeur ajoutÃ©e (Pilotage des trains, reporting financier, gestion des conducteurs). Votre rÃ´le est donc prÃ©pondÃ©rant dans la rÃ©ussite du projet.
Vous intervenez sur toute la chaÃ®ne de valeur du cycle projet :
- Vous rÃ©digez des spÃ©cifications fonctionnelles gÃ©nÃ©rales ou dÃ©taillÃ©es sur la base dâ€™expression de besoins
- Vous participez Ã  la conception et au dÃ©veloppement des applications Big Data, les tester, les faites Ã©voluer et assurer leur maintenance.
- Vous assurez lâ€™intÃ©gritÃ© et la qualitÃ© de la donnÃ©e sur tout le processus dâ€™ETL
- Vous industrialisez et optimisez la gestion des flux de donnÃ©es
- Vous participez Ã  la conception de lâ€™architecture et lâ€™infrastructure de nos systÃ¨mes de collecte et de traitement des donnÃ©es.
- Vous pilotez et accompagnez les utilisateurs durant les phases de recette
- Vous accompagnez des key users et des utilisateurs finaux dans lâ€™usage des nouveaux rapports (formations, supportâ€¦)
- Vous contribuez Ã  lâ€™amÃ©lioration du reporting et du pilotage de la performance.
GrÃ¢ce Ã  votre excellent esprit collectif vous avez Ã  cÅ“ur de partager votre savoir et contribuer Ã  la progression des membres de lâ€™Ã©quipe.
Environnement technologique riche : Talend, Power BI, Cloud computing, Java, Python, PostgreSQL, Cloudera, Sparkâ€¦
Qualifications
DiplÃ´mÃ©(e) dâ€™une Ã©cole dâ€™IngÃ©nieurs ou Ã©quivalent, vous justifiez dâ€™une expÃ©rience technique de 3 ans minimum et souhaitez Ã©voluer rapidement dans un contexte motivant.
Vous avez au moins lâ€™une de ces compÃ©tences requises :
Â· MaÃ®trise des technologies de bases de donnÃ©es Relationnelles et NoSQL
Â· MaÃ®trise des technologies de traitement distribuÃ© de donnÃ©es (spark, Hadoop)
Â· MaÃ®trise dâ€™au moins un framework de streaming de donnÃ©es (Kafka, RabbitMQ, etc.)
Â· MaÃ®trise de chaines CI/CD et de des bonnes pratiques de DataOps
Â· MaÃ®trise de solution de Virutualisation de donnÃ©es (Denodo, Dremio, etc.)
Â· MaÃ®trise dâ€™au moins un environnement cloud public ou privÃ© (Azure, AWS, Outscale, etc.)
Vous Ãªtes attirÃ©(e) par le monde du numÃ©rique, le Cloud et des technologies innovantes.
Vous avez un bon esprit dâ€™analyse, Ãªtes curieux(se) et passionnÃ©(e) et vous avez le sens du travail en Ã©quipe.
Informations supplÃ©mentaires
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressant : une mutuelle, un CSE, des titres restaurants, un accord
dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 30 familles de mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de sâ€™engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â».
Lâ€™opportunitÃ© de rejoindre le collectif Techâ€™Me UP (formations, confÃ©rences, veille, et bien plus encoreâ€¦).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
Voir moins",
CDI- Tech lead Data Engineer GCP - Groupe Rocher,"{'name': 'GROUPE ROCHER', 'sector': 'Mode, CosmÃ©tique', 'employees': '16000 collaborateurs', 'creation_year': '1959', 'turnover': ""+2,4 milliards d'â‚¬"", 'mean_age': None}",CDI,La Chapelle-du-Mont-de-France,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,Bac +5 / Master,"Descriptif du poste
 MISSIONS
 Design / Build / Run :
Collaborer avec les parties prenantes (mÃ©tier, data scientists, product owner), les experts (system architect, data architect, system team) et les Ã©quipes de delivery pour concevoir et dÃ©livrer des solutions performantes.
Concevoir et chiffrer les solutions techniques pour les use cases, sâ€™assurer de la cohÃ©rence et de la bonne conception des solutions implÃ©mentÃ©es dans le respect de guidelines du Centre dâ€™excellence Data.
Etre garant du delivery des use cases.
Contribuer au support et Ã  la maintenance des applications dÃ©veloppÃ©es.
Animation :
Sâ€™assurer que les data engineers appliquent correctement le framework technique dÃ©fini
Veiller au maintien des compÃ©tences techniques de lâ€™Ã©quipe.
Innovation :
RÃ©aliser des POCs et suivre les derniÃ¨res Ã©volutions des composants techniques du produit. ÃŠtre moteur sur lâ€™Ã©volutivitÃ© des outils et applications en mettant en place un plan dâ€™amÃ©lioration continue du produit.
Cette offre est faite pour vous si :
Vous Ãªtes de formation supÃ©rieure en ingÃ©nierie statistique, data science, informatique, vous avez une expÃ©rience significative minimale de 5 ans dans le dÃ©veloppement et le support de SystÃ¨mes dâ€™information DATA
Vous maitrisez notamment les technologies suivantes : GPC, SQL, Python, Java
Vous maitrisez parfaitement lâ€™anglais Ã  l'oral Ã  l'Ã©crit
Vous maitrisez les mÃ©thodes dâ€™analyse et de modÃ©lisation conceptuelle, fonctionnelle et physique de donnÃ©es. 
ResponsabilitÃ©, exigence professionnelle, coopÃ©ration et curiositÃ© sont requises
Le poste est basÃ© Ã  Issy Les Moulineaux ou Ã  Rennes.
 Voir moins","Profil recherchÃ©
Profile description:

 PrÃªt Ã  faire bouger les lignes avec nous ? Nâ€™attendez plus et postulez !
Le Groupe Rocher accueille tous les talents et analyse chaque candidature avec la mÃªme attention sans distinction de genre, dâ€™orientation sexuelle, dâ€™Ã¢ge, de culture, ou de handicap.
Comme pour la Nature, nous sommes convaincus que la diversitÃ© est une force pour nos entreprises.
Venez dÃ©couvrir les valeurs que nous partageons sur : https://groupe-rocher.com/nos-valeurs
> "
DATA ENGINEER H/F,"{'name': 'HEROIKS', 'sector': 'PublicitÃ©', 'employees': '400 collaborateurs', 'creation_year': '2005', 'turnover': None, 'mean_age': '35 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,,"Descriptif du poste
Vous souhaitez industrialiser des cas dâ€™usage mÃ©tier en Ã©troite collaboration avec les Data Analysts, les Data Scientists et les Ã©quipes de lâ€™IT?
Un Data Engineer chez Peak ace câ€™est qui ?
â€œ Elle/Il travaille avec des donnÃ©es riches et bÃ©nÃ©ficie dâ€™une infrastructure de pointe en matiÃ¨re dâ€™apprentissage automatique. Il collabore avec une Ã©quipe solide dâ€™ingÃ©nieurs et de data scientists pour Ã©valuer de nouvelles approches, dÃ©velopper des fonctionnalitÃ©s et crÃ©er des algorithmes. Il a Ã©galement la responsabilitÃ© dâ€™expliquer des concepts sophistiquÃ©s de la science des donnÃ©es de maniÃ¨re claire et prÃ©cise aux dÃ©cideurs de lâ€™entreprise. Il travaille principalement sur GCP et le stack technique repose sur les Ã©lÃ©ments suivants :
â€¢ Orchestrateur : Kubernetes
â€¢ Data processing: Google workflow, Airflow, Airbyte
â€¢ Stockage des donnÃ©es : Cloud Storage, Bigquery et MongoDB
â€¢ Processing: docker, cloud functions + code Python
â€¢ Dataviz : Datastudio principalement pour les dashboards + notre saasSAAS interneâ€
Afin de renforcer les Ã©quipes en place nous souhaitons intÃ©grer un Data Engineer, qui aura pour responsabilitÃ©s :
Le maintien, lâ€™Ã©volution et la crÃ©ation dâ€™outils liÃ©s Ã  la gestion des donnÃ©es. Elle/Il sera chargÃ©(e) de rÃ©pondre aux besoins des clients internes et de proposer des solutions optimales pour optimiser les opÃ©rations de lâ€™entreprise :
Votre passion pour les donnÃ©es sera votre meilleur atout afin de dÃ©velopper des solutions pour traiter dâ€™importants volumes de donnÃ©es et concevoir, collecter et transformer des donnÃ©es brutes en informations exploitables. Mais Ã©galement crÃ©er des outils et des algorithmes.
Vous avez Habitude de travailler avec des Data Scientists et de gÃ©rer lâ€™industrialisation de projets de Data Science, alors tout naturellement vous prÃ©parez les donnÃ©es pour les Data Analysts et sÃ©curiser les pipelines de donnÃ©es.
Votre formation ingÃ©nieur sera le garant de votre capacitÃ© Ã  organiser lâ€™architecture du cloud, Ã  transformer des ensembles de donnÃ©es volumineux et complexes en informations pragmatiques.
Votre curiositÃ© et dynamisme assureront votre contribution Ã  lâ€™effort dâ€™animation technique, de veille technologique et dâ€™innovation.
Enfin vous serez un bon Team Player comme chacun des membres de nos Ã©quipes !
Pour vous convaincre?
Une agence au sein dâ€™un groupe international
Des projets au cÅ“ur de lâ€™innovation
Alors prÃªt(e) Ã  nous rejoindre ?
Voir moins","Profil recherchÃ©
Orchestrateur : Kubernetes
â€¢ Data processing: Google workflow, Airflow, Airbyte
â€¢ Stockage des donnÃ©es : Cloud Storage, Bigquery et MongoDB
â€¢ Processing: docker, cloud functions + code Python
â€¢ Dataviz : Datastudio principalement pour les dashboards"
"Data Engineer - Scientific Engine (Airflow, DVC) - CDI","{'name': 'DESCARTES UNDERWRITING', 'sector': 'Intelligence artificielle / Machine Learning, Assurance, FinTech / InsurTech', 'employees': '160 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
ABOUT DESCARTES UNDERWRITING
Descartes was born out of the conviction that climate change calls for a revolutionary approach in insurance to better protect corporations, governments, and vulnerable communities. We offer a new generation of parametric insurance that builds resilience against the full spectrum of climate and emerging risks. Utilizing Machine Learning and real-time monitoring from satellite imagery & IoT, our state-of-the-art climate tech provides innovative coverage for all trade sectors in all regions of the world. After a successful Series B raise of $120M USD, Descartes Underwriting is proud to be recognized among the French Tech Next40 and launched Descartes Insurance, a â€˜full stackâ€™ insurer licensed to underwrite risk by the French Regulator (ACPR). With a growing corporate client base (350+ and counting) - our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. 

ABOUT YOUR ROLE
Due to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenario to make a climate risk assessment. You will have to take initiative and assess the viability of proof of concept projects.
You will have to work with data scientists and software engineers to run and develop our models. You will be working along DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events.
ğŸ””KEY MISSIONS ğŸ””
Setup, automate, maintain and update:
Connections to external and internal APIs
Data preparation process
Model training and inference process
Data storage process
Associated CI/CD pipelines
Associated package versioning and releasing pipeline
Modularization of code base
Notification tools to inform the team of the status of the operations
Setup data storage, data processing and data visualizing tools, by :
Assessing the pains and needs of the teams
Benchmarking the open source and private solutions
Assessing the security, price and reliability of data architecture
Following the development the evolution of technologies on the topic
Forecasting the usage of the tools
Tracking the cost of the tools
Participate in:
Tech stack selection
Discussions with tech partners
Training of software and underwriting teams
Support and debug of internal users
TECH STACKğŸ–¥ï¸
Cloud provider: GCP
Code versioning tool: Git + Gitlab
OS: Linux
Container: Docker
Container orchestrator: Kubernetes
Website architecture: LAMP
Code base: Python
Notification tool: Slack
DATA STACKğŸ—„ï¸
Types: images, timeseries,
Storage: GCP bucket
Version: DVC (roll out in progress)
Pipeline: Airflow (PoC stage)
Data base: to be setup depending on the use cases
In our project, data is collected by sensors (satellite, weather station, IoT). We donâ€™t work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation â€¦).
EQUIPMENT ğŸ–±ï¸
Laptop: Dell Latitude 7530
OS: you decide

ABOUT YOU 
EXPERIENCE & QUALIFICATIONSğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»
[Hard skills]
Knowledge of the tech stack or equivalent tools
Experience converting python code to efficient data engineering tools (eg: spark)
Experience with Docker
Experience with a cloud provider (GCP, AWS or azure)
Experience automating a CI/CD pipeline
Good knowledge in English and fluency in French
[Soft skills]
Desire to train junior developers and explain CI/CD and cloud tools
Desire to suggest improvements to the architecture
[Nice-to-have]
Experience working data science project or scientific code
Experience with Kubernetes
Experience in HPC
Contribution to an open source project
MINDSET ğŸ’¥
Strong interest with climate issue (itâ€™s not a hoax, many people suffer from it)
Being comfortable to work alongside corporate insurers (some still wear suits ğŸ‘”)
You enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline)
Strong team spirit and ability to work (youâ€™ll have to review code and have your code reviewed)
Rigorous, creative and meticulous mind (we handle large insurance, we take our time)
Strong desire to learn (thereâ€™s no limitation to the tech used, weâ€™re happy to test and learn new tools)
Eagerness to work in a multi-cultural environment (policies and teams are from all around the world ğŸ—ºï¸)

WHY JOIN DESCARTES UNDERWRITING?
Join a company with a true purpose â€“ help us help our clients be more resilient towards climate risks;
A competitive salary, bonus and benefits (Premium Alan health insurance, Swile restaurant vouchers, Navigo reimbursement etc.);
The opportunity to grow in your role, as the company does;
Commitment from Descartes to itâ€™s staff of continued learning and development (think annual seminars, training etc.);
Be part of a collaborative, diverse team where your ideas are heard;
A paid referral scheme for successfully referring peers;
Frequent team events.

OUR COMMUNITY
At Descartes Underwriting, we are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences.
With equal skills, all our positions are open to people with disabilities.

HOW TO APPLY?
If you want to develop your skills and work in a friendly start-up atmosphere, don't hesitate and send us your application!
https://www.descartesunderwriting.com/careers/
If you donâ€™t check all the requirements in the description, donâ€™t worry. We can try to make some room for you within the company if youâ€™re motivated to work on climate risk.

RECRUITMENT PROCESS
Step 1: Call and HR Interview with our Talent Recruiter
Step 2: Technical project submitted via GitHub
Step 3: Technical interview
Step 4: Manager interview
Step 5: Final round interview with the team
(Candidates can opt to have the manager interview before the technical project and interview)
Voir moins",
Data Engineer,"{'name': 'WIREMIND', 'sector': 'Logiciels, MobilitÃ©, SaaS / Cloud Services', 'employees': '91 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '29 ans'}","Stage
(6 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,"Descriptif du poste
At Wiremind, the Data Science team is responsible for the development, monitoring and evolution of all ML-powered forecasting and optimization algorithms in use in our Revenue Management systems. Our algorithms are divided in 2 parts:
A modelling of the unconstrained demand using ML models (e.g. deep learning, boosted trees) trained on historical data in the form of time-series
Constrained optimizations problems solved using linear programming techniques
The team is now entering a scaling phase where we will face the challenge to stay agile in terms of innovation while supporting and closely monitoring deployed algorithms.
This rapid growth comes with a multiplication of data sources and deployed predictive models. In order to maintain high prediction accuracies and ascertain data quality, we are looking for a Data Engineer Intern with a passion for software engineering and rigorous mind.
You will be joining a team shaped to have all profiles necessary to constitute an autonomous departement (devops, software and data engineering, data science, AIML, operational research).
There, you will support the ML engineers by improving our MLOps platform, work closely with software engineers to implement the data science algorithms in the client applications and exchange with the platform team to keep the infrastructure debt at a minimum.
As a Data Engineer Intern, you will be responsible for :
Help the team deploy our algorithms in production in a safe, scalable and maintainable way
Support the ML team in their use of the MLOPs framework
Technical stack:
Backend: Python 3.7+ with SQLAlchemy, Remoulade, Flask/FastAPI
Argo over an auto-scaled Kubernetes cluster for orchestration
Data-store: Postgresql, Elasticsearch, Redis
Gitlab for continuous delivery
Common ML libraries: TensorFlow, LightGBM, XGBooost, Pandas, Dask, Dash
THE BENEFITS OF THE JOB ğŸš€
International environment ğŸŒ
Hyper-growth start-up: strong growth in our turnover and workforce ğŸ“ˆ
Joining a committed team that offers you opportunities for development ğŸ§‘â€ğŸ’»
Variety of tasks and a high degree of autonomy
Position based in the heart of Paris (Bd PoissonniÃ¨re) âœ¨
Attractive remuneration indexed to performance ğŸ’ª
Luncheon vouchers ğŸŒ®
A hybrid policy: 2 daysâ€™ remote a week and the possibility of occasionally working from abroad ğŸ’»
Start date: as soon as possible
Type of contract: internship
Voir moins","Profil recherchÃ©
Above average in terms of rigor and autonomy, you are proactive and curious.
Good general culture in computer science and you are looking for a quick progression perspective in an environment with best development practices.
Interested in solving business problems through technological solutions."
Stage Climate & Nature Data Engineer H/F,"{'name': 'ECOACT', 'sector': 'Environnement / DÃ©veloppement durable, StratÃ©gie, Transformation', 'employees': '350 collaborateurs', 'creation_year': '2006', 'turnover': None, 'mean_age': '30 ans'}","Stage
(6 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,02 janvier 2024,,Bac +4,"Descriptif du poste
Rejoignez notre Ã©quipe dâ€™analyse des donnÃ©es climatiques Climate Data Analytics (CDA) dâ€™EcoAct et aidez-nous Ã  accroÃ®tre notre impact sur le changement climatique en dÃ©veloppant des produits numÃ©riques qui aident nos clients Ã  dÃ©finir des stratÃ©gies Ã  faible Ã©mission de carbone.
La vision dâ€™EcoAct : un monde net zÃ©ro et durable ğŸŒ
Notre mission : contribuer Ã  lâ€™Ã©chelle mondiale Ã  la transformation net zero en proposant des solutions percutantes et innovantes.
Notre pÃ©rimÃ¨tre dâ€™activitÃ© : tous les services liÃ©s au climat dont les entreprises et les territoires ont besoin pour rÃ©ussir leur transformation (Ã©valuation des risques climatiques, empreinte carbone & biodiversitÃ©, stratÃ©gie de rÃ©duction carbone, etc.).
RÃ´le de CDA : concevoir des mÃ©thodes et des outils innovants pour rÃ©pondre aux besoins des clients liÃ©s au changement climatique.
MISSIONS
CapacitÃ©s techniques et dâ€™ingÃ©nierie des donnÃ©es pour prendre en charge lâ€™analyse des donnÃ©es climatiques, y compris le dÃ©veloppement de lâ€™entrepÃ´t de donnÃ©es EcoAct avec une couche dâ€™IA.
Aider les Ã©quipes internes (NTBS, Advisory) Ã  centraliser leurs donnÃ©es de projets et Ã  exploiter les donnÃ©es existantes.
En collaboration avec les propriÃ©taires de donnÃ©es et les contributeurs des lignes de services, identifier les opportunitÃ©s dans lâ€™Ã©cosystÃ¨me de donnÃ©es climatiques et naturelles existant, identifier les lacunes et recommander des amÃ©liorations.
Garantir la qualitÃ© et la fiabilitÃ© des donnÃ©es.
Mettre en Å“uvre des solutions de donnÃ©es et dâ€™analyse grÃ¢ce Ã  des systÃ¨mes de gestion, des techniques de science des donnÃ©es et des techniques de visualisation de donnÃ©es appropriÃ©es.
Ã‰tablir des normes et des meilleures pratiques pour la gestion des donnÃ©es et transfÃ©rer les connaissances aux collÃ¨gues concernÃ©s.
DÃ©velopper et maintenir une documentation complÃ¨te sur les donnÃ©es qui fournit aux producteurs et aux consommateurs de donnÃ©es les outils nÃ©cessaires pour comprendre, dÃ©couvrir et collaborer sur les donnÃ©es.
Centraliser la gestion des contrats de donnÃ©es et coordonner les Ã©changes internes sur les usages de ces donnÃ©es.
Monitoring de lâ€™usage des donnÃ©es.
Participer aux activitÃ©s de veille technologique (nouvelles solutions apportant de la valeur) et des pratiques de marchÃ© autour de la donnÃ©e (data scraping, data crunching, data mining, feature engineering, etc.).
Voir moins","Profil recherchÃ©
AcadÃ©mique :
â€¢ DiplÃ´me universitaire de niveau supÃ©rieur (bac+5) en informatique, ingÃ©nierie, statistiques, mathÃ©matiques ou domaines quantitatifs connexes.
â€¢ DiplÃ´me dâ€™ingÃ©nieur en ingÃ©nierie des donnÃ©es ou en science des donnÃ©es.
Professionnel :
â€¢ ExpÃ©rience dans le domaine de lâ€™informatique et des bases de donnÃ©es, dans la mise en Å“uvre de solutions techniques et de systÃ¨mes destinÃ©s Ã  lâ€™analyse de donnÃ©es, idÃ©alement des donnÃ©es climatiques.
â€¢ ExpÃ©rience de travail avec de grands ensembles de donnÃ©es structurÃ©es et non structurÃ©es.
â€¢ ExpÃ©rience en extraction/structuration de donnÃ©es et en nettoyage de donnÃ©es.
â€¢ CapacitÃ© Ã  Ã©couter et Ã  communiquer efficacement avec des publics techniques et non techniques.
â€¢ Anglais courant.
Outils :
â€¢ Connaissances et compÃ©tences pour recommander et dÃ©velopper des systÃ¨mes et une architecture de gestion de bases de donnÃ©es.
Voir plus"
Data Engineer - Intern,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",Stage,Neuilly-sur-Seine,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
AXA IM est un gestionnaire d'actifs international faisant partie du groupe AXA, leader mondial de lâ€™assurance. Notre Ã©quipe comprend de nombreuses compÃ©tences et expÃ©riences pour mieux rÃ©pondre aux besoins de nos clients
Votre rÃ´le de stagiaire Data Engineer sera rattachÃ© au  et vous ferez partie du dÃ©partement AXAIM TECHNOLOGY - Data, Digital & Finance
DECOUVREZ votre opportunitÃ© 
Vos rÃ´les et responsabilitÃ©s : 
â€¢ Concevoir, construire et optimiser des pipelines de donnÃ©es Ã©volutifs pour collecter, intÃ©grer et transformer des donnÃ©es provenant de diverses sources dans un format unifiÃ© adaptÃ© Ã  l'analyse et au reporting.â€¢ Travailler avec des donnÃ©es financiÃ¨res pour crÃ©er des rapports et des informations qui aident Ã  soutenir les dÃ©cisions commerciales clÃ©sâ€¢ CrÃ©er et maintenir des tableaux de bord financiers, des mÃ©triques et des KPI pour les Ã©quipes Finance d'AXA IMâ€¢ Effectuer une analyse de donnÃ©es ad hoc pour soutenir les dÃ©cisions commercialesâ€¢ Maintenir la documentation des sources de donnÃ©es, des mÃ©thodologies et des spÃ©cifications des rapportsâ€¢ Aider Ã  identifier les opportunitÃ©s d'amÃ©lioration des outils et des mÃ©thodologies de reporting financier.
Nous nous engageons Ã  vous offrir un environnement oÃ¹ vous pourrez :
DÃ©veloppez votre potentielâ€¯: IntÃ©grer une entreprise engagÃ©e sur le dÃ©veloppement de ses collaborateurs via une mobilitÃ© interne dynamique et une large offre de parcours de formation personnalisÃ©s.
Personnalisez votre maniÃ¨re de travaillerâ€¯: Travailler pour une entreprise qui s'engage Ã  garantir flexibilitÃ© et Ã©quilibre Ã  ses employÃ©s, en vous offrant une large gamme d'avantages (intÃ©ressement, tÃ©lÃ©travail, avantages sociaux compÃ©titifs, etc.).
Epanouissez-vous par la diversitÃ© de notre communautÃ©â€¯: Jouer un rÃ´le au sein d'une entreprise inclusive qui reconnaÃ®t et valorise activement les diffÃ©rences individuelles dans un environnement de travail diversifiÃ© et inclusif.
Faites avancer le mondeâ€¯: Rejoindre un employeur responsable qui agit en faveur des causes sociÃ©tales et environnementales en tant qu'investisseur, assureur et entreprise, notamment au travers de l'association AXA Atout CÅ“ur. Dans le cadre de notre engagement en faveur de la durabilitÃ© et de la responsabilitÃ© environnemental, nous cÃ©lÃ¨brerons votre arrivÃ©e en plantant un arbre.
Voir moins","Profil recherchÃ©
PARTAGEZ votre expertise unique  Nous accueillons diffÃ©rentes combinaisons de compÃ©tences et d'expÃ©riences.  Vos diplÃ´mes et expÃ©riences 
Master 1 ou 2 en Ã©cole d'ingÃ©nieur
Une premiÃ¨re expÃ©rience sur un poste similaire est un plus 
Stage Ã  pourvoir en Janvier/FÃ©vrier 2024
CompÃ©tences relationnelles et comportementales :
Rigueur
Esprit curieux et forte capacitÃ© dâ€™analyse / goÃ»t pour le dÃ©tail
Aptitude Ã  travailler en Ã©quipe
Autonomie et initiative
Ouverture dâ€™esprit et dynamisme
FlexibilitÃ© et capacitÃ© Ã  travailler en parallÃ¨le sur diffÃ©rentes tÃ¢ches selon les prioritÃ©s
Anglais indispensable (contexte international)"
Data Engineer - Industries et Services - Metz,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Metz,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail :
Vous intervenez en rÃ©gie directement chez notre client sur ses problÃ©matiques en lien avec la data.
Vos missions :
Vous participez aux sujets techniques data (engineering, Big Data) en lien avec la collecte et la mise Ã  disposition des donnÃ©es.
Vous participez Ã  l'industrialisation et Ã  la mise en production des traitements sur les donnÃ©es
Vous effectuez la rÃ©daction de spÃ©cification techniques et fonctionnelles, cette action nÃ©cessitant de travailler en anglais
Vous participez aux rÃ©unions projet
Environnement technologique/fonctionnel : Big Data : Cloudera, Hive, Spark,â€¦, ETL : Talend, Bases donnÃ©es : SQL Server, Reporting : Power BI
Ce que nous vous proposons :
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressants : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor. Des opportunitÃ©s de carriÃ¨res multiples : plus de 50 mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â». - L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encore).
Informations supplÃ©mentaires
Ce que nous vous proposons :
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressants : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor. Des opportunitÃ©s de carriÃ¨res multiples : plus de 50 mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â». - L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encore).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherchÃ©
Votre profil :
Vous avez dÃ©veloppÃ© de solides compÃ©tences en matiÃ¨re d'autonomie, d'adaptabilitÃ© et de communication.
Des compÃ©tences et/ou de solides connaissances en Talend sont fortement souhaitÃ©es.
Des compÃ©tences en Data Visualisation / data Viz peuvent Ãªtre un plus sans Ãªtre obligatoires
Vous avez un bon niveau d'anglais
DiplÃ´mÃ©(e) d'une formation supÃ©rieur en informatique type Bac + 5 (Ã©cole ingÃ©nieur, universitÃ© ou Ã©quivalent), vous avez dÃ©jÃ  acquis une expÃ©rience significative en data, de minimum 3 ans, principalement sur des sujets traitant de la data engineer et du big data."
Data Engineer â€“ CDI,"{'name': 'WEBYN', 'sector': 'Intelligence artificielle / Machine Learning, SaaS / Cloud Services, AdTech / MarTech', 'employees': '7 collaborateurs', 'creation_year': '2023', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail total,01 mars 2024,> 2 ans,Bac +5 / Master,,
Data Engineer F/H,"{'name': 'ORANGE', 'sector': 'Objets connectÃ©s, Big Data, Electronique / TÃ©lÃ©communications', 'employees': '136000 collaborateurs', 'creation_year': '1994', 'turnover': '43,5 milliards â‚¬', 'mean_age': '44 ans'}",CDI,Rennes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Vous intervenez pour nos comptes clients de la rÃ©gion dans diffÃ©rents secteurs dâ€™activitÃ© en mettant en oeuvre lâ€™infrastructure pour le traitement des donnÃ©es, lâ€™analyse, la surveillance des modÃ¨les appliquÃ©s et la mise au point des calculs dâ€™algorithmes tout en dÃ©veloppant votre expertise.

Un poste de Data Engineer chez Orange Business câ€™est :

Concevoir, implÃ©menter et optimiser les modÃ¨les visant Ã  stocker et traiter les donnÃ©es

ContrÃ´ler et Ã©valuer la qualitÃ© des modÃ¨les

ImplÃ©menter, optimiser et maintenir des algorithmes de traitement de donnÃ©es distribuÃ©es (Scala, Spark, Java)

DÃ©ployer et industrialiser les pipelines de collecte, dâ€™ingestion et de stockage de donnÃ©es

Surveiller et assurer le bon fonctionnement des pipelines en production

DÃ©finir les bonnes pratiques de dÃ©veloppement en implÃ©mentant des outils de CI/CD

Assurer une veille technologique sur les technologies Big Data

Participer Ã  la dÃ©finition, conception et/ou Ã©volution de lâ€™architecture, en intÃ©grant de nouveaux composants (frameworks, bibliothÃ¨ques, â€¦) permettant de mieux rÃ©pondre aux besoins

Des missions riches et variÃ©es qui vous permettront dâ€™Ã©voluer sur tous les enjeux dâ€™un projet.
Voir moins","Profil recherchÃ©
De formation informatique Bac+5, vous justifiez dâ€™une expÃ©rience dâ€™au moins 3 ans dâ€™expÃ©rience dans la mise en oeuvre de projets Big Data et BI.

Votre profil pour mener Ã  bien cette mission :

La maÃ®trise du framework Spark

La maitrise de Kubernetes

Une bonne connaissance de lâ€™Ã©cosystÃ¨me hadoop et technologies Big Data (Hadoop/Cloudera, Kafka, ELK, NoSQL)

Une bonne maitrise des langages de programmation tels que Scala, SQL, Python, Java,

Une appÃ©tence sur les pratiques Devops (Git, Jenkins, Ansible, Docker, Terraform)

La maÃ®trise de lâ€™anglais est souhaitÃ©e pour intervenir auprÃ¨s de nos clients internationaux.
Votre curiositÃ©, votre autonomie et esprit dâ€™initiative sont des atouts pour dÃ©velopper vos compÃ©tences et contribuer Ã  votre Ã©volution. Votre esprit dâ€™Ã©quipe favorisera votre intÃ©gration au sein de lâ€™agence.
Vous Ãªtes partant pour vivre lâ€™aventure Postulez dÃ¨s maintenant en nous envoyant votre CV.
Tous nos postes sont accessibles, Ã  compÃ©tences Ã©gales, aux travailleurs en situation de handicap.
Voir plus"
Data Engineer F/H,"{'name': 'CENISIS - DATA AGENCY', 'sector': 'IT / Digital, StratÃ©gie, Transformation, CollectivitÃ©s publiques et territoriales', 'employees': '38 collaborateurs', 'creation_year': '1995', 'turnover': None, 'mean_age': '35 ans'}",CDI,Lille,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Tu souhaites rejoindre une communautÃ© Data Addict Ã  taille humaineâ€¯?
Nous recherchons un Data Engineer F/H qui aura un rÃ´le Ã  part entiÃ¨re dans la communautÃ© CENISIS.
Nous tâ€™apportons lâ€™opportunitÃ© dâ€™intervenir sur un large choix de projets mais Ã©galement de faire partie de la CENISIS Academy.
Tes missionsâ€¯?
GÃ©rer et mettre en place les structures nÃ©cessaires ainsi que les donnÃ©es de type big data pour permettre lâ€™exploitabilitÃ© par les data scientists
Permettre la collecte, le stockage et lâ€™exploitabilitÃ© fluide des donnÃ©es
Constuire les outils de collecte et dâ€™analyse de donnÃ©es (structurÃ©es et non structurÃ©es)
Choisir la ou les mÃ©thode(s)/technologie(s) les plus adaptÃ©e
Rejoindre CENISIS, câ€™est rejoindre une entreprise quiâ€¯:
â™ŸPositionne ses consultants au cÅ“ur de la stratÃ©gie de transformation digitale ğŸš€
âš¡ï¸Permet Ã  ses collaborateurs dâ€™avoir un rÃ©el impact, dâ€™innover, tester et construire notre avenir ğŸ’¥
ğŸŒChoisit de porter des valeurs fortes et dâ€™Ãªtre avancÃ© au niveau social et environnemental avec une forte politique de diversitÃ© et dâ€™inclusion #TeamRSE ğŸƒ
ğŸŸ Anime des formations en interne et en externe #CENISISAcademy ğŸ“š
Ce qui nous animeâ€¯?
Nos valeurs basÃ©es sur lâ€™audace, la cohÃ©sion, lâ€™authenticitÃ© et la responsabilitÃ© nous poussent Ã  lâ€™innovation et Ã  la croissance. Pour cela, en 2020, CENISIS a intÃ©grÃ© lâ€™accÃ©lÃ©rateur BPI dÃ©diÃ© aux entreprises ambitieuses pour ainsi, devenir une Data Agency.
En tant quâ€™entreprise engagÃ©e dans une dÃ©marche responsable, nous accordons une grande importance Ã  lâ€™impact du bien-Ãªtre personnel et collectif et Ã  lâ€™engagement envers la diversitÃ©, lâ€™Ã©quitÃ© et lâ€™inclusion.
Voir moins","Profil recherchÃ©
Ton profilâ€¯?
Tu es issu(e) dâ€™une formation supÃ©rieure Bac+3/5 de type licence ou master dans le domaine de lâ€™ingÃ©nierie avec une orientation Data. IdÃ©alement tu possÃ¨des une expÃ©rience significative de 3 ans dans la Data.
Ton savoir-Ãªtreâ€¯:
Ta capacitÃ© Ã  fÃ©dÃ©rer une Ã©quipe et Ã  contribuer Ã  la rÃ©ussite de celle-ci dans ses diffÃ©rents projets
Ta curiositÃ©, ton envie de toujours innover, et ton autonomie
Tu es force de proposition et tu aimes le challenge et challenger les autres
Ta diffÃ©rence, ce qui fait ta force et ta richesse pour lâ€™entreprise
Ton savoir-faireâ€¯:
Ton expertise Ã©levÃ©e dans les technologies de manipulation des donnÃ©es
Ta maÃ®trise des technologies de base de donnÃ©es (NoSql, SQL, â€¦),
Ta maÃ®trise des technologies type Cassandra, Python, R, â€¦
Ta comprÃ©hension des problÃ©matiques des datascientists
Voir plus"
Big Data Engineer,"{'name': 'TATA CONSULTANCY SERVICES', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '615000 collaborateurs', 'creation_year': '1968', 'turnover': '$ 28 milliards', 'mean_age': None}",CDI,Neuilly-sur-Seine,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,"Descriptif du poste
Develop Big Data capabilities for bank, for the data lake on the public cloud.
Implement the fundamentals of software engineering.
Analyze, propose, and develop the necessary evolutions (study, monitoring / planning, reporting, alerts, risk management).
Contribute to the prototyping, validation, design and development of the solution in Java and/or Python and/or Scala.
Contribute to the optimization of the Run activity and the improvement of the quality of service.","Profil recherchÃ©
Environnement : Hive, Microstrategy, PL SQL, Python, SAS, SQL Server Database, Teradata, Vue.js Flask Spark, Elasticsearch, Linux/Unix"
(PARIS) Data Engineer (H/F),"{'name': 'MERITIS', 'sector': 'IT / Digital, Finance', 'employees': '900 collaborateurs', 'creation_year': '2007', 'turnover': '87Mâ‚¬', 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,Bac +5 / Master,,
Stagiaire de Fin dâ€™Etudes Consultant Data Engineer - Paris - 2024 H/F,"{'name': 'MAZARS ET LA TECH', 'sector': 'IT / Digital', 'employees': '28000 collaborateurs', 'creation_year': '1945', 'turnover': '2,1 milliards', 'mean_age': '30 ans'}",CDI,Courbevoie,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 6 mois,Bac +5 / Master,"Descriptif du poste
Lâ€™Ã©quipe Data Services de Mazars, câ€™est plus de 60 consultants spÃ©cialistes de la data, rÃ©partis sur 2 hubs (Paris La DÃ©fense, New-York).  Ils couvrent lâ€™ensemble de la chaÃ®ne de valeur de la donnÃ©e : Data Strategy et qualification de cas dâ€™usage, Gouvernance et qualitÃ© des donnÃ©es, Data Visualisation, Data Science, Data Engineering et Data Architecture.
Nous sommes convaincus que le Data Engineering est la pierre angulaire de cette industrie. Nous mobilisons, pour servir nos clients, une stack technologique riche et variÃ©e, tant sur les outils open-sources (Python, Pandas, PySpark, FastAPI, Vim, SQL/NoSQL, ...) que sur les solutions du marchÃ© (Snowflake, AWS, Azure, ...).
Notre Ã©quipe de Data Engineers travaille au quotidien avec les membres de Mazars R&D et nos Data Analysts. Pour nos clients, nous produisons des solutions qui intÃ©grent le DevOps (GitLab, Ansible, Docker, Terraform, ...) dÃ¨s la phase de conception.
Vous serez formÃ©(e) Ã  nos mÃ©thodologies et aurez lâ€™opportunitÃ© de travailler au sein dâ€™Ã©quipes pluridisciplinaires, y compris les Ã©quipes de R&D qui dÃ©veloppent et maintiennent nos outils dâ€™Analytics ainsi que notre infrastructure interne (GitLab-CI, VMs OpenNebula, CephFS, etc...).
Vous interviendrez de faÃ§on opÃ©rationnelle sur des missions de conseil data ambitieuses et innovantes pour nos clients du CAC40 et SBF120, en France et Ã  lâ€™international.
Vous participerez notamment Ã  :
Â· Lâ€™amÃ©lioration de la performance opÃ©rationnelle de nos clients au travers de lâ€™exploitation et la valorisation de donnÃ©es sur des cas dâ€™usage mÃ©tier concrets (stratÃ©gie, marketing et vente, R&D, finance, RSE, etc..).
Â· Le dÃ©veloppement de bout en bout de flux de donnÃ©es, de lâ€™extraction / transformation jusquâ€™Ã  leur consommation (API, BI / Visualisation, ...)
Â· Le dÃ©ploiement et lâ€™intÃ©gration continus de pipelines sur plusieurs paradigmes : serverless cloud (AWS Lambdas, Azure Functions, GC Functions, Kubernetes) ou cloud privÃ© (OpenNebula, CloudStack, CephFS)
Pourquoi nous rejoindre ?
Â· ACCOMPAGNEMENT PAR DES EXPERTS : Les AssociÃ©s en charge de lâ€™Ã©quipe Data Services cumulent une expertise rare dans leurs domaines respectifs, e.g. Ã©quipe pionniÃ¨re du MLOps (CI/CD opÃ©rationnelle depuis 2013). Ils participent activement Ã  la mise en place des activitÃ©s les plus pointues du cabinet et de la crÃ©ation de start-up technologiques acquises par Mazars. Cet environnement Ã  la fois exigeant et formateur vous propulsera au top des bonnes pratiques coding et opÃ©rationnelles pour assurer un delivery projet de qualitÃ© !
Â· AUTONOMIE ET AMBITION : Ã‰cosystÃ¨me jeune, dynamique et trÃ¨s responsabilisant, aux fortes ambitions de croissance. Venez vous impliquer dans le dÃ©veloppement du Lab Mazars et construire lâ€™offre de service en conseil data du cabinet !
Â· HACKING SPIRIT : Veille technologique omniprÃ©sente, Ã  la pointe des technologies open-source les plus performantes du moment. Nos consultant(e)s se forment en permanence pour Ã©largir leur socle de compÃ©tences.
Â· CABINET INTERNATIONAL : Rejoindre Mazars câ€™est intÃ©grer un cabinet aux dimensions internationales et bÃ©nÃ©ficier dâ€™opportunitÃ©s dâ€™Ã©volution de carriÃ¨re : bootcamp data, learning center de pointe (Mazars Academy, LinkedIn learning, etc.) et mobilitÃ©s internationales.
Venez partager avec nous cette fiertÃ© que nous avons dâ€™apporter des rÃ©ponses pertinentes Ã  nos clients. Vous vous dÃ©passez sur des sujets techniques variÃ©s et ambitieux, au sein dâ€™une Ã©quipe humaine et bienveillante !
Voir moins","Profil recherchÃ©
De formation Bac+5 type Ã©cole dâ€™ingÃ©nieur gÃ©nÃ©raliste ou spÃ©cialisÃ©e, ou dâ€™un 3Ã¨me cycle dans un domaine connexe Ã  la data (systÃ¨mes dâ€™informations, traitements de donnÃ©es, big data, statistiques, gÃ©nie logiciel, etc.) :
Vous avez dÃ©jÃ  montrÃ© un intÃ©rÃªt pour le domaine du dÃ©veloppement applicatif intÃ©grant une composante Data, Ã  travers des stages, cours ou projets personnels impliquant le dÃ©veloppement back-end et/ou front-end dâ€™une application.
Vous avez une expÃ©rience pratique et une bonne connaissance de :
- Un ou plusieurs langages de programmation analytique (Python, R, Haskell, Rust, etc.)
- Une ou plusieurs couches de persistance (MySQL, MongoDB, ElasticSearch, S3, Node4j)
Vous nâ€™envisagez pas de travaux sÃ©rieux en dehors dâ€™un systÃ¨me Linux (Ubuntu, Debian, CentOS), ou sans systÃ¨me de contrÃ´le de version (Git), et lâ€™utilisation dâ€™une chaÃ®ne dâ€™intÃ©gration vous parait naturelle
Vous pensez que lâ€™Ã©cosystÃ¨me tech open-source est un puissant terrain de jeu Ã  la pointe de la technologie, qui met Ã  disposition lâ€™ensemble des outils nÃ©cessaires Ã  la rÃ©alisation des projets les plus ambitieux.
Vous souhaitez travailler avec les utilisateurs mÃ©tiers et les clients pour comprendre leurs besoins.

Voir plus"
CAT Data Engineer and Claims Analyst - (M/F),"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",CDI,Neuilly-sur-Seine,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Whatever their stage of life, we provide over 108 million customers with the products and services they need to progress. From insurance to personal protection, and savings to wealth management, no matter the need weâ€™re always there for them. And weâ€™re always there for our employees. In 50 countries, we work hard to inspire pride and a sense of belonging in our people. To provide opportunities that challenge them, inspire them, and reward them. And to create a culture thatâ€™s open, supportive, and empowering. Because we know thatâ€™s the real secret to success â€“ and the best way for us to keep building a better world for both our customers and the talented people who put them first.
Your work environment
The headquarters of the AXA Group (GIE AXA) brings together our corporate activities. It provides guidance and support to subsidiaries around the world, to ensure the coordination and monitoring of the Group's global strategy, the application of its standards, the consistency of commercial approaches and the sharing of best practices. The headquarters gathers approximately 1000 employees and is distinguished by its strong international culture (45 nationalities), which makes it a rich and stimulating place to work.
Context
AXA Group Risk Management Property & Casualty (GRM P&C) deals with the most sophisticated P&C technical and actuarial challenges of a leading international insurance company, among which the management of natural catastrophe risks (CAT). Natural variability of climate and seismic activity have demonstrated their devastating potential, climate change bringing additional uncertainty for the future. AXAâ€™s rapid expansion over the last years â€“ both in terms of geographical footprint and P&C insurance offer â€“ widely exposes AXA to natural perils, being in charge of the financial protection of its clients. In this context, AXA must maintain state-of-the-art CAT risk management techniques through permanent innovations.
AXA GRM brings together high level and multidisciplinary staff with engineers, PhDs, actuaries, data scientists and financials split between Paris, Hong Kong, ZÃ¼rich and Madrid. Its main missions are focused on the following key areas:
develop and maintain models and tools in an efficient and strong IT ecosystem to industrialise deliverables;
analyse, model and aggregate the Groupâ€™s risks (economic capital);define and implement the process enabling to secure the undertaken risks (risk appetite, assets accumulation, longevity, natural catastrophe ...);
optimize the Group protections (reinsurance, securitization, hedging, etc.) to meet the desired strategy.
Job Summary
Position belongs to the Group P&C Risk Management Natural Catastrophe and Reinsurance team (21 FTE) which is organized several excellence centers: CAT R&D Modeling, Data Analytics, Accumulation Management and Reinsurance. As part of AXAâ€™s Internal Model under the Solvency II framework, the CAT and Reinsurance team are primarily in charge of delivering the annual CAT modeling process, consisting of:
Collecting CAT exposure data (geographical, physical and financial information) on a per-entity (AXA France, AXA Mexico, AXA Philippinesâ€¦) and per-location basis (houses, factories, vehicles etc.);
Assessing the risk on a per-entity per-peril basis (cyclones, earthquakes, floods, hailstorms...) which feeds the whole downstream chain locally (pricing, budgets, reinsurance decisions, capital modeling)
Estimating the efficiency of the Group Reinsurance covers
Developing in-house models, methodologies and applications to support the CAT risk monitoring.
The CAT modelling process has strong strategic and operational impacts since it feeds AXA Economic Capital internal model, the Economic Combined Ratio and NAT CAT budget calculations which drives the earnings and the solvency position of AXA Group. It and determines adequate levels of reinsurance needs, which may boost or hinder profitability. It is also a technical challenge with the data collection of 25+ millions of complex and worldwide policies covering 50+ millions risks, the parallel use of multiple modeling solutions including both physics and machine learning techniques, and finally the assessment of 190 country x peril levels of risk.
Going beyond the use of external solutions, AXA Group develops its own suite of CAT models. The models are nested in a global and robust workflow, largely automated and auditable. In addition, leveraging this Group knowledge and expertise for the business, the team has been developing actuarial frameworks and operational solutions to diffuse CAT model result data, alert and assess live event impacts across the world.
The CAT Data Engineer & Claims Analyst will focus on the key challenge of buildingâ€™s vulnerability which is one of the three basic modules of catastrophe models (exposure, hazard, vulnerability), to reinforce the R&D modeling ambitions for the development of various in-house CAT models. The primary mission will be to build sound data foundations and to grow technical capabilities to meet this challenge. The CAT Data Engineer & Claims Analystwidely interacts with AXA entities, the Group R&D Modeling, Data Analytics and Aggregation teams and benefits from the IT expertise of FTEs (internal consulting). It will imply weekly collaboration with AXA entities, IT developers and continuous interactions with scientists and analysts. The selected candidate will be fully onboarded in the team where he will benefit from the close collaboration with junior and senior experts and will be the group referent of designated P&C operational entities on natural perilsâ€™ aspects (notably the annual CAT modeling process).
This position offers a great exposure across the Group, supporting different functions among entities, on a highly valued segment while working on innovative solutions and dealing directly with insurance challenges, on the domain of Climate Change and Natural Hazards.
Position Responsibilities
Develop and implement vulnerability models for natural hazard damages
Create CAT claim collection process from AXA entities following natural hazard events;
Design and implement a solid data scheme to gather, standardize and build a homogeneous claim database at Group level, ensuring compliance with security constraints and data privacy (GDPR)
Design and implement internal procedures to verify and ensure appropriate data quality assessment for natural hazard damage modeling;
Develop buildingsâ€™ vulnerability modules and implement civil engineering methods to model property damages exposed to natural hazards
Gather historical eventsâ€™ referencing and loss modeling;
Analyse and study resilience strategies for buildingsâ€™ vulnerability adaptation to natural hazards and extreme events in the context of climate change
Participate in the Groupâ€™s response to climate risks and their evolutions, within its corporate responsibility framework;
 Assess CAT risks borne by AXA entitiesexposed to natural events
Provide a technical support to local entities around the collection of their exposure data;
Assess CAT risks (cyclones, earthquakes, floods, hailstorms, droughts, wildfires) associated to these exposures using dedicated catastrophe modelling tools;
Deliver an AXA view of the gross risk for AXA entities, enabling them to purchase adequate reinsurance in line with their risk appetite;
Participate in the Group Reinsurance mechanism and estimate the impact at local and group level buildingsâ€™ vulnerability modeling for Natural Hazard damages.
 Vous rejoignez une entreprise :
-    Responsable, vis-Ã -vis des personnes, y compris ses employÃ©s et ses clients, et de la planÃ¨te. 
-    Aux valeurs fortes
-    Qui encourage la mobilitÃ© interne, et la formation de ses employÃ©s
-    Qui vous offre de nombreux avantages (en savoir plus ici : Reward & Benefits - french | AXA Group)
-    Flexible, qui permet le travail hybride, au bureau et Ã  la maison.
Les informations fournies par les candidat(e)s seront traitÃ©es de maniÃ¨re strictement confidentielle et utilisÃ©es uniquement Ã  des fins de recrutement.
Voir moins","Profil recherchÃ©
The candidate will have a solid scientific background together with strong inter-personal skills allowing him / her to evolve in a highly exposed and international environment.
Professional and technical skills
Master degree or equivalent in relevant field (civil engineering, natural hazards, applied maths, actuary);
Civil Engineering knowledge/experience is a plus;
Robust Data and programming skills: collection, transformation and mining (R/Python, SQL);
Strong interest in Climate Change and Natural Hazard science;
Interest in the business fields related to (re)insurance;
French and Business English â€“ fluent (spoken and written);
4 years experience in a relevant field.
 Interpersonal skills
Analytical skills / Ability to evolve in a diverse technical and operational environment;
Team work / Project management abilities / Entrepreneurial spirit and ambition to drive change;
Voir plus"
Stage â€“ Data Engineer - F/H,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",Stage,Suresnes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
Lâ€™Ã©quipe Â« Big Data Â» de Direct Assurance a pour mission principale de contribuer Ã  la dynamique continue dâ€™innovation et de perfectionnement de lâ€™entreprise en rÃ©solvant des problÃ©matiques business concrÃ¨tes par la mise en place dâ€™une plateforme Data dans le Cloud, ainsi que la conception et la rÃ©alisation de solutions techniques de data science en sâ€™appuyant sur des sources de donnÃ©es variÃ©es tant en interne quâ€™en externe.
 Vos missions seront les suivantes :
Â·       Concevoir des tableaux de bord de suivi des dÃ©penses (FinOps) pour aider les Ã©quipes Data Ã  mieux comprendre la consommation Cloud associÃ©e Ã  leurs traitements et garder le contrÃ´le sur les coÃ»ts
Â·       Concevoir et mettre en Å“uvre les traitements dâ€™alimentation du DataLake et de transformation des donnÃ©es
Â·       Garantir la qualitÃ© des donnÃ©es en mettant en place les outils de mesure et de suivi adÃ©quats
Â·       Identifier, collecter, explorer, comprendre et intÃ©grer les donnÃ©es nÃ©cessaires Ã  la rÃ©solution de problÃ©matiques mÃ©tier et opÃ©rationnelles
Â·       Assurer le suivi de la production
Â·       Participer, avec lâ€™Ã©quipe, au dÃ©veloppement de la plateforme sur Azure et Ã  la dÃ©finition des bonnes pratiques de dÃ©veloppement
Â·       Accompagner les Ã©quipes mÃ©tier dans la prise en main de la plateforme Azure et les aider Ã  monter en compÃ©tences en programmation en sâ€™assurant du respect des standards internes
 Environnement technique : Spark, Scala, Python, SQL, Cloud Azure, PowerBI
Lâ€™ExpÃ©rience Collaborateur est pour nous essentielle pour la rÃ©ussite de notre entreprise.
Nous proposons des parcours de dÃ©veloppement professionnel en adÃ©quation avec la transformation digitale du secteur de lâ€™assurance pour enrichir leur panel de compÃ©tences.
Nous avons Ã  cÅ“ur de cÃ©lÃ©brer nos rÃ©ussites. La convivialitÃ© qui nous anime est le fruit de la diversitÃ© des profils que nous recrutons.
Nos locaux proposent un cadre de travail moderne avec une mise Ã  disposition dâ€™espaces de dÃ©tente (baby-foot, cafÃ©tÃ©ria) et de services (espace forme, places en crÃ¨cheâ€¦) pour une ExpÃ©rience Collaborateur rÃ©ussie !
Nous nous engageons en faveur de la lutte contre les discriminations et soutenons la diversitÃ© et l'Ã©galitÃ© des chances. Tous nos emplois sont ouverts aux personnes en situation de handicap.
Si ce poste vous intÃ©resse et si la perspective de contribuer fortement au dÃ©veloppement de lâ€™entreprise dans un environnement innovant et dynamique vous motive, rejoignez-nous !
Voir moins","Profil recherchÃ©
De formation Bac+5 (ou plus) en dÃ©veloppement informatique / data engineering, vous avez pu dÃ©velopper les compÃ©tences techniques suivantes :
Â·       Cloud Azure (DataFactory, ADLS, Databricks)
Â·       Spark
Â·       Scala + Python
Â·       Bonnes connaissances sur les architectures de donnÃ©es et le cloud
Â·       Connaissances des processus collaboratifs et outils de dÃ©veloppement (DevOps, Git, CI/CDâ€¦)
Â·       SQL
Â·       Data visualisation
 Les qualitÃ©s suivantes sont nÃ©cessaires :
Â·       Bonne facultÃ© pour apprÃ©hender les couches technologiques et les outils
Â·       CapacitÃ© Ã  travailler de maniÃ¨re collaborative au sein dâ€™Ã©quipes pluridisciplinaires
Â·       Autonomie, grande rigueur, pragmatisme et rÃ©elle capacitÃ© Ã  dÃ©livrer
Â·       Bon niveau dâ€™anglais, parlÃ© et Ã©crit
Voir plus"
Lead Data Engineer,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",CDI,Suresnes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Lâ€™Ã©quipe Â« Big Data Â» a pour mission principale de contribuer Ã  la dynamique continue dâ€™innovation et de perfectionnement de lâ€™entreprise en rÃ©solvant des problÃ©matiques business concrÃ¨tes par la mise en place dâ€™une plateforme Data dans le Cloud, ainsi que la conception et la rÃ©alisation de solutions techniques de data science en sâ€™appuyant sur des sources de donnÃ©es variÃ©es tant en interne quâ€™en externe.
Vos missions seront les suivantes :
Â·       Prendre en charge la supervision, l'organisation et l'animation d'une Ã©quipe de data engineers
Â·       Participer au recrutement, Ã  la formation et au coaching des data engineers
Â·       Proposer des architectures et orienter le choix des technologies adaptÃ©es aux besoins de diffÃ©rents projets Data
Â·       Concevoir et mettre en Å“uvre les traitements dâ€™alimentation du DataLake et de transformation des donnÃ©es
Â·       Garantir la qualitÃ© des donnÃ©es en mettant en place les outils de mesure et de suivi adÃ©quats
Â·       Identifier, collecter, explorer, comprendre et intÃ©grer les donnÃ©es nÃ©cessaires Ã  la rÃ©solution de problÃ©matiques mÃ©tier et opÃ©rationnelles
Â·       Participer, avec lâ€™Ã©quipe, au dÃ©veloppement de la plateforme sur Azure et Ã  la dÃ©finition des bonnes pratiques de dÃ©veloppement
Â·       Accompagner les Ã©quipes mÃ©tier dans la prise en main de la plateforme Azure et les aider Ã  monter en compÃ©tences en programmation en sâ€™assurant du respect des standards internes
Environnement technique : Spark, Scala, Python, Cloud Azure, OpenShift, SQL
Lâ€™ExpÃ©rience Collaborateur est pour nous essentielle pour la rÃ©ussite de notre entreprise.
Nous proposons des parcours de dÃ©veloppement professionnel en adÃ©quation avec la transformation digitale du secteur de lâ€™assurance pour enrichir leur panel de compÃ©tences.
Nous avons Ã  cÅ“ur de cÃ©lÃ©brer nos rÃ©ussites. La convivialitÃ© qui nous anime est le fruit de la diversitÃ© des profils que nous recrutons.
Nos locaux proposent un cadre de travail moderne avec une mise Ã  disposition dâ€™espaces de dÃ©tente (baby-foot, cafÃ©tÃ©ria) et de services (espace forme, places en crÃ¨cheâ€¦) pour une ExpÃ©rience Collaborateur rÃ©ussie !
Nous nous engageons en faveur de la lutte contre les discriminations et soutenons la diversitÃ© et l'Ã©galitÃ© des chances. Tous nos emplois sont ouverts aux personnes en situation de handicap.
Si ce poste vous intÃ©resse et si la perspective de contribuer fortement au dÃ©veloppement de lâ€™entreprise dans un environnement innovant et dynamique vous motive, rejoignez-nous !
Voir moins","Profil recherchÃ©
Nous recherchons un profilâ€¦
 De formation Bac+5 (ou plus) en dÃ©veloppement informatique / data engineering, vous justifiez a minima 2 ans sur un poste de Lead, au cours desquels vous avez pu dÃ©velopper les compÃ©tences techniques suivantes :
Â·       Cloud Azure (DataFactory, ADLS, Databricks)
Â·       Spark
Â·       Scala (obligatoire) + Python
Â·       Bonnes connaissances sur les architectures de donnÃ©es et le cloud
Â·       Solides connaissances des processus collaboratifs et outils de dÃ©veloppement (DevOps, Git, CI/CDâ€¦)
Â·       SQL
Les qualitÃ©s suivantes sont nÃ©cessaires :
Â·       Bonne facultÃ© pour apprÃ©hender les couches technologiques et les outils
Â·       CapacitÃ© Ã  travailler de maniÃ¨re collaborative au sein dâ€™Ã©quipes pluridisciplinaires
Â·       CapacitÃ© Ã  motiver et encadrer une Ã©quipe pour aider chacun Ã  se dÃ©velopper
Voir plus"
Data engineer - Control Software,"{'name': 'PASQAL', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es', 'employees': '210 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '34 ans'}",CDI,Massy,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
About Pasqal
PASQAL designs and develops Quantum Processing Units (QPUs) and associated software tools.
Our innovative technology enables us to address use cases that are currently beyond the reach of the most powerful supercomputers; these cases can concern industrial application challenges as well as fundamental science needs.
In addition to the exceptional computing power they provide, QPUs are highly energy efficient and will contribute to a significant reduction in the carbon footprint of the HPC industry. 
 Job Description
 As part of our strong growth, we are recruiting a Data Engineer to strengthen our team in charge of the control software of our QPUs (Quantum Processing Units): Embedded Software team.
During operations, the control software gathers a varied set of data from QPU devices, such as camera images, optical measurements, runtime processing and environmental data. These data are a key resource, used by several teams at Pasqal for analysis purposes: performance measurement, characterization, calibration, investigation.
You will contribute to development, integration and deployment of the data analysis infrastructure, including platform, databases, API, services, frontend / user interface.
 In this role, your main responsibilities will include:
Clarify needs with system engineers.
Implement features (including unit tests) on whole data lifecycle: collection, storage, management, access, analysis, display, back-up, migration
Develop automated tests, integrate them in CI pipelines
Define, deploy and maintain data infrastructure
Update existing or create new document to reflect implemented features.
Participate in code and doc review process for own and peers' tasks.
Investigate raised issues then propose and implement solution

About you
A master's degree or an engineering degree with a specialization in computer science
Over 3 years of experience in software development and data engineering
Ability to understand complex systems to propose and implement effective solutions
Your professional background has provided you with experience throughout the entire software development lifecycle
You demonstrate a genuine interest in new technologies and scientific challenges.
You have a strong ability to work independently and can take responsibility for your projects while collaborating with the rest of the team. 
 The required technical skills for this position include:
Experience in database (PostgreSQL, InfluxDB) management and query languages
Experience in Python for data engineering (including tools like pandas, numpy, matplotlib, plotly, streamlit) and API, development practices (coding standards, testing, review...), and tools (git, pytest)
Knowledge of Linux, Gitlab, docker
English professional proficiency
What we offer
Offices in Massy, France
A flexible rhythm of remote work (2 to 3 days per week)
Type of contract : CDI
A dynamic and close-knit international team
A key role in a growing scale-up

Recruitment process
An interview with our Talent Acquisition Specialist of 30'.
An exchange with the Engineering manager of Embedded Software team
A meeting with the team in our offices
An offer!
PASQAL is an equal opportunity employer. We are committed to creating a diverse and inclusive workplace, as inclusion and diversity are essential to achieving our mission. We encourage applications from all qualified candidates, regardless of gender, ethnicity, age, religion or sexual orientation.
Voir moins",
Data Engineer - Big Data,"{'name': 'APHP DSI', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, SantÃ©', 'employees': '495 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '46 ans'}",CDD / Temporaire,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
La mission de votre Ã©quipe
Afin de permettre le dÃ©veloppement de projets de recherche innovants, en particulier dans le domaine de lâ€™intelligence artificielle, lâ€™APâ€“HP a mis en place une plateforme Big Data, infrastructure informatique propre, intÃ©grant des capacitÃ©s de stockage et de calcul pour lâ€™exploitation sÃ©curisÃ©e et performante des donnÃ©es de santÃ© dont elle est dÃ©positaire. Cette plateforme hÃ©berge notamment lâ€™entrepÃ´t de donnÃ©es de santÃ© (EDS) de lâ€™AP-HP.

Lâ€™EntrepÃ´t de DonnÃ©es de SantÃ© (EDS) de lâ€™AP-HP intÃ¨gre des donnÃ©es administratives et mÃ©dicales de plus de 8 millions de patients hospitalisÃ©s ou venus en consultation au sein des 39 Ã©tablissements de lâ€™AP-HP (20 millions de dossiers mÃ©dicaux, plus de 10 millions de diagnostics, 181 millions de rÃ©sultats de laboratoiresâ€¦). Cet entrepÃ´t permet dâ€™amÃ©liorer le pilotage de lâ€™activitÃ© hospitaliÃ¨re et de faire avancer la recherche scientifique dans le domaine de la santÃ© en favorisant la rÃ©alisation dâ€™Ã©tudes sur donnÃ©es, la mise en place dâ€™essais cliniques et le dÃ©veloppement dâ€™algorithmes dâ€™aide Ã  la dÃ©cision.

La Plateforme Big Data de lâ€™AP-HP compte actuellement +20 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po dâ€™espace disque), de machines GPU (56 Nvidia P40 et V100), de 20 machines dÃ©diÃ©es aux environnements Jupyter pour lâ€™analyse de donnÃ©es, et de nombreuses autres machines applicatives.

Votre Ã©quipe, le domaine Â« Plateforme Big Data Â», a pour mission lâ€™intÃ©gration des donnÃ©es de santÃ© massives et complexes (donnÃ©es structurÃ©s, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation Ã  grande Ã©chelle, de maniÃ¨re performante, ergonomique et sÃ©curisÃ©e dans le respect des principes et rÃ¨gles de gouvernance des donnÃ©es dÃ©finis par lâ€™AP-HP.
Vos missions
Au sein de lâ€™Ã©quipe en charge de la Plateforme Big Data de lâ€™APHP, vous aurez pour missions de proposer et de dÃ©velopper des outils ou composants rÃ©pondant aux attentes des mÃ©decins et chercheurs pour lâ€™exploitation des donnÃ©es collectÃ©es dans le cadre de leurs projets de recherche. Ces dÃ©veloppements sâ€™inscrivent dans un contexte de standardisation des donnÃ©es selon le modÃ¨le de donnÃ©es commun OMOP et dâ€™interopÃ©rabilitÃ© sur la base du standard dâ€™Ã©change HL7-FHIR.
En tant que data engineer - donnÃ©es massives, sous la responsabilitÃ© du chef dâ€™Ã©quipe dÃ©veloppement donnÃ©es massives, il sâ€™agira de contribuer Ã  la crÃ©ation dâ€™outils dâ€™intÃ©gration, de visualisation, dâ€™exploration et dâ€™enrichissement de donnÃ©es mÃ©dicales pour la recherche, souvent en lien direct avec des personnels mÃ©dicaux. Outre lâ€™intÃ©gration technique des donnÃ©es cliniques, les dÃ©veloppements relÃ¨vent globalement de la pseudonymisation des donnÃ©es pour assurer la confidentialitÃ© des dossiers mÃ©dicaux, de la standardisation des modÃ¨les de donnÃ©es, de la mise en place de moteurs de recherche performant incluant des notions sÃ©mantiques et de lâ€™analyse qualitative et statistique des donnÃ©es collectÃ©es. Selon la typologie des donnÃ©es (donnÃ©es structurÃ©s, imagerie, voix, signaux physiologiques, etc.) des outils plus spÃ©cifiques sont Ã©galement mise en Å“uvre. Vos missions comportent typiquement des facettes suivantes :
Contribuez Ã  la dÃ©finition des besoins techniques et Ã  lâ€™accompagnement des datascientists, chercheurs, et mÃ©decins lors de la rÃ©alisation de projets de recherche impliquant de nouvelles sources de donnÃ©es
Analyserez les diffÃ©rents sources de donnÃ©es dâ€™un point de vue technique (acquisition, stockage, transformation, exploitation, â€¦)
DÃ©velopperez, industrialiserez et maintiendrez des traitements de donnÃ©es (extraction, sÃ©lection, collecte et intÃ©gration) dans un contexte big data (dÃ©veloppements en Spark/Scala)
Contribuerez Ã  lâ€™utilisation de ces nouvelles typologies de donnÃ©es (extraction, sÃ©lection, collecte et intÃ©gration) via des connecteurs spÃ©cifiques dÃ©veloppÃ©s en java/scala, python ou dâ€™autres langages
Aiderez Ã  lâ€™implÃ©mentation de standards et normes de mise Ã  disposition des donnÃ©es (OMOP/FHIR)
Industrialiserez le code de gÃ©nÃ©ration du flux de donnÃ©es et assurer sa performance globale
Optimisation de la performance des outils dans un contexte big data (Hadoop / Spark)
DÃ©velopperez des mÃ©thodologies standardisÃ©es pour lâ€™intÃ©gration de nouvelles donnÃ©es
Mettrez en place des outils les processus de tests unitaires, de recette et de qualification des donnÃ©es
Travaillerez en collaboration avec des partenaires industriels dans le cadre des diffÃ©rents projets de recherche
Voir moins","Profil recherchÃ©
IdÃ©alement, vous..
Avez un diplÃ´me dâ€™ingÃ©nieur ou Ã©quivalent (bac+4/5, master2) en informatique ou sciences avec formation complÃ©mentaire en informatique
Avez une expÃ©rience de dÃ©veloppement sous Linux, des langagage Java/Scala et si possible Python
Avez une expÃ©rience dans la manipulation de donnÃ©es avec le langage SQL
Connaissez les standards en informatique de santÃ© (HL7 v2, DICOM, HL7-FHIR, OMOP, â€¦)
Avez le goÃ»t de lâ€™intÃ©gration de systÃ¨mes informatiques hÃ©tÃ©rogÃ¨nes
Avez des connaissances des bonnes pratiques de sÃ©curitÃ© informatique et de la rÃ©glementation informatique et libertÃ©s
AdhÃ©rez aux valeurs du service public et vous avez un intÃ©rÃªt prononcÃ© pour le domaine de la santÃ©
Avez un niveau dâ€™anglais courant
Vous avez un savoir faire dans un de ces domaines :
Bonne maitrise des langages Java/Scala (Spark), Python et de bash
Voir plus"
Data Engineer - Big Data - Data Factory - Services Financiers - Ile de France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Notre Data Factory
Vous Ãªtes passionnÃ©(e) par la valorisation de la donnÃ©e, rejoignez notre Data Factory localisÃ©e Ã  Paris ! Vous y rencontrerez des experts de la mise en Å“uvre de Plateforme de DonnÃ©es, des Data Architectes ou autres experts solution autour des problÃ©matiques de valorisation de la donnÃ©e.
Vous Ãªtes accompagnÃ©(e) au dÃ©veloppement de vos connaissances aux travers de diffÃ©rents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnÃ©e, la modÃ©lisation et mise Ã  disposition.
Rejoindre notre Data Factory Sopra Steria, c'est rejoindre une communautÃ© de Data IngÃ©nieurs fiers de partager leur savoir et ouverts aux nouvelles expÃ©riences et expÃ©rimentations de la donnÃ©e.
Votre rÃ´le et mission :
Dans le cadre de la mise en place du centre Data pour un grand acteur financier de lâ€™Ã©tat et selon votre appÃ©tence, vous participerez Ã  plusieurs Ã©tapes de la chaÃ®ne :
- La comprÃ©hension des besoins mÃ©tiers et la traduction solution de data ingÃ©nierie
- La mise en Å“uvre de solution d'ingestion des donnÃ©es quelles soit en batch et/ou en streaming dans un contexte Cloud ;
- La structuration du DataLake, la mise en place des processus de gouvernance et de sÃ©curisation des donnÃ©es ;
- Le traitement de la donnÃ©e jusqu'Ã  l'exposition au mÃ©tier ;
- La mise en place de la chaine CI/CD et de sa supervision ;
- La veille technologie avec nos partenaires Ã©diteurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idÃ©ation pour nos clients.
 Additional Information
 Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusqu'Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressants : une mutuelle, un CSE, des titres restaurants, un accord d'intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 50 mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.
La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« vendredi Â».
L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encore).
 Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
> 
Voir moins","Profil recherchÃ©
DiplÃ´mÃ©(e) d'une Ecole d'ingÃ©nieur ou formation Ã©quivalente, vous avez dÃ©jÃ  participÃ© Ã  un projet Data (Big Data, BI) et vous avez une expÃ©rience de minimum 3 ans.
Vous maitrisez un langage de programmation appliquÃ© Ã  lâ€™analyse de donnÃ©es (SQL, Scala, R, Python, Java), le traitement distribuÃ© de donnÃ©es (Spark, Pyspark , Hadoop) et un Framework de streaming de donnÃ©es (Kafka, RabbitMQ, etc.)
Vous Ãªtes attirÃ©(e) par le monde du numÃ©rique, le Cloud et des technologies innovantes.
Vous avez un bon esprit d'analyse, Ãªtes curieux(se) et passionnÃ©(e) et vous avez le sens du travail en Ã©quipe dans une organisation Agile type Srcum ou SAFE
Vous accordez une importance particuliÃ¨re au dÃ©veloppement de vos compÃ©tences sur plusieurs technologies. Vous souhaitez une Ã©volution rÃ©elle de carriÃ¨re Ã  travers l'expÃ©rience projet. Vous Ãªtes soucieux de l'apport de valeur pour vos clients. Et vous voulez transmettre votre savoir auprÃ¨s de collaborateurs moins expÃ©rimentÃ©s. Alors, n'attendez-plus, ce poste est fait pour vous !
 "
Data Engineer H/F,"{'name': 'INNOVELA', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '15 collaborateurs', 'creation_year': '2016', 'turnover': '1.7Mâ‚¬', 'mean_age': '30 ans'}",CDI,Paris,45K Ã  65K â‚¬,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Le poste
Au sein de lâ€™Ã©quipe de dÃ©veloppement dâ€™Innovela, vous participerez Ã  la conception et au dÃ©veloppement de pipeline de donnÃ©es en utilisant les solutions de la plateforme Google principalement.
Vous travaillerez en mode agile au sein dâ€™une Ã©quipe passionnÃ©e et dynamique, et sur des technologies toujours plus innovantes.
Les projets sont effectuÃ©s soit chez nos clients, soit directement dans les locaux dâ€™Innovela situÃ©s dans le 11Ã¨me arrondissement de Paris.
Enfin, vous participerez Ã©galement aux Ã©vÃ©nements organisÃ©s par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.
Les responsabilitÃ©s
Identifier et conseiller les solutions appropriÃ©es pour rÃ©pondre aux besoins des clients.
Participer aux diffÃ©rentes phases dâ€™un projet (analyse, prototypage, conception, dÃ©veloppement, dÃ©ploiement, maintenance).
Veiller Ã  la gouvernance des donnÃ©es et mise en place de process MDM : Rapprochement de donnÃ©es de diffÃ©rentes sources non homogÃ¨nes, DÃ©doublonnage, Normalisation, Historisation, Calcul dâ€™indicateurs et dâ€™agrÃ©gats.
Construire et monitorer des pipeline de donnÃ©es sur GCP.
Effectuer de la veille technologique sur les technologies web, cloud et Google.
Voir moins","Profil recherchÃ©
Master/IngÃ©nieur en informatique ou dans un domaine technique associÃ©.
3 ans dâ€™experiences min (hors stages ou alternances).
CompÃ©tences en programmation Python (minimum 2 ans de pratique en entreprise).
Bonne connaissance des bases de donnÃ©es (relationnelles et non-relationnelles).
Bonne connaissance de la partie data et de la gouvernance sur GCP (Dataflow, Composer, Storage, Bigquery â€¦).
ExpÃ©rience significative avec des technologies Big Data telles que Hadoop, Spark, Snowflake, Bigquery, Airflow sont fortement apprÃ©ciÃ©es.
Autonome, curieux(-se), passionnÃ©(e) et motivÃ©(e)."
Data Engineer Senior H/F,"{'name': 'INNOVELA', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '15 collaborateurs', 'creation_year': '2016', 'turnover': '1.7Mâ‚¬', 'mean_age': '30 ans'}",CDI,Paris,55K Ã  80K â‚¬,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Le poste Au sein de lâ€™Ã©quipe de dÃ©veloppement dâ€™Innovela, vous participerez Ã  la conception et au dÃ©veloppement de pipeline de donnÃ©es en utilisant les solutions de la plateforme Google principalement.
Vous travaillerez en mode agile au sein dâ€™une Ã©quipe passionnÃ©e et dynamique, et sur des technologies toujours plus innovantes.
Les projets sont effectuÃ©s soit chez nos clients, soit directement dans les locaux dâ€™Innovela situÃ©s Ã  Paris.
Enfin, vous participerez Ã©galement aux Ã©vÃ©nements organisÃ©s par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.
Les responsabilitÃ©s
Identifier et conseiller les solutions appropriÃ©es pour rÃ©pondre aux besoins des clients.
Participer aux diffÃ©rentes phases dâ€™un projet (analyse, prototypage, conception, dÃ©veloppement, dÃ©ploiement, maintenance).
Veiller Ã  la gouvernance des donnÃ©es et mise en place de process MDM : Rapprochement de donnÃ©es de diffÃ©rentes sources non homogÃ¨nes, DÃ©doublonnage, Normalisation, Historisation, Calcul dâ€™indicateurs et dâ€™agrÃ©gats.
Construire et monitorer des pipeline de donnÃ©es sur GCP.
Effectuer de la veille technologique sur les technologies web, cloud et Google.
Voir moins","Profil recherchÃ©
Master/IngÃ©nieur en informatique ou dans un domaine technique associÃ©.
5 ans dâ€™experiences min (hors stages ou alternances).
CompÃ©tences en programmation Python.
Bonne connaissance des bases de donnÃ©es (relationnelles et non-relationnelles).
Bonne connaissance de la partie data et de la gouvernance sur GCP (Dataflow, Composer, Storage, Bigquery â€¦).
ExpÃ©rience significative avec des technologies Big Data telles que Hadoop, Spark, Snowflake, Bigquery, Airflow sont fortement apprÃ©ciÃ©es.
Autonome, curieux(-se), passionnÃ©(e) et motivÃ©(e)."
Data Engineer - Madonne Core (H/F),"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards â‚¬ de PNB', 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous rejoignez l'Ã©quipe Core en charge de la maintenance Ã©volutive des applications Madonne (RÃ©colte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiÃ©e au coeur de l'IT Risque).

Au quotidien vous avez pour missions de :

Participer Ã  l'adaptation de nos applications en adÃ©quation avec les besoins mÃ©tiers (nouveaux produits, nouvelles rÃ¨glementations, nouveaux SI Front) ;
Participer activement Ã  la modernisation de nos outils, modernisation de notre chaÃ®ne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;
Monter en compÃ©tences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous dÃ©velopperez une comprÃ©hension globale des chaÃ®nes de traitements ;
Participer Ã  tous les travaux de modernisation de notre SI, et Ãªtre donc engagÃ© dans la migration de nombreux process vers le DataLake Risk.





#TransformativeFinance
Ce poste est basÃ© Ã  Paris avec la possibilitÃ© de tÃ©lÃ©travailler.
En tant que Top Employer, nous plaÃ§ons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilitÃ© interne, dÃ©veloppement de carriÃ¨re et de formation vous permettent de grandir et de vous Ã©panouir tout au long de votre parcours.
Vous Ã©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.
Vous avez Ã©galement la possibilitÃ© de vous engager en faveur de la sociÃ©tÃ© et de causes qui vous tiennent Ã  cÅ“ur via notre fondation d'entreprise.
A propos du processus de recrutement
Vous serez contactÃ© par l'un de nos recruteurs avant de rencontrer nos experts mÃ©tier (manager, membre de l'Ã©quipe ou de la filiÃ¨re mÃ©tier).
Voir moins","Profil recherchÃ©
Qui Ãªtes-vous ? Si vous vous reconnaissez dans la description suivante vous Ãªtes fait pour travailler avec nous : Vous souhaitez bÃ©nÃ©ficier d'une premiÃ¨re expÃ©rience significative en dÃ©veloppement Spark et Scala. Vous maitrisez : * Les mÃ©thodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appÃ©tence pour la manipulation de la data. Vous Ãªtes : * Reconnu par votre esprit d'Ã©quipe ; * Capable de communiquer avec des publics diffÃ©rents, notamment avec le mÃ©tier ; * Autonome et ntÃ©ressÃ© par l'environnement finance de marchÃ©. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous Ãªtes intÃ©ressÃ© en rÃ©pondant Ã  cette annonce."
Senior Data Engineer (H/F/X),"{'name': 'REPLY', 'sector': 'SaaS / Cloud Services, Objets connectÃ©s, Big Data', 'employees': '14000 collaborateurs', 'creation_year': '1996', 'turnover': ""1.89 milliard d'euros en 2023"", 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,01 mars 2024,> 5 ans,Bac +5 / Master,"Descriptif du poste
Tu un Data Engineer avec 5 ans dâ€™expÃ©rience ? Tu es convaincu que le cloud nâ€™a pas fini de bouleverser le domaine de la data, mais tu nâ€™en vois pas sur ta mission actuelle et tu souhaites avoir accÃ¨s Ã  un rÃ©seau et des ressources pour monter en compÃ©tences ?
Alors cette offre est pour toi ! ğŸ™ŒğŸ¼
âœ… Pourquoi nous croire ?
Reply est lâ€™un des 3 Premiums Consulting Partner dâ€™AWS en 2023 en France, 80 % de nos missions sont sur AWS - tu auras lâ€™assurance dâ€™avoir du AWS chez nous.
50 % de nos missions en Ã©quipe de petite taille multidisciplinaire et 50 % directement chez nos clients - dans les deux cas, tu pourras interagir avec tes utilisateurs
Nous dÃ©ployons des plateformes data, des gouvernances et des solutions de Machine Learning ainsi que nos propres produits - tu seras entourÃ© dâ€™experts.
ğŸ“£ Pourquoi avons-nous besoin de toi ?
Nous avons besoin de toi afin dâ€™accompagner nos clients dans la mise en place dâ€™Architectures Data robustes et Ã©volutives.
Tu ne seras pas seule, car pour accÃ©lÃ©rer notre croissance et rÃ©pondre Ã  la demande de nos clients, nous prÃ©voyons de grandir dâ€™un tiers cette annÃ©e !
ğŸŒ± Quelle sera ton Ã©quipe ?
En fonction de nos opportunitÃ©s et de tes prÃ©fÃ©rences, tu auras deux options :
rejoindre lâ€™une de nos Ã©quipes pour livrer des solutions Ã  plusieurs clients. Tu devras alors te rendre 2 ou 3 jours par semaine dans nos locaux, pour faciliter le partage des connaissances et des informations.
ou directement rejoindre lâ€™un de nos clients pour lâ€™accompagner dans sa transformation sur plusieurs mois. La politique de tÃ©lÃ©travail sera celle du client, mais tu garderas le contact avec ton manager et tes collÃ¨gues en te rendant quelque fois par mois dans nos locaux.
Nous sommes dans le 9Ã¨me arrondissement de Paris, entre la gare Saint-Lazare et la Gare du Nord.
Ce nâ€™est pas tout, le Partner de Data Reply tâ€™invitera Ã  de nombreux Ã©vÃ©nements afin de garder une ambiance de travail conviviale :
un afterwork au moins une fois par mois,
Les Data Universities, au moins une fois par mois en prÃ©sentiel ou Ã  distance, un moment oÃ¹ chacun peut  prÃ©senter une nouvelle technologie,
une journÃ©e par mois oÃ¹ tous les Data Replyers se retrouveront pour partager leurs cas pratiques, suivi (et oui ) dâ€™un afterwork Ã  thÃ¨me.
ğŸš€ Qui seront tes clients ?
Nous ciblons des grands groupes tout secteur dâ€™activitÃ© confondus ainsi que des Editeurs de logiciel en forte croissance, tu dÃ©couvriras des contextes variÃ©s.
ğŸ› ï¸ Que feras-tu avec nous ?
Nous avons besoin de toi pour aider nos clients Ã  :
ImplÃ©menter les nouveaux cas dâ€™usage, notamment la mise en place dâ€™architecture data, de plateforme data, de modÃ¨les de donnÃ©es et lâ€™implÃ©mentaton de data mesh.
Cartographier des donnÃ©es et des flux de donnÃ©es
ImplÃ©menter les pipelines dâ€™analyse et de traitement de donnÃ©es
Industrialiser les flux de donnÃ©es et leurs visualisations en dashboards, reporting.
RÃ©aliser les tests unitaires et dâ€™intÃ©gration
Ainsi que participer Ã  la vie de Data Reply et notamment :
La diffusion et le partage de connaissances au sein de Data Reply
Les Ã©vÃ©nements organisÃ©s par Reply (Reply eXchange, hackathon, AWS summit â€¦)
Le dÃ©veloppement des offres packagÃ©es en appui des managers
ğŸ’ Ce que tu gagnes Ã  nous rejoindre :
Des missions variÃ©es sur des environnements cloud avec de nombreux clients reconnus nationalement et Ã  lâ€™international
Un programme de certifications intÃ©grÃ© Ã  tes objectifs, qui donnent lieu Ã  des primes complÃ©mentaire et dont le coÃ»t est bien sÃ»r pris en charge par Reply
Une progression de carriÃ¨re structurÃ©e vers plus de responsabilitÃ© technique ou managÃ©riales, et des passerelles entre les deux.
Une Ã©quipe soudÃ©e et une ambiance de travaille conviviale grÃ¢ce Ã  des afterworks organisÃ©s au moins une fois par mois,
Lâ€™opportunitÃ©s de participer Ã  des Hackathons, Code Challenges et Lab Camps ainsi quâ€™Ã  la diffusion et le partage de connaissance au sein de lâ€™Ã©quipe Data Reply
Voir moins","Profil recherchÃ©
ğŸ‘¨ğŸ¼â€ğŸš€ Ce dont on a besoin :
Un Master dans la data ou lâ€™informatique dâ€™une Grande Ecole dâ€™IngÃ©nieur ou dâ€™une UniversitÃ© EuropÃ©ennes
Au moins 5 ans dâ€™expÃ©rience en tant que Data Engineer dans des environnements cloud
Pouvoir mener un entretien en anglais
Tu nâ€™as pas encore ses compÃ©tences ? Ce nâ€™est que parti remise, suis nous surLinkedinet surWelcome to the Junglepour ne pas rater la prochaine offre.
ğŸ¦¸ğŸ¼â€â™€ï¸ Ce que nous apprÃ©cions :
Une connaissance dâ€™un ETL (Glue, Rivery, DBT, Airbyte), dâ€™outils de data visualisation ou de technologies de temps rÃ©el (Kafka, Kinesis, Confluent ou Databricks).
Une expÃ©rience ou une certification sur AWS
Lâ€™envi dâ€™Ãªtre le premier de Reply Ã  rejoindre un nouveau client, ou de former des consultants juniors en intern"
Cloud Data Engineer,"{'name': 'VISIAN', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, StratÃ©gie', 'employees': '80 collaborateurs', 'creation_year': '2017', 'turnover': ""14 Millions d'euros"", 'mean_age': '28 ans'}",CDI,Courbevoie,42 Ã  55 â‚¬,TÃ©lÃ©travail frÃ©quent,11 mars 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
Visian, SociÃ©tÃ© de conseil spÃ©cialisÃ©e en innovation, design produit, gestion de projet IT et dÃ©veloppement Data. Recherche un Cloud Data Engineer pour un de ces clients.
Nous recherchons un Cloud Data Engineer passionnÃ© et expÃ©rimentÃ© pour rejoindre notre Ã©quipe dynamique. En tant que membre clÃ© de notre Ã©quipe de donnÃ©es, vous serez responsable de la conception, du dÃ©veloppement et de la maintenance des solutions de traitement et dâ€™analyse de donnÃ©es chez nos clients. Vous contribuerez Ã  la crÃ©ation dâ€™une architecture robuste et Ã©volutive dans le cloud pour rÃ©pondre Ã  aux besoins croissants de nos clients en matiÃ¨re de donnÃ©es.
Missions :
Concevoir et dÃ©velopper des pipelines de donnÃ©es efficaces et Ã©volutifs.
IntÃ©grer et traiter des donnÃ©es Ã  partir de diffÃ©rentes sources pour alimenter des entrepÃ´ts de donnÃ©es.
Collaborer avec les Ã©quipes mÃ©tier pour comprendre les besoins en donnÃ©es et fournir des solutions adaptÃ©es.
Mettre en Å“uvre des solutions de stockage et de gestion des donnÃ©es dans le cloud.
Optimiser les performances des requÃªtes et garantir la qualitÃ© des donnÃ©es.
Assurer la maintenance continue des infrastructures et des pipelines de donnÃ©es.
Stack :
Plateformes Cloud : AWS, Azure, GCP
Langages de Programmation : Python, SQL
Outils de Traitement de DonnÃ©es : Apache Spark, Apache Flink
Stockage de DonnÃ©es : Amazon S3, Azure Data Lake, Google Cloud Storage
Bases de DonnÃ©es : Amazon Redshift, Google BigQuery
Outils ETL : Apache Airflow, Talend
Infrastructure en tant que Code : Terraform
Voir moins","Profil recherchÃ©
+3ans dâ€™expÃ©riences
ExpÃ©rience pratique dans la conception et le dÃ©veloppement de pipelines de donnÃ©es cloud.
Solides compÃ©tences en programmation, en particulier avec Python, et en requÃªtage SQL.
Connaissance approfondie dâ€™un de ses plateformes cloud (AWS, Azure, GCP) et de leurs services associÃ©s.
MaÃ®trise des outils de traitement de donnÃ©es tels que Apache Spark et Apache Flink.
ExpÃ©rience dans la mise en Å“uvre de solutions de stockage de donnÃ©es et dâ€™entrepÃ´ts de donnÃ©es cloud.
FamiliaritÃ© avec les principes du dÃ©veloppement orientÃ© objet avec une expertise en Python.
CapacitÃ© Ã  travailler de maniÃ¨re autonome, Ã  rÃ©soudre des problÃ¨mes complexes et Ã  gÃ©rer plusieurs tÃ¢ches simultanÃ©ment.
MaÃ®trise de lâ€™anglais (Ã©crit et parlÃ©) pour une communication efficace au sein dâ€™une Ã©quipe internationale."
Data Engineer (H/F) | POEI,"{'name': 'DATASCIENTEST', 'sector': 'SaaS / Cloud Services, EdTech, Formation', 'employees': '130 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}",CDI,Puteaux,35K Ã  48K â‚¬,TÃ©lÃ©travail occasionnel,01 septembre 2023,> 1 an,Bac +5 / Master,,
Data Engineer Senior,"{'name': 'IN THE MEMORY', 'sector': 'Grande distribution, SaaS / Cloud Services, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2018', 'turnover': '17Mâ‚¬', 'mean_age': '28 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Nous recherchons un(e) Data Engineer expÃ©rimentÃ©(e) (SQL, Python, Spark) pour accompagner le dÃ©veloppement de la sociÃ©tÃ© et ses produits, en particulier dans le contexte de la multiplicitÃ© croissante des volumes, sources et types de donnÃ©es exploitÃ©s par la sociÃ©tÃ©.
IntÃ©grÃ©(e) en tant que collaborateur Ã  lâ€™Ã©quipe Data de Memory, ton rÃ´le sera dâ€™assurer lâ€™exploitation optimale de la donnÃ©e exploitÃ©e dans la plateforme dâ€™analyse Memory 360.
Tes principales responsabilitÃ©s seront :
Editer le cahier des charges des donnÃ©es Ã  collecter auprÃ¨s de nos partenaires distributeurs et accompagner sur la partie data la mise en Å“uvre de la plateforme dâ€™analyse Memory 360.
Faire un Ã©tat des lieux du modÃ¨le de donnÃ©es de la sociÃ©tÃ©, qui intÃ¨gre dÃ©jÃ  plusieurs types de donnÃ©es issues de diffÃ©rentes sources, en particulier les donnÃ©es transactionnelles / de fidÃ©litÃ©.
Prendre en main la gestion de la donnÃ©e dans le cloud de la sociÃ©tÃ© (Azure), pour optimiser les coÃ»ts et lâ€™efficacitÃ© des analyses effectuÃ©es par lâ€™Ã©quipe Analytics.
Utiliser Python, Apache Spark/Databricks, Apache Airflow et Docker pour crÃ©er des solutions de traitement de donnÃ©es efficaces et assurer la qualitÃ©, la sÃ©curitÃ© et la conformitÃ© des donnÃ©es Ã  toutes les Ã©tapes du processus.
Accompagner les Ã©quipes data / conseil / software sur lâ€™ensemble des sujets liÃ©s Ã  la data.
Anticiper les Ã©volutions et participer aux choix structurants de la sociÃ©tÃ© liÃ©s Ã  la gestion de la data ainsi que la stack technique.
Voir moins","Profil recherchÃ©
Nous recherchons un candidat qui possÃ¨de les compÃ©tences suivantes :
Au moins 5 ans dâ€™expÃ©rience sur un poste de Data Engineer.
Une solide expÃ©rience en Python, Apache Spark/Databricks, Apache Airflow et Docker.
Une connaissance approfondie dâ€™un fournisseur de services cloud, de prÃ©fÃ©rence Azure.
FamiliaritÃ© avec Kubernetes.
Une connaissance de Kafka est un plus
Une comprÃ©hension approfondie des bonnes pratiques de gestion des donnÃ©es, de la sÃ©curitÃ© et de la conformitÃ©.
Un esprit dâ€™Ã©quipe et dâ€™excellentes compÃ©tences en communication pour collaborer avec des Ã©quipes interfonctionnelles.
En rejoignant notre Ã©quipe, vous aurez lâ€™opportunitÃ© de travailler sur des projets passionnants dans le secteur du retail, dâ€™apprendre et de grandir dans un environnement stimulant."
Data Engineer Airflow AWS - FULL TÃ©lÃ©travail,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©",TÃ©lÃ©travail total,,,> 3 ans,Bac +5 / Master,"Descriptif du poste
MP DATA, recrute un DataEngineer expert de la stack technique AWS afin de travailler sur un projet impactant de sur la data platform dâ€™un client, acteur majeur du secteur transport, le tout en tÃ©lÃ©travail complet.
Vos missions seront les suivantes:
En collaboration avec lâ€™architecte data, les experts data et le gestionnaire/propriÃ©taire produit, vous serez amenÃ© Ã  participer aux opÃ©rations et Ã  lâ€™implÃ©mentation de la roadmap technique de la plateforme dâ€™orchestration basÃ© sur le produit Airflow. Ainsi vous assurerez le dÃ©veloppement et le support expert des fonctionnalitÃ©s de la plateforme en elle-mÃªme mais aussi de lâ€™outillage DevOps autour du produit dont en prioritÃ©, lâ€™observabilitÃ©, la gestion de la performance et lâ€™amÃ©lioration continue du service Orchestration
Participer au cycle de dÃ©veloppement du produit Airflow
Assurer lâ€™implÃ©mentation/dÃ©veloppement de lâ€™outillage et des fonctionnalitÃ©s de la plateforme nÃ©cessaires avec accord de lâ€™Architecte Data et les experts Data du groupe.
Contribuer au dÃ©veloppement des graphes orientÃ©s acycliques (DAG) nÃ©cessaires Ã  la bonne opÃ©rabilitÃ© des plateformes datalake et datamart (AWS et Snowflake)
Assurer le rÃ´le de support technique auprÃ¨s des end-users lors de leur usage de la plateforme.
Assurer les livraisons et dÃ©ploiement du code.
Assurer le run de la plateforme
Support niveau 2 expertise de la production et participation aux situations de crises.
Contribution Ã  la Knowledge Base du produit.
Reporter au gestionnaire de la plateforme Airflow, les performances IT, lâ€™Ã©tat de santÃ© temps rÃ©el et principaux risques opÃ©rationnels de la plateforme.
Contribuer Ã  la communautÃ© Data Orchestration
Assurer le relais (Key User) auprÃ¨s des Ã©quipes utilisatrices de la plateforme : BI, projets metiers, Data Science, DataLake, etc â€¦
Participer aux points rÃ©guliers avec les utilisateurs afin dâ€™Ã©changer autour des bonnes pratiques dâ€™usage et de dÃ©veloppement.
Passage de connaissance Ã  lâ€™Ã©quipe de support off-shore.
Produire la documentation nÃ©cessaire Ã  ce passage de connaissance : tuto, document dâ€™exploitation, etcâ€¦
Assurer et animer les sessions de transfert de connaissances au travers de dÃ©mos produit
Accompagner les premiers dÃ©veloppements de lâ€™Ã©quipe de support
Aider lâ€™Ã©quipe de support lors de la rÃ©solution dâ€™incidents/problÃ¨mes
Voir moins","Profil recherchÃ©
De formation Bac+5 (ou plus) en dÃ©veloppement informatique / data engineering, vous justifiez de plusieurs expÃ©riences professionnelles au cours desquelles vous avez pu dÃ©velopper les connaissances suivantes :
MÃ©thodologie Agile Scrum/Kanban
Connaissance de lâ€™Ã©cosystÃ¨me de la gestion de donnÃ©es (profil Data Engineer)
Notions DEVOPS
Notions dâ€™observabilitÃ© des SystÃ¨mes dâ€™Information
Soft skills : Force de proposition, Autonome, Dynamisme, FÃ©dÃ©rateur / Communiquant (serait un plus)
Connaissance des outils suivants :
Airflow (obligatoire) : Orchestration des processus
AWS
Snowflake
dbt : Principes ETL/ELT
JIRA/Confluence
Voir plus"
"Data Engineer (Spark, Scala)","{'name': 'SHAPE IT', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '103 collaborateurs', 'creation_year': '2020', 'turnover': '7.650.000', 'mean_age': '29 ans'}",CDI,Lyon,40K Ã  48K â‚¬,TÃ©lÃ©travail frÃ©quent,25 mars 2024,> 4 ans,Bac +5 / Master,,
"Data Engineer (Spark, Scala)","{'name': 'SHAPE IT', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '103 collaborateurs', 'creation_year': '2020', 'turnover': '7.650.000', 'mean_age': '29 ans'}",CDI,Lille,40K Ã  48K â‚¬,TÃ©lÃ©travail frÃ©quent,25 mars 2024,> 4 ans,Bac +5 / Master,,
Data Engineer Snowflake,"{'name': 'SHAPE IT', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '103 collaborateurs', 'creation_year': '2020', 'turnover': '7.650.000', 'mean_age': '29 ans'}",CDI,Lyon,42K Ã  50K â‚¬,TÃ©lÃ©travail frÃ©quent,11 mars 2024,> 5 ans,Bac +5 / Master,,
Data Engineer Snowflake,"{'name': 'SHAPE IT', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '103 collaborateurs', 'creation_year': '2020', 'turnover': '7.650.000', 'mean_age': '29 ans'}",CDI,Lille,42K Ã  50K â‚¬,TÃ©lÃ©travail frÃ©quent,11 mars 2024,> 5 ans,Bac +5 / Master,,
Cloud Data Engineer (Lille),"{'name': 'CENOVA', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Transformation', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '32 ans'}",CDI,Marcq-en-Baroeul,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Vous travaillerez chez lâ€™un de nos clients, spÃ©cialiste du #Retail, au sein de lâ€™Ã©quipe Data sur le dÃ©veloppement de solutions Data Analytics. Vos missions, si vous les acceptez, seront les suivantes : 
Â·       Participer aux rituels agiles de lâ€™Ã©quipe,
Â·       Analyser les besoins des utilisateurs et proposer des solutions innovantes et en phase avec les drivers de lâ€™entreprise,
Â·       ÃŠtre garant de lâ€™accÃ¨s qualitatif aux sources de donnÃ©es,
Â·       Sâ€™assurer de la maÃ®trise de la donnÃ©e et Ãªtre garant de la qualitÃ© de son utilisation (rÃ©fÃ©rencement, normalisation, et qualification) afin dâ€™en faciliter lâ€™exploitation par les Ã©quipes (Data Analysts et Data Scientists),
Â·       Contribuer Ã  la dÃ©finition de la politique de la donnÃ©e et Ã  la structuration de son cycle de vie dans le respect des rÃ©glementations en vigueur,
Â·       ÃŠtre capable dâ€™intervenir sur les systÃ¨mes applicatifs autour de la gestion de la donnÃ©e et du traitement, et sur les plateformes Big Data,
Â·       Assurer la supervision et lâ€™intÃ©gration des donnÃ©es de diverse nature qui proviennent de ces sources multiples et vÃ©rifier la qualitÃ© des donnÃ©es qui entrent dans le Data Lake.
Environnement technique :
SQL, Python, ETL
Power BI, Data Studio, Looker, Tableau, Business Object
CI/CD, Github, Terraform, Kafka, Airflow, Databricks
GCP (BigQuery), AWS, Azure
Voir moins","Profil recherchÃ©
Vous avez une expÃ©rience minimale de 2 ans sur des missions de Data Engineering et vous disposez dâ€™une grande appÃ©tence technique.
Vous apprÃ©ciez comprendre le cycle de vie de la donnÃ©e et vous Ãªtes Ã  lâ€™aise avec les concepts de data lineage, data gouvernance, data privacy. Vous Ãªtes amateur.e de datavisualisation, idÃ©alement avec PowerBI.
Travailler en mode agile ? Vous adorez !
Vous avez par ailleurs, le contact facile et vous comprenez les enjeux business et adaptez vos analyses en ce sens.
Vous Ãªtes proactif(ve), autonome, bon(ne) communiquant(e) et vous Ãªtes Ã  lâ€™aise en anglais.
Votre personnalitÃ© et votre savoir-faire feront le reste."
Data Engineer & Data Scientist - CDI - Sicara - Paris,"{'name': 'SICARA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': '6,5Mâ‚¬', 'mean_age': '27 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
PrÃ©sentation Sicara
CrÃ©Ã©e en novembre 2016 au sein du groupe M33 (Theodo group), un Ã©cosystÃ¨me de 10 filiales et +650 personnes situÃ©es Ã  Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, basÃ©e Ã  Paris.
Notre mission : aider les startups, scaleups et grands comptes Ã  rÃ©soudre leurs problÃ©matiques business grÃ¢ce Ã  la tech. Nos Ã©quipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. Lâ€™objectif : capitaliser sur le potentiel de la donnÃ©e.
Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en dÃ©veloppant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.
Pourquoi on recrute un Data Software Engineer ?
Afin de contribuer Ã  la croissance de Sicara, nous recrutons un Data Engineer & Scientist pour renforcer l'Ã©quipe de Sicara !
Tes missions
Comprendre le mÃ©tier et les donnÃ©es de ton client.
Travailler en Ã©quipe avec 2 Ã  4 ingÃ©nieurs data, 1 Product Owner et 1 Lead Tech
CrÃ©er un produit qui crÃ©e de la valeur pour ton client avec : les algorithmes les plus adaptÃ©s, une base de code maintenable, testÃ©e et scalable des flux de donnÃ©es robustes et fiables
Concevoir lâ€™architecture du produit et lâ€™intÃ©grer dans le SI du client pour le mettre en production
GÃ©nÃ©rer de la connaissance technique sur un sujet d'expertise et le propager au sein de Sicara
Participer Ã  la croissance de Sicara (selon tes prÃ©fÃ©rences : recrutement, avant-ventes, marketing technique)
Contribuer Ã  notre blog technique (+30 000 visiteurs mensuels) : www.sicara.ai/blog.
Contribuer Ã  amÃ©liorer nos savoir-faire en expÃ©rimentant continuellement de nouvelles mÃ©thodes et de nouveaux outils afin dâ€™amÃ©liorer lâ€™efficacitÃ© des Ã©quipes.
En fonction de tes envies et de tes compÃ©tences, tu auras la possibilitÃ© de :
Devenir un(e) expert(e) sur les sujets techniques qui te passionnent
Devenir un(e) leader grÃ¢ce au dÃ©veloppement de compÃ©tences transverses : coaching, recrutement, commercial, management, marketing, etc
Monter une tribe ou une guilde pour dÃ©velopper un nouvelle offre et amÃ©liorer nos pratiques
Les avantages
Notre Ã©cosystÃ¨me de startup tech est un vÃ©ritable tremplin pour accÃ©lÃ©rer la progression et les carriÃ¨res !
Des bureaux au coeur du quartier des Batignolles Ã  Paris, partagÃ©s avec les autres startup tech du groupe Theodo
Un coach dÃ©diÃ© pour accÃ©lÃ©rer la progression de carriÃ¨re
La possibilitÃ© de participer Ã  des confÃ©rences techniques internationales
Des conditions de tÃ©lÃ©travail flexibles
Un budget trimestriel pour acheter ton matÃ©riel tech (laptop, smartphone, casque,...)
Des Ã©vÃ©nements rÃ©guliers de team building et un WE d'entreprise Ã  chaque annÃ©e
La possibilitÃ© de s'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les inÃ©galitÃ©s et la sÃ©curitÃ© des donnÃ©es
Ton profil
DiplÃ´mÃ©(e) dâ€™une Ã©cole d'ingÃ©nieur bac+5
Tu as une forte appÃ©tence pour le secteur de la data et tu as idÃ©alement une premiÃ¨re expÃ©rience dans le conseil ou dans la tech
Tu as une bonne connaissance de Python et tu connais ou as envie dâ€™apprendre Ã  utiliser lâ€™un des Cloud Providers (AWS, Google Cloud Platform, Microsoft Azure)
Tu as envie de progresser et dâ€™Ã©voluer dans un environnement challengeant et bienveillant au quotidien
A trÃ¨s vite !
Voir moins",
Data Engineer ConfirmÃ©,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
MP DATA recrute un(e) Data Engineer (H/F) ConfirmÃ©
En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des donnÃ©es, en veillant Ã  ce quâ€™elles soient prÃªtes pour lâ€™analyse. Votre expertise dans la conception de pipelines ETL et la sÃ©curisation des donnÃ©es sera essentielle pour soutenir les activitÃ©s dâ€™analyse et de prise de dÃ©cision de lâ€™entreprise. Votre rÃ´le contribuera Ã  crÃ©er une base de donnÃ©es solide et sÃ©curisÃ©e pour des insights pertinents et en temps rÃ©el.","Profil recherchÃ©
DiplÃ´mÃ©(e) dâ€™une GRANDE Ã©cole dâ€™ingÃ©nieur, vous avez de bonnes connaissances en Python pour coder ces algorithmes. Suite Ã  votre cursus ingÃ©nieur ou vos expÃ©riences professionnelles, vous disposez dâ€™une appÃ©tence mÃ©tier.
Vous Ãªtes reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacitÃ© Ã  Ãªtre force de proposition.
Vous Ãªtes intÃ©ressÃ©s pour vous dÃ©passer en data science & data engineering et vous avez des premiÃ¨res expÃ©riences dans ce domaine, comme par exemple :
Expertise dans plusieurs langages de dÃ©veloppement, notamment Scala, Powershell, SQL et Python.
Spark
Kafka
Cloud : AWS / GCP / Azure
Technologies de stockage : Snowflake / S3 / GCS / Azure Blob
Django / Flask
FamiliaritÃ© avec le processus de dÃ©veloppement de logiciels, y compris le contrÃ´le de version (Git), lâ€™intÃ©gration continue et le dÃ©ploiement continu (CI/CD).
Voir plus"
Data Engineer - Azure H/F,"{'name': 'SKIILS', 'sector': 'Intelligence artificielle / Machine Learning, Transformation, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2020', 'turnover': '11Mâ‚¬', 'mean_age': '34 ans'}",CDI,"Salaire :
60K Ã  85K â‚¬",TÃ©lÃ©travail frÃ©quent,,,> 5 ans,Bac +5 / Master,"Descriptif du poste
ğŸª„Tu as le pouvoir de crÃ©er des pipelines capables de transformer des donnÃ©es en vÃ©ritables trÃ©sors exploitables, alors tu es peut-Ãªtre notre Super Data IngÃ©nieur !
ğŸ¯Tu es prÃªt Ã  affronter des dÃ©fis titanesques, Ã  gÃ©rer des montagnes de donnÃ©es, Ã  dÃ©fendre la rÃ©silience des systÃ¨mes, et Ã  affronter des flux de donnÃ©es massifs, lâ€™Ã©quipe DATA Factorii tâ€™ouvre ses portes comme un vÃ©ritable repaire de super-hÃ©ros !
ğŸš€En tant que Super Data Engineer - Azure H/F, tes missions seront de :
DÃ©finir et dÃ©ployer le socle technologique dâ€™un Datalake
Conseiller et concevoir une architecture de donnÃ©es
ImplÃ©menter lâ€™intÃ©gration des donnÃ©es au sein du Datalake
Identifier, Ã©tudier et prototyper des cas dâ€™usage stratÃ©giques
Industrialiser les projets Big Data en environnement cloud
ImplÃ©menter les mÃ©thodologies Devops pour optimiser les processus de dÃ©veloppement
Participer Ã  lâ€™estimation des besoins utilisateurs.
Concevoir du code et le documenter.
Collaborer Ã©troitement au sein de lâ€™Ã©quipe SCRUM, comprenant le Product Owner, les dÃ©veloppeurs, Quality Analyst, et le support, pour assurer le succÃ¨s des projets.
ğŸ Ce que nous tâ€™offrons ?
Un salaire qui Ã©volue comme une rock star sur scÃ¨ne !
Une carriÃ¨re Ã  la â€œJames Bondâ€ : Ã  moyen et long terme, câ€™est toi le hÃ©ros !
Ta mutuelle et ton titre de transport pris en charge Ã  100% (bye-bye les frais) !
TÃ©lÃ©travail partiel : lâ€™Ã©quilibre parfait entre pyjama et costume !
Et surtout, la chance de tâ€™investir dans des projets ultra cool qui te propulseront techniquement vers lâ€™infini et au-delÃ  ! ğŸš€
Voir moins","Profil recherchÃ©
En 1er, un savoir Ãªtre qui correspond Ã  lâ€™ADN de skiils !
Les processus agiles, câ€™est ton super-pouvoir ! Le Manifeste Agile, câ€™est ton livre de chevet, toujours prÃªt Ã  lâ€™action.
Comprendre lâ€™environnement fonctionnel du client est ta mission principale, car tu sais que câ€™est lÃ  que se trouvent les indices cruciaux pour tes analyses hÃ©roÃ¯ques.
DotÃ©(e) dâ€™une autonomie inÃ©branlable, dâ€™un dynamisme surpuissant et dâ€™un sens des relations humaines extraordinaire, tu es une vÃ©ritable icÃ´ne.
En 2nd, un bagage technique qui tient la route :
Connaissance approfondie du cloud Azure.
De premiÃ¨res expÃ©riences sur Databricks.
Excellente communication Ã©crite et orale pour la crÃ©ation de livrables et de rapports.
Bonne pratique du DBT.
Esprit analytique et orientation vers lâ€™amÃ©lioration continue."
STAGE - DATA ENGINEER F/H,"{'name': 'CDISCOUNT', 'sector': 'Logistique, SaaS / Cloud Services, E-commerce', 'employees': '2000 collaborateurs', 'creation_year': '1998', 'turnover': None, 'mean_age': '38 ans'}","Stage
(6 mois)",Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,> 6 mois,Bac +5 / Master,"Descriptif du poste
Chez Cdiscount, nous sommes convaincus quâ€™un environnement de travail Ã©panouissant contribue au dÃ©veloppement de nos talents. RelÃ¨ve nos dÃ©fis et viens participer au dÃ©veloppement du leader franÃ§ais et engagÃ© du e-commerce.
 
Dans le cadre de son dÃ©veloppement, Cdiscount recrute un stagiaire Data Engineer pour intÃ©grer le pÃ´le dÃ©cisionnel.
Tu interviendras principalement sur la mise en Å“uvre de nouvelles solutions et outils dÃ©cisionnels. Tu participeras Ã  lâ€™ensemble des phases dâ€™un projet BI, alliant les aspects fonctionnel et technique.
 
Tu auras pour missions principales les tÃ¢ches suivantes : 
â€¢    DÃ©veloppement de traitements dâ€™extraction et de transformation de donnÃ©es
â€¢    Alimentation du Datawarehouse
â€¢    RÃ©alisation et dÃ©veloppement de tableaux de bords
â€¢    RÃ©daction de documentations techniques
â€¢    Maintenance corrective et Ã©volutive
â€¢    Gestion de bases de donnÃ©es
â€¢    Collecte des besoins auprÃ¨s des diffÃ©rentes BU
Lâ€™offre est Ã  pourvoir Ã  partir de juillet pour un stage de 6 mois.
Voir moins","Profil recherchÃ©
Description du profil :

Nous recherchons des collaborateurs ayant une Ã©nergie hors pair pour prendre part Ã  une aventure humaine et professionnelle unique.
De formation BAC +5 (ingÃ©nieur ou Ã©quivalent), tu recherches un stage de fin dâ€™Ã©tudes.Tu justifies dâ€™une premiÃ¨re expÃ©rience en BI ou en implÃ©mentation de flux de donnÃ©es et/ou analyse des donnÃ©es.
Tu as une bonne connaissance thÃ©orique et pratique des plateformes dÃ©cisionnelle (ETL, DWH, outils de reporting) et tu maitrises le management de bases de donnÃ©es (langage SQL, modÃ©lisation). Une expÃ©rience avec Talend ou Google BigQuery serait un plus.
Autonome, organisÃ©(e), mÃ©thodique, tu communiques avec aisance et avez le sens du service. DotÃ©(e) dâ€™un trÃ¨s bon relationnel avec les utilisateurs et les Ã©quipes, de qualitÃ©s rÃ©dactionnelles et dâ€™un goÃ»t prononcÃ© pour la technique, tu pourras parfaire votre expertise et intÃ©grer une Ã©quipe dynamique.
En tant que leader franÃ§ais et engagÃ© du e-commerce, Cdiscount est un employeur investi en faveur de la diversitÃ© : du recrutement Ã  lâ€™Ã©volution professionnelle, nous garantissons lâ€™Ã©galitÃ© des chances Ã  tous nos collaborateurs. 




Voir plus"
Data Engineer Senior - Spark/ Databricks,"{'name': 'PULSOVER', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, SaaS / Cloud Services, Big Data', 'employees': 'CrÃ©Ã©e en 2021', 'creation_year': 'Ã‚ge moyen : 34 ans', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Nous renforÃ§ons notre pÃ´le Data pour accompagner la croissance de notre sociÃ©tÃ© en recherchant un.e Senior Data Engineer expÃ©rimentÃ©.e.
Si tu es passionnÃ©.e par les donnÃ©es, que tu possÃ¨des une expertise approfondie sur Spark, Databricks et AWS, cette offre dâ€™emploi est faite pour toi.
En tant que Data Engineer Senior, tu joueras un rÃ´le essentiel dans la crÃ©ation, la mise en Å“uvre et la gestion de nos pipelines de donnÃ©es. Tu seras responsable de concevoir des architectures de donnÃ©es robustes, de dÃ©velopper des solutions dâ€™intÃ©gration de donnÃ©es efficaces et dâ€™optimiser les performances de nos infrastructures de donnÃ©es.
Tes missions principales :
Participer Ã  des projets de data engineerings basÃ©s sur un framework mÃ©thodologique
DÃ©velopper, industrialiser et maintenir des pipelines de donnÃ©es (principalement ETL et ML)
Effectuer de lâ€™exploration de donnÃ©es et du prototypage rapide
Mettre en application les meilleures pratiques : versioning, tests automatisÃ©s, CI/CD
Participer activement Ã  lâ€™automatisation des infrastructures basÃ©es sur des services de Cloud Computing
ImplÃ©menter des architectures de type Lakehouse pour casser les silos
DÃ©ployer des algorithmes de machine learning at scale et sur des flux de streaming
Collaborer avec lâ€™ensemble des Ã©quipes depuis les spÃ©cifications fonctionnelles jusquâ€™aux validations mÃ©tiers des solutions implÃ©mentÃ©es
Contribuer Ã  la mise en place de mÃ©thodologies Agile de type Scrum
Socle technologique et mÃ©thodologique :
Stack technique du poste : Spark, Python, Scala, Scikit learn, MLFlow, Versionning (Git), CI/CD (GitHub Actions/ GitLab/ Jenkins)
Job orchestration : Apache Airflow
Data platform: Databricks, Snowflake
Cloud : AWS et/ ou GCP, Azure
MÃ©thodo : dÃ©veloppement Agile/ travail en Ã©quipe collaborative
Tests automatisÃ©s : Pytest, Scalatest, Cucumber
Les avantages :
Un environnement de travail collaboratif et stimulant, favorisant lâ€™apprentissage continu et lâ€™Ã©volution professionnelle
Des opportunitÃ©s de formation et de dÃ©veloppement professionnel pour rester Ã  jour sur les derniÃ¨res technologies
La possibilitÃ© de travailler sur des projets de donnÃ©es complexes et stimulants, ayant un impact direct sur les dÃ©cisions stratÃ©giques de lâ€™entreprise
Une rÃ©munÃ©ration compÃ©titive et des avantages sociaux attractifs
Voir moins","Profil recherchÃ©
De formation ingÃ©nieur ou Ã©quivalent avec une expÃ©rience de 5 ans minimum dans ce domaine
ExpÃ©rience significative en tant que Data Engineer, avec une expertise approfondie sur Spark, Databricks, AWS et/ ou GCP
Solide comprÃ©hension des principes de lâ€™ingÃ©nierie des donnÃ©es, des architectures distribuÃ©es et des meilleures pratiques de gestion des donnÃ©es
Excellentes compÃ©tences en programmation, notamment dans les langages tels que Python ou Scala
Connaissance des technologies de bases de donnÃ©es, des outils ETL et de lâ€™intÃ©gration de donnÃ©es
CapacitÃ© Ã  travailler de maniÃ¨re autonome, Ã  gÃ©rer plusieurs projets simultanÃ©ment et Ã  respecter les dÃ©lais
Bon niveau en anglais pour nos projets dans un contexte international
Et surtout : bonne humeur et attitude positive sont essentielles ;)"
Data Engineer confirmÃ©(e) / AWS,"{'name': 'LIVINGPACKETS', 'sector': 'Environnement / DÃ©veloppement durable, Logistique, E-commerce', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '34 ans'}",CDI,"Salaire :
40K Ã  50K â‚¬",TÃ©lÃ©travail frÃ©quent,,,> 3 ans,,"Descriptif du poste
Tu vas rejoindre la team Cloud & Data en tant que Data Engineer confirmÃ©(e). Vous travaillerez en Ã©troite collaboration pour mener Ã  bien vos missions et rÃ©pondre aux besoins.
Tu es responsable de la conception et lâ€™optimisation de solutions technologiques pour le traitement de nos donnÃ©es et rÃ©pondre aux besoins des utilisateurs/clients.
Tes missions :
Concevoir, dÃ©velopper et maintenir les pipelines, les analyses et les visualisations des donnÃ©es
Collecter, transformer et enrichir les donnÃ©es provenant de multiples data sources de lâ€™entreprise
Garantir le bon fonctionnement, la disponibilitÃ©, lâ€™Ã©volution et la performance des outils
Accompagner les Data Analysts dans lâ€™optimisation de leurs algorithmes et dans la vÃ©rification de la qualitÃ© des donnÃ©es et des processus
Participer Ã  lâ€™Ã©volution de la stack technique
Partager ton expertise avec lâ€™ensemble des Ã©quipes
Veille technologique
Stack Technique : AWS (RDS Aurora PostgreSQL, Glue, S3, Athena, QuickSight, Lambda), Python, SQL, Docker, Terraform, Kubernetes, Git, Github Actions â€¦","Profil recherchÃ©
Au moins 3 ans dâ€™expÃ©rience sur des projets Data engineering dont au moins une annÃ©e dâ€™expÃ©rience avec le Cloud AWS et ses services Data (RDS, Lambda, Kinesis, EMR, SageMaker, Glue, S3, Athena, etc) 
Une expÃ©rience dans la data visualisations (QuickSight, PowerBI, Tableau, QlikView, etc)
Une expÃ©rience dans le monde DevOps et de ses outils (Git, Github actions, GitLab, Terraform, AWS/GCP/Azure, etc)
Tu maÃ®trises python et/ou Java et tu as une expertise dans lâ€™Ã©criture et lâ€™optimisation du code SQL
Tu as un esprit analytique et une appÃ©tence pour la Data/Big Data et la BI
Tu es rigoureux(se) et autonome
Tu fais preuve dâ€™initiative et tu es force de proposition pour lâ€™amÃ©lioration continue des processus existants
Ce qui fera la diffÃ©rence :
une bonne comprÃ©hension des solutions de stockage donnÃ©es (bases de donnÃ©es SQL / NoSQL, datawarehouse, datalake, data lakehouse)
maÃ®trise dâ€™un autre langage de programmation (Spark, Scala, Java, R)
Voir plus"
Data Engineer,"{'name': 'QWANT', 'sector': 'Big Data', 'employees': '84 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '37 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©",TÃ©lÃ©travail frÃ©quent,,,> 3 ans,,"Descriptif du poste
Vous travaillez au sein de lâ€™Ã©quipe technique chargÃ©e dâ€™amÃ©liorer les pratiques data et de concevoir et maintenir des pipelines de donnÃ©es :
-        DÃ©finir une architecture data Ã  long terme et assurer la cohÃ©rence (type data lake)
-        Sâ€™assurer de la disponibilitÃ© de la donnÃ©e
-        Conception et mise en Å“uvre de pipelines de donnÃ©es pour de la mesure de performance et lâ€™entrainement de modÃ¨le de machine learning
-        Industrialisation de ces pipelines en collaboration avec lâ€™Ã©quipe de ML
A ce titre les activitÃ©s principales Ã  effectuer sont :
-        Concevoir et mettre en Å“uvre un processus ETL automatisÃ© de bout en bout afin de prÃ©parer les donnÃ©es pour lâ€™apprentissage automatique et lâ€™analyse ad hoc, y compris lâ€™anonymisation des donnÃ©es
-        Structurer et dÃ©ployer, en lien Ã©troit avec les Ã©quipes de machine learning, lâ€™export automatisÃ© de donnÃ©es pour lâ€™entrainement de modÃ¨les
-        Atteindre les objectifs en collaboration avec les Ã©quipes technique, produit et business
-        Faire monter en compÃ©tence les membres de lâ€™Ã©quipe","Profil recherchÃ©
Hard skills souhaitÃ©es :
-        ExpÃ©rience impÃ©rative de minimum 3 ans dans la mise en Å“uvre de pipelines de donnÃ©es idÃ©alement dans un Ã©cosystÃ¨me Python
-        Bonnes connaissances en architecture Big Data et systÃ¨mes ETL (on-premise)
-        Familier avec des systÃ¨mes de calcul distribuÃ©, type Spark
-        Connaissances des bonnes pratiques de dÃ©veloppement : versioning, tests, code reviews, CI/CD etc.
Hard skills bonus :
-        CompÃ©tences en dÃ©ploiement dâ€™applications conteneurisÃ©es (Docker / Kubernetes / Argo Workflow)
-        ExpÃ©riences avec des bases de donnÃ©es distribuÃ©es telles que Elasticsearch, Vespa
-        Connaissance de spark streaming, kafka stream ou similaire
-        ExpÃ©rience en Rust
-        ExpÃ©rience en langage SQL
Soft skills :
Voir plus"
Data Engineer ConfirmÃ©(e) H/F - Lyon,"{'name': 'EVOTEO', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '35 collaborateurs', 'creation_year': '2017', 'turnover': '3Mâ‚¬', 'mean_age': '30 ans'}",CDI,Lyon,42K Ã  55K â‚¬,TÃ©lÃ©travail frÃ©quent,19 fÃ©vrier 2023,> 3 ans,Bac +5 / Master,"Descriptif du poste
Dans le cadre de notre expansion ambitieuse mais contrÃ´lÃ©e, et pour satisfaire aux besoins changeants de tous nos clients, nous recherchons une/un Data Engineer pour renforcer nos Ã©quipes.
Dans le cadre du projet de migration de notre client, de leur ancien systÃ¨me BI vers leur nouvel Ã©cosystÃ¨me Lakehouse (Discover) sur Databricks / AWS, nous sommes Ã  la recherche dâ€™une personne qui peut gÃ©rer :
La rÃ©cupÃ©ration (et surtout la refonte) de leur modÃ¨le de donnÃ©es pour quâ€™il soit la base de leurs futurs cas dâ€™utilisation des donnÃ©es (refonte des procÃ©dures SQL Server de Side vers des travaux Databricks en Python / SQL / Spark)
La migration des tableaux de bord PowerBI ainsi que la refonte de leur modÃ¨le pour les simplifier, en les source sur le Lakehouse au lieu de Sid
La refonte des rapports SSRS vers des tableaux de bord Databricks pour les rapports opÃ©rationnels
La rÃ©cupÃ©ration des exports (principalement des fichiers CSV) gÃ©rÃ©s par Side aujourdâ€™hui.
La durÃ©e de ce projet devrait sâ€™Ã©taler sur 2023-2024.","Profil recherchÃ©
Nous recherchons avant tout des personnalitÃ©s : curieuses, habiles, sociales, adaptables et passionnÃ©es.
De formation BAC+5 (Master 2,DESS,DEA), formation ingÃ©nieure ou informatique, tu as une expÃ©rience dâ€™au moins 3 ans en engineering des environnements Big #DATA
Les technos:
DÃ©veloppement : Spark (scala), Python
IntÃ©gration continue : GIT, Maven, Jenkins, Ansible, Docker
Technologies Big #DATA (Hadoop, Yarn, Pig, Hive, Sqoop, Flume, Impala, Spark, ElasticSearch)
Cloud AWS : S3, Glue, ECS
Cloud Azure
Nous insistons sur les compÃ©tences Spark.
Ce poste en CDI est Ã  pourvoir dÃ¨s que possible sur la rÃ©gion lyonnaise.
Tu Ãªtes un futur collaborateur acteur, en quÃªte de perspectives dâ€™Ã©volution, capable de rigueur et dâ€™esprit dâ€™analyse ? Rejoins-nous !"
CDI - Data Engineer H/F @ Startup CybeleTech,"{'name': 'OSS VENTURES', 'sector': 'SaaS / Cloud Services', 'employees': '20 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,15 fÃ©vrier 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
Qui sommes nous ?
CybeleTech est une jeune entreprise qui dÃ©veloppe des outils logiciels au service de lâ€™agriculture dâ€™aujourdâ€™hui et de demain : stratÃ©gies de production Ã  la fois productives et respectueuses de lâ€™environnement, amÃ©lioration de la qualitÃ© nutritionnelle et gustative des aliments, rÃ©duction des pesticides, pÃ©rennitÃ© des cultures vis-Ã -vis des alÃ©as climatiquesâ€¦
Ces outils reposent sur des algorithmes innovants combinant Data Science et ModÃ©lisation, rendus accessibles Ã  nos clients grÃ¢ce Ã  des logiciels SaaS.
Initialement spin-off du laboratoire de mathÃ©matiques appliquÃ©es de Centrale Paris, nous sommes aujourdâ€™hui une Ã©quipe pluridisciplinaire de 15 personnes, Å“uvrant aussi bien dans le champ des mathÃ©matiques, de lâ€™informatique, de la biologie et de lâ€™agronomie.
Nous sommes implantÃ©s Ã  OrlÃ©ans et au cÅ“ur de Montrouge (M4 parisien).
Afin dâ€™accompagner la croissance de notre activitÃ©, nous recherchons un(e) Data Engineer. Le poste est Ã  pourvoir en CDI Ã  temps plein.
Vous intÃ©grerez au quotidien lâ€™Ã©quipe Datascience de Cybeletech. Vos missions en lien avec les Datascientists, ModÃ©lisateurs, Agronomes de lâ€™Ã©quipe mais aussi en lien avec notre Ã©quipe DevOps :
DÃ©veloppement et industrialisation de pipelines dâ€™ingestion et transformation de donnÃ©es, exploitant notamment de lâ€™imagerie satellite : dÃ©veloppement, requÃªtes performantes, distribution des calculs des modÃ¨lesâ€¦
Optimisation de lâ€™exÃ©cution distribuÃ©e des modÃ¨les.
Maintenance et Ã©volution de la codebase scientifique (gestion des environnements et version, organisation des librairies, configuration de la CIâ€¦).
Participer aux reviews et Ã  la mise en place de bonnes pratiques de dÃ©veloppement (gestion des exceptionsâ€¦), rÃ©daction de rÃ©fÃ©rentiels.
Design des bases et des modÃ¨les de donnÃ©es (architecture des tables et schÃ©mas, gestion des droitsâ€¦)
Skills techniques / Stack
Python, pandas/geopandas, jupyter
postgresQL, S3, mongodb
Aws et azure cloud services, docker, kubernetes, rabbitMQ, azureML
La connaissance des Ã©lÃ©ments suivants est un plus : SystÃ¨mes SIG, data visualisation, C/C++, images satellites
Voir moins","Profil recherchÃ©
Vous Ãªtes titulaire dâ€™une formation dâ€™ingÃ©nieur(e) dÃ©veloppeur(se).
Vous possÃ©dez dÃ©jÃ  3 ans dâ€™expÃ©rience minimum en temps que titulaire sur un poste de dÃ©veloppement autour de la Data mettant en Å“uvre SQL et Python.
Vous aimez Ã©changer avec des profils complÃ©mentaires (modÃ©lisateurs, DevOpsâ€¦), et partager vos savoirs faire."
Senior Data Engineer / Data Developper,"{'name': 'SOMM-IT', 'sector': 'Restauration, Boissons, FoodTech', 'employees': '15 collaborateurs', 'creation_year': '2015', 'turnover': '250kâ‚¬', 'mean_age': '35 ans'}",CDI,Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,15 fÃ©vrier 2024,> 5 ans,> Bac +5 / Doctorat,,
[AIX] Data Engineer (H/F),"{'name': 'MERITIS', 'sector': 'IT / Digital, Finance', 'employees': '900 collaborateurs', 'creation_year': '2007', 'turnover': '87Mâ‚¬', 'mean_age': '30 ans'}",CDI,Aix-en-Provence,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,Bac +5 / Master,"Descriptif du poste
En collaboration avec lâ€™architecte data, les experts data et le gestionnaire/propriÃ©taire produit, vous serez amenÃ© Ã  participer aux opÃ©rations et Ã  lâ€™implÃ©mentation de la roadmap technique de la plateforme dâ€™orchestration. Voici vos missions :
Participer au cycle de dÃ©veloppement du produit Airflow,
Assurer lâ€™implÃ©mentation/dÃ©veloppement de lâ€™outillage et des fonctionnalitÃ©s de la plateforme nÃ©cessaires avec accord de lâ€™Architecte Data et les experts Data du groupe,
Contribuer au dÃ©veloppement des graphes orientÃ©s acycliques (DAG) nÃ©cessaires Ã  la bonne opÃ©rabilitÃ© des plateformes datalake et datamart (AWS et Snowflake),
Assurer le rÃ´le de support technique auprÃ¨s des end-users lors de leur usage de la plateforme,
Assurer les livraisons et dÃ©ploiement du code,
Assurer le mode run de la plateforme,
Support niveau 2 expertise de la production et participation aux situations de crises,
Reporter au gestionnaire de la plateforme Airflow, les performances IT, lâ€™Ã©tat de santÃ© temps rÃ©el et principaux risques opÃ©rationnels de la plateforme,
Contribuer Ã  la communautÃ© Data Orchestration,
Produire la documentation nÃ©cessaire Ã  ce passage de connaissance : tuto, document dâ€™exploitation, etcâ€¦
Assurer et animer les sessions de transfert de connaissances au travers de dÃ©mos produit.
Voir moins","Profil recherchÃ©
Vous avez un diplÃ´me dâ€™ingÃ©nieur ou un Bac+5 Ã©quivalent
Vous avez 3 ans d'expÃ©rience en tant que Data Engineer
Vous avez une bonne conne connaissance de l'environnement cloud AWS
Vous avez une bonne maitrise de l'Orchestration des processus, notamment avec Airflow
Vous Ãªtes familier avec les principes ETL/ELT
Vous avez dÃ©jÃ  travaillÃ© avec la mÃ©thodologie Agile Scrum/Kanban"
Senior Data Engineer,"{'name': 'PLANITY', 'sector': 'Application mobile, SaaS / Cloud Services', 'employees': '400 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,01 fÃ©vrier 2024,,,"Descriptif du poste
Ã€ propos
Planity est une start-up en hyper-croissance, leader de la rÃ©servation beautÃ© en ligne en France. Depuis une application mobile et un site web intuitifs, chacun peut prendre rendez-vous dans un salon de coiffure, barbier ou institut de beautÃ© Ã  cÃ´tÃ© de chez soi, 24h/24 et gratuitement. Mais surtout, Planity a pour mission dâ€™accompagner les professionnels de la beautÃ© dans la gestion de leur activitÃ© au quotidien avec un logiciel SaaS performant dotÃ© dâ€™un agenda en ligne et dâ€™un logiciel de caisse.
Tu veux rejoindre le numÃ©ro 1 franÃ§ais de la rÃ©servation beautÃ© ?
Planity câ€™est :
7 millions dâ€™utilisateurs par mois
30 000 Ã©tablissements partenaires
400 collaborateurs ğŸ‡«ğŸ‡·ğŸ‡©ğŸ‡ªğŸ‡§ğŸ‡ª
200 millions de rendez-vous gÃ©rÃ©s depuis le lancement de la plateforme en 2017
Planity, câ€™est bien plus quâ€™un portail de rÃ©servation beautÃ© en ligne! Câ€™est aussi un SaaS avec un logiciel de caisse, des algos complexes de gestion des disponibilitÃ©s de nos clients, 7 applications web/mobiles...
Descriptif du poste
Au sein de lâ€™Ã©quipe Data, tu contribueras Ã  dÃ©velopper et exploiter une infrastructure moderne mettant les donnÃ©es au service du dÃ©veloppement du produit et de lâ€™activitÃ©. En tant que Senior Data Engineer, tu auras un rÃ´le clÃ© dans la dÃ©finition et lâ€™implÃ©mentation des choix techniques. Tu pourras de plus participer Ã  de nombreuses initiatives allant du Data Ops Ã  l'Analytics Engineering.
Tes premiÃ¨res missions consisteront Ã  :
Te familiariser avec notre infrastructure existante et la challenger, amÃ©liorer sa performance et sa fiabilitÃ©
Ã‰lever les standards en matiÃ¨re de dÃ©ploiement, de qualitÃ© de code et de sÃ©curitÃ©
Consolider nos outils dâ€™ingestion de donnÃ©es et leur monitoring
Ã‰tablir la prioritÃ© des sujets Ã  traiter en collaboration avec le reste de lâ€™organisation
Profil recherchÃ©
Au moins 4 ans dâ€™expÃ©rience de data engineering dans un environnement cloud
MaÃ®trise de Python, Spark et SQL
Aisance dâ€™utilisation des outils standards du marchÃ© (orchestration et ordonnancement, entrepÃ´ts de donnÃ©esâ€¦) et capacitÃ© Ã  les dÃ©ployer puis les maintenir
A lâ€™Ã©coute des derniÃ¨res Ã©volutions en termes dâ€™outils et dâ€™architecture
ComprÃ©hension des enjeux de sÃ©curitÃ© et de respect de la vie privÃ©e liÃ©s au traitement de larges volumes de donnÃ©es
CapacitÃ© Ã  exposer tes convictions avec clartÃ© et de convaincre des audiences moins techniques
Anglais courant
Les plus
Connaissance poussÃ©e dâ€™AWS et des outils serverless
Pratique des outils de data modelling (notamment dbt)
MaÃ®trise de lâ€™infrastructure-as-code (notamment Terraform)
FamiliaritÃ© avec les APIs REST
Stack actuel
Lakehouse AWS: Lake Formation, S3, Glue, Athena; formats JSON, Parquet, Iceberg
IntÃ©gration avec Appflow & Fivetran
Infrastructure-as-Code avec Terraform
Transformation avec dbt
BI avec Amazon Quicksight
IA avec OpenAI
Ce que nous proposons Ã  nos talents
SiÃ¨ge social au coeur de Paris 2Ã¨me proche de Sentier & Grands Boulevards
AccÃ¨s Ã  un CSE ğŸ˜
DÃ©jeuners & soirÃ©es dâ€™Ã©quipe ğŸ¾ğŸ¥—
Environnement de travail stimulant ğŸš€
7 semaines de vacances ğŸ–
Tous nos postes sont ouverts aux personnes en situation de handicap H/F.
DÃ©roulement des entretiens
1Â°) Entretien tÃ©lÃ©phonique avec le Talent Acquisition Recruiter
2Â°) Entretien visio avec le Head of Data
3Â°) Test technique
4Â°) Echanges avec dâ€™autres membres des Ã©quipes Tech & Data (visio ou physique)
Voir moins",
Data Engineer H/F,"{'name': 'NEXTON', 'sector': 'Design, IT / Digital, Digital', 'employees': '450 collaborateurs', 'creation_year': '2011', 'turnover': '31 millions', 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,Bac +5 / Master,"Descriptif du poste
NEXTON recrute un DATA ENGINEER H/F, en CDI, Ã  Paris !

Qui sommes-nous ?

NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBASâ€¦).

Nous sommes experts du digital aussi bien sur de l'accompagnement stratÃ©gique qu'opÃ©rationnel.

Fort du succÃ¨s, NEXTON connaÃ®t aujourd'hui un dÃ©veloppement significatif, autour de ses valeurs piliers : cohÃ©sion, confiance et performance.

Et pour toi ? Notre politique de dÃ©veloppement des compÃ©tences dynamique saura te sÃ©duire avec un programme de suivi de carriÃ¨re sur-mesure.

Contexte :


Nous recherchons pour notre client spÃ©cialisÃ© dans le secteur des TÃ©lÃ©com, un Data Engineer.

Les missions :


Tes principales missions sont :

de maÃ®triser les requÃªtes SQL pour effectuer des analyses avancÃ©es sur des ensembles de donnÃ©es complexes.

de concevoir, dÃ©velopper et mettre en Å“uvre des pipelines de donnÃ©es robustes en utilisant Python pour assurer la collecte, la transformation et l'intÃ©gration efficaces des donnÃ©es.

d'utiliser Power BI pour crÃ©er des tableaux de bord interactifs et des rapports visuels.

de travailler en Ã©troite collaboration avec les dÃ©veloppeurs de l'Ã©quipe afin de rÃ©pondre Ã  l'ensemble des pratiques en place (tests, relectures de code, industrialisation, cÃ©rÃ©monies agiles)




Voir moins","Profil recherchÃ©
Tu justifies d'une expÃ©rience de minimum 4 ans en tant que dÃ©veloppeur ou ingÃ©nieur data. Tu maÃ®trises Python, SQL, Power BI et un environnement Cloud serait un plus.
Enfin, tu es sensible aux problÃ©matiques techniques et best-practices pour la rÃ©alisation de projets DATA fiables et robustes. NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'annÃ©e :

- Des communautÃ©s : 2 Meet Up par mois pour partager et Ã©changer avec des experts

- De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'annÃ©e

- Des moments privilÃ©giÃ©s avec ton manager

PrÃªt Ã  nous rejoindre ? Rencontrons-nous !"
Data Engineer (H/F),"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
MP DATA recrute un(e) Data Engineer (H/F).
Dans le cadre de la transformation digitale industriel, lâ€™Ã©quipe de data engineering en charge de lâ€™exploitation du Cluster Big Data cherche Ã  se dÃ©velopper.
En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des donnÃ©es, en veillant Ã  ce quâ€™elles soient prÃªtes pour lâ€™analyse. Votre expertise dans la conception de pipelines ETL et la sÃ©curisation des donnÃ©es sera essentielle pour soutenir les activitÃ©s dâ€™analyse et de prise de dÃ©cision de lâ€™entreprise. Votre rÃ´le contribuera Ã  crÃ©er une base de donnÃ©es solide et sÃ©curisÃ©e pour des insights pertinents et en temps rÃ©el.","Profil recherchÃ©
DiplÃ´mÃ©(e) dâ€™une Ã©cole dâ€™ingÃ©nieur, vous avez des connaissances en modÃ©lisation et machine learning (deep learning, random forest, svmâ€¦) acquises lors de votre scolaritÃ© ou de vos expÃ©riences passÃ©es (stage ou cÃ©sure).
Vous avez de bonnes connaissances en Python pour coder ces algorithmes. Suite Ã  votre cursus ingÃ©nieur ou vos expÃ©riences professionnelles, vous disposez dâ€™une appÃ©tence mÃ©tier dans les domaines de lâ€™aÃ©ronautique, Ã©nergie, transport, etcâ€¦
Vous Ãªtes reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacitÃ© Ã  Ãªtre force de proposition.
Vous Ãªtes intÃ©ressÃ©s pour vous dÃ©passer en data science & data engineering et vous avez des premiÃ¨res expÃ©riences dans ce domaine, comme par exemple :
C/C++ / Java / Rust / Python
Spark
Kafka
Cloud : AWS / GCP / Azure
Technologies de stockage : Snowflake / S3 / GCS / Azure Blob
Voir plus"
"Senior Data Engineer (Paris, Madrid, Milan, London, Lux), VX and EU-AVS","{'name': 'AMAZON E-COMMERCE', 'sector': 'E-commerce', 'employees': '1300000 collaborateurs', 'creation_year': '1995', 'turnover': None, 'mean_age': None}",CDI,Clichy,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Amazon strives to be Earthâ€™s most customer-centric company, where customers can find and discover anything they might want to buy online. By giving customers more of what they want - low prices, vast selection, and convenience - Amazon continues to grow and evolve as a world-class e-commerce website. Core to Amazonâ€™s mission to delight and serve customers is a need to invent on behalf of vendors. Our team is at the forefront of two pivotal programs, EU AVS and WW VX, each integral to enhancing the end Customer Experience and contributing to Amazonâ€™s Long-Term Free Cash Flow. The EU AVS program aims to provide an industry-leading account management service at the optimal cost-to-serve for Amazon that exceeds vendorsâ€™ expectations and expedites their growth on Amazon. The WW VX program vision is to make Amazon the most preferred, trusted, and efficient distribution option for vendors by building an industry-leading experience for every vendor across all global touchpoints.
Key job responsibilities
Our team is looking for an experienced Senior Data engineer to implement and support scalable data infrastructure solutions in one of the world's largest and most complex data warehouse environments. You will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You will be exposed to cutting edge AWS big data technologies. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and data-sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate. Position can be from Paris, Madrid, Milan, London, Amsterdam or Lux
A day in the life
Your major responsibilities will include:
â€¢ Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies.
â€¢ Explore and learn AWS technologies to provide new capabilities and increase efficiencies.
â€¢ Designing and implementing complex pipelines and other BI solutions.
â€¢ Work closely with business owners, developers, Business Intelligence Engineer to explore new data sources and deliver the data.
About the team
The AVS and VX program teams are diverse organizations with employees across Europe and with partner teams around the globe. This role can be based in London, Paris, Madrid, or Luxembourg. These teams drive improvements in products, services, tools, processes, communication, and vendor education world-wide working with partner teams in Europe, North America, Japan, and emerging locales and are responsible for all elements of a vendorâ€™s interaction with Amazon including listing, catalog management, ordering, supply chain, marketing, payments, value-added services, and vendor support.
We are open to hiring candidates to work out of one of the following locations:
Clichy, FRA
Voir moins","Profil recherchÃ©
â€¢ Bachelor's degree in Engineering, Computer Science, or a related technical discipline
â€¢ 5+ years of industry experience in Data Engineering, BI Engineer, or related field with a track record of and extracting value from bigdata
â€¢ Strong experience in distributed data, ETL pipelines and Data Warehousing
â€¢ Hands-on experience and advanced knowledge of SQL, Shell scripting and Python."
Data Engineer | CDI,"{'name': 'TENACY', 'sector': 'Logiciels, SaaS / Cloud Services, CybersÃ©curitÃ©', 'employees': '50 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '30 ans'}",CDI,Lyon,45K Ã  55K â‚¬,TÃ©lÃ©travail frÃ©quent,04 mars 2024,> 4 ans,Bac +5 / Master,"Descriptif du poste
En tant que Senior Data Engineer, tu joueras un rÃ´le central dans la conception, la construction et le dÃ©ploiement de solutions de traitement de donnÃ©es complexes au sein de notre organisation. RattachÃ©(e) au VP of Engineering, tu seras responsable de lâ€™optimisation de nos architectures de donnÃ©es et de lâ€™implÃ©mentation de pipelines efficaces, soutenant ainsi la prise de dÃ©cision basÃ©e sur les donnÃ©es et le dÃ©veloppement de produits data-driven. Ta contribution sera essentielle pour garantir lâ€™intÃ©gritÃ©, la disponibilitÃ© et la performance des donnÃ©es.
En tant que Data Engineer, tu seras en charge de :
Concevoir et construire des architectures de donnÃ©es robustes et Ã©volutives.
DÃ©velopper et optimiser des pipelines de donnÃ©es pour la collecte, lâ€™extraction, la transformation et le chargement (ETL).
Collaborer avec les Ã©quipes Produits, Sales et Customers pour soutenir les initiatives dâ€™analyse de donnÃ©es et de machine learning.
Assurer la qualitÃ© et la fiabilitÃ© des donnÃ©es en mettant en place des mÃ©canismes de contrÃ´le et de gouvernance des donnÃ©es.
Participer Ã  lâ€™amÃ©lioration continue des processus et des outils de gestion de donnÃ©es.
Fournir un support technique et des conseils aux autres membres de lâ€™Ã©quipe, en partageant tes connaissances et ton expertise.
Ce que nous offrons :
Contrat CDI au statut cadre
Package 45-55Kâ‚¬ bruts/an
TÃ©lÃ©travail possible jusquâ€™Ã  2 jours par semaine
Tickets restaurant Swile : 9â‚¬/jour, pris en charge Ã  60% par lâ€™entreprise
Mutuelle AXA prise en charge Ã  70% par lâ€™entreprise
RTT
Et aussi : prime mobilitÃ© pour les dÃ©placements â€œmode douxâ€ ğŸš², chÃ¨ques cadeaux mariage et naissance ğŸ¼, plan dâ€™Ã©pargne entreprise ğŸ’°, formations rÃ©guliÃ¨res ğŸ“–, plusieurs temps forts de teambuilding dans lâ€™annÃ©e (soirÃ©es, sÃ©minaires)ğŸˆ, parcours dâ€™onboarding gamifiÃ© avec systÃ¨me de parrainage interne pour que ton intÃ©gration se dÃ©roule dans les meilleures conditions ğŸª‚, partenariat avec un fournisseur de fruits et lÃ©gumes (circuit court et bio) ğŸ‹, tarifs prÃ©fÃ©rentiels Ã  la salle de sport ğŸ‹ï¸â€¦
Voir moins","Profil recherchÃ©
Must have
ExpÃ©rience significative en ingÃ©nierie de donnÃ©es, avec une maÃ®trise des outils de data engineering (DBT ou autres)
CompÃ©tences solides en conception et gestion de bases de donnÃ©es SQL
ExpÃ©rience solide en gestion de projet et communication
Nice to have
SensibilitÃ© aux problÃ©matiques de sÃ©curitÃ©, dâ€™anonymisation
ExpÃ©rience avec des outils de CI/CD et de conteneurisation (Docker, Kubernetes)."
Tech Lead Data Engineer,"{'name': 'SOCIÃ‰TÃ‰ GÃ‰NÃ‰RALE', 'sector': 'Banque, FinTech / InsurTech, Finance', 'employees': '117000 collaborateurs', 'creation_year': '1864', 'turnover': None, 'mean_age': None}",CDI,Neuilly-sur-Seine,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Vous avez envie d'un environnement vous permettant d'Ãªtre Ã  la pointe Ã  la fois des technologies Cloud et Big data tout en mettant Ã  profit vos soft skills ? Si vous Ãªtes aussi Ã  l'aise pour coder que pour co-concevoir dans un cadre mÃ©thodologique riche et complexe alors rejoignez-nous en tant que Technical Leader.

Dans un contexte de vaste transformation/rÃ©Ã©criture d'un SI pour portage vers des technologies BigData et public Cloud, nous attendons des Technical Leader qu'ils soient les artisans du design et de l'implÃ©mentation technique de la plate-forme. Ils sont Ã©galement rÃ©fÃ©rents pour une ou plusieurs Feature Team (Equipe Agile) auprÃ¨s des dÃ©veloppeurs.

En tant que Technical Leader de la FT Basis, concrÃ¨tement, vous serez amenÃ© Ã  :
Concevoir des solutions pour collecter, nettoyer, organiser et synthÃ©tiser de gros volumes de donnÃ©es (pour alimenter bases de donnÃ©es, datalakes et projets Big Data)
Co-Ã©laborer le design technique du produit dÃ©livrÃ©
Apporter votre soutien sur les dÃ©veloppements de votre Ã©quipe
En fonction du contexte, vous rÃ©aliserez les activitÃ©s de Software Engineer pour des dÃ©veloppements stratÃ©giques
DÃ©velopper, entretenir et utiliser votre expertise sur la stack Scala, BigData, Cloud
Vous serez responsable de l'intÃ©gration cohÃ©rente du zproduit dans le SI avec l'Architecte Technique
Contribuer Ã  la veille technique de votre pÃ©rimÃ¨tre et Ã  sa diffusion, faire progresser les Ã©quipes et contribuer Ã  l'animation du chapter en collaboration avec les homologues tech lead d'autres directions


Et si câ€™Ã©tait vous ?


DiplÃ´mÃ© d'un Bac +5 en Informatique / Ã‰cole d'IngÃ©nieur, vous avez une premiÃ¨re expÃ©rience dans un environnement tech : Hadoop Hortonworks, Kafka, Nifi, etc.
Vous disposez a minima de 5 ans d'expÃ©rience en data Engineerig
Vous Ãªtes Incollable sur Spark et Scala
IdÃ©alement, vous avez une premiÃ¨re expÃ©rience en tant que Lead/Tech Lead Data engineer.
PassionnÃ© de data, vous proposez des amÃ©liorations et partagez avec votre Ã©quipe
Vous Ãªtes curieux, avec un bon esprit d'analyse et de synthÃ¨se
You're fluent in English

Plus qu'un poste, un tremplin


Notre vision est de jouer un rÃ´le moteur dans les transformations positives du monde et de contribuer Ã  un avenir plus Ã©cologique, respectueux de la planÃ¨te !

Choisir SociÃ©tÃ© GÃ©nÃ©rale, c'est intÃ©grer un Groupe oÃ¹ la culture d'entreprise est tournÃ©e vers l'inclusion, la diversitÃ© et l'esprit d'Ã©quipe !

C'est construire une carriÃ¨re dynamique avec la possibilitÃ© de changer de poste en moyenne tous les 4 ans, en France et Ã  l'international tout en bÃ©nÃ©ficiant de formations rÃ©guliÃ¨res !

Au regard de vos compÃ©tences, une rÃ©munÃ©ration attractive revue annuellement, composÃ©e d'un salaire fixe, d'une part variable individuelle et d'une prime d'intÃ©ressement et de participation vous sera proposÃ©e.

Vous bÃ©nÃ©ficiez Ã©galement de tarifs prÃ©fÃ©rentiels sur vos services bancaires, d'un compte Ã©pargne temps monÃ©tisable et d'un Plan d'Epargne Entreprise abondÃ©.

Attentif Ã  votre qualitÃ© de vie et conditions de travail, vous bÃ©nÃ©ficiez de nombreux avantages complÃ©mentaires :
Ã€ minima 2 jours de tÃ©lÃ©travail par semaine
26 Ã  28 jours de congÃ©s payÃ©s par an et 14 Ã  18 jours de RTT (suivant les annÃ©es), des congÃ©s liÃ©s aux Ã©vÃ©nements de la vie
Un ComitÃ© d'Entreprise (billetterie Ã©vÃ©nements sportifs & culturels, primes et subventions vacances, garde d'enfants, chÃ¨que cadeaux Ã  Noel)
Une offre variÃ©e de restaurants d'entreprise et de cafÃ©tÃ©rias Ã  tarifs compÃ©titifs ainsi que des titres restaurants dÃ©matÃ©rialisÃ©s quand vous Ãªtes en tÃ©lÃ©travail

Pourquoi nous choisir ?


Chez SociÃ©tÃ© GÃ©nÃ©rale, nous sommes convaincus que vous Ãªtes le moteur du changement, et que le monde de demain sera fait de toutes vos initiatives, des plus petites aux plus ambitieuses.

Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques annÃ©es ou toute votre carriÃ¨re, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. CrÃ©er, oser, innover, entreprendre font partie de notre ADN.

Si vous aussi vous souhaitez Ãªtre dans l'action, Ã©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et dÃ©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !

Vous hÃ©sitez encore ?
Sachez que nos collaborateurs peuvent s'engager quelques jours par an pour des actions de solidaritÃ© sur leur temps de travail : parrainer des personnes en difficultÃ© dans leur orientation ou leur insertion professionnelle, participer Ã  l'Ã©ducation financiÃ¨re de jeunes en apprentissage ou encore partager leurs compÃ©tences avec une association. Les formats d'engagement sont multiples.

Nous sommes un employeur garantissant l'Ã©galitÃ© des chances et nous sommes fiers de faire de la diversitÃ© une force pour notre entreprise. Le groupe s'engage Ã  reconnaÃ®tre et Ã  promouvoir tous les talents, quels que soient leurs croyances, Ã¢ge, handicap, parentalitÃ©, origine ethnique, nationalitÃ©, identitÃ© de genre, orientation sexuelle, appartenance Ã  une organisation politique, religieuse, syndicale ou Ã  une minoritÃ©, ou toute autre caractÃ©ristique qui pourrait faire l'objet d'une discrimination.

RÃ©fÃ©rence: 23000EUD
EntitÃ©: Fonctions centrales groupes
Date de dÃ©but: immediat

Date de publication: 06/11/2023
Voir moins",
Data Engineer @Aive (Inovexus community startup),"{'name': 'INOVEXUS', 'sector': ""SaaS / Cloud Services, Incubateur / AccÃ©lÃ©rateur, Accompagnement d'entreprises"", 'employees': '8 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 3 ans,,"Descriptif du poste
En temps que Data Engineer chez Aive, vos missions seront de :
Participer Ã  la conception et lâ€™implÃ©mentation de nouvelles fonctionnalitÃ©s reposant sur lâ€™analyse ou le traitement vidÃ©o, audio ou textuel.
Concevoir ou appliquer des modÃ¨les, algorithmes et mÃ©thodes pour mettre un oeuvres ces fonctionnalitÃ©s
Maintenir une veille technologique sur les sujets pertinents pour le produit
Collaborer avec les autres spÃ©cialitÃ©s de lâ€™Ã©quipe pour industrialiser le produit (qualitÃ©, performance, maintenance)
Lâ€™offre est ouverte pour toute la France, avec une prÃ©fÃ©rence pour les candidats en rÃ©gion Parisienne ayant la possibilitÃ© de venir rÃ©guliÃ¨rement dans les locaux.","Profil recherchÃ©
Une bonne connaissance des sujets et technologies suivants est apprÃ©ciÃ©e (exemples tirÃ©s de nos projets rÃ©cents ou Ã  venir):
Languages: Python, Golang
Frameworks de machine learning: Torch, ONNX
OpÃ©ration: Github CI, Docker, Kubernetes
Computer Vision (object/logo/face detection, shot/scene detection, feature extraction)
Signal Processing (automatic speech recognition, diarization)
Natural Language Processing (topic segmentation, summarization)
Les compÃ©tences et expÃ©riences suivantes seront fortement apprÃ©ciÃ©es :
3 ans dâ€™expÃ©rience prÃ©alable
Vous aimez travailler en Ã©quipe, partager vos connaissances et les approfondir au contact des autres
Recherchez lâ€™efficacitÃ© dans la crÃ©ation dâ€™algorithme Ã  grande Ã©chelle et Ã©volutifs
Si jamais vous ne remplissez pas tous ces critÃ¨res, nâ€™hÃ©sitez pas Ã  nous contacter quand mÃªme, nous Ã©tudierons tous les profils intÃ©ressants !
Voir plus"
Data Engineer Internship (Altitude),"{'name': 'AXA CLIMATE', 'sector': 'StratÃ©gie, SaaS / Cloud Services, EdTech', 'employees': '150 collaborateurs', 'creation_year': '2019', 'turnover': '18M â‚¬', 'mean_age': '36 ans'}","Stage
(5 Ã  6 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,04 mars 2024,> 6 mois,Bac +5 / Master,"Descriptif du poste
AXA Climate and Altitude
AXA Climate has 5 business unit to support its clients and partners, based on expertise: Insurance, Training, Consulting, SaaS Products, and Regen. Globally, we are a team of +200 climate experts, headquartered in Paris, spread over 5 continents and driven by the same desire for impact. Our purpose is to help Planet Earth become a true stakeholder of all companies, in the same way that employees, customers and shareholders are!
Altitude is the brand of our SaaS business. Our purpose is Adaptation. We build solutions, for decision makers, to enable climate and environmental adaptation. Our products are tailor-made for each persona: Private Equity firms, Agricultural cooperative, etc. We are +20 people working on it: product managers, designers, developers, business developers, etc.
We are autonomous within AXA Climate, but we work closely with the consulting teams dedicated to Financial Services and Agri sectors. We strongly believe that success is collective and we play as one team.
Altitude for Finance
Altitude for Finance is our first product, launched un September 2022. It is a platform dedicated for Infrastructure and Private Equity funds, enabling risk screening in pre-acquisition Due-Diligence, and enabling portfolio monitoring for reporting (such as TCFD). It is an innovative one-stop-shop for sustainability and investment teams, screening climate and nature-related risks and opportunities within minutes, very easy to use, and fully automated.
You can know more about our product here: www.axa-altitude.com
In 2023, we signed +35 clients, totalizing +170bnâ‚¬ of Asset Under Management. To keep developing and growing our positive impact on the investment industry, we are recruiting.
Your Mission, as a Data Engineer Intern
You will join the Data Team, which focuses on geospatial data and risk analysis.
As part of our data quality improvement objective, your main goals will be:
To define a framework for end-to-end testing of the data platform, based on recommendations from the science team, and normalized on the projectâ€™s infrastructure
To benchmark geospatial data formats, allowing us to to discover means of improving the platformâ€™s performance
Optionally, a benchmark of geospatial data formats would also allow us to discover means of improving the platformâ€™s performance.
While working on those goals, you will be fully integrated in the daily life of the data team, and the ecosystem as a whole:
Participate in the various rituals: daily, demo, retrospective, etc.
Understand the component and architecture of the data platform
Learn about geospatial data manipulation with Python
Participate in tasks related to current feature developments
Our technical stack:
Running on AWS
Entirely serverless: Lambda, Fargate, DynamoDB, etc.
Python (data) and TypeScript (front-end)
Managed via Terraform
Voir moins","Profil recherchÃ©
You are graduating from an engineering school, with a focus on data engineering
You have experience with Python and its ecosystem
You are rigorous and detail-oriented
You are proactive and autonomous in your work
You are able to deliver project on time and with the right level of quality
You have a strong interest for climate issues and challenges, and the science around it
A first experience with geospatial formats is a plus"
Data Engineer BI,"{'name': 'BNP PARIBAS', 'sector': 'Banque', 'employees': '183883 collaborateurs', 'creation_year': '2000', 'turnover': '50,4 Mdsâ‚¬', 'mean_age': '40 ans'}",CDI,Nantes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,01 septembre 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
Data Engineer BI H/F
(Poste basÃ© Ã  NANTES (44) disponible Ã  partir de septembre 2024)
BCEF IT, l'informatique de la Banque Commerciale en France travaille en mode Agile, en proximitÃ© du Business. Ensemble, ces Ã©quipes ont pour mission de dÃ©velopper des solutions fonctionnelles, innovantes et sÃ©curisÃ©es pour rÃ©pondre aux besoins et aux attentes des clients et des collaborateurs, en alignement avec les enjeux et les standards de place (Data, IA, Devops, Cloud, NumÃ©rique responsable, cybersÃ©curitÃ©â€¦).
Historiquement implantÃ©s en rÃ©gion parisienne, nous ouvrons un nouveau Campus Ã  Nantes (7 boulevard de Berlin - 44000 Nantes) afin de renforcer nos compÃ©tences sur les mÃ©tiers du dÃ©veloppement et des mÃ©tiers d'expertise.
Facile d'accÃ¨s, Ã  seulement 10 minutes de la gare, ce campus vous offrira un environnement de travail agrÃ©able et stimulant. Vous travaillerez en environnement Flex Office et tÃ©lÃ©travail en mode hybride avec l'accÃ¨s aux outils collaboratifs digitaux (Teams, klaxoonâ€¦) et en Ã©troite collaboration avec notre campus parisien.
MotivÃ©(e) Ã  relever ce nouveau challenge sur Nantes ? Rejoignez-nous !
Missions, Ã©quipe et environnement de travail, Ã§a donne quoi ?
Au sein de la DSI de la Banque Commerciale En France (BCEF IT) et plus particuliÃ¨rement dans le domaine transverse IT ""Data / IA & Foundations"", nous recherchons un Data Engineer BI.
Vos principales missions seront :
* De Concevoir et dÃ©velopper les features du sprint backlog
* d'ÃŠtre force de proposition, participer aux choix techniques en lien avec les architectes du groupe et participer aux recrutements de l'Ã©quipe
* d'Ãªtre garant des respects des bonnes pratiques de dÃ©veloppement
* De participer sur des cadrages de projets IT ou mÃ©tiers sur la plateforme en tant qu'Expert en lien Ã©troit avec les architectes et autres experts (sÃ©curitÃ©, data management,â€¦)
* d'Etre en veille technologique

Au sein de la squad Â« Datafactory Â» avec des Ã©quipes Ã  la fois sur notre site Nantais et notre site francilien, vous serez en charge des dÃ©veloppements sur notre plateforme d'ingestion de flux.
Voir moins","Profil recherchÃ©
Etes-vous notre prochain Data Engineer BI - H/F ?
Oui, si vous disposez d'un BAC +5 en Ã©cole d'ingÃ©nieur ou Ã©quivalent universitaire, avec une spÃ©cialisation en informatique.
Vous avez 3 annÃ©es d'expÃ©riences minimum dans le domaine informatique et plus spÃ©cifiquement sur les technologies Data.
Vous avez des connaissances en DÃ©veloppement informatique, Tests informatiques, Architecture, Infrastructure informatique, SÃ©curitÃ© informatique et cyber sÃ©curitÃ© et Relations IT / Business.
Votre capacitÃ© d'adaptation, capacitÃ© Ã  dÃ©cider, crÃ©ativitÃ© & innovation/capacitÃ© Ã  rÃ©soudre des problÃ¨mes, capacitÃ© Ã  synthÃ©tiser/simplifier, Ã‰coute active, orientation client, CapacitÃ© Ã  synthÃ©tiser / simplifier seront autant d'atouts nÃ©cessaires pour rÃ©ussir sur le poste.
Vous Ãªtes reconnu pour votre CapacitÃ© Ã  comprendre, expliquer et intÃ©grer les enjeux de dÃ©veloppement durable dans mon travail au quotidien, CapacitÃ© Ã  incarner la DiversitÃ©, l'EgalitÃ© et l'Inclusion au sein du Groupe, CapacitÃ© Ã  adopter et promouvoir l'Ã©tat d'esprit Agile.
Votre niveau d'anglais et de franÃ§ais est opÃ©rationnel. Vous maÃ®trisez le Pack Office et Teradata, Business Object, Tableau, Power BI et Dataiku.
Voir plus"
Lead Data Engineer FR,"{'name': 'PELICO', 'sector': 'Intelligence artificielle / Machine Learning', 'employees': '68 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
As a Lead Data Engineer within our company, you will play a pivotal role in overseeing and developing our team dedicated to data integration of our clients.
You will be responsible for leading but also contributing in the structure of data integration activities of our clients, by defining data pipelines architectures, automatisation process and make our Software & Data Engineering team grow.

What youâ€™ll do & learn ğŸ“–
Plan, coordinate, and manage software and data integration projects, ensuring adherence to timelines and budgets agreed with the clients
Work closely with other departments to understand business needs and translate them into technical solutions.
Oversee the development, maintenance, and updating of practice, ensuring compliance with quality and security standards.
Establish rigorous testing processes to ensure application stability.
Supervise data collection, storage, quality, and security.
Collaborate with the Customer Operations team to extract valuable insights from data.
Efficiency through Standardization: Standardize processes across the organization. Reduces the risk of errors, improves consistency, and streamlines operations.
Optimization: Regularly assess processes, gather feedback from team members, and implement improvements to respond to changing needs.
Data-Driven Decision-Making: Utilize data and analytics to provide objective guidance to obtain the most significant impact
Alignment with customers to embrace a perfect data integration: Tailor your interactions and services to each customer's preferences and needs using data and insights to personalized experiences.
Embrace multiple channels to communicate with customers effectively.
Implement systems and processes to proactively identify and resolve issues before they impact the data integration experience.
Stay updated with relevant technological trends and advancements for the team.
Design, develop, maintain and evolve the data stack to answer both business and product needs (especially back end features within the platform)
Build data pipelines and configure the platform (incl. algorithms) to on-board new customers.

 What you embody ğŸ¯
Pelico promotes inclusion and non-discrimination, and acts daily in favour of social mix, gender equality, senior citizens & disability
 At least 7 years of Data engineering experience, ideally in a SAAS environment
You are mastering on Python Javascript, C++, Kotlin, You-name-itâ€¦ but note that we hire based on engineering fundamentals rather than familiarity with specific technologies
Experience in building data-rich products or complex data pipelines (professional or personal projects) or working with data (data transformation & event driven pipeline)
SQL expert
Bilingual English mandatory (verbal & written), French is a plus
Proactive, Autonomous, results oriented and you excel in stimulating environments
Willingness to create impact for customers and see the product in the hand of happy users
Team player and comfortable working with others
Comfortable in client facing if needed

Technical Stack ğŸ’»
Python
Airflow
PostgreSQL
Gitlab CI/CD
Linus
Docker
What we offerğŸ’¡
Join an exciting adventure with a lot of challenges at all levels!
Work on a highly impactful product that users love!
Office location at the heart of Paris (75002)
Stock Options for every pelican
Remote flexibility & 6 weeks of Work from Anywhere
Premium health coverage : Alan Blue
50% meal allowance: 10â‚¬/day worked (Swile card)
50% public transportation or equivalent in sustainable mobility package
Team events every quarter
 Our recruitment Process ğŸ“£
HR Introduction of 45 mins by GG Meet
Tech Interview
Case Study (1h30)
Debrief with Chief Customer Officer or VP Eng
Ref check & offer letter to join Pelico within 48 hours
Voir moins",
Senior Software and Data Engineer,"{'name': 'PELICO', 'sector': 'Intelligence artificielle / Machine Learning', 'employees': '68 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
The Tech Delivery Team is the technical link between the Customer Operations and Customer Support with the rest of the company, we fix bugs when a client finds a problem, we help the CustOps with onboarding of new customers, the DevOps with the deployment of new products and features and we study how to make our clientâ€™s transition to Pelico SAAS smooth & easy.
We have identified several opportunities that will make today's processes and daily work easier for the CustOps onboarding new clients and adding new data to the current ones.
What you'll do & learnğŸ“–
Youâ€™ll play an instrumental role at maximizing the impact of the Pelico platform at customers:
Design, develop, maintain and evolve the data stack to answer both business and product needs (especially back end features within the platform)
Build data pipelines and configure the platform (incl. algorithms) to on-board new customers
Work closely with the customer operations & product strategy teams to iterate based on user feedback and bring impact to our clients
Own features end-to-end from technical design to dev.
Help your coworkers review code, spread your technical expertise, improve our tool chain
Play an integral role in establishing our engineering culture and best practices
Contribute actively in alignment between others technical teams in the Engineering department
Be a A player in product roadmap & engineering delivery towards business targets.

Technical Stack ğŸ’»
Stack:
Python
Kotlin
Flask with Blueprints
WebSocket
Pandas, numpy Parallelisation
Parallelisation Framework: ZMQ, Pub/Sub
Environment :
dedicated gcloud VM
boilerplate docker / docker-compose
Services :
GraphQL
PostgreSQL
Redis
RabbitMQ
ElasticSearch
InfluxDB
Processes Management :

Airflow (ETLs, management batches)
Gitlab CI / CD
Security :
Yubikeys
Keeper passwords
Gsuite SSO

What you embody ğŸ¯
At least 5 years of Data engineering experience, ideally in a SAAS environment
You are mastering on Python Javascript, C++, Kotlin, You-name-itâ€¦ but note that we hire based on engineering fundamentals rather than familiarity with specific technologies
Experience in building data-rich products or complex data pipelines (professional or personal projects) or working with data (data transformation & event driven pipeline)
SQL expert
Bilingual English mandatory (verbal & written), French is a plus
Proactive, Autonomous, results oriented and you excel in stimulating environments
Willingness to create impact for customers and see the product in the hand of happy users
Team player and comfortable working with others

 Pelico promotes inclusion and non-discrimination, and acts daily in favour of social mix, gender equality, senior citizens & disability

What we offerğŸ’¡
Join an exciting adventure with a lot of challenges at all levels!
Work on a highly impactful product that users love!
Office location at the heart of Paris (75002)
Stock Options for every Pelican
Remote flexibility & 6 weeks of Work from Anywhere
Premium health coverage : Alan Blue
50% meal allowance: 10â‚¬/day worked (Swile card)
50% public transportation or equivalent in sustainable mobilty package
Afterwork every quarter
Voir moins",
Data Engineer Intern,"{'name': 'DOLEAD', 'sector': 'IT / Digital, PublicitÃ©', 'employees': '91 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '33 ans'}",Stage,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Based in : ParisTeam : Data6 months internshipStart : As soon as possible
Do you want to work in a fast-paced environment where you will learn a lot, be rewarded and inspired ? Come and join Dolead, one of the top lead generation companies.
About us
We are a global leader in Lead generation and we power the growth of 200 clients across 15 countries. We are lucky to have a team of experts with 13 different nationalities, working remotely and in offices across France and the U.S.
We work alongside our client marketing and sales team to power their growth. Dolead runs paid marketing campaigns faster, integrates customer data with confidence and generates sales-ready leads at a fixed cost per lead.
To reach our goals, Dolead is seeking for a motivated Data Engineer Intern to join our Engineering team. This position will play a central role in consolidating Dolead as a data driven company.
You will have the opportunity to learn about & use the best tools & practices in the data engineering field:
Python, SQL
Google Cloud Platform : BigQuery (Data Warehouse), Looker (Business Intelligence), Dataflow, Cloud Composerâ€¦
DBT
Airbyte
Mission
Understand Dolead Data.
Optimize our data pipelines written in Python & SQL (Airbyte, DBT)
Assess our data quality by creating automated tests
Make data easy to access for business teams
Work with other teams to deliver data related products
Profile
You are curious and proactive about learning new technologies in the field of data engineering.
You think that data is a key factor of success for a company and want to contribute to it.
You have a professional level in English (French is a plus).
You have a good knowledge of Python and SQL.
You share Dolead corporate values (Data wins argument; Work Hard / Play Hard; Dream big, stay Humble; POC and Scale; Your Success is my Success)
What we offer:
ğŸ’³ Tickets Restaurants: Swile lunchcard - 9â‚¬/day
ğŸ’» Flexible remote policy: up to 2 days/week
ğŸŒ Multiculturual: +13 nationalities represented
ğŸ¥³ Environment: Monthly team & company events! Strong company culture
ğŸ“ Offices: Located in the center of Paris (near OpÃ©ra) - you will enjoy our well-equipped kitchen or the various restaurants around our office (incl. the best Japanese spots in Paris)!
Recruitment process:
Interview with the Hiring Manager 
Small test to assess your technical skills
Dolead wants to guarantee equality and an opportunity to all candidates. Therefore, all applications received are considered regardless of racial and ethnic origin, opinions or beliefs, gender, sexual orientation, health or disability.
Voir moins",
Data Engineer - Italy ğŸ‡®ğŸ‡¹,"{'name': 'DOCTRINE', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Service juridique', 'employees': '120 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Notre mission âš–ï¸
Nous nous engageons pour un enjeu dÃ©mocratique majeur : rendre le droit plus accessible et transparent aux justiciables et aux professionnels du droit.
Doctrine est la premiÃ¨re plateforme d'intelligence juridique. Nous centralisons et organisons toute l'information juridique disponible pour permettre aux avocats et juristes de mieux conseiller et dÃ©fendre leurs clients. Plus d'un million de personnes viennent tous les mois sur Doctrine se renseigner sur leurs droits, et dÃ©jÃ  12 000 professionnels du droit nous font confiance.
Nos valeurs ğŸ¤
Challenge the status quo. Nous dÃ©fendons les idÃ©es audacieuses et la prise de risque intelligente.
Liberty and responsibility. Nous promouvons lâ€™autonomie, lâ€™impact de chacunÂ·e et lâ€™ownership.
Knowledge is power. L'information est au cÅ“ur de la mission de Doctrine, et nous voulons toujours apprendre plus.
Release early, release often and listen to your customers. Nous croyons au pouvoir de lâ€™itÃ©ration et Ã  lâ€™importance dâ€™Ã©couter en permanence notre marchÃ©, nos clientÂ·eÂ·s et leurs problÃ©matiques.
Le contexte
Suite Ã  une croissance rapide et rentable en France, Doctrine pose les premiÃ¨res briques de son internationalisation en Italie. Nous sommes Ã  la recherche de notre premier.e Data Engineer sur ce pays, pour nous aider Ã  lancer la premiÃ¨re plateforme dâ€™intelligence juridique sur le marchÃ© italien.
Câ€™est un rÃ´le stratÃ©gique qui impactera la roadmap produit et les futurs succÃ¨s de Doctrine en Italie.
A noter : le poste est basÃ© Ã  Paris, dans nos bureaux du 8Ã¨me arrondissement.
Tu peux trouver des dÃ©tails sur lâ€™ensemble de la stack  sur Github
A savoir : il nâ€™est pas nÃ©cessaire dâ€™avoir une expÃ©rience professionnelle dans le domaine du droit, cependant lâ€™envie de sâ€™investir et de monter en compÃ©tence dans la comprÃ©hension des documents juridiques est importante :)
Les missions ğŸ› 
Concevoir, dÃ©velopper, monitorer les pipelines de donnÃ©es et les scripts d'acquisition utilisÃ©es pour tous les contenus de notre plateforme
Assurer la qualitÃ© de la donnÃ©e et son monitoring
Travailler main dans la main avec les ingÃ©nieurs machine learning en charge des parties Ã©quivalentes de leur cÃ´tÃ©
Contribuer Ã  lâ€™Ã©volution de nos outils de pipeline de donnÃ©es (Airflow, Kubernetes, Dask, Amazon S3, PostgreSQL, Terraform, etc...), et faire en sorte dâ€™en tirer le meilleur profit au quotidien
Au sein du Chapter Data Engineering, participer Ã  l'Ã©laboration de nos pratiques de modÃ©lisation et de traitement des donnÃ©es.
Le profil idÃ©al ğŸ‘€
De bonnes compÃ©tences en programmation Python
Une expÃ©rience des pratiques d'acquisition et de modÃ©lisation des donnÃ©es
Une bonne connaissance de SQL, NoSQL, Elasticsearch et du stockage objet
Lâ€™envie de partager tes connaissances pour participer Ã  la progression de chacun.e
La maÃ®trise de la langue franÃ§aise car ce sera ta langue de travail avec tes collÃ¨gues
IdÃ©alement, des notions dâ€™italien car tu seras amenÃ© Ã  manipuler des donnÃ©es en italien
Les Ã  cÃ´tÃ©s du poste ğŸ‘
Comme tous les ingÃ©nieurs de Doctrine, tu participeras Ã  un de nos chapters transverses, en lâ€™espÃ¨ce le chapter Data Engineering. Au sein de ce chapter, tu contribueras Ã  des projets internes pour amÃ©liorer nos process et notre vision long-terme. Le chapter se rÃ©unit toutes les deux semaines pour :
ğŸ¤ Partager des connaissances : amÃ©lioration continue, bonnes pratiques,â€¦
ğŸ¯ Proposer des Ã©volutions : nouveaux outils Ã  expÃ©rimenter, nouveaux process Ã  mettre en Å“uvre
Tu participeras Ã©galement au ğŸ‘©â€ğŸ’» recrutement : tous les contributeurs individuels rencontrent des candidats Ã  lâ€™occasion de tests techniques ou dâ€™entretiens.
Ce qui t'attend si tu rejoins Doctrine ğŸ¤—
- Contribuer Ã  un projet ambitieux, avec un impact rÃ©el et positif sur la sociÃ©tÃ© : rendre le droit plus accessible et plus ouvert.
- Un accompagnement sur mesure dÃ¨s ton arrivÃ©e sur l'Ã©cosystÃ¨me juridique pour t'aider Ã  naviguer trÃ¨s vite dans cet environnement stimulant.
- Une aventure dans laquelle tu apprendras sans cesse et partageras tes connaissances Ã  lâ€™ensemble de tes collÃ¨gues (talks internes/externes, meetups, Tech & Sales Monthly, blog Medium, etc.)
- Travailler au sein dâ€™une Ã©quipe en Ã©bullition qui cherche sans cesse Ã  se renouveler : de la place pour innover et mener des projets en autonomie ou en Ã©quipe.
Nos avantages pour faire la diffÃ©rence â˜€ï¸
ğŸ¡ Une politique de tÃ©lÃ©travail flexible, avec 2 jours de prÃ©sence au bureau par semaine (mardi et jeudi)
ğŸŒ± De nombreuses options pour ta carriÃ¨re, et des mobilitÃ©s internes ouvertes Ã  toutes et tous chez Doctrine
ğŸŒ´ Des vacances flexibles et illimitÃ©es
ğŸ“š Un vrai accent sur la formation individuelle et collective, avec un budget annuel de 750â‚¬ en usage libre et des formations en Ã©quipe et pour toute l'entreprise rÃ©guliÃ¨rement
ğŸ„â€â™‚ï¸ Des Ã©vÃ¨nements collectifs rÃ©guliers
ğŸ‘©â€âš•ï¸ Une bonne assurance santÃ© avec Alan
ğŸš² Un forfait mobilitÃ© durable Ã  hauteur de 66 euros par mois
ğŸ‹ï¸â€â™€ï¸ Un abonnement Gymlib pour les activitÃ©s sportives et bien-Ãªtre
ğŸ± Une carte Swile pour tes tickets restaurants
ğŸ§˜ Un accÃ¨s gratuit Ã  la plateforme d'accompagnement Ã  la santÃ© mentale Moka.care
ğŸ’¡ Des centaines de rÃ©ductions et avantages nÃ©gociÃ©s grÃ¢ce Ã  notre CSE
ğŸ Un Ã©quipement de travail neuf chez Apple
Notre processus de recrutement ğŸš€
- Un premier Ã©change de 30 min avec lâ€™un.e de nos Talent Acquisition Manager pour bien comprendre ton projet professionnel et te prÃ©senter ce qu'on construit chez Doctrine
- Une rencontre dâ€™1h avec ton/ta futur.e manager, pour dÃ©tailler le poste et le scope de lâ€™Ã©quipe, mais aussi rÃ©pondre Ã  toutes tes questions.
- Un ou deux tests techniques pour Ã©valuer concrÃ¨tement tes compÃ©tences
- Un dÃ©jeuner avec 3 personnes de diffÃ©rents dÃ©partements chez Doctrine, pour te donner un aperÃ§u de tes futur.e.s collÃ¨gues
- Un Ã©change sur les valeurs de lâ€™entreprise pour te partager notre vision
- Une rencontre avec Guillaume, notre CEO.
(si nÃ©cessaire le processus pourra Ãªtre adaptÃ© pour rÃ©pondre Ã  tes contraintes personnelles et professionnelles)
Mesdames, autorisez-vous Ã  candidater !
Certaines Ã©tudes scientifiques montrent qu'en particulier les femmes ont moins tendance Ã  postuler Ã  une offre d'emploi quand elles n'ont pas toutes les qualifications. Si cela peut vous rassurer, sachez que cette fiche de poste est indicative donc prenez la comme telle : c'est un guide, ni plus ni moins.
Si Doctrine vous intÃ©resse, sachez que nous aurons plaisir Ã  recevoir votre candidature !
Voir moins",
Fullstack Data Engineer,"{'name': 'DOCTRINE', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Service juridique', 'employees': '120 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Notre mission âš–ï¸
Nous nous engageons pour un enjeu dÃ©mocratique majeur : rendre le droit plus accessible et transparent aux justiciables et aux professionnels du droit.
Doctrine est la premiÃ¨re plateforme d'intelligence juridique. Nous centralisons et organisons toute l'information juridique disponible pour permettre aux avocats et juristes de mieux conseiller et dÃ©fendre leurs clients. Plus d'un million de personnes viennent tous les mois sur Doctrine se renseigner sur leurs droits, et dÃ©jÃ  12 000 professionnels du droit nous font confiance.
Nos valeurs ğŸ¤
Challenge the status quo. Nous dÃ©fendons les idÃ©es audacieuses et la prise de risque intelligente.
Liberty and responsibility. Nous promouvons lâ€™autonomie, lâ€™impact de chacunÂ·e et lâ€™ownership.
Knowledge is power. L'information est au cÅ“ur de la mission de Doctrine, et nous voulons toujours apprendre plus.
Release early, release often and listen to your customers. Nous croyons au pouvoir de lâ€™itÃ©ration et Ã  lâ€™importance dâ€™Ã©couter en permanence notre marchÃ©, nos clientÂ·eÂ·s et leurs problÃ©matiques.
Le contexte
Nous recherchons un data engineer fullstack confirmÃ© pour nous aider Ã  construire des pipelines de traitement de documents en quasi temps rÃ©el. Tu verrais le cycle complet des donnÃ©es, depuis le moment oÃ¹ les documents sont fournis par lâ€™utilisateur jusquâ€™aux modÃ¨les de machine learning qui les analyseront ensuite.
Tu rejoindrais la squad â€œProductivityâ€ dont la mission est de rÃ©volutionner la maniÃ¨re dont travaillent les professionnels du droit en proposant des outils de productivitÃ© qui simplifient lâ€™analyse et la rÃ©daction de documents juridiques privÃ©s. Productivity est une nouvelle ligne de produit qui se dÃ©veloppe chez Doctrine, oÃ¹ tout reste Ã  construire !
Notre stack technique est basÃ©e sur Python, React, NodeJS, NextJS, NestJS.
Tu peux trouver des dÃ©tails sur lâ€™ensemble de la stack sur Github 
A savoir : il nâ€™est pas nÃ©cessaire dâ€™avoir une expÃ©rience professionnelle dans le domaine du droit, cependant lâ€™envie de sâ€™investir et de monter en compÃ©tence dans la comprÃ©hension des documents juridiques est importante :)
Les missions ğŸ› 
Concevoir, dÃ©velopper, monitorer des architectures de pipelines et de services backend pour le traitement de donnÃ©es en quasi temps rÃ©el, utilisÃ©es pour tous types de documents juridiques.
Designer et implÃ©menter des interfaces adaptÃ©es Ã  lâ€™acquisition des documents et Ã  la prÃ©sentation des rÃ©sultats des analyses.
Travailler main dans la main avec des product managers, des designers, des ingÃ©nieurs fullstack et machine learning en charge des parties Ã©quivalentes de leur cÃ´tÃ©.
Participer Ã  la diffusion interne et Ã  la consolidation de nos bonnes pratiques ; contribuer Ã  lâ€™Ã©laboration de notre stratÃ©gie Engineering.
Le profil idÃ©al ğŸ‘€
Une large expÃ©rience des pratiques d'acquisition et de modÃ©lisation des donnÃ©es.
Une bonne connaissance de SQL, Elasticsearch et du stockage objet.
De bonnes compÃ©tences en programmation Python.
Une bonne connaissance de NodeJS, TypeScript, React, NextJS, NestJS, ou dâ€™autres frameworks frontend et backend.
De lâ€™intÃ©rÃªt pour la qualitÃ© du code et pour les bonnes pratiques de dÃ©veloppement en gÃ©nÃ©ral (p. ex. tests, CI/CD) ; lâ€™ambition de livrer des applications avec une haute fiabilitÃ© et une haute disponibilitÃ©.
Un fort intÃ©rÃªt pour les aspects produit, la comprÃ©hension du besoin utilisateur, et lâ€™envie de contribuer Ã  la dÃ©finition de ce quâ€™on construit !
Les Ã  cÃ´tÃ©s du poste ğŸ‘
Comme tous les ingÃ©nieurs de Doctrine, tu participeras Ã  nos chapters transverses, en lâ€™espÃ¨ce les chapters Web et Data Engineering. Au sein de ces chapters, tu contribueras Ã  des projets internes pour amÃ©liorer nos process et notre vision long-terme. Le chapter se rÃ©unit toutes les deux semaines pour :
ğŸ¤ Partager des connaissances : amÃ©lioration continue, bonnes pratiques,â€¦
ğŸ¯ Proposer des Ã©volutions : nouveaux outils Ã  expÃ©rimenter, nouveaux process Ã  mettre en Å“uvre
Tu participeras Ã©galement au ğŸ‘©â€ğŸ’» recrutement : tous les contributeurs individuels rencontrent des candidats Ã  lâ€™occasion de tests techniques ou dâ€™entretiens.
Ce qui t'attend si tu rejoins Doctrine ğŸ¤—
- Contribuer Ã  un projet ambitieux, avec un impact rÃ©el et positif sur la sociÃ©tÃ© : rendre le droit plus accessible et plus ouvert.
- Un accompagnement sur mesure dÃ¨s ton arrivÃ©e sur l'Ã©cosystÃ¨me juridique pour t'aider Ã  naviguer trÃ¨s vite dans cet environnement stimulant.
- Une aventure dans laquelle tu apprendras sans cesse et partageras tes connaissances Ã  lâ€™ensemble de tes collÃ¨gues (talks internes/externes, meetups, Tech & Sales Monthly, blog Medium, etc.)
- Travailler au sein dâ€™une Ã©quipe en Ã©bullition qui cherche sans cesse Ã  se renouveler : de la place pour innover et mener des projets en autonomie ou en Ã©quipe.
Nos avantages pour faire la diffÃ©rence â˜€ï¸
ğŸ¡ Une politique de tÃ©lÃ©travail flexible, avec 2 jours de prÃ©sence au bureau par semaine (mardi et jeudi)
ğŸŒ± De nombreuses options pour ta carriÃ¨re, et des mobilitÃ©s internes ouvertes Ã  toutes et tous chez Doctrine
ğŸŒ´ Des vacances flexibles et illimitÃ©es
ğŸ“š Un vrai accent sur la formation individuelle et collective, avec un budget annuel de 750â‚¬ en usage libre et des formations en Ã©quipe et pour toute l'entreprise rÃ©guliÃ¨rement
ğŸ„â€â™‚ï¸ Des Ã©vÃ¨nements collectifs rÃ©guliers
ğŸ‘©â€âš•ï¸ Une bonne assurance santÃ© avec Alan
ğŸš² Un forfait mobilitÃ© durable Ã  hauteur de 66 euros par mois
ğŸ‹ï¸â€â™€ï¸ Un abonnement Gymlib pour les activitÃ©s sportives et bien-Ãªtre
ğŸ± Une carte Swile pour tes tickets restaurants
ğŸ§˜ Un accÃ¨s gratuit Ã  la plateforme d'accompagnement Ã  la santÃ© mentale Moka.care
ğŸ’¡ Des centaines de rÃ©ductions et avantages nÃ©gociÃ©s grÃ¢ce Ã  notre CSE
ğŸ Un Ã©quipement de travail neuf chez Apple
Notre processus de recrutement ğŸš€
- Un premier Ã©change de 30 min avec lâ€™un.e de nos Talent Acquisition Manager pour bien comprendre ton projet professionnel et te prÃ©senter ce qu'on construit chez Doctrine
- Une rencontre dâ€™1h avec ton/ta futur.e manager, pour dÃ©tailler le poste et le scope de lâ€™Ã©quipe, mais aussi rÃ©pondre Ã  toutes tes questions.
- Un ou deux tests techniques pour Ã©valuer concrÃ¨tement tes compÃ©tences
- Un dÃ©jeuner avec 3 personnes de diffÃ©rents dÃ©partements chez Doctrine, pour te donner un aperÃ§u de tes futur.e.s collÃ¨gues
- Un Ã©change sur les valeurs de lâ€™entreprise pour te partager notre vision
- Une rencontre avec Guillaume, notre CEO.
(si nÃ©cessaire le processus pourra Ãªtre adaptÃ© pour rÃ©pondre Ã  tes contraintes personnelles et professionnelles)
Mesdames, autorisez-vous Ã  candidater !
Certaines Ã©tudes scientifiques montrent qu'en particulier les femmes ont moins tendance Ã  postuler Ã  une offre d'emploi quand elles n'ont pas toutes les qualifications. Si cela peut vous rassurer, sachez que cette fiche de poste est indicative donc prenez la comme telle : c'est un guide, ni plus ni moins.
Si Doctrine vous intÃ©resse, sachez que nous aurons plaisir Ã  recevoir votre candidature !
Voir moins",
Data Engineer (Stage Mars 2024) - H/F,"{'name': 'SHOWROOMPRIVE.COM', 'sector': 'Application mobile, Mode, E-commerce', 'employees': '1050 collaborateurs', 'creation_year': '2006', 'turnover': '697.5Mâ‚¬', 'mean_age': '33 ans'}",Stage,Saint-Denis,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 6 mois,,,
Data Engineer - Energie - Ile-de-France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Courbevoie,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail : 
La division Â« Energie Â» accompagne les grands acteurs du secteur en France dans les domaines de la production et de la distribution thermique, hydraulique et nuclÃ©aire. Dans un contexte agile, nos Ã©quipes d'experts participent Ã  des projets autour de la transformation numÃ©rique pour conduire nos clients vers une transition Ã©cologique.
Le dÃ©fi que nous vous proposons de relever ? Mettre l'Ã©nergie au service des Smart Grid & Cities !
Sous la responsabilitÃ© d'un directeur de la Business Unit Energie, vous participez aux principaux grands projets de transformation numÃ©rique de ses secteurs.
Acteur majeur de l'avant-vente jusqu'Ã  la livraison du produit final, vous intervenez sur un pÃ©rimÃ¨tre large, au sein d'un environnement technique innovant
Votre rÃ´le et missions : 
Au sein d'une Ã©quipe Agile, accompagnÃ© par un chef de projet, en tant que Data Engineer et dans le cadre de nos projets de data management dans le secteur de lâ€™Ã©nergie, vous intervenez dans le cadre de dÃ©veloppement de projet BI (incluant la rÃ©alisation de datamarts, cubes ou rapports) complexes et Ã  forte valeur ajoutÃ©e (Pilotage des trains, reporting financier, gestion des conducteurs). Votre rÃ´le est donc prÃ©pondÃ©rant dans la rÃ©ussite du projet.
Vous intervenez sur toute la chaÃ®ne de valeur du cycle projet :
- Vous rÃ©digez des spÃ©cifications fonctionnelles gÃ©nÃ©rales ou dÃ©taillÃ©es sur la base d'expression de besoins
- Vous participez Ã  la conception et au dÃ©veloppement des applications Big Data, les tester, les faites Ã©voluer et assurer leur maintenance.
- Vous assurez lâ€™intÃ©gritÃ© et la qualitÃ© de la donnÃ©e sur tout le processus dâ€™ETL
- Vous industrialisez et optimisez la gestion des flux de donnÃ©es
- Vous participez Ã  la conception de lâ€™architecture et l'infrastructure de nos systÃ¨mes de collecte et de traitement des donnÃ©es.
- Vous pilotez et accompagnez les utilisateurs durant les phases de recette
- Vous accompagnez des key users et des utilisateurs finaux dans l'usage des nouveaux rapports (formations, support...)
- Vous contribuez Ã  l'amÃ©lioration du reporting et du pilotage de la performance.
GrÃ¢ce Ã  votre excellent esprit collectif vous avez Ã  cÅ“ur de partager votre savoir et contribuer Ã  la progression des membres de l'Ã©quipe.
Environnement technologique riche : Talend, Power BI, Cloud computing, Java, Python, PostgreSQL, Cloudera, Spark...
 Informations supplÃ©mentaires
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions. 
Un package avantages intÃ©ressant : une mutuelle, un CSE, des titres restaurants, un accord
dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 30 familles de mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â».
L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encoreâ€¦).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherchÃ©
DiplÃ´mÃ©(e) d'une Ã©cole d'IngÃ©nieurs ou Ã©quivalent, vous justifiez d'une expÃ©rience technique de 3 ans minimum et souhaitez Ã©voluer rapidement dans un contexte motivant.
Vous avez au moins l'une de ces compÃ©tences requises :
Â· MaÃ®trise des technologies de bases de donnÃ©es Relationnelles et NoSQL
Â· MaÃ®trise des technologies de traitement distribuÃ© de donnÃ©es (spark, Hadoop)
Â· MaÃ®trise dâ€™au moins un framework de streaming de donnÃ©es (Kafka, RabbitMQ, etc.)
Â· MaÃ®trise de chaines CI/CD et de des bonnes pratiques de DataOps
Â· MaÃ®trise de solution de Virutualisation de donnÃ©es (Denodo, Dremio, etc.)
Â· MaÃ®trise dâ€™au moins un environnement cloud public ou privÃ© (Azure, AWS, Outscale, etc.)
Vous Ãªtes attirÃ©(e) par le monde du numÃ©rique, le Cloud et des technologies innovantes.
Vous avez un bon esprit d'analyse, Ãªtes curieux(se) et passionnÃ©(e) et vous avez le sens du travail en Ã©quipe."
Data Engineer - Services Financiers - Ile de France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail :
Au sein de notre Data Factory, vous Ãªtes pleinement impliquÃ©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi Ã  leur succÃ¨s. Vous avez l'occasion de dÃ©velopper vos compÃ©tences techniques et fonctionnelles de maniÃ¨re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.
Votre rÃ´le et vos missions :
Vous avez pour rÃ´le la mise en place de pipelines de donnÃ©es fiables, sÃ©curisÃ©s et Ã  lâ€™Ã©chelle pour soutenir la mise Ã  disposition des donnÃ©es aux cas dâ€™usage mÃ©tier qui en ont besoin.
Vos activitÃ©s principales sont les suivantes :
Vous travaillez avec le client pour Ã©valuer, concevoir, dÃ©ployer, amÃ©liorer et maintenir les pipelines de donnÃ©es ;
Vous vous assurez que les pipelines de donnÃ©es crÃ©Ã©s sont rÃ©silients, sÃ©curisÃ©s et accessibles ;
Vous dÃ©finissez le modÃ¨le opÃ©rationnel pour monitorer et supporter les pipelines de donnÃ©es
Vous fournissez une expertise Ã  nos clients sur leurs donnÃ©es pour assurer leur optimisation et leur sÃ©curitÃ© par rapport Ã  leurs besoins ;
Vous apportez un savoir en gestion de la qualitÃ© et la gouvernance de la donnÃ©e pour assurer le suivi de la conformitÃ© Ã  la gouvernance de la donnÃ©e
Vous faites de la veille technologique dans le domaine afin dâ€™enrichir les roadmaps technologiques et fournir des solutions modernes Ã  nos clients.
 Informations supplÃ©mentaires
Ce que nous vous proposons :
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusqu'Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressants : une mutuelle, un CSE, des titres restaurants, un accord d'intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 50 mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.
.La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â».
L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encore).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherchÃ©
Votre profil :
De formation Master 2 Ecole d'IngÃ©nieurs ou Informatique, ou Ã©quivalent, vous justifiez d'une expÃ©rience technique de 3 ans minimum et souhaitez Ã©voluer rapidement dans un contexte motivant. 
Vous avez au moins l'une de ces compÃ©tences requises :
MaÃ®trise des technologies de bases de donnÃ©es Relationnelles et NoSQL
MaÃ®trise dâ€™au moins un outil dâ€™ETL/ELT (Informatica, datastage, etc.)
MaÃ®trise des technologies de traitement distribuÃ© de donnÃ©es (spark, Hadoop)
MaÃ®trise dâ€™au moins un framework de streaming de donnÃ©es (Kafka, RabbitMQ, etc.)
MaÃ®trise de chaines CI/CD et de des bonnes pratiques de DataOps
MaÃ®trise de solution de Virutualisation de donnÃ©es (Denodo, Dremio, etc.)
MaÃ®trise dâ€™au moins un environnement cloud public ou privÃ© (Azure, AWS, Outscale, etc.)
Vous Ãªtes attirÃ©(e) par le monde du numÃ©rique, le Cloud et des technologies innovantes.
Vous avez un bon esprit d'analyse, Ãªtes curieux(se) et passionnÃ©(e) et vous avez le sens du travail en Ã©quipe. "
Lead Software/Data Engineer | LLM,"{'name': 'JUS MUNDI', 'sector': 'Intelligence artificielle / Machine Learning, Service juridique, Justice', 'employees': '64 collaborateurs', 'creation_year': '2018', 'turnover': '4 million ARR', 'mean_age': '35 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
As a pioneering force in the global legal tech landscape, Jus Mundi is seeking an experienced Tech Lead to spearhead the development of our cutting-edge Large Language Model (LLM) powered AI solutions. This role is a unique opportunity to be at the forefront of the LLM revolution in the legal domain and to join a mission company to have an impact in powering global justice.
Key Responsibilities:
Supervise project development from conception to completion of our LLM-powered AI solutions, ensuring they meet the specific needs of our users.
Collaborate with cross-functional teams, including NLP researchers, software engineers, legal experts, and product managers, to build outstanding LLM-powered products.
Managing, leading and mentoring a team of developers and data-scientists, fostering a culture of innovation and continuous learning.
Providing guidance on software development and best practices.
Ensuring the quality and reliability of technical outputs.
Stay abreast of the latest advancements in AI and LLM technologies, applying cutting-edge research to practical solutions.
Ensure adherence to ethical AI principles and compliance with legal and regulatory standards in AI application.
Voir moins","Profil recherchÃ©
Who you are:
You have 7+ years as software/data engineer and masters at least part of our Tech Stack.
You have solid engineering skills in computer science, NLP, LLMs and machine learning: how they work, how to implement them, what we can do with and what are their limits.
You have experience with AI products and data pipelines.
You have experience leading and inspiring an engineering team.
You are passionate about your craft and can communicate it.
You thrive in a fast-paced environment.
You are trustworthy.
Our Engineering Culture:
Do what you say, Say what you do.
Communication builds Trust. Trust improves Performance.
Try, fail and, learn. Iterate until success.
Leave your ego at the door.
Big Ideas, Pragmatical Implementation.
Voir plus"
Data Engineer - Azure & Informatica IICS internship (H/F),"{'name': 'TATA CONSULTANCY SERVICES', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '615000 collaborateurs', 'creation_year': '1968', 'turnover': '$ 28 milliards', 'mean_age': None}","Stage
(4 Ã  6 mois)",Suresnes,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,"Descriptif du poste
We are seeking a highly skilled, proactive, and communicative Data Engineer with expertise in Azure and Informatica Intelligent Cloud Services (IICS) to join our IT team. The candidate will be responsible for designing, implementing, testing, and maintaining data ingestion pipelines. This role is crucial for transforming raw data into actionable insights for our international projects involving stakeholders from multiple countries. Fluent English communication skills are essential for this role.
Your missions:
Data Ingestion and Transformation
Â·       Help Architects & Tech Leads design and implement data ingestion pipelines using Azure services and Informatica IICS.
Â·       Transform raw data from various sources into a clean and structured format for analytical purposes.
Data Testing
Â·       Develop and execute test cases to ensure data integrity and quality.
Â·       Work closely with data analysts and senior data engineers and architects and Data Asset Owners to validate data sets for analytics.
Maintenance and Optimization
Â·       Monitor data pipelines and perform troubleshooting to ensure optimal performance.
Â·       Continuously improve existing codebase for scalability and maintainability.
Collaboration and Communication
Â·       Collaborate with cross-functional teams, including Project Management, Business Analysts, and Data Scientists.
Â·       Communicate effectively with international stakeholders to understand data requirements and deliver accordingly.
Â·       Fluent in English to ensure clear and effective communication across all levels of the organization.
Project Management and Reporting
Â·       Proactively update the Azure Board each day to track the progress of data engineering tasks.
Â·       Generate regular reports on data pipeline performance, issues, and resolutions.
Documentation
Â·       Create and maintain technical documentation for data pipelines, code, and data dictionaries.
Â·       Train end-users and technical staff on new data pipelines and transformations.
Voir moins","Profil recherchÃ©
Bachelorâ€™s or Masterâ€™s degree in Computer Science, Engineering, or a related field.
Â·       Strong expertise in Azure Data Services like Azure Data Lake, Azure SQL Database, Azure Data Factory, etc.
Â·       Proficient in Informatica Intelligent Cloud Services (IICS) for data integration.
Â·       Familiarity with data modeling, data warehousing, and ETL processes.
Â·       Strong programming skills in Python, SQL, or other data-related languages.
Â·       Excellent problem-solving skills.
Â·       Strong communication skills, both written and verbal, with the ability to work in a collaborative team environment.
Â·       Proactive mindset with a focus on continuous improvement.
Â·       Fluent in English.
If you have strong interest in Digital Technologies, and if challenges are part of your DNA, so join us!"
Data Engineer (H/F),"{'name': 'EKKIDEN TECHNOLOGIES', 'sector': 'IT / Digital, Transformation', 'employees': '230 collaborateurs', 'creation_year': '2019', 'turnover': '12 millions of euros', 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Le rÃ´le : Data Engineer (H/F)Vous ferez partie d'une Ã©quipe SCRUM et vous vous focaliserez sur des fonctions spÃ©cifiques. Votre rÃ´le sera de contribuer aux projets data, en apportant votre expertise technique.
ResponsabilitÃ©s :

Vous participerez activement aux diffÃ©rents projets mÃ©tiers, en assurant leur rÃ©alisation.


Vous prendrez en charge les corrections nÃ©cessaires suite aux incidents ou anomalies.


Vous contribuerez Ã  l'auto-formation et Ã  l'accroissement des compÃ©tences au sein de l'Ã©quipe de dÃ©veloppement.


Vous appliquerez les meilleures pratiques de dÃ©veloppement et les normes associÃ©es.


Vous mettrez en Å“uvre les mÃ©thodes ""devops"".


Vous participerez aux chiffrages des usages ainsi qu'Ã  la constitution des releases.


Vous travaillerez sur lâ€™automatisation du delivery.


Vous dÃ©velopperez et documenterez votre code.


Vous collaborerez avec lâ€™Ã©quipe SCRUM, incluant le Product Owner, les dÃ©veloppeurs, les QA et le support.


Ce que nous recherchons :
CompÃ©tences techniques :

Vous disposez d'un diplÃ´me Bac+5 en informatique ou Ã©quivalent, avec au moins 3 ans d'expÃ©rience en tant que Data Engineer.
Vous avez de l'expÃ©rience dans l'architecture de systÃ¨mes distribuÃ©s Big Data.

Vous maÃ®trisez Scala ou Java, avec une expÃ©rience obligatoire dans l'un de ces langages.


Vous connaissez l'Ã©cosystÃ¨me Big Data, incluant Hadoop, Spark, Apache Kafka, Avro, etc.


Vous maÃ®trisez les processus de CI/CD et les outils de dÃ©ploiement et orchestration tels que Jenkins, GitLab, Kubernetes, Docker, Ansible.


Vous comprenez les concepts fondamentaux de Kafka.


Vous avez de l'expÃ©rience avec les bases de donnÃ©es NoSQL comme Cassandra ou BigTable.


Vous possÃ©dez des compÃ©tences en Kafka-Stream, une familiaritÃ© avec la Google Cloud Platform, et la pratique du Software Craftsmanship est valorisÃ©e.
Ce que nous proposons :
ğŸ¤ Nous rejoindre au bon moment pour faire ta place au sein d'une organisation en trÃ¨s forte croissance 
ğŸš€ Des missions variÃ©es dans un environnement challengeant qui te permettront d'avoir un rÃ©el impact sur la boite
ğŸ’ª La possibilitÃ© de travailler de faÃ§on autonome et d'Ãªtre force de proposition pour grandir ensemble 
âœ¨ Un parcours de carriÃ¨re adaptÃ© Ã  ta personnalitÃ©, aussi bien au niveau du rÃ´le que de la localitÃ© 
ğŸ‘ Une formation exigeante en continu pour libÃ©rer tout ton potentiel
ğŸ™Œ Des conditions de travail flexibles (horaires, tÃ©lÃ©travail, â€¦)
ğŸ‘© Une culture de la performance avec de belles primes de rÃ©sultats
â¤ï¸ Une mutuelle trÃ¨s complÃ¨te (Alan) et des titres-restaurant (carte Swile)
Voir moins",
Data Engineer / Data Scientist MÃ©dia,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,12 fÃ©vrier 2024,> 6 mois,Bac +5 / Master,"Descriptif du poste
MP DATA, recrute un Data Engineer afin de travailler pour notre client dans le secteur des MÃ©dias :
Vos missions seront les suivantes :
Renforcer notre connaissance 360 de nos clients/utilisateurs (segmentation, enrichissement, activation de la donnÃ©eâ€¦),
Superviser les alimentations de production grÃ¢ce aux outils (AirFlowâ€¦),
DÃ©velopper lâ€™offre de ciblage publicitaire en TV segmentÃ©e,
Gestion et maintenance de lâ€™offre,
â Apport dâ€™une expertise sur lâ€™offre de ciblage afin dâ€™amÃ©liorer les recommandations,annonceurs/agences,
Travailler avec les Data Scientists Ã  la mise en Å“uvre des modÃ¨les statistiques et algorithmiques,","Profil recherchÃ©
De formation Bac+5 (ou plus) en dÃ©veloppement informatique / Data Engineering, vous justifiez dâ€™une expÃ©rience professionnelle significative dans le secteur de la PublicitÃ© au cours de laquelle vous avez pu dÃ©velopper les compÃ©tences techniques suivantes :
Python
SQL
Pyspark
Streaming"
Data Engineer / Fullstack Data (SÃ©nior),"{'name': 'HIBOO SYSTEMS SAS', 'sector': 'SaaS / Cloud Services', 'employees': '38 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail total,,> 5 ans,,"Descriptif du poste
Nos valeurs
Nous avons dÃ©fini notre Tech manifesto pour nous apporter de la clartÃ© et un guide dans nos dÃ©cisions. Pour en reprendre les grand thÃ¨mes :
Collaborative Minds over Solo Efforts
Engaged Accountability over Passive Compliance
Continuous Delivery over Perfectionism
Continuous improvement over Stagnation
Human-oriented Code over Machine-only Code
Done Means Live
Pourquoi nous rejoindre ?
Une Ã©quipe Tech rÃ©ellement remote (La RÃ©union ğŸ, BrianÃ§on ğŸ§—â€â™€ï¸, Bordeaux ğŸ‡, BÃ©ziers ğŸ–ï¸, Tours ğŸ°, Paris ğŸ¥–â€¦)
Une Ã©quipe expÃ©rimentÃ©e et qui cherche Ã  sâ€™amÃ©liorer (Dojos, Pair/Mob Programming, DDD, Clean Architecture, Tech meetup interneâ€¦)
Des dÃ©fis technologiques importants : Collecte et traitement de donnÃ©es, Gestion de multiple sources de donnÃ©es, Analytics, Rapports et valorisation des donnÃ©esâ€¦
Lâ€™Ã©quipe tech nâ€™est pas simplement â€œexÃ©cutanteâ€ mais pleinement empowered
RÃ©munÃ©ration basÃ©e sur les compÃ©tences et pas la gÃ©ographie
Une dimension Ã©cologique (Aider les industriels Ã  mesurer leur impact et le rÃ©duire ğŸŒ¿)
Voir moins","Profil recherchÃ©
En tant que Data Engineer chez Hiboo, tu seras en charge de la conception, du dÃ©veloppement, de la maintenance et de lâ€™optimisation des infrastructures de donnÃ©es. Cela implique :
Le dÃ©veloppement des outils et des traitements permettant la migration de lâ€™ingestion de nos diffÃ©rentes sources de donnÃ©es vers une architecture orientÃ©e big data
La construction de pipeline de donnÃ©es (batch et temps rÃ©el) permettant dâ€™alimenter notre application, nos APIs, nos analytics et nos projets de data-science
Au quotidien, tu interviendras donc sur le dÃ©ploiement et le monitoring des briques techniques nÃ©cessaires Ã  lâ€™infrastructure data dâ€™Hiboo (plateforme dâ€™ingestion, datalake, calcul distribuÃ©) mais Ã©galement du code de collecte, structuration, mise en qualitÃ©, documentation et mise Ã  disposition de la donnÃ©e. Tu contribueras Ã©galement activement aux dÃ©cisions concernant les choix produit et techniques, en lien avec le reste de lâ€™Ã©quipe.
En complÃ©ment de partager nos valeurs, on souhaiterait que les Ã©lÃ©ments suivants te parlent :
Un esprit entrepreneurial
Enthousiaste pour le travail dâ€™Ã©quipe, lâ€™apprentissage et le partage de connaissances
Voir plus"
,,,,,,,,,,
Stage - Data Engineer,"{'name': 'NUMBERLY', 'sector': 'Logiciels, Digital Marketing / Data Marketing, Big Data', 'employees': '500 collaborateurs', 'creation_year': '2000', 'turnover': None, 'mean_age': '27 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Numberly recherche un(e) Data Engineer en stage pour rejoindre son Ã©quipe dÃ©diÃ©e aux problÃ©matiques Data. Vous participerez aux traitements, transformations et restitutions des donnÃ©es auprÃ¨s des Ã©quipes internes afin dâ€™amÃ©liorer les performances des campagnes et des stratÃ©gies marketing de nos clients.
Vous :
Aimez la donnÃ©e sous toutes ses formes : brute, travaillÃ©e et analysÃ©e ;
Avez le dÃ©sir de la comprendre et de la faire parler ;
PossÃ©dez une formation axÃ©e sur la big data, la fouille de donnÃ©es ou plus gÃ©nÃ©ralement en software engineering;
ApprÃ©ciez le travail bien fait, avez le sens du dÃ©tail et vous aimez comprendre les problÃ©matiques de vos clients ;
Aspirez Ã  travailler pour des clients variÃ©s et prestigieux sur des problÃ©matiques pointues ;
ÃŠtes Ã  lâ€™affÃ»t des nouveaux langages/technologies et des derniÃ¨res tendances open source;
ÃŠtes spontanÃ©(e) et apprÃ©ciez le travail en Ã©quipe en collaborant avec diffÃ©rents mÃ©tiers de la data;
Portez de l'intÃ©rÃªt au Marketing et souhaitez dÃ©couvrir ce domaine.
 Stage de 6 mois dÃ©butant en fÃ©vrier 2024.
RÃ©munÃ©ration : 1400 â‚¬ brut mensuel en M1 et 1700 â‚¬ brut mensuel en M2.
 Voir moins","Profil recherchÃ©
Vous connaissez :
ModÃ©lisation
SQL 
Python
ETL
 Encore mieux si vous connaissez :
Workflows management platforms
Environnement Hadoop
SystÃ¨mes et calculs distribuÃ©s
API REST, Web Services
Realtime / Streaming
Docker
 Ce que nous utilisons :
Voir plus"
Data Engineer (F/H),"{'name': 'STACK LABS', 'sector': 'Application mobile, IT / Digital, SaaS / Cloud Services', 'employees': '40 collaborateurs', 'creation_year': '2017', 'turnover': '5Mâ‚¬', 'mean_age': '33 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©","DÃ©but :
08 janvier 2024",TÃ©lÃ©travail frÃ©quent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Pour renforcer notre Ã©quipe Data et accompagner notre croissance, nous recherchons actuellement un Data Engineer, avec une appÃ©tence pour les solutions Cloud.
De part votre mÃ©tier, vous serez amenÃ©(e) Ã  intervenir dÃ¨s les phases amont de projets de migration cloud pour des clients Ã  forts enjeux de scalabilitÃ© sur du conseil technique et sur les fondamentaux du cloud public (sÃ©curitÃ©, observabilitÃ©, rÃ©seau, billing, automatisation) jusquâ€™Ã  la mise en service des solutions.
 Reconnu(e) pour votre polyvalence au sein des Ã©quipes, vous Ãªtes orientÃ©(e) aussi bien vers la sphÃ¨re technique que vers lâ€™Humain. Vous participez notamment Ã  :
Lâ€™audit de configuration cloud de client et des prÃ©conisations dâ€™amÃ©lioration.
Proposition dâ€™architectures data cloud native (GCP/AWS)
La mise en place dâ€™entrepÃ´ts de donnÃ©es massivement scalable avec BigQuery, Redshift, MongoDB, Athena, CloudSQL, Firestoreâ€¦
Le dÃ©veloppement de pipelines de traitement de donnÃ©es avec Spark, Dataflow, PubSub, SQSâ€¦
Lâ€™analyse des donnÃ©es et leur mise Ã  disposition de processus de Data science (Machine Learning)
Lâ€™onboarding de clients sur les bonnes pratiques et la philosophie cloud et devops.
La mise en place des bonnes pratiques dâ€™automatisation (CI/CD, GitOps)
La conduite du dÃ©ploiement, de lâ€™intÃ©gration et du passage en opÃ©ration de la solution
Notre Ã©cosystÃ¨me technique (indicatif, variable en fonction des missions) :
Architecture Data : ETL, ELT, Dataflow, Spark, Airflow, GCP Workflows
Big Data: BigQuery, Firestore, Redshift, Athena, MongoDB
Containers & microservices : Docker, Kubernetes, Istio,â€¦
Architectures orientÃ©es messages : Kafka, PubSub,..
Automatisation & Infrastructure as Code (IaC) : Terraform, CloudFormation, Ansible, GitLab, GitHub,â€¦
Public Cloud : AWS, GCP, â€¦
Langages de dÃ©veloppement : Python, Go, Javaâ€¦
Voir moins","Profil recherchÃ©
Vous disposez de plusieurs expÃ©riences en tant Data Engineer, notamment dans la mise en place de pipelines et le traitement automatisÃ© des donnÃ©es. Vous avez une vraie appÃ©tence pour les technologies Cloud, et de lâ€™expÃ©rience sur au moins un fournisseur Cloud. Moteur au sein des Ã©quipes, vous Ãªtes naturellement tournÃ©(e) vers la proactivitÃ©, le partage et la bienveillance. Plus quâ€™un profil type, nous recherchons chez Stack Labs des personnes proches de notre ADN : passionnÃ©es de tech, curieuses et disposant dâ€™une vÃ©ritable â€œsoif dâ€™apprentissageâ€."
Data Engineer - BORDEAUX H/F,"{'name': 'CAPGEMINI', 'sector': 'IT / Digital, Organisation / Management, StratÃ©gie, Transformation', 'employees': '360000 collaborateurs', 'creation_year': '1967', 'turnover': '18 Mds â‚¬', 'mean_age': '37 ans'}",CDI,Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 2 ans,Bac +5 / Master,"Descriptif du poste
VOTRE RÃ”LE
 Vous Ãªtes passionnÃ©.e par le domaine de la DATA et vous souhaitez prendre part Ã  un projet dâ€™envergure dans le secteur Telecom ? Rejoignez notre Ã©quipe Hybrid Intelligence au sein de Capgemini Engineering en tant que DATA Engineer.
 Vous avez acquis une expÃ©rience solide dans le dÃ©veloppement de pipelines de donnÃ©es et de solutions pour le traitement d'un grand volume de donnÃ©es. Vous Ãªtes capable de crÃ©er des solutions qui rÃ©pondent aux besoins de diffÃ©rentes parties prenantes telles que les spÃ©cialistes de la visualisation de donnÃ©es, les scientifiques de donnÃ©es et les analystes de donnÃ©es.
 En qualitÃ© de DATA Engineer, vos missions seront les suivantes :
â–ª Concevoir et dÃ©velopper des solutions Data/IA Ã  des fins analytics & dashboarding
â–ª Accompagner les MÃ©tier dans la comprÃ©hension des Analytics et mise en Å“uvre de solution ""data driven""
â–ª Collaborer avec les data scientiste et data ops dans la construction d'une culture axÃ©e sur les donnÃ©es
â–ª GÃ©rer un Ã©cosystÃ¨me de partenaires data science et assurer un haut niveau d'expertise
â–ª Assurer un rÃ´le de veille technologique sur tous les outils autours de la data, IA et BI.


Voir moins","Profil recherchÃ©
Profile description:

VOTRE PROFIL
 Vous Ãªtes issu.e dâ€™une formation IngÃ©nieur ou Ã©quivalent Bac + 5 Informatique spÃ©cialisÃ© en DATA et vous justifiez dâ€™une expÃ©rience rÃ©ussie dans le domaine du dÃ©veloppement de pipelines de donnÃ©es et de solution Data (5 ans min).
 Vous maÃ®trisez les technologies informatiques pour manipuler des bases de donnÃ©es de type : Oracle, Postgre, NoSQL,.. et framework : Hadoop, Spark, Hive, Oozie, Nifi, Jupyter, Kafka , â€¦ Votre maÃ®trise des langages : SQL, SCALA, Pyhton, JAVA, Shellâ€¦vous permettent dâ€™Ãªtre autonome sur la manipulation de donnÃ©es. Enfin, vous avez acquis une expÃ©rience dans les outils BI, data visualisation : Kibana, Qliksense, Power Biâ€¦ La maitrise de lâ€™Anglais est nÃ©cessaire pour ce poste.


We offer:

Voir plus"
Data Engineer - H/F,"{'name': 'FREEBOX', 'sector': 'Logistique, Electronique / TÃ©lÃ©communications', 'employees': '60 collaborateurs', 'creation_year': '2000', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,Sans diplÃ´me,"Descriptif du poste
SituÃ©e dans le 8e arrondissement de Paris, Freebox est la filiale R&D dâ€™Iliad qui dÃ©veloppe les produits triple play Free (dÃ©codeurs tv, servers et rÃ©pÃ©teurs). 
Le Data Engineer intÃ©grera lâ€™Ã©quipe Data Freebox. 
Pour valoriser les donnÃ©es nÃ©cessaires Ã  lâ€™amÃ©lioration et la conception des Freebox, tes missions seront les suivantes : 
Concevoir, dÃ©velopper, mettre en production et gÃ©rer les pipelines de streaming pour la transformation et ingestion de donnÃ©es dans Bigquery 
GÃ©rer et faire Ã©voluer l'architecture de la plateforme Data sur GCP
Automatiser en production le dÃ©ploiement et lâ€™exÃ©cution de la plateforme Data
Montrer et mettre en place des indicateurs de contrÃ´le sur la plateforme Data 
Qui sommes-nous ? 
Depuis 20 ans, Freebox a gardÃ© un fort esprit entrepreneurial. Nos 60 collaborateurs conÃ§oivent, dÃ©veloppent et industrialisent les produits utilisÃ©s par nos 7 millions de foyers dâ€™abonnÃ©s.
Chez Freebox, la volontÃ© de tout faire en interne permet Ã  chaque collaborateur dâ€™avoir un poste complet avec beaucoup dâ€™autonomie. Avec peu de hiÃ©rarchie, chacun a une vÃ©ritable valeur ajoutÃ©e dans son Ã©quipe et un impact rÃ©el sur les projets auxquels il participe. 
EntourÃ©(e) dâ€™experts, tu trouveras ta place chez Freebox si tu as un intÃ©rÃªt pour les nouvelles technologies et que tu aimes faire Ã©voluer tes compÃ©tences techniques.
Ce que nous te proposons : 
Un environnement avec une forte culture tech et des projets Ã  la hauteur de tes ambitions
De rejoindre une entreprise et une Ã©quipe Ã  taille humaine 
Un environnement de travail unique au cÅ“ur de Paris
Un cadre social agrÃ©able et adaptÃ© (tÃ©lÃ©travail partiel, RTT, prise en charge des repas, etc.)
Etc. 
Ta future Ã©quipe : 
Lâ€™Ã©quipe Data est chargÃ©e dâ€™accompagner lâ€™innovation Freebox en imaginant et dÃ©livrant les outils et analyses autour de la donnÃ©e. 
Tes collÃ¨gues : 
Un product manager
Une Data Analyst
Tu rejoindras une Ã©quipe transverse qui travaille en collaboration Ã©troite avec les Ã©quipes produits R&D (set-top-box, gateway, Wi-Fi et applications).
Voir moins","Profil recherchÃ©
ExpÃ©rience :
Tu as 7 ans dâ€™expÃ©rience en tant que Data Engineer. 
CompÃ©tences : 
MaÃ®triser les langages/framework suivants : Java (Apache Beam en streaming) et Python (Flask)
Automatisation (Ansible, Shell Linux, Gitlab-CI, Docker)
GCP - BigQuery, Dataflow (Apache Beam en streaming), Cloud Run, Pub/Sub, Agipgateway, Memorystore (Redis)
Bonus :
ExpÃ©rience sur kafka et kafka-stream
Tu trouveras ta place chez Freebox si tu :
Collabores avec toutes les parties prenantes afin dâ€™identifier les nouveau besoins et de rÃ©pondre aux retours dâ€™expÃ©rience sur lâ€™usage de la plateforme Data,
Es capable de comprendre lâ€™utilisation des donnÃ©es et de tâ€™informer sur les roadmaps des Ã©quipes pour identifier leurs futurs besoins.
Process de recrutement : 
Voir plus"
,,,,,,,,,,
Senior Data Engineer,"{'name': 'FAIRLY MADE', 'sector': 'SaaS / Cloud Services, Luxe, Mode', 'employees': '60 collaborateurs', 'creation_year': '2018', 'turnover': '2.2Mâ‚¬', 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 4 ans,,"Descriptif du poste
Lâ€™Ã©quipe data chez Fairly Made, câ€™est une Ã©quipe ambitieuse, en croissance rapide.
ğŸ§± 2023 a permis de poser les premiÃ¨res briques de la data platform : Airbyte, dbt, BigQuery, Datahub, â€¦
ğŸ¯ Notre objectif 2024 ? Servir de plus en plus de use cases pour nos utilisateurs internes et externes. Câ€™est pourquoi nous faisons grossir lâ€™Ã©quipe (objectif x4) ğŸš€
Tes missions ğŸ’ªğŸ»
Pour cela, nous avons besoin dâ€™un Data Engineer pour monter une infrastructure data fiable, performante, scalable, qui suive le rythme de notre croissance. En tant que premier DE, nous attendons de toi que tu sois force de proposition pour poser des bases solides et nous permettre de dÃ©velopper sereinement tous nos projets data. Travaillant main dans la main avec notre Head of Data, voici quelques exemples de missions que tu pourrais Ãªtre amenÃ©.e Ã  rÃ©aliser :
Stabiliser les produits data existants (app streamlit, architecture mÃ©daillon sur BigQuery, Data Model pour BI, â€¦)
DÃ©ployer des services externes sur notre infrastructure cloud (Cloud Run, GCE, GKE, â€¦)
Mettre en place des bonnes pratiques Ops (IaC, CI/CD, accÃ¨s sÃ©curisÃ© aux donnÃ©es, â€¦)
Mettre en place un orchestrateur
Mettre en place des process de validation automatique des donnÃ©es
Challenger le modÃ¨le de donnÃ©es existant
DÃ©ployer des modÃ¨les de Data Science et les exposer
Construire Ã  terme une Ã©quipe de Data Engineers chez Fairly Made
Notre stack data
Cloud : GCP
Stockage de donnÃ©es : BigQuery, PostgreSQL
Langages : Python, SQL
ELT : Airbyte, dbt, orchestrateur (Kestra en cours dâ€™Ã©valuation)
Visualization : Power BI
Autre : Github, Docker, ClickUp, Datahub â€¦
Voir moins","Profil recherchÃ©
Nous recherchons un(e) Data Engineer ayant une volontÃ© de sâ€™impliquer dans un projet Ã  fort impact social et environnemental.
Ce poste est fait pour toi si :
Tu es passionnÃ©Â·e par la data et suis les tendances tech
Tu as des convictions sur comment monter une data platform robuste et scalable
Tu as au moins 4 ans dâ€™expÃ©rience dans un poste similaire
Tu maÃ®trises Python et ses bonnes pratiques de code
Le cloud computing nâ€™a pas de secret pour toi (avec une bonne expÃ©rience GCP idÃ©alement)
Tu connais trÃ¨s bien BigQuery et connait ses pistes dâ€™optimisation
Tu aimes les aspects infra et ops
Tu as un bon sens pratique et aimes travailler en Ã©quipe
La chaÃ®ne complÃ¨te de valeur de la donnÃ©e, de la rÃ©colte Ã  lâ€™analyse, nâ€™a pas de mystÃ¨re pour toi
Tu es proactifÂ·ve et solution-oriented
Tu adhÃ¨res aux valeurs de FAIRLY MADEÂ® et es intÃ©ressÃ©Â·e par notre produit
âœ… Tu ne coches pas tous les cases de la liste ? Pas de pression ! On sait bien que chaque personne est unique. Si tu es motivÃ©.e Ã  travailler avec nous, postule sans hÃ©siter ! On a hÃ¢te dâ€™en apprendre plus sur ton parcours et de voir comment on pourrait grandir ensemble. Fais-nous signe et rejoins lâ€™aventure !
Voir plus"
Senior Data Engineer (F/M/D),"{'name': 'VESTIAIRE COLLECTIVE', 'sector': 'Luxe, Mode, E-commerce', 'employees': '800 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': '34 ans'}",Autres,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Vestiaire Collective is the leading global online marketplace for desirable pre-loved fashion. Our mission is to transform the fashion industry for a more sustainable future by empowering our community to promote the circular fashion movement. Vestiaire was founded in 2009 and is headquartered in Paris with offices in London, Berlin, New York, Singapore and Hong Kong and warehouses in Tourcoing (France), Crawley (UK), Hong Kong and New York.
We currently have a diverse global team of 700 employees representing over 50 nationalities. Our values are community, activism, transparency, dedication and greatness. We are proud to be a BCorp.
Senior Data Engineer (F/M/D)
Full-time, Permanent role based in Paris
About the role
Vestiaire Collective is hiring a Senior Data Engineer on our data platform team, to play a crucial role in developing and enhancing our data infrastructure, driving Vestiaire Collective's mission towards a sustainable fashion industry.
What you'll do
Real-Time Data Processing
Create real-time data processing applications, leveraging Kafka for timely data availability.
Ensure high throughput and low latency in data processing/service.
Data Platform Architecture:
Design and evolve our data platform's architecture for scalable, efficient data processing and analytics.
Participate in strategic planning for long-term alignment with business goals
Data Integration and Modeling
Implement robust, scalable data integration strategies.
Optimize data models for efficient storage, retrieval, and analytics.
Building ML Platform Ecosystem
Collaboratively develop a scalable, reliable ML platform, focusing on model serving, training, and essential MLOps features.
Prioritize efficiency, automation, and best practices in MLOps.
Workflow Automation
Develop automated solutions to enhance data operations.
Utilize Apache Airflow for effective data workflow management.
Continuous Learning and Improvement
Stay abreast of the latest data engineering trends and technologies.
Foster a culture of continuous learning and knowledge sharing.
Who you are
Concrete knowledge on Real-Time data processing (Apache Spark/Flink, Apache Beam)
Required Skills
Python
Expert in clean, efficient Python coding; proficient with data libraries and web frameworks
Skilled in asynchronous programming.
SQL: Strong in SQL syntax and query optimization.
Kafka:Proficient in Kafka architecture and stream processing.
ML Deployment / Optimization: Experienced in ML model deployment and MLOps principles.
Required Toolings
Spark/Flink (or any other framework): Experienced in distributed data processing
Apache Airflow: Expertise in workflow management.
FastAPI/Robyn: Skilled in FastAPI/Robyn development and features.
Git:Advanced knowledge in version control and CI/CD integration.
Cloud Services: AWS or similar cloud experience.
Data Visualization Tools: Proficient in tools like Streamlit.
Monitoring and Logging Tools: Experienced with tools like DataDog, Prometheus, and Grafana.
Nice to have skills
Terraform/Ansible: Skills in infrastructure automation.
Golang: Experience in Go programming and its ecosystem.
DBT: Proficient in DBT for data warehousing.
What we offer
A meaningful job with an impact on the way people consume fashion and promote sustainability
Flexible work possibilities
The opportunity to do career-defining work in a fast-growing French-born scale up
The possibility to work as part of a globally diverse team with more than 50 nationalities
Two days to help Project - reinforcing your activist journey and volunteer for an association
Significant investment in your learning and growth
Competitive compensation and benefits package
As full member of our entrepreneurial project, you will be eligible to free shares
Vestiaire Collective is an equal opportunities employer
Voir moins",
Principal Data Engineer,"{'name': 'OGURY', 'sector': 'Marketing / Communication, PublicitÃ©, AdTech / MarTech', 'employees': '521 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Ogury, the global leader in personified advertising, has created a breakthrough advertising engine that delivers comprehensive audience interests, brand performance, privacy protection and sustainability within one technology stack, built and optimised for mobile. Advertisers working with Ogury benefit from fully visible impactful ads, future-proof targeting and unwavering protection. Publishers enjoy the rewards of a respectful user experience, incremental revenues and premium demand with Oguryâ€™s solutions. Founded in 2014, Ogury is a global organisation with 500+ people, including 100 engineers across 16 countries.
About the Role
This is an exciting opportunity to shape the future of Oguryâ€™s data platform, make data available to all teams and enable them to take well-informed data-driven decisions.
The team worked hard in the past months to streamline and optimise our data load and transformation pipelines using Redshift, DBT, Airflow and CI tools (Jenkins). The next challenges ahead of us are:
- Near-real-time data reporting and analytics
- Enabling all engineering teams to load and transform their data
- Enforce the highest standards of data quality and reliability
All this at a truly large scale! Our data lake holds Petabytes of data and we ingest and transform several terabytes per day!
What you will be doing
Define the long-term vision and lead execution of Oguryâ€™s data platform
Be hands-on: build and maintain the data platform from the pipeline itself to the documentation, dictionary, and critical support processes
Identify, design and implement solutions for data processing and governance. Current key areas of improvements include: Near-real-time reporting, end-to-end data documentation and self-service analytics.
Mentor other data engineers, drive excellency and software craftsmanship within the team and across the organization
Evangelize data engineering and architecture best practices in the engineering team, building a data culture based on the highest quality and reliability standards
About you
A high level of professional experience as a Data Engineer, focusing on building scalable data solutions
Strong proficiency in Python and SQL
Significant experience with a cloud provider (AWS preferred)
A track record of building and leading the technical development of large-scale data platforms
Experience with Cloud Data Warehouses or OLAP engines (Redshift, Snowflake, Clickhouse, Ocient, et al)
Strong experience modelling data warehouses and building data pipelines
Experience with Kafka, Airflow and dbt
Team-player, curious, always eager to improve our current tools
A proven track record of mentoring and leading other team members, technically
Keen sense of data as a product and how it can serve the company
Proficiency in English, both written and spoken
#LI-HP1 #LI-Hybrid
Benefits vary by location but you can expect:
Competitive salary with a bonus, paid quarterly.
Health Insurance via Willis Towers Watson.
Flexible approach to working hours and location.
Keeping our Ogurians happy and healthy is a priority for us, so we offer access to both physical and mental health and wellbeing benefits.
Company family mutuelle.
25 days holiday plus an extra 10 days.
Look after your family with a life assurance plan.
Daily lunch voucher.
Modern and collaborative working space in central Paris.
CSE benefits.
At Ogury we are a group of creative thinkers and action-takers that thrive in a diverse and inclusive workplace.
Voir moins",
Stage Data Engineer (H/F/N) â€“ PARIS,"{'name': 'EKIMETRICS', 'sector': 'IT / Digital, StratÃ©gie, Audit, Big Data', 'employees': '400 collaborateurs', 'creation_year': '2006', 'turnover': None, 'mean_age': '29 ans'}",Stage,Paris,"1,8K â‚¬ par mois",TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
Ekimetrics est leader en data science et fournisseur de solutions AI. Depuis 2006, nous utilisons la data science au service de lâ€™optimisation de performance marketing, business et de la transition vers une performance plus durable.
Si vous Ãªtes passionnÃ©.e de data, ou de technologie en gÃ©nÃ©ral, et que vous avez envie dâ€™Ãªtre acteur.rice de votre avenir professionnel, votre place est sÃ»rement chez Ekimetrics !
ğŸ“Šâ€ŠEkimetrics, c'est:
Â· 400 expert.e.s en data science
Â· 1000 projets divers et variÃ©s pour plus de 350 clients
Â· 4 bureaux : Paris, Hong Kong, Londres et New York
Â· 1 milliard de $ de profits gÃ©nÃ©rÃ©s pour nos clients depuis 2006
Â· 7000 tonnes de CO2 Ã©vitÃ©es pour nos clients en 2022
ğŸŒ±Chez Ekimetrics, nous avons lâ€™ambition dâ€™accompagner nos clients Ã  repenser leur business model, en rÃ©conciliant performance Ã©conomique et objectifs durables, grÃ¢ce Ã  la data science.
Câ€™est pourquoi nous avons en interne toutes les compÃ©tences nous permettant de rÃ©pondre aux besoins de nos clients : Product Managers, Product Designers, Data Architects, Lead Tech, Data Engineers, DevOps Engineers, Data Scientists.
Vous rejoignez lâ€™Ã©quipe Data engineering composÃ©e de 30 personnes, dans un environnement de travail stimulant, et participez Ã  plusieurs projets autour de la data science.
Votre rÃ´le dans lâ€™Ã©quipeâ€¯:â€¯ 
En tant que Data Engineer, vous avez pour missions : 
Concevoir et industrialiser des pipelines de donnÃ©es 
DÃ©velopper avec des technologies et sur des plateformes data modernes 
Mettre en placedes processus de CI/CD 
Approfondir vos connaissances en Data Engineering et Data Science 
Participer aux activitÃ©s de R&D (Veille technologique, formations, animation de Meetups, etc.) 
Profil recherchÃ©â€¯: 
Bac+ 5 Ecole d'ingÃ©nieur ou Ã‰quivalent 
PremiÃ¨re expÃ©rience sur des sujets Data (Projet ou expÃ©rience professionnelle) 
ExpÃ©rience dans lâ€™industrialisation dâ€™algorithmes 
ExpÃ©rience dans un environnement Cloud 
Connaissances avancÃ©es en data engineering 
AppÃ©tence pour la Data Science. 
ğŸ¤ Pourquoi nous rejoindre ?
Rejoindre Ekimetrics, câ€™est intÃ©grer une entreprise dont les valeurs sâ€™appliquent au quotidien :
Â· Evoluer dans un environnement type start-up et non traditionnel (#curiositÃ©)
Â· ÃŠtre capable de prendre le feedback pour sâ€™amÃ©liorer (#excellence)
Â· Se former dÃ¨s son arrivÃ©e et en continu grÃ¢ce Ã  une expÃ©rience apprenante unique et riche de nombreuses ressources (internes, externes, live et digital) alliant savoirs techniques, savoir-Ãªtre et savoir-faire (#transmission)
Â· Faire partie dâ€™une Â« famille Â» soudÃ©e et unie (#plaisir)
Â· Imaginer des solutions inattendues & sortir de sa zone de confort (#crÃ©ativitÃ©)
En 2023, Ekimetrics a obtenu le statut dâ€™entreprise Ã  mission qui tÃ©moigne de notre ambition forte en matiÃ¨re de RSE. Nous sommes Ã©galement certifiÃ©s Great Place to Work.
ğŸ¤©â€ŠVous aurez accÃ¨s Ã  â€¦
Â· Au catalogue de formation EkiA qui contient des programmes qui vous feront monter en compÃ©tences sur nos solutions et nos mÃ©tiers, des parcours apprenants sur notre plateforme digitale ainsi que des programmes dÃ©diÃ©s Ã  nos enjeux prioritaires, dont la sensibilisation aux sujets environnementaux avec la Climate School AXA.
Â· Une vie sportive, artistique, musicale, ludique, caritative et engagÃ©e : de notre salle de sport privatisÃ©e Ã  nos expositions dâ€™art, en passant par des jeux vidÃ©o et des concerts, ou encore les dÃ©fis RSE sur la plateforme Vendredi ;
Â· De nombreux Ã©vÃ¨nements et sÃ©minaires pour rester proche de votre communautÃ© ;
Â· Des locaux modernes dans un quartier dynamique au cÅ“ur de Paris (Grands boulevards)
Â· Une politique de tÃ©lÃ©travail flexible.
ğŸ”„ Notre processus recrutement
ğŸ”¸ Un entretien RH
ğŸ”¸ Un entretien technique
ğŸ”¸ Un entretien final
Nous serions ravi.e.s de vous donner de plus amples informations lors dâ€™un entretien et attendons votre candidature avec impatience !
En tant quâ€™employeur, Ekimetrics offre Ã  tous les mÃªmes opportunitÃ©s dâ€™accÃ¨s Ã  lâ€™emploi sans distinction de genre, ethnicitÃ©, religion, orientation sexuelle, statut social, handicap et dâ€™Ã¢ge. Ekimetrics veille Ã  dÃ©velopper un environnement de travail inclusif qui reflÃ¨te la diversitÃ© dans ses Ã©quipes.
Voir moins",
Data Engineer - Banque Data Factory - Nantes,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Nantes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Description de lâ€™entreprise
Sopra Steria, lâ€™un des leaders europÃ©ens de la Tech reconnu pour ses activitÃ©s de conseil, de services numÃ©riques et dâ€™Ã©dition de logiciels, aide ses clients Ã  mener leur transformation digitale et Ã  obtenir des bÃ©nÃ©fices concrets et durables. Il apporte une rÃ©ponse globale aux enjeux de compÃ©titivitÃ© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs dâ€™activitÃ© et des technologies innovantes Ã  une approche rÃ©solument collaborative.
Sopra Steria place lâ€™humain au centre de son action et sâ€™engage auprÃ¨s de ses clients Ã  tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 50 000 collaborateurs dans prÃ¨s de 30 pays, le Groupe a rÃ©alisÃ© un chiffre dâ€™affaires de 5,1 milliards dâ€™euros en 2022.
The world is how we shape it.
Description du poste
Votre environnement de travail :
La division Â« Services Financiers Â» sâ€™est dÃ©veloppÃ©e autour des mÃ©tiers de la banque de dÃ©tail, de la banque privÃ©e et des services financiers spÃ©cialisÃ©s. Nous participons Ã  la rÃ©volution digitale grÃ¢ce Ã  notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compÃ©tences dans les domaines fonctionnels des CrÃ©dits, des Risques/ConformitÃ© et des Moyens de Paiement.
Si vous Ãªtes passionnÃ©(e) par la valorisation de la donnÃ©e, rejoignez notre Data Factory localisÃ©e Ã  Nantes et les quelques 100 Data IngÃ©nieurs qui la composent. Vous y rencontrerez des experts de la mise en Å“uvre de Plateforme de DonnÃ©es, des Data Architectes ou autres experts solution autour des problÃ©matiques de valorisation de la donnÃ©e.
Vous Ãªtes accompagnÃ©(e) au dÃ©veloppement de vos connaissances aux travers de diffÃ©rents parcours Data que ce soit pour lâ€™ingestion, la construction de datahub, la transformation et valorisation de la donnÃ©e, la modÃ©lisation et mise Ã  disposition.
Rejoindre la Data Factory Sopra Steria, câ€™est rejoindre une communautÃ© de Data IngÃ©nieurs fiers de partager leur savoir et ouverts aux nouvelles expÃ©riences et expÃ©rimentations de la donnÃ©e.
Votre rÃ´le et vos missions :
Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expÃ©rience et votre appÃ©tence pour lâ€™un de nos chapitres Data ci-dessous, vous participez Ã  :
La comprÃ©hension des besoins mÃ©tiers et la traduction solution de data ingÃ©nierie et ou data analysis ;
La mise en Å“uvre de solution dâ€™ingestion des donnÃ©es quelles soit en batch et/ou en streaming dans un contexte Cloud ;
La structuration du DataLake, la mise en place des processus de gouvernance et de sÃ©curisation des donnÃ©es ;
Le traitement de la donnÃ©e jusquâ€™Ã  lâ€™exposition au mÃ©tier ;
La mise en place de la chaine CI/CD et de sa supervision ;
La veille technologie avec nos partenaires Ã©diteurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif dâ€™idÃ©ation pour nos clients.
Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, R
Qualifications
Votre profil :
DiplÃ´mÃ©(e) dâ€™une Ecole dâ€™ingÃ©nieur ou formation Ã©quivalente, vous avez dÃ©jÃ  participÃ© Ã  un projet Data (Big Data, BI) et vous avez une expÃ©rience de minimum 2 ans.
Vous accordez une importance particuliÃ¨re au dÃ©veloppement de vos compÃ©tences sur plusieurs technologies. Vous souhaitez une Ã©volution rÃ©elle de carriÃ¨re Ã  travers lâ€™expÃ©rience projet. Vous Ãªtes soucieux de lâ€™apport de valeur pour vos clients. Et vous voulez transmettre votre savoir auprÃ¨s de collaborateurs moins expÃ©rimentÃ©s. Alors, nâ€™attendez-plus, ce poste est fait pour vous !
Informations supplÃ©mentaires
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressant : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 30 familles de mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de sâ€™engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â».
Lâ€™opportunitÃ© de rejoindre le collectif Techâ€™Me UP (formations, confÃ©rences, veille, et bien plus encoreâ€¦).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
Voir moins",
Alternance DATA ENGINEER (H/F),"{'name': 'LINEUP7', 'sector': 'Digital Marketing / Data Marketing, Big Data, Digital', 'employees': '90 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}","Alternance
(12 Ã  24 mois)","Salaire :
Non spÃ©cifiÃ©","DÃ©but :
02 septembre 2024",TÃ©lÃ©travail occasionnel,,,,,
DATA ENGINEER - H/F,"{'name': 'BANQUE DE FRANCE', 'sector': 'Banque, Assurance', 'employees': '9103 collaborateurs', 'creation_year': '1800', 'turnover': None, 'mean_age': None}",Stage,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 6 mois,,"Descriptif du poste
Dans le cadre de son plan de travail sur l'Intelligence Artificielle, le Lab propose un stage afin de dÃ©velopper et de concrÃ©tiser les sujets suivants :
Maintenance de scraping de sites avec lâ€™IA (Ã©valuer si Ã  partir de scraping existant, lâ€™IA pourrait corriger les erreurs liÃ©es aux Ã©volutions des sites scrapÃ©s.)
Ã‰valuation du produit Giskard (framework pour tester les modÃ¨les LLM)
Gestion des CRA (Comptes Rendus dâ€™ActivitÃ©s) des prestataires (traitement Ã  base de OCR les CRA transmis par les prestataires, contrÃ´le sur les consommations, voir la possibilitÃ© de faire des traitements IA)","Profil recherchÃ©
Formation recherchÃ©e : 
Master (1 ou 2) Data Engineer, Data Scientist
Master (1 ou 2) IngÃ©nierie des systÃ¨mes numÃ©riques
CompÃ©tences : 
Technologie: IA, IA GÃ©nÃ©rative
outils de gestion/analyse de la data: PowerBI ou autres
Langages de programmation: Python, ReactJS, Java
Environnements: Cloud, Docker, Git
QualitÃ©s : 
Capable de travailler Ã  la fois en autonomie et en Ã©quipe.
Force de proposition dans son domaine d'expertise
Une trÃ¨s bonne communication autant Ã  l'Ã©crit qu'Ã  l'oral
  Contactez nos ambassadeurs 
Voir plus"
Data Engineer - F/H,"{'name': 'LYDIA', 'sector': 'Application mobile, Banque', 'employees': '220 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '27 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Created in 2013, Lydia quickly became the reference for payment between friends. The French fintech has gained great notoriety for this feature and now has more than 7 million users.In recent years, Lydia has developed other services - pot, current account, common account, savings, credit, investment... to become the daily and complete payment application for millions of French people.
With 250 employees based in Paris, Nantes, Bordeaux and Lyon, Lydia has set itself the task of changing the codes of the bank by offering all the essential services to manage your money on a daily basis through a simple, accessible and enjoyable customer experience.
We are now looking for an experienced Data Engineer to consolidate and improve our GCP Data stack.
What you will do:
Maintain and consolidate our ELT pipeline (Airflow, BigQuery, DBT, PubSub, Dataflow)
Standardize the design of our Kubernetes apps for APIs, leading initiatives for improved monitoring, instrumentation, and state-of-the-art continuous deployment
Standardize tooling across Lydiaâ€™s ML landscape, with a focus on MLOps for training and monitoring
Rigorously enforce and audit our GDPR landscape
Collaborate with Analytics Engineers and Data Scientists to support and facilitate their goals
Improve the test culture for both our BI and ML stacks
You are in the right place if:
You hold a Masterâ€™s degree in Computer Science or Engineering
You have at least three years of experience as a Data Engineer or backend engineer, preferably in a start-up environment
You are proficient in SQL and Python
You have strong analytical skills and a problem-solving mindset
You are a team player with a marked ability to start and lead new projects independently
You have excellent written and spoken communication skills in English
Recruitment Process:
Phone interview with our Talent Acquisition Recruiter
Home-assignment: technical and analytical test
Physical Interview with a Tech Lead
Video interview for debriefing

* Job is opened to Lydiaâ€™s Paris French office

At Lydia, we believe that diversity is a strength. Diversity is part of our culture and identity. We want to create an inclusive culture where all forms of diversity are seen as a real value to the company. Lydia is therefore proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, colour, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, physical characteristics (size, weight ... ).age, status as an individual with a disability, genetic information, or other applicable legally protected characteristics.
Voir moins",
Senior Data Engineer F/H,"{'name': 'ECO COMPTEUR', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, Electronique / TÃ©lÃ©communications', 'employees': '150 collaborateurs', 'creation_year': '2000', 'turnover': None, 'mean_age': '38 ans'}",CDI,Lannion,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 7 ans,Bac +5 / Master,"Descriptif du poste
Toi aussi tu veux avoir un impact dans la transformation des villes de demain et participer au dÃ©veloppement du tourisme durable ? Rejoins-nous et deviens acteur dans le dÃ©veloppement des villes intelligentes et la prÃ©servation des espaces naturels !
ğŸš²Chez Eco Compteur, nous accompagnons les villes dans leur transition vers le dÃ©veloppement des mobilitÃ©s douces et aidons Ã  la prÃ©servation des plus beaux sites naturels du monde !
Lâ€™objectif ? Donner aux gestionnaires dâ€™espaces naturels et aux villes des donnÃ©es de frÃ©quentation terrain fiables pour les aider Ã  prendre des dÃ©cisions objectives : Â« Faut-il pÃ©renniser cette piste cyclable temporaire ? Faut-il moduler le nombre de visiteurs pour prÃ©server ce site naturel protÃ©gÃ© ? Â»
Depuis plus de 20 ans, nous proposons des solutions de comptage connectÃ©es de piÃ©tons et cyclistes en environnement urbain et naturel. Solutions qui vont des capteurs installÃ©s sur les pistes cyclables et les sentiers de randonnÃ©es aux logiciels dâ€™interprÃ©tation des donnÃ©es, parce que compter câ€™est bien mais donner du sens aux chiffres câ€™est encore mieux !
FocalisÃ©s sur lâ€™innovation et lâ€™international, nous sommes leader mondial dâ€™un mÃ©tier que nous avons crÃ©Ã© ! ğŸ’ª
ImplantÃ© en Bretagne avec des filiales au Canada, en Allemagne et Ã  ShangaÃ¯, Eco Compteur est aussi prÃ©sent dans plus de 55 pays. Câ€™est aussi et surtout une entreprise de taille humaine oÃ¹ chacun partage une vision et des valeurs : autonomie, responsabilitÃ© & transparence avec beaucoup de passion et de plaisir !
Nous sommes aujourdâ€™hui Ã  la recherche de notre prochain talent :
SENIOR DATA ENGINEER - LANNION/ RENNES - CDI
En tant que Data Engineer chez Eco-Compteur, tu Ã©volueras dans le cercle (Ã©quipe) R&D Software et tu travailleras en Ã©troite collaboration avec le cercle Data. Tu dÃ©velopperas des solutions innovantes qui permettront Ã  nos clients une comprÃ©hension plus qualitative de la frÃ©quentation et des dÃ©placements sur leur territoire.
âœï¸Tes rÃ´les :
Participer Ã  la dÃ©finition dâ€™une architecture optimale pour :
les chaÃ®nes de traitement de donnÃ©es
lâ€™extraction, la transformation et le chargement (ETL) de donnÃ©es Ã  partir de multiples sources.
Collaborer avec des experts data (data scientist, gÃ©omaticien) Ã  lâ€™intÃ©gration de nouvelles donnÃ©es dans nos solutions
DÃ©velopper, maintenir et industrialiser les flux dâ€™intÃ©gration de donnÃ©es et les chaÃ®nes de traitement associÃ©s
Structurer et stocker la donnÃ©e en veillant Ã  sa qualitÃ©
Assurer lâ€™accÃ¨s aux donnÃ©es afin dâ€™exploiter les donnÃ©es dans nos solutions
Ce que lâ€™on te met Ã  disposition :
Un onboarding ultra complet qui te permettra dâ€™avoir une vision 360 de lâ€™entreprise
Des outils performants qui permettront dâ€™exprimer pleinement tes talents
Une Ã©quipe de passionnÃ©s qui travaillera Ã  tes cÃ´tÃ©s
Voir moins","Profil recherchÃ©
ğŸ‘‰Et si câ€™Ã©tait toi ?
On a besoin que tu apportes ton expertise, ton expÃ©rience : Tu possÃ¨des donc au moins 5 annÃ©es dâ€™expÃ©rience sur un poste similaire (et surtout de l'expÃ©rience en Big Data). 
Tu as des compÃ©tences dans lâ€™environnement technique suivant :
Langages: Java, Kotlin, Python, SQL, No SQL
DonnÃ©es: MySQL, PostgreSQL, Elasticsearch, Object storage (S3)
Traitement: Apache Airflow, Apache Kafka, Apache Spark
Visualisation : Tableau Software
Et comme on est jamais trop exigent, tu parles couramment Anglais (Interactions avec nos Ã©quipes et clients internationaux). 
Ton petit plus Ã  toi ? Une expÃ©rience sur les plateformes Cloud (AWS, GCP, Azure), ou bien sur du traitement de donnÃ©es et visualisation SIG. 
TES QUALITÃ‰S
Tu es autonome, force de proposition et tu prends souvent des initiatives 
Tu sais analyser les problÃ¨mes, Ãªtre critique et constructif pour les rÃ©soudre
Voir plus"
Data Engineer Collecting and decoding of data for Fleet Data Engineering F/H,"{'name': 'SAFRAN AIRCRAFT ENGINES', 'sector': 'AÃ©ronautique / Spatiale', 'employees': '16400 collaborateurs', 'creation_year': '1945', 'turnover': '9,1â‚¬ milliard', 'mean_age': None}",CDI,Ã‰vry-Courcouronnes,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous souhaitez mettre vos talents au service de la transformation digitale ?

La direction Engineering du support et des Services souhaite dynamiser sa transformation digitale via ce poste renforcer l'Ã©quipe en charge de processus de collect et decodage des donnÃ©es de vols des avions.

Les donnÃ©es d'exploitation (donnÃ©es de vol, de health monitoring et de fiabilitÃ©) jouent un rÃ´le de plus en plus important dans la gestion des flottes clients. Les Ã©quipes du support technique ont ainsi besoin d'outils de plus en plus performant pour leur faciliter l'accÃ¨s et l'analyse de ces informations.

Au sein du dÃ©partement Fleet Data Engineering, dans l'unitÃ© Advanced Monitoring Systems, le data Engineer assura les fonctions suivantes :

* Specifier le besoin des Ã©volutions des outils de collecte et de dÃ©codage dont vous avez le perimÃ¨tre avec les key user.
* Capter les besoins d'Ã©volution Ã  venir , maintenir le backlog des besoins sur les outils .
* Piloter le dÃ©veloppement des Ã©volutions avec les integrateurs, en Ã©troite collaboration avec les acteurs de la DSI
* Communiquer sur les Ã©volutions des outils auprÃ¨s des utilisateurs
- RÃ©aliser/faire rÃ©aliser la validation/ recette mÃ©tier des Ã©volutions
* RÃ©alisation des dashboard ( Power Bi, Python) suivant les besoins des utilisateurs.
* Capable de dÃ©velopper en Phyton/ devOps pour protypage rapide
- Connaissances globale du fonctionnement d'un moteur type LEAP/ CFM ainsi que les processus de service autour de support moteur seraient apprÃ©ciÃ©es.
Voir moins","Profil recherchÃ©
* Vous avez dÃ©jÃ  une expÃ©rience en developpment de solution IT
* Bonne connaissance dans le management de projet IT avec la mÃ©thodologie Agile
- Sens de l'innovation
* Sens du client
* CapacitÃ© de synthÃ¨se et communication efficace
* Pratique des outils bureautiques courants
- Pratique de l'anglais indispensable
* Pratique de langage de programmation usuel (python, VBA)
* ComptÃ©tence en PowerBI et base de donnÃ©e SQL serait apprÃ©ciÃ©
* Une bonne connaissance des mÃ©tiers et processus du support et services des moteurs civils serait apprÃ©ciÃ©e
* Connaissance des donnÃ©es de Vols( ACMS, EEC) serait apprÃ©ciÃ©
* Vous Ãªtes reconnu pour votre ouverture d'esprit et votre bon relationnel."
Data Engineer,"{'name': 'BLACK TIGER', 'sector': 'Logiciels, Digital Marketing / Data Marketing, Big Data', 'employees': '158 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Au sein des Ã©quipes de dÃ©veloppement de Black Tiger, Ã©diteur spÃ©cialisÃ© dans le traitement des donnÃ©es personnelles, lâ€™Ã©quipe de data engineering / intÃ©gration a pour mission de rÃ©pondre aux besoins exprimÃ©s par nos clients pour faire face Ã  leurs enjeux de Big Data. 
En rejoignant cette Ã©quipe en tant que Data Engineer, tu as la responsabilitÃ© de la mise en Å“uvre (paramÃ©trage, dÃ©veloppements spÃ©cifiques et dÃ©ploiement) des briques logicielles de notre plateforme. Câ€™est un poste Ã  multiples facettes techniques (conception, modÃ©lisation et dÃ©veloppement ; ops pour le dÃ©ploiement ; implication dans la R&D de lâ€™entreprise et dans les choix dâ€™architecture et de technos) oÃ¹ tu te confronteras Ã  de rÃ©els challenges techniques.
La stack est variÃ©e et sâ€™articule, en plus des briques logicielles dÃ©veloppÃ©es en interne, autour des technologies suivantes :  Spark/Scala, Python, MongoDB, Elasticsearch, Docker, Kafkaâ€¦","Profil recherchÃ©
- Tu es titulaire dâ€™un bac+5 en Data Engineering, Data Science, DÃ©veloppement informatique pour la Big Data ou Ã©quivalent ;
- Tu justifies de 3 annÃ©es dâ€™expÃ©rience ou plus en tant que Cloud / Data Engineer ;
- Tu maÃ®trises maÃ®trisez Spark/Scala, MongoDB et la modÃ©lisation orientÃ©e objet (UML) ;
- Tu as de lâ€™expÃ©rience dans la mise en place de flux ETL et de bonnes connaissances en ingÃ©nierie logicielle (devops, CI/CD, tests automatisÃ©s).
Nous recherchons des personnes qui sont sensibles aux enjeux Big Data, avec une appÃ©tence tant pour le dÃ©veloppement que pour lâ€™analyse fonctionnelle et lâ€™optimisation des performances. Il faut avoir envie de challenges techniques. Rigueur, curiositÃ© et agilitÃ© requises !
Et on apprÃ©cie les gens sÃ©rieux qui ne se prennent pas au sÃ©rieux ;)"
IngÃ©nieur Data SÃ©nior / Lead Data engineer F/H,"{'name': 'DIRECTION DU NUMÃ‰RIQUE DES MINISTÃˆRES SOCIAUX', 'sector': 'Logiciels, Administration publique', 'employees': '240 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '45 ans'}","CDD / Temporaire
(36 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,01 fÃ©vrier 2024,> 5 ans,Bac +5 / Master,"Descriptif du poste
Le Data Office de la DNUM recherche un(une) IngÃ©nieur des DonnÃ©es SÃ©nior pour accompagner techniquement et opÃ©rationnellement lâ€™Ã©quipe Data (Data Product Owner, DevOps, Data Engineer, Data Analystes, MLOps â€¦) et travailler Ã©troitement avec les Ã©quipes dâ€™infrastructures pour le dÃ©veloppement des projets innovants.
Disposant dâ€™une solide connaissance des technologies et pratiques de valorisation des donnÃ©es, dotÃ© dâ€™une hauteur de vue avec un gout pour la mise en Å“uvre opÃ©rationnelle, vous faites les choix techniques les plus adaptÃ©s en fonction des besoins identifiÃ©s.
Vos missions sont :
- Contribuer, avec les Ã©quipes du Data Office, Ã  la conception dâ€™un environnement industriel complet dÃ©diÃ© Ã  la fabrication des produits de donnÃ©es,
- ImplÃ©menter des flux de collecte, de transformation et de stockage des donnÃ©es multi- sources
- Concevoir des dispositifs pour nettoyer, transformer et valider les donnÃ©es,
- Assister les Ã©quipes de conception de produits,
- Assurer la mise en production des produits de donnÃ©es
En tant quâ€™expert reconnu de votre domaine, vous avez volontÃ© dâ€™Ã©largir vos responsabilitÃ©s, dâ€™apporter une contribution plus stratÃ©gique et globale aux projets de donnÃ©es, et de continuer Ã  Ã©voluer vers des fonctions dâ€™architecte des donnÃ©es.
Voir moins","Profil recherchÃ©
- Vous possÃ©dez au minimum 5 ans dâ€™expÃ©rience professionnelle dans le domaine et avez contribuÃ© au dÃ©ploiement dâ€™une chaine CICD fortement automatisÃ©e, idÃ©alement dans un contexte de cloud public de type OVH,
- ÃŠtre membre actif dâ€™une communautÃ© en lien avec les technologies du numÃ©riques serait un plus.
CompÃ©tences techniques:
- Maitrise des aspects dâ€™authentification, de sÃ©curitÃ©, de containerisation et dâ€™orchestration,
- MaÃ®trise des entrepÃ´ts de donnÃ©es notamment dans un contexte Cloud type OVH,
- Maitrise de plusieurs technologies parmi : PostgreSql, Elastic Search, Spark, Talend, Kubernetes, Docker,
- Bonne connaissance avec la programmation en SQL, Python, JavaScript et les outils de Dataviz (Power BI, DigDash),
- FamiliarisÃ© avec les principes de la virtualisation.
CompÃ©tences fonctionnelles:
- Maitrise du dÃ©veloppement de produit data en mÃ©thode agile,
- Acculturation aux principes et rÃ¨gles de la gouvernance des donnÃ©es,
Voir plus"
IngÃ©nieur Data Engineer (F/H),"{'name': 'THALES', 'sector': 'Logiciels, CybersÃ©curitÃ©, AÃ©ronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mdsâ‚¬', 'mean_age': None}",CDI,VÃ©lizy-Villacoublay,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Au sein du site de VÃ©lizy, nos Ã©quipes hautement qualifiÃ©es conÃ§oivent et produisent des amplificateurs de puissance (tubes Ã  ondes progressives, klystrons, gyrotrons, sous-systÃ¨mes pour les Grandes Infrastructures de Recherche, etc.) Ã  destination des marchÃ©s DÃ©fense, SÃ©curitÃ©, Spatial et Scientifique. Chaque jour nos cadres, ingÃ©nieurs, techniciens et opÃ©rateurs mettent en commun leurs savoir-faire unique au service de lâ€™innovation.
QUI SOMMES-NOUS ?
 Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs prÃ©sents sur tous les continents. Le Groupe investit dans les innovations du numÃ©rique et de la Â« deep tech Â» â€“ big data, intelligence artificielle, connectivitÃ©, cybersÃ©curitÃ© et quantique â€“ pour construire un avenir de confiance, essentiel au dÃ©veloppement de nos sociÃ©tÃ©s, en plaÃ§ant lâ€™humain au cÅ“ur des dÃ©cisions.
Thales propose des solutions, services et produits qui aident ses clients â€“ entreprises, organisations, Etats â€“ dans cinq grands marchÃ©s vitaux pour le fonctionnement de nos sociÃ©tÃ©s : identitÃ© et sÃ©curitÃ© numÃ©riques, dÃ©fense, aÃ©ronautique, espace, et transport.
 QUI ETES-VOUS ?
 DiplÃ´mÃ© dâ€™un Bac+5 en Ã©cole dâ€™ingÃ©nieur ou Ã©quivalent universitaire avec une spÃ©cialisation en informatique, vous avez au moins 3 ans d'expÃ©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
 En tant que Data Engineer, vous jouerez un rÃ´le clÃ© dans la conception, le dÃ©veloppement et la maintenance de notre infrastructure de donnÃ©es, ainsi que dans la transformation et la gestion des flux de donnÃ©es.
 VOS MISSIONS :
 â€¢ Concevoir, dÃ©velopper et dÃ©ployer des solutions Big Data en utilisant les technologies Hadoop.
 â€¢ Mettre en place des pipelines de donnÃ©es performants pour l'ingestion, le traitement et le stockage des donnÃ©es massives.
 â€¢ Collaborer Ã©troitement avec les Ã©quipes mÃ©tier pour comprendre leurs besoins en matiÃ¨re d'analyse de donnÃ©es et proposer des solutions adaptÃ©es.
 â€¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donnÃ©es.
 â€¢ Assurer la qualitÃ© et la fiabilitÃ© des donnÃ©es traitÃ©es, en mettant en place des processus de validation et de nettoyage.
 â€¢ Identifier et rÃ©soudre les problÃ¨mes liÃ©s Ã  l'infrastructure Big Data et proposer des amÃ©liorations.
 â€¢ Travailler en Ã©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents Ã  partir des donnÃ©es.
  Innovation, passion, ambition : rejoignez Thales et crÃ©ez le monde de demain, dÃ¨s aujourdâ€™hui.
Innovation, passion, ambition : rejoignez Thales et crÃ©ez le monde de demain, dÃ¨s aujourdâ€™hui.
Voir moins",
Data Engineer (H/F),"{'name': 'THALES', 'sector': 'Logiciels, CybersÃ©curitÃ©, AÃ©ronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mdsâ‚¬', 'mean_age': None}",CDI,Sophia-Antipolis,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Thales propose des systÃ¨mes dâ€™information et de communication sÃ©curisÃ©s et interopÃ©rables pour les forces armÃ©es, les forces de sÃ©curitÃ© et les opÃ©rateurs dâ€™importance vitale. Ces activitÃ©s, qui regroupent radiocommunications, rÃ©seaux, systÃ¨mes de protection, systÃ¨mes dâ€™information critiques et cybersÃ©curitÃ©, rÃ©pondent aux besoins de marchÃ©s oÃ¹ lâ€™utilisation des nouvelles technologies numÃ©riques est dÃ©terminante. Thales intervient tout au long de la chaÃ®ne de valeur, des Ã©quipements aux systÃ¨mes en passant par le soutien logistique et les services associÃ©s.Nos Ã©quipes de lâ€™activitÃ© SystÃ¨mes dâ€™information critiques et cybersÃ©curitÃ© fournissent des services et des solutions globales optimisant la performance, la rÃ©silience et la sÃ©curitÃ© des systÃ¨mes dâ€™information afin de faire face aux ruptures technologiques et aux cybermenaces.
Le dÃ©partement IA & Big Data recherche plusieurs Data Engineers (H/F) basÃ©s Ã  Sophia Antipolis (06).
QUI ETES-VOUS ?
De formation Bac+4 ou Bac +5 (type Ã©cole dâ€™ingÃ©nieur), vous possÃ©dez de bonnes connaissances dans le domaine de la donnÃ©e (Data Science, Data Engineering, Stockage), en ingÃ©nierie logicielle globalement.
Une connaissance cloud serait un rÃ©el atout, quâ€™il soit public (AWS, GCP, AZURE) ou privÃ©.
Les principales activitÃ©s que vous rÃ©aliserez sont les suivantes :
Mise en place de pipelines de traitement de donnÃ©es
Utilisation de lâ€™Ã©tat de lâ€™art des technologies actuelles dÃ©diÃ©es Ã  ces activitÃ©s : Kafka / Spark / Spark Streaming / Flink / Storm
DÃ©veloppement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie)
Utilisation de tous les types de stockage actuels : 
SQL : Oracle, SQLServer, PostgreSQL
NoSQL : Cassandra / MongoDB / HBase
Objet : S3 / MinIO
Vous avez de bonnes expÃ©riences en dÃ©veloppement logiciel et/ou scripting (principalement Scala & Java).
Vous Ãªtes Ã  lâ€™aise en Anglais.
Vous Ãªtes curieux et rigoureux.
Vous aimez travailler en Ã©quipe au quotidien, pour vous le succÃ¨s nâ€™est que collectif.
Vous vous reconnaissez ? Alors parlons missions â€¦
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
Le dÃ©partement IA & Big Data fÃ©dÃ¨re et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers dâ€™une structure permettant dâ€™accÃ©lÃ©rer la transformation des enjeux Data de nos clients.
Nos savoir-faire :
Big Data, Intelligence Artificielle, Algorithmie, Expertise Imagerie
Projets dâ€™intÃ©gration systÃ¨me
Nos domaines mÃ©tier :
Maintenance prÃ©dictive, Traitement dâ€™image pour la santÃ©
Archivage certifiant, Gestion de contenu, Analyse risque et optimisation de rÃ©ponse
Aerospace : Centre de Mission et de ContrÃ´le, Dynamique du Vol, QualitÃ© Image, Occupation des sols, Sondage AtmosphÃ©rique
Nos partenaires :
Recherche : INRIA, CNRS, 3IA
Externes : Nvidia, Microsoft
En collaboration avec les membres de notre dÃ©partement :
Vous contribuerez au dÃ©veloppement et Ã  la scalabilitÃ© de nos plateformes au travers dâ€™activitÃ©s dâ€™automatisation, de crÃ©ation de services managÃ©s et dâ€™API.
Vous accompagnerez nos clients dans leurs projets de valorisation de donnÃ©es en proposant des solutions techniques et fonctionnelles, Ã©valuÃ©es, choisies et opportunes.
Vous participerez Ã  lâ€™intÃ©gration des plateformes techniques sÃ©curisÃ©es dÃ©veloppÃ©es par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com)
Vous collaborerez Ã  nos publications, confÃ©rences et webinars.
Vous serez partie prenante de la 3Ã¨me rÃ©volution industrielle impactant tous les secteurs dâ€™activitÃ©, Ã©nergie, santÃ©, industrie, â€¦
La perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant Ã  cette offre.
Innovation, passion, ambition : rejoignez Thales et crÃ©ez le monde de demain, dÃ¨s aujourdâ€™hui.
Voir moins",
Data Engineer F/H,"{'name': 'THALES', 'sector': 'Logiciels, CybersÃ©curitÃ©, AÃ©ronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mdsâ‚¬', 'mean_age': None}",CDI,VÃ©lizy Villacoublay,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Thales propose des systÃ¨mes dâ€™information et de communication sÃ©curisÃ©s et interopÃ©rables pour les forces armÃ©es, les forces de sÃ©curitÃ© et les opÃ©rateurs dâ€™importance vitale. Ces activitÃ©s, qui regroupent radiocommunications, rÃ©seaux, systÃ¨mes de protection, systÃ¨mes dâ€™information critiques et cybersÃ©curitÃ©, rÃ©pondent aux besoins de marchÃ©s oÃ¹ lâ€™utilisation des nouvelles technologies numÃ©riques est dÃ©terminante. Thales intervient tout au long de la chaÃ®ne de valeur, des Ã©quipements aux systÃ¨mes en passant par le soutien logistique et les services associÃ©s.Sur le site de VÃ©lizy, les Ã©quipes dÃ©veloppent et installent des systÃ¨mes dâ€™information de commandement et de renseignement, systÃ¨mes de sÃ©curitÃ© nationale et solutions de sÃ©curitÃ© pour les villes, les Ã‰tats et les infrastructures critiques, ainsi que des systÃ¨mes dâ€™information critiques et de cyber sÃ©curitÃ©.
QUI ETES-VOUS ?
DiplÃ´mÃ©.e d'un Bac +5 et/ou Ã©cole d'ingÃ©nieur orientÃ© IT/data, vous disposez d'une expÃ©rience d'au moins 3 ans sur un poste similaire.Vous Ãªtes Ã  l'aise avec les technologies Python et Jupyter,
Vous maitrisez les bases de donnÃ©es S3 et Cassandra,
Vous avez une comprÃ©hension des processus et des technologies de data virtualisation via Superset, Grafana, etc.CE QUE NOUS POUVONS FAIRE ENSEMBLE :Au sein de la JV ATHEA, vous gÃ©rez les activitÃ©s de data engineer pour participer au dÃ©veloppement de diffÃ©rents Cas dâ€™Usage de plateforme Artemis, dans ses diffÃ©rentes configurations, et aux formations associÃ©es dans lâ€™Ã©quipe qui gÃ¨re et faire Ã©voluer la Solution.
A ce titre, vos principales missions sont
- Participer aux dÃ©veloppements techniques de transformation de donnÃ©es par lâ€™utilisation des technologies de transformation de donnÃ©es dÃ©ployÃ©es dans le cadre du programme ; utilisation de Python, Jupyter.
- Encadrer les formations des Ã©quipes sur les fonctionnalitÃ©s
- Gestion de base de donnÃ©es
Si cette offre vous correspond, n'hÃ©sitez pas Ã  postuler,
Le poste pouvant nÃ©cessiter d'accÃ©der Ã  des informations relevant du secret de la dÃ©fense nationale, la personne retenue fera l'objet d'une procÃ©dure dâ€™habilitation, conformÃ©ment aux dispositions des articles R.2311-1 et suivants du Code de la dÃ©fense et de lâ€™IGI 1300 SGDSN/PSE du 09 aoÃ»t 2021.
Innovation, passion, ambition : rejoignez Thales et crÃ©ez le monde de demain, dÃ¨s aujourdâ€™hui.
Voir moins",
Data Engineer (F/H),"{'name': 'THALES', 'sector': 'Logiciels, CybersÃ©curitÃ©, AÃ©ronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mdsâ‚¬', 'mean_age': None}",CDI,VÃ©lizy-Villacoublay,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Au sein du site de VÃ©lizy, nos Ã©quipes hautement qualifiÃ©es conÃ§oivent et produisent des amplificateurs de puissance (tubes Ã  ondes progressives, klystrons, gyrotrons, sous-systÃ¨mes pour les Grandes Infrastructures de Recherche, etc.) Ã  destination des marchÃ©s DÃ©fense, SÃ©curitÃ©, Spatial et Scientifique. Chaque jour nos cadres, ingÃ©nieurs, techniciens et opÃ©rateurs mettent en commun leurs savoir-faire unique au service de lâ€™innovation.Description de l'emploi
QUI SOMMES-NOUS ?
 Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs prÃ©sents sur tous les continents. Le Groupe investit dans les innovations du numÃ©rique et de la Â« deep tech Â» â€“ big data, intelligence artificielle, connectivitÃ©, cybersÃ©curitÃ© et quantique â€“ pour construire un avenir de confiance, essentiel au dÃ©veloppement de nos sociÃ©tÃ©s, en plaÃ§ant lâ€™humain au cÅ“ur des dÃ©cisions.
Thales propose des solutions, services et produits qui aident ses clients â€“ entreprises, organisations, Etats â€“ dans cinq grands marchÃ©s vitaux pour le fonctionnement de nos sociÃ©tÃ©s : identitÃ© et sÃ©curitÃ© numÃ©riques, dÃ©fense, aÃ©ronautique, espace, et transport.
 QUI ETES-VOUS ?
 DiplÃ´mÃ© dâ€™un Bac+5 en Ã©cole dâ€™ingÃ©nieur ou Ã©quivalent universitaire avec une spÃ©cialisation en informatique, vous avez au moins 3 ans d'expÃ©rience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
 En tant que Data Engineer, vous jouerez un rÃ´le clÃ© dans la conception, le dÃ©veloppement et la maintenance de notre infrastructure de donnÃ©es, ainsi que dans la transformation et la gestion des flux de donnÃ©es.
 VOS MISSIONS :
 â€¢ Concevoir, dÃ©velopper et dÃ©ployer des solutions Big Data en utilisant les technologies Hadoop.
 â€¢ Mettre en place des pipelines de donnÃ©es performants pour l'ingestion, le traitement et le stockage des donnÃ©es massives.
 â€¢ Collaborer Ã©troitement avec les Ã©quipes mÃ©tier pour comprendre leurs besoins en matiÃ¨re d'analyse de donnÃ©es et proposer des solutions adaptÃ©es.
 â€¢ Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des donnÃ©es.
 â€¢ Assurer la qualitÃ© et la fiabilitÃ© des donnÃ©es traitÃ©es, en mettant en place des processus de validation et de nettoyage.
 â€¢ Identifier et rÃ©soudre les problÃ¨mes liÃ©s Ã  l'infrastructure Big Data et proposer des amÃ©liorations.
 â€¢ Travailler en Ã©troite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents Ã  partir des donnÃ©es.
  Innovation, passion, ambition : rejoignez Thales et crÃ©ez le monde de demain, dÃ¨s aujourdâ€™hui.
Innovation, passion, ambition : rejoignez Thales et crÃ©ez le monde de demain, dÃ¨s aujourdâ€™hui.
Voir moins",
Data Engineer (secteur aÃ©rien) - H/F,"{'name': 'THALES', 'sector': 'Logiciels, CybersÃ©curitÃ©, AÃ©ronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mdsâ‚¬', 'mean_age': None}",CDI,Sophia-Antipolis,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Thales propose des systÃ¨mes dâ€™information et de communication sÃ©curisÃ©s et interopÃ©rables pour les forces armÃ©es, les forces de sÃ©curitÃ© et les opÃ©rateurs dâ€™importance vitale. Ces activitÃ©s, qui regroupent radiocommunications, rÃ©seaux, systÃ¨mes de protection, systÃ¨mes dâ€™information critiques et cybersÃ©curitÃ©, rÃ©pondent aux besoins de marchÃ©s oÃ¹ lâ€™utilisation des nouvelles technologies numÃ©riques est dÃ©terminante. Thales intervient tout au long de la chaÃ®ne de valeur, des Ã©quipements aux systÃ¨mes en passant par le soutien logistique et les services associÃ©s.Nos Ã©quipes de lâ€™activitÃ© SystÃ¨mes dâ€™information critiques et cybersÃ©curitÃ© fournissent des services et des solutions globales optimisant la performance, la rÃ©silience et la sÃ©curitÃ© des systÃ¨mes dâ€™information afin de faire face aux ruptures technologiques et aux cybermenaces.
QUI ETES-VOUS ? 
PROFIL ET COMPETENCES:
De formation Bac +5 (type Ã©cole dâ€™ingÃ©nieur), vous possÃ©dez de bonnes connaissances dans le domaine de la donnÃ©e (Data Science, Data engineering, Stockage), en ingÃ©nierie logicielle globalement. Une connaissance cloud serait un rÃ©el atout, quâ€™il soit public (AWS, GCP, de prÃ©fÃ©rence AZURE) ou privÃ©.
Principales activitÃ©s que vous rÃ©aliserez :
Concevoir et coder des pipelines de donnÃ©es efficaces et Ã©volutifs en utilisant des technologies big data dans un environnement cloud (Azure, Databricks).
Utilisation de lâ€™Ã©tat de lâ€™art des technologies actuelles dÃ©diÃ©es Ã  ces activitÃ©s : Kafka / Spark / Spark Streaming / Flink / Storm
DÃ©veloppement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie)
Utilisation de tous les types de stockage actuels : SQL : Oracle, SQLServer, PostgreSQL / NoSQL : Cassandra / MongoDB / HBase / Objet : S3 / MinIO
Vous avez de bonnes expÃ©riences en dÃ©veloppement logiciel et/ou scripting (principalement Scala)
Vous avez plus de 2 ans dâ€™expÃ©rience (alternance prise en compte)
Vous Ãªtes Ã  lâ€™aise en Anglais
Vous avez une certaine appÃ©tence pour lâ€™univers du voyage ?
Vous Ãªtes curieux(se) et rigoureux(se) ?
Vous aimez travailler en Ã©quipe au quotidien. Pour vous le succÃ¨s nâ€™est que collectif.
CE QUE NOUS POUVONS FAIRE ENSEMBLE :
Le dÃ©partement IA & Big Data fÃ©dÃ¨re et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers dâ€™une structure permettant dâ€™accÃ©lÃ©rer la transformation des enjeux Data de nos clients.
Nos savoir-faire :
Big Data, Intelligence Artificielle, Algorithmie, Expertise Imagerie
Projets dâ€™intÃ©gration systÃ¨me
Votre mission :
Vous interviendrez dans un contexte international au sein dâ€™Ã©quipes multiculturelles pour un acteur majeur de lâ€™industrie du voyage. Plus particuliÃ¨rement, vous participerez Ã  lâ€™amÃ©lioration de lâ€™expÃ©rience de vente au profit de nombreuses compagnies aÃ©riennes.
Vous pourrez contribuer aux diffÃ©rentes phases du projet et serez en charge de :
Convertir les spÃ©cifications fonctionnelles en nouvelles solutions logicielles grÃ¢ce Ã  l'analyse des spÃ©cifications.
Proposer et concevoir des solutions techniques viables et rÃ©aliser des Ã©tudes de faisabilitÃ©.
DÃ©velopper des logiciels conformÃ©ment aux normes de notre client.
Participer Ã  la phase de validation du cycle du produit, en procÃ©dant aux ajustements nÃ©cessaires pour finaliser le produit.
Soutenir le client en dÃ©boguant les solutions existantes en collaboration avec le chef de   produit ou l'analyste chargÃ© de la dÃ©finition du produit.
Produire la documentation logicielle nÃ©cessaire Ã  l'application.
Nos partenaires :
Recherche : INRIA, CNRS, 3IA
Externes : Nvidia, Microsoft
En collaboration avec les membres de notre dÃ©partement :
Vous allez contribuer au dÃ©veloppement et Ã  la scalabilitÃ© de nos plateformes au travers dâ€™activitÃ©s dâ€™automatisation, de crÃ©ation de services managÃ©s et dâ€™API
Vous accompagnerez nos clients dans leurs projets de valorisation de donnÃ©es en proposant des solutions techniques et fonctionnelles, Ã©valuÃ©es, choisies et opportunes.
Vous participerez Ã  lâ€™intÃ©gration des plateformes techniques sÃ©curisÃ©es dÃ©veloppÃ©es par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com)
Vous collaborerez Ã  nos publications, confÃ©rences et webinars.
Vous serez partie prenante de la 3Ã¨me rÃ©volution industrielle impactant tous les secteurs dâ€™activitÃ©, Ã©nergie, santÃ©, industrie, â€¦
VOTRE CARRIÃˆRE CHEZ THALESDiffÃ©rentes opportunitÃ©s vous permettront de dÃ©couvrir d'autres domaines ou sites. Vous pourrez Ã©voluer et dÃ©velopper vos compÃ©tences dans diffÃ©rents domaines :
Explorez un espace attentif au dÃ©veloppement personnel
DÃ©veloppez vos talents dans un autre domaine du groupe Thales, en dÃ©couvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe
Choisissez entre une expertise technique ou un parcours de leadership
Construisez une carriÃ¨re internationale au sein d'un groupe d'ingÃ©nierie de premier plan
Innovation, passion, ambition : rejoignez Thales et crÃ©ez le monde de demain, dÃ¨s aujourdâ€™hui.
Voir moins",
Lead data engineer (H/F),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Lille,45K Ã  60K â‚¬,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
SII Lille recherche un(e) : Lead data engineer (H/F)
En tant que Lead data engineer, vous avez lâ€™opportunitÃ© dâ€™intervenir sur des missions dâ€™expertise et de conseils auprÃ¨s de nos clients grands comptes. 
Vous concevez, faites Ã©voluer et gÃ©rer des plateformes Data et outils associÃ©s ainsi que des flux entre les diffÃ©rentes sources de donnÃ©es de l'entreprise.  
Lors de ces missions d'expertise, vous allez :
<li>Analyser les besoins clients: animer des ateliers, prÃ©coniser des architectures, dÃ©finir des mÃ©thodologies et plans de migration,</li>
<li>IntÃ©grer les futurs services et outils dans un environnement cloud provider (GCP, AWS ou Microsoft Azure),</li>
<li>Construire des architectures de donnÃ©es rÃ©silients et sÃ©curisÃ©es, mener les analyse d&#39;impacts et diffuser les bonnes pratiques,</li>
<li>Concevoir, automatiser, assurer la qualitÃ© des Ã©changes et le traitement des donnÃ©es (flux, streams, dataopsâ€¦),</li>
<li>Conseiller et participer Ã  la conception, mise en place et/ou migration de data warehouses/data lakes,</li>
<li>Assurer le pilotage et lâ€™optimisation des outils de transport et de traitement de la donnÃ©e.</li>
En complÃ©ment de ces missions pour nos clients, nous vous proposons Ã©galement dâ€™intervenir en interne et au niveau national sur une mission dâ€™expertise.
Vos 3 principales activitÃ©s sont :
<li>Animation et encadrement de la communautÃ© Data,</li>
<li>Accompagner et former nos consultants data junior,</li>
<li>Le dÃ©veloppement et la valorisation de lâ€™expertise du groupe SII (publications, confÃ©rences, webinaires...),</li>
<li>Lâ€™appui au business : participation Ã  des phases dâ€™avant-vente, aide au ciblage des clients, proposition de solutionsâ€¦</li>
Vous disposerez dâ€™un jour par semaine minimum pour mener Ã  bien cette mission.
Vous bÃ©nÃ©ficierez de la dynamique de notre Ã©quipe dâ€™experts, composÃ©e Ã  terme dâ€™une cinquantaine de personnes sur diffÃ©rents domaines dâ€™expertise (Applicatif, Devops, Cloud, Data, IA,â€¦)
Profil :  Vous justifiez dâ€™une expÃ©rience significative dâ€™au moins 5 ans sur un poste similaire dans un environnement cloud.   CompÃ©tences techniques : o    Maitrise dâ€™au moins un cloud public : AWS ou GCP o    Maitrise des langages suivants : SQL, Python (Java, Scala et/ou Spark serait un plus) o    Maitrise du fonctionnement des ETL/ESB o    Maitrise des architectures big data o    Connaissance dâ€™un outil de stockage et de gestion de donnÃ©es sur le cloud : Snowflake, Cloudera, Databrics o    Connaissance dâ€™un outil de data visualisation : Looker, PowerBI, Tableau o    Maitrise des processus et bonnes pratiques de dÃ©veloppement o    Anglais technique
Au-delÃ  des compÃ©tences techniques, vous faÃ®tes preuve de rigueur, dâ€™une bonne capacitÃ© dâ€™analyse et Ãªtes force de proposition. Vous avez un bon relationnel et savez communiquer auprÃ¨s des mÃ©tiers pour recueillir leur besoin. Vous Ãªtes Ã  l'aise lorsque vous prenez la parole face Ã  un large public.
Vous souhaitez mettre votre expÃ©rience au service des clients et mettre votre expertise au sein dâ€™SII pour relever des challenges techniques en apportant de la valeur sur le domaine de la data.
Le Groupe SII est une sociÃ©tÃ© dâ€™ingÃ©nierie et de conseils en technologies (ICT) et une entreprise de services numÃ©riques (ESN). Nous sommes au cÅ“ur de l'innovation au service de grands comptes dans des secteurs d'ingÃ©nierie variÃ©s. En 2023, pour la 6e annÃ©e consÃ©cutive, SII France a obtenu le label Great Place To WorkÂ®. Nous avons Ã©tÃ© reconnues entreprise de Â« + de 2500 salariÃ©s Â» oÃ¹ il fait bon vivre. Nous sommes trÃ¨s fiers dâ€™obtenir cette reconnaissance de nos salariÃ©s ! Ce succÃ¨s est le reflet de notre culture basÃ©e sur notre volontÃ© de proposer Ã  tous nos salariÃ©s un cadre de travail Ã©panouissant pour le dÃ©veloppement de leurs compÃ©tences et carriÃ¨res. Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la crÃ©ativitÃ©, la proximitÃ© et lâ€™esprit dâ€™Ã©quipe sont mis Ã  lâ€™honneur. Le Groupe SII est une sociÃ©tÃ© handi-accueillante, signataire de la Charte de la diversitÃ© en entreprise.
Alors si ces valeurs vous parlent, rejoignez nous !
Voir moins","Profil recherchÃ©
CompÃ©tences requises : Big data, ETL, GCP, Power BI, SQL.
QualitÃ©s dÃ©sirÃ©es : CapacitÃ©s d'analyse, Force de proposition, Rigueur.
Avantages : TrÃ¨s bon CSE, Tickets restaurant."
Data Engineer (H/F),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 Mâ‚¬', 'mean_age': '34 ans'}",CDI,La DÃ©fense,40K Ã  60K â‚¬,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Dans le cadre du dÃ©veloppement de notre agence Parisienne, nous recherchons un Data Engineer (h/f). IntÃ©grÃ©(e) au sein des Ã©quipes chez l'un de nos Clients Grands Comptes
Vos missions :
<li>Proposer, tester et mettre en Å“uvre des solutions permettant aux data scientists de travailler et collaborer efficacement, dans un objectif de mettre en production des modÃ¨les de machine learning construits avec ces outils. Le pÃ©rimÃ¨tre va de la collecte des donnÃ©es Ã  la mise en production, en passant par leur contrÃ´le, stockage, traitement et modÃ©lisation.</li>
<li>Accompagner et conseiller les diffÃ©rentes Ã©quipes des produits dans la bonne mise en Å“uvre de ces outils.</li>



<li>Proposer, tester et mettre en place des mÃ©thodes dâ€™anonymisation et dÃ©sensibilisation des donnÃ©es.</li>
<li>Construire, collecter et documenter les bonnes pratiques liÃ©es au stockage et traitement des donnÃ©es dans le cloud.</li>



<li>Proposer, tester et mettre en place des mÃ©thodes de sÃ©curisation de donnÃ©es plus poussÃ©es.</li>
Votre profil :
Vous Ãªtes diplÃ´mÃ© dâ€™un Bac +5 ou dâ€™un diplÃ´me dâ€™ingÃ©nieur et disposez au moins 5 ans dâ€™expÃ©rience ainsi que des connaissances suivantes :
<li>Connaissance des pratiques de dÃ©veloppement et opÃ©rations sur le Cloud</li>
<li>Connaissances des processus de dÃ©ploiement : nos processus se basent sur les services du cloud provider et sur les produits internes existants assurant leur bonne configuration (Kubernetes, Pipeline CI/CD, IBM Cloud, en particulier les bases de donnÃ©es et lâ€™object storage)</li>
<li>Connaissance des briques de base qui sont nÃ©cessaires Ã  une platform de Data Science (Notebook, framewoks ML, Model serving)</li>



<li>La connaissance de KubeFlow est un plus</li>
<li>Connaissance des diffÃ©rentes technologies de transfert et traitement de donnÃ©es dans le cloud : streaming et transformation des donnÃ©es, dans un objectif dâ€™ingestion des donnÃ©es</li>
<li>QualitÃ©s de pÃ©dagogie nÃ©cessaire vis Ã  vis des projets et des architectes du groupe.</li>
Qui sommes-nous ?
Le Groupe SII est une sociÃ©tÃ© dâ€™ingÃ©nierie et de conseils en technologies (ICT) et une entreprise de services numÃ©riques (ESN). Nous sommes au cÅ“ur de l'innovation au service de grands comptes dans des secteurs d'ingÃ©nierie variÃ©s.
En 2023, pour la 6e annÃ©e consÃ©cutive, SII France a obtenu le label Great Place To WorkÂ®. Nous avons Ã©tÃ© reconnus 3e entreprise de Â« + de 2500 salariÃ©s Â» oÃ¹ il fait bon vivre et nous en sommes trÃ¨s fiers ! Ce succÃ¨s est le reflet de notre culture basÃ©e sur notre volontÃ© de proposer Ã  tous nos salariÃ©s un cadre de travail Ã©panouissant pour le dÃ©veloppement de leurs compÃ©tences et carriÃ¨res.
En fonction de la mission, il est possible de rÃ©aliser jusquâ€™Ã  50 % de tÃ©lÃ©travail grÃ¢ce Ã  notre accord dÃ©diÃ©.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la crÃ©ativitÃ©, la proximitÃ© et lâ€™esprit dâ€™Ã©quipe sont mis Ã  lâ€™honneur.
Le Groupe SII est une sociÃ©tÃ© handi-accueillante, signataire de la Charte de la diversitÃ© en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins",
Data Engineer (F/H),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Rouen,37K Ã  45K â‚¬,TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
Nous recherchons un(e) Data Engineer (H/F) pour accompagner les dÃ©veloppements faits auprÃ¨s des applications de lâ€™un de nos clients Grand Compte. En mode Agile et organisÃ©e en ""Feature Team"", l'Ã©quipe technophile vous permettra de participer Ã  toute la chaÃ®ne projet.
En quÃªte de dÃ©fis techniques ? Alors nâ€™hÃ©sitez plus, postulez! 
Votre mission :
PrÃ©parer les donnÃ©es Ã  traiter,
Analyser les modÃ¨les,
Concevoir des algorithmes,
Programmer en back-end,
InterprÃ©ter et prÃ©senter les rÃ©sultats,
Mettre en production des solutions.
Votre profil : DiplÃ´mÃ©(e) dâ€™un Bac+5 en informatique, mathÃ©matique ou statistique (Grandes Ecoles, UniversitÃ©s), vous justifiez d'au moins une premiÃ¨re expÃ©rience significative dans le traitement de donnÃ©e avec utilisation ou connaissance dâ€™un ETL (Talend ou Informatica). Vous Ãªtes curieux(se), investi(e) et surtout passionnÃ©(e) par le monde du web. Vous savez travailler en Ã©quipe et vous vous intÃ©grer rapidement, vous Ãªtes autonome, organisÃ©(e) et rigoureux (se), bon communiquant et douÃ©(e) du sens de l'Ã©coute.
Qui sommes-nous ?
Le Groupe SII est une sociÃ©tÃ© dâ€™ingÃ©nierie et de conseils en technologies (ICT) et une entreprise de services numÃ©riques (ESN). Nous sommes au cÅ“ur de l'innovation au service de grands comptes dans des secteurs d'ingÃ©nierie variÃ©s.
En 2023, pour la 6e annÃ©e consÃ©cutive, SII France a obtenu le label Great Place To WorkÂ®. Nous avons Ã©tÃ© reconnus 3e entreprise de Â« + de 2500 salariÃ©s Â» oÃ¹ il fait bon vivre et nous en sommes trÃ¨s fiers ! Ce succÃ¨s est le reflet de notre culture basÃ©e sur notre volontÃ© de proposer Ã  tous nos salariÃ©s un cadre de travail Ã©panouissant pour le dÃ©veloppement de leurs compÃ©tences et carriÃ¨res.
En fonction de la mission, il est possible de rÃ©aliser jusquâ€™Ã  50 % de tÃ©lÃ©travail grÃ¢ce Ã  notre accord dÃ©diÃ©.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la crÃ©ativitÃ©, la proximitÃ© et lâ€™esprit dâ€™Ã©quipe sont mis Ã  lâ€™honneur.
Le Groupe SII est une sociÃ©tÃ© handi-accueillante, signataire de la Charte de la diversitÃ© en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins","Profil recherchÃ©
CompÃ©tences requises : Informatica, Talend.
QualitÃ©s dÃ©sirÃ©es : Esprit de synthÃ¨se, AdaptabilitÃ©, CapacitÃ©s d'analyse, Autonomie, Bon relationnel, Organisation, QualitÃ©s rÃ©dactionnelles, RÃ©activitÃ©.
Avantages : TrÃ¨s bon CSE, Mutuelle et prÃ©voyance, Tickets restaurant, Places en crÃ¨che, Participation aux bÃ©nÃ©fices de l'entreprise, Participation aux frais de transport, Primes de cooptation, TÃ©lÃ©travail."
Data Engineer (H/F),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 Mâ‚¬', 'mean_age': '34 ans'}",CDI,La DÃ©fense,45K Ã  55K â‚¬,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Dans le cadre du dÃ©veloppement de notre agence Parisienne, nous recherchons un Data Engineer (h/f). IntÃ©grÃ©(e) au sein des Ã©quipes chez l'un de nos Clients Grands Comptes
Vos missions :
Proposer, tester et mettre en Å“uvre des solutions permettant aux data scientists de travailler et collaborer efficacement, dans un objectif de mettre en production des modÃ¨les de machine learning construits avec ces outils. Le pÃ©rimÃ¨tre va de la collecte des donnÃ©es Ã  la mise en production, en passant par leur contrÃ´le, stockage, traitement et modÃ©lisation.
Accompagner et conseiller les diffÃ©rentes Ã©quipes des produits dans la bonne mise en Å“uvre de ces outils.
Proposer, tester et mettre en place des mÃ©thodes dâ€™anonymisation et dÃ©sensibilisation des donnÃ©es.
Construire, collecter et documenter les bonnes pratiques liÃ©es au stockage et traitement des donnÃ©es dans le cloud.
Proposer, tester et mettre en place des mÃ©thodes de sÃ©curisation de donnÃ©es plus poussÃ©es.
Votre profil :
Vous Ãªtes diplÃ´mÃ© dâ€™un Bac +5 ou dâ€™un diplÃ´me dâ€™ingÃ©nieur et disposez au moins 5 ans dâ€™expÃ©rience ainsi que des connaissances suivantes :
Connaissance des pratiques de dÃ©veloppement et opÃ©rations sur le Cloud
Connaissances des processus de dÃ©ploiement : nos processus se basent sur les services du cloud provider et sur les produits internes existants assurant leur bonne configuration (Kubernetes, Pipeline CI/CD, IBM Cloud, en particulier les bases de donnÃ©es et lâ€™object storage)
Connaissance des briques de base qui sont nÃ©cessaires Ã  une platform de Data Science (Notebook, framewoks ML, Model serving)
La connaissance de KubeFlow est un plus
Connaissance des diffÃ©rentes technologies de transfert et traitement de donnÃ©es dans le cloud : streaming et transformation des donnÃ©es, dans un objectif dâ€™ingestion des donnÃ©es
QualitÃ©s de pÃ©dagogie nÃ©cessaire vis Ã  vis des projets et des architectes du groupe.
Qui sommes-nous ?
Le Groupe SII est une sociÃ©tÃ© dâ€™ingÃ©nierie et de conseils en technologies (ICT) et une entreprise de services numÃ©riques (ESN). Nous sommes au cÅ“ur de l'innovation au service de grands comptes dans des secteurs d'ingÃ©nierie variÃ©s.
En 2023, pour la 6e annÃ©e consÃ©cutive, SII France a obtenu le label Great Place To WorkÂ®. Nous avons Ã©tÃ© reconnus 3e entreprise de Â« + de 2500 salariÃ©s Â» oÃ¹ il fait bon vivre et nous en sommes trÃ¨s fiers ! Ce succÃ¨s est le reflet de notre culture basÃ©e sur notre volontÃ© de proposer Ã  tous nos salariÃ©s un cadre de travail Ã©panouissant pour le dÃ©veloppement de leurs compÃ©tences et carriÃ¨res.
En fonction de la mission, il est possible de rÃ©aliser jusquâ€™Ã  50 % de tÃ©lÃ©travail grÃ¢ce Ã  notre accord dÃ©diÃ©.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la crÃ©ativitÃ©, la proximitÃ© et lâ€™esprit dâ€™Ã©quipe sont mis Ã  lâ€™honneur.
Le Groupe SII est une sociÃ©tÃ© handi-accueillante, signataire de la Charte de la diversitÃ© en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins","Profil recherchÃ©
CompÃ©tences requises : Kubernetes."
Senior Data Engineer (H/F),"{'name': 'BELIEVE', 'sector': 'Musique', 'employees': '1600 collaborateurs', 'creation_year': '2005', 'turnover': None, 'mean_age': '35 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Contexte 
Le Tribe Â«â€¯Customer Financeâ€¯Â» est composÃ© de plusieurs Squad, parmi elles la squadâ€¯Finance Ingestion qui a pour mission de dÃ©velopper des outils et des applications pour la collecte de royalties auprÃ¨s des plateformes de streaming de musique ainsi que prÃ©parer les donnÃ©es afin de faire la distribution des royalties auprÃ¨s des producteurs de musiques. 
En tant que Data Engineer, tu intÃ©gras une Ã©quipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette Ã©quipe est composÃ©e essentiellement de 5 Data Engineer et 1 Software Engineer. Nous avons un Ã©cosystÃ¨me qui se compose  
une socle de gestion des donnÃ©es (Delta Lake) plus dâ€™1.5 milliard de lignes /mois 
data engineering avec du Scala Spark utilisant le runtime de Databricks 
orchestration de nos data pipelines avec Airflow managÃ© 
des APIs avec les Lambda AWS pour faire interagir les utilisateurs avec notre interface front (PHP) 
RDS pour hoster la base de donnÃ©es back-end sous PostgreSQL  
versionning du code sous GitLab avec un environnement de dev, staging et production 
infrastructures sous AWS    
Les missions du Data Engineer au sein de lâ€™Ã©quipe : 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Interagir avec le Product Owner, le mÃ©tierâ€¯pour comprendre les besoins 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Interagir avec lâ€™architecte, les Ã©quipes infrastructures et Cloud pour concevoir les solutions de data engineering 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ DÃ©velopper des flux de donnÃ©es (data pipelines) avec du Apache Spark et du Scala 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Faire de lâ€™orchestration via Airflow avec du Python 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Maintenir et amÃ©liorer les modules existants de lâ€™application 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Utiliser GitLab pour tester, builder et dÃ©ployer son code sur les diffÃ©rents       environnements 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Effectuer des revues de codes des autres membres de lâ€™Ã©quipe 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Interagir avec les membres de lâ€™Ã©quipe pour atteindre lâ€™objectif du sprint 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Faire du support applicatif et fonctionnel de lâ€™application auprÃ¨s des opÃ©rationnel 
Set the tone with us
Chez Believe, nous avons deux cÅ“urs : nos collaborateurs et nos artistes.
Nous croyons en la force de nos collaborateurs, qui s'Ã©panouissent chaque jour en dÃ©veloppant leur potentiel... Notre objectif est d'offrir Ã  nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'Ã©panouir.
Rock the job
Programme de formation et de coaching sur mesure 
Une politique de tÃ©lÃ©travail
Un programme de bien-Ãªtre ""Pauses"" avec de nombreuses activitÃ©s et animations en interne
AccÃ¨s Ã  Eutelmed, la plateforme numÃ©rique de santÃ© mentale et de bien-Ãªtre qui permet de parler Ã  un psychologue expÃ©rimentÃ©
Un restaurant d'entreprise sain et Ã©co-responsable
Une assurance santÃ© individuelle ou familiale
Avantages CE 
Un rooftop
Une salle de sport avec des cours gratuits
 Sing in harmony
Des groupes d'ambassadeurs pour s'engager sur la rÃ©duction de l'empreinte carbone et environnementale de Believe et lâ€™Ã©quitÃ© professionnelle Femme/Homme.
Mise en place du Forfait mobilitÃ© durable: remboursement jusquâ€™Ã  600â‚¬ des frais de transport en commun/avec une faible empreinte carbone.
CongÃ© 2nd parent de 5 jours calendaires rÃ©munÃ©rÃ©s Ã  100% (en plus du congÃ© lÃ©gal paternitÃ© ou du congÃ© dâ€™adoption, nous ne lâ€™attribuons pas au congÃ© maternitÃ©)
  Believe sâ€™engage Ã  garantir lâ€™Ã©galitÃ© des chances en matiÃ¨re dâ€™emploi, sans tenir compte de lâ€™origine, du sexe, des mÅ“urs, de lâ€™orientation sexuelle, du genre, de lâ€™Ã¢ge, de la situation de famille, de lâ€™Ã©tat de grossesse, dâ€™une prÃ©tendue race, des opinions politiques, des activitÃ©s syndicales, des convictions religieuses, de lâ€™apparence physique, du nom de famille, du lieu de rÃ©sidence, de lâ€™Ã©tat de santÃ©, ou en situation de handicap.

DÃ©couvrez nos nouveaux locaux : bit.ly/believeoffice
Voir moins","Profil recherchÃ©
Qualifications du Data Engineer 
- 3-5 ans dâ€™expÃ©rience dans la pratique de dÃ©veloppement sous Scala 
- une trÃ¨s bonne maitrise du framework Spark avec du Scala, nous ne faisons pas de PySpark 
- une bonne maitrise de conception et dÃ©veloppement des data pipelines 
- DÃ©velopper avec un Ã©tat dâ€™esprit Keep it Simple, Stupid (KISS)  
- une bonne maitrise dâ€™un outil de versionning de code tel que Gitlab 
- une bonne maitrise des APIs avec du Lambda   
- une expÃ©rience dans lâ€™Ã©cosystÃ¨me AWS "
Data engineer (H/F),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Lille,33K Ã  45K â‚¬,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Devenez le prochain collaborateur d'SII Nord en tant que :
Data Engineer (H/F)
IntÃ©grÃ© chez l'un de nos clients, vous intervenez en tant que Data Engineer au sein de lâ€™Ã©quipe IT Data. Vous dÃ©veloppez et gÃ©rez la maintenance de la plateforme Data et dâ€™autres outils mais aussi des flux entre les diffÃ©rentes sources de donnÃ©es de lâ€™entreprise.  Vous contribuez Ã  :
Concevoir et dÃ©velopper les futures fonctionnalitÃ©s de la plateforme Big Data sous Google Cloud Platform,
Concevoir les flux dâ€™alimentation et les tables (structure de donnÃ©e),
Automatiser et industrialiser les flux,
Assurer le run applicatif, le cas Ã©chÃ©ant.
Profil :  Dans l'idÃ©al (oui uniquement dans lâ€™idÃ©al, chez nous on ne cherche pas quâ€™un CV mais une collaboration durable), de formations supÃ©rieure en informatique, type Bac+3/5, vous justifiez dâ€™une expÃ©rience significative en dÃ©veloppement sur un environnement BI et Big Data.   CompÃ©tences techniques :
Maitrise des langages suivants : SQL, Python (Java/Scala serait un plus)
Connaissances de Google Cloud Dataflow (Python)
Anglais nÃ©cessaire Ã  lâ€™Ã©crit
Notion de programmation fonctionnelle
Au-delÃ  des compÃ©tences techniques, vous faÃ®tes preuve de rigueur, de curiositÃ© et aimez relever les challenges. Vous Ãªtes dotÃ©(e) dâ€™un bon sens du service client, Ãªtes organisÃ© et pragmatique. Ces qualitÃ©s vous permettent de mener Ã  bien le projet.   Vous vous reconnaissez dans ces compÃ©tences et qualitÃ©s ? Vous souhaitez bousculer les codes, sortir des sentiers battus et rendre votre dynamisme contagieux ? Alors, rejoignez le mouvement #FungÃ©nieur de SII dans lequel la crÃ©ativitÃ© et lâ€™esprit dâ€™Ã©quipe sont mis Ã  lâ€™honneur !  Vous Ãªtes les crÃ©ateurs de demain, osez mettre en avant vos compÃ©tences, investissez-vous dans des projets innovants et venez relever de nouveaux dÃ©fis technologiques.  Expertise, Innovation et fun est le mix que nous vous proposons ! 
Qui sommes-nous ? Le Groupe SII est une sociÃ©tÃ© dâ€™ingÃ©nierie et de conseils en technologies (ICT) et une entreprise de services numÃ©riques (ESN). Nous sommes au cÅ“ur de l'innovation au service de grands comptes dans des secteurs d'ingÃ©nierie variÃ©s. En 2023, pour la 6Ã¨me annÃ©e consÃ©cutive, SII France a obtenu le label Great Place To WorkÂ®. Nous avons Ã©tÃ© reconnus 3Ã¨me entreprise de Â« + de 2500 salariÃ©sÂ» oÃ¹ il fait bon vivre. Nous sommes trÃ¨s fiers dâ€™obtenir cette reconnaissance de nos salariÃ©s !
Ce succÃ¨s est le reflet de notre culture basÃ©e sur notre volontÃ© de proposer Ã  tous nos salariÃ©s un cadre de travail Ã©panouissant pour le dÃ©veloppement de leurs compÃ©tences et carriÃ¨res. En fonction de la mission, il est possible de rÃ©aliser jusquâ€™Ã  50 % de tÃ©lÃ©travail grÃ¢ce Ã  notre accord dÃ©diÃ©.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la crÃ©ativitÃ©, la proximitÃ© et lâ€™esprit dâ€™Ã©quipe sont mis Ã  lâ€™honneur. Le Groupe SII est une sociÃ©tÃ© handi-accueillante, signataire de la Charte de la diversitÃ© en entreprise.
Alors si ces valeurs vous parlent, rejoignez-nous !
 Voir moins","Profil recherchÃ©
CompÃ©tences requises : Python, Scala, Spark, SQL.
QualitÃ©s dÃ©sirÃ©es : Organisation, Rigueur, Satisfaction client.
Avantages : TrÃ¨s bon CSE, Mutuelle et prÃ©voyance, Tickets restaurant."
Senior Data Engineer (H/F),"{'name': 'BELIEVE', 'sector': 'Musique', 'employees': '1600 collaborateurs', 'creation_year': '2005', 'turnover': None, 'mean_age': '35 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Contexte
Le Tribe Â«â€¯Customer Financeâ€¯Â» est composÃ© de plusieurs Squad, parmi elles la squadâ€¯Finance Ingestion qui a pour mission de dÃ©velopper des outils et des applications pour la collecte de royalties auprÃ¨s des plateformes de streaming de musique ainsi que prÃ©parer les donnÃ©es afin de faire la distribution des royalties auprÃ¨s des producteurs de musiques. 
En tant que Senior Data Engineer, tu intÃ©gras une Ã©quipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette Ã©quipe est composÃ©e essentiellement de 5 Data Engineer et 1 Software Engineer.  
Nous avons un Ã©cosystÃ¨me composÃ© de : 
Un socle de gestion des donnÃ©es (Delta Lake) plus dâ€™1.5 milliard de lignes /mois 
Data processing avec Scala et Spark utilisant le runtime de Databricks 
Orchestration de nos data pipelines avec Airflow managÃ© 
Des APIs dÃ©ployÃ©es avec AWS Lambda et API Gateway pour faire interagir les utilisateurs avec notre interface front (PHP) 
AWS RDS pour hoster la base de donnÃ©es back-end sous PostgreSQL  
Versionning du code sous GitLab avec un environnement de dev, staging et production 
Infrastructure sous AWS    
Les missions du Senior Data Engineer au sein de lâ€™Ã©quipe :
-          Accompagner les dÃ©veloppeurs Ã  Ã©crire du code propre, qualitatif et conforme aux standards de lâ€™Ã©quipe 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Interagir avec lâ€™architecte, les Ã©quipes infrastructures Cloud pour concevoir les solutions de data engineering 
-          Proposer des amÃ©liorations continues et Ãªtre garant de rÃ©duire les dettes techniques 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ DÃ©velopper des flux de donnÃ©es (data pipelines) avec de lâ€™Apache Spark et du Scala 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Faire de lâ€™orchestration via Airflow avec du Python 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Maintenir le workflow GitLab afin de garantir une bonne productivitÃ© de lâ€™Ã©quipe de dÃ©veloppement 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Effectuer des revues de codes des autres membres de lâ€™Ã©quipe 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Collaborer les membres de lâ€™Ã©quipe dev pour atteindre lâ€™objectif du sprint 
-â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯â€¯ Faire du support applicatif et fonctionnel de lâ€™application auprÃ¨s des opÃ©rationnel 
Set the tone with us
Chez Believe, nous avons deux cÅ“urs : nos collaborateurs et nos artistes.
Nous croyons en la force de nos collaborateurs, qui s'Ã©panouissent chaque jour en dÃ©veloppant leur potentiel... Notre objectif est d'offrir Ã  nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'Ã©panouir.
Rock the job
Programme de formation et de coaching sur mesure 
Une politique de tÃ©lÃ©travail
Un programme de bien-Ãªtre ""Pauses"" avec de nombreuses activitÃ©s et animations en interne
AccÃ¨s Ã  Eutelmed, la plateforme numÃ©rique de santÃ© mentale et de bien-Ãªtre qui permet de parler Ã  un psychologue expÃ©rimentÃ©
Un restaurant d'entreprise sain et Ã©co-responsable
Une assurance santÃ© individuelle ou familiale
Avantages CE 
Un rooftop
Une salle de sport avec des cours gratuits
 Sing in harmony
Des groupes d'ambassadeurs pour s'engager sur la rÃ©duction de l'empreinte carbone et environnementale de Believe et lâ€™Ã©quitÃ© professionnelle Femme/Homme.
Mise en place du Forfait mobilitÃ© durable: remboursement jusquâ€™Ã  600â‚¬ des frais de transport en commun/avec une faible empreinte carbone.
CongÃ© 2nd parent de 5 jours calendaires rÃ©munÃ©rÃ©s Ã  100% (en plus du congÃ© lÃ©gal paternitÃ© ou du congÃ© dâ€™adoption, nous ne lâ€™attribuons pas au congÃ© maternitÃ©)
  Believe sâ€™engage Ã  garantir lâ€™Ã©galitÃ© des chances en matiÃ¨re dâ€™emploi, sans tenir compte de lâ€™origine, du sexe, des mÅ“urs, de lâ€™orientation sexuelle, du genre, de lâ€™Ã¢ge, de la situation de famille, de lâ€™Ã©tat de grossesse, dâ€™une prÃ©tendue race, des opinions politiques, des activitÃ©s syndicales, des convictions religieuses, de lâ€™apparence physique, du nom de famille, du lieu de rÃ©sidence, de lâ€™Ã©tat de santÃ©, ou en situation de handicap.

DÃ©couvrez nos nouveaux locaux : bit.ly/believeoffice
Voir moins","Profil recherchÃ©
Qualifications du Data Engineer 
-         5-8 ans dâ€™expÃ©rience en Scala 
-         Une maitrise horizontale de tous les composants dâ€™une plateforme de data 
-         ExpÃ©rience en programmation fonctionnel 
-         Connaissance dâ€™un effect system en Scala (ZIO ou cats) 
-         Excellente maÃ®trise de lâ€™API Spark en Scala avec pour but de guider lâ€™Ã©quipe sur les bonnes pratiques 
-         ExpÃ©rience en dÃ©veloppement backend  
-         Une bonne maitrise des services AWS (API Gateway, Lambda, SNS, SQS, S3, Cloudwatch, VPC) 
-         DÃ©velopper avec un Ã©tat dâ€™esprit Keep it Simple, Stupid (KISS) 
-         Excellente compÃ©tence dans la gestion de relation avec une Ã©quipe en remote 
-         Bonne communication pour gÃ©rer les diffÃ©rents points de vue et expliquer les contraintes aux utilisateurs 
 Optionnel 
Voir plus"
Data engineer secteur retail (F/H),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Lille,35K Ã  45K â‚¬,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Devenez le prochain collaborateur d'SII Nord en tant que :
Data Engineer (H/F)
IntÃ©grÃ© chez l'un de nos clients dans le secteur du retail, vous intervenez en tant que Data Engineer (F/H) au sein de lâ€™Ã©quipe Data et en Ã©troite collaboration avec les autres spÃ©cialistes du domaine.
Vous dÃ©veloppez et maintenez la plateforme Data et rÃ©pondez Ã  des problÃ©matiques complexes grÃ¢ce Ã  des solutions innovantes.  
Vous contribuez Ã  :
Mettre en Å“uvre et maintenir les pipelines de donnÃ©es
ModÃ©liser le patrimoine de donnÃ©es
Concevoir les flux dâ€™alimentation
CrÃ©er et maintenir les dataset permettant le pilotage et la prise de dÃ©cision
Profil :  Vous justifiez dâ€™une expÃ©rience significative en data sur les technologies suivantes :
GCP Big query ou AWS Datadog
ETL
Vous maitrisez au moins 2 des langages suivants : Spark, SQL, Python
Au-delÃ  des compÃ©tences techniques, vous faÃ®tes preuve de rigueur, de curiositÃ© et aimez relever les challenges. Vous savez rÃ©diger les specs et maitrisez le processus de CI/CD. Vous maitrisez lâ€™anglais et avait des connaissances dans le secteur retail.
Qui sommes-nous ?
SII Nord câ€™est 180 collaborateurs, rassemblÃ©e autour de diffÃ©rents pÃ´les dâ€™expertise (chefferie de projet, dÃ©veloppement informatique, ingÃ©nierie systÃ¨mes, data). Notre communautÃ© Data est aujourdâ€™hui dynamique au sein de lâ€™agence de Lille et rayonne au niveau du groupe, Ã  travers diffÃ©rents Ã©vÃ¨nements organisÃ©s : ateliers, rÃ©alisation de speak-up, retours dâ€™expÃ©rience.
Chez SII Nord vous Ãªtes accompagnÃ©s au quotidien sur votre Ã©volution de carriÃ¨re par un manager de proximitÃ© qui vous suit tout au long de votre parcours
Le Groupe SII est une sociÃ©tÃ© dâ€™ingÃ©nierie et de conseils en technologies (ICT) et une entreprise de services numÃ©riques (ESN). Nous sommes au cÅ“ur de l'innovation au service de grands comptes dans des secteurs d'ingÃ©nierie variÃ©s. En 2023, pour la 6Ã¨me annÃ©e consÃ©cutive, SII France a obtenu le label Great Place To WorkÂ®. Nous avons Ã©tÃ© reconnus 3Ã¨me entreprise de Â« + de 2500 salariÃ©sÂ» oÃ¹ il fait bon vivre. Nous sommes trÃ¨s fiers dâ€™obtenir cette reconnaissance de nos salariÃ©s !
Ce succÃ¨s est le reflet de notre culture basÃ©e sur notre volontÃ© de proposer Ã  tous nos salariÃ©s un cadre de travail Ã©panouissant pour le dÃ©veloppement de leurs compÃ©tences et carriÃ¨res. En fonction de la mission, il est possible de rÃ©aliser jusquâ€™Ã  50 % de tÃ©lÃ©travail grÃ¢ce Ã  notre accord dÃ©diÃ©.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la crÃ©ativitÃ©, la proximitÃ© et lâ€™esprit dâ€™Ã©quipe sont mis Ã  lâ€™honneur. Le Groupe SII est une sociÃ©tÃ© handi-accueillante, signataire de la Charte de la diversitÃ© en entreprise.
Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins","Profil recherchÃ©
CompÃ©tences requises : AWS, ETL, GCP, Python, SQL.
QualitÃ©s dÃ©sirÃ©es : AdaptabilitÃ©, Rigueur.
Avantages : TrÃ¨s bon CSE, Tickets restaurant, Participation aux frais de transport, TÃ©lÃ©travail."
Data engineer secteur bancaire (F/H),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Lille,35K Ã  45K â‚¬,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Devenez le prochain collaborateur d'SII Nord en tant que :
Data Engineer (H/F)
IntÃ©grÃ© chez l'un de nos clients dans le secteur du bancaire, vous intervenez en tant que Data Engineer (F/H) au sein de lâ€™Ã©quipe Data et en Ã©troite collaboration avec les autres spÃ©cialistes du domaine.
Vous dÃ©veloppez et maintenez la plateforme Data et rÃ©pondez Ã  des problÃ©matiques complexes grÃ¢ce Ã  des solutions innovantes.  
Vous contribuez Ã  :
Mettre en Å“uvre et maintenir les pipelines de donnÃ©es
ModÃ©liser le patrimoine de donnÃ©es
Concevoir les flux dâ€™alimentation
CrÃ©er et maintenir les dataset permettant le pilotage et la prise de dÃ©cision
Profil :  Vous justifiez dâ€™une expÃ©rience significative en data sur les technologies suivantes :
GCP Big query ou AWS Datadog
ETL
Vous maitrisez au moins 2 des langages suivants : Spark, SQL, Python
Au-delÃ  des compÃ©tences techniques, vous faÃ®tes preuve de rigueur, de curiositÃ© et aimez relever les challenges. Vous maitrisez lâ€™anglais. Vous Ãªtes dotÃ©(e) dâ€™un bon sens du service client, Ãªtes organisÃ© et pragmatique. Des connaissances dans le secteur bancaire est un plus.
Qui sommes-nous ? SII Nord câ€™est 180 collaborateurs, rassemblÃ©e autour de diffÃ©rents pÃ´les dâ€™expertise (chefferie de projet, dÃ©veloppement informatique, ingÃ©nierie systÃ¨mes, data). Notre communautÃ© Data est aujourdâ€™hui dynamique au sein de lâ€™agence de Lille et rayonne au niveau du groupe, Ã  travers diffÃ©rents Ã©vÃ¨nements organisÃ©s : ateliers, rÃ©alisation de speak-up, retours dâ€™expÃ©rience.
Chez SII Nord vous Ãªtes accompagnÃ©s au quotidien sur votre Ã©volution de carriÃ¨re par un manager de proximitÃ© qui vous suit tout au long de votre parcours
Le Groupe SII est une sociÃ©tÃ© dâ€™ingÃ©nierie et de conseils en technologies (ICT) et une entreprise de services numÃ©riques (ESN). Nous sommes au cÅ“ur de l'innovation au service de grands comptes dans des secteurs d'ingÃ©nierie variÃ©s. En 2023, pour la 6Ã¨me annÃ©e consÃ©cutive, SII France a obtenu le label Great Place To WorkÂ®. Nous avons Ã©tÃ© reconnus 3Ã¨me entreprise de Â« + de 2500 salariÃ©sÂ» oÃ¹ il fait bon vivre. Nous sommes trÃ¨s fiers dâ€™obtenir cette reconnaissance de nos salariÃ©s !
Ce succÃ¨s est le reflet de notre culture basÃ©e sur notre volontÃ© de proposer Ã  tous nos salariÃ©s un cadre de travail Ã©panouissant pour le dÃ©veloppement de leurs compÃ©tences et carriÃ¨res. En fonction de la mission, il est possible de rÃ©aliser jusquâ€™Ã  50 % de tÃ©lÃ©travail grÃ¢ce Ã  notre accord dÃ©diÃ©.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la crÃ©ativitÃ©, la proximitÃ© et lâ€™esprit dâ€™Ã©quipe sont mis Ã  lâ€™honneur. Le Groupe SII est une sociÃ©tÃ© handi-accueillante, signataire de la Charte de la diversitÃ© en entreprise.
Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins","Profil recherchÃ©
CompÃ©tences requises : AWS, ETL, GCP, Python, SQL.
QualitÃ©s dÃ©sirÃ©es : Autonomie, Rigueur.
Avantages : TrÃ¨s bon CSE, Mutuelle et prÃ©voyance, Tickets restaurant."
Data Engineer H/F - Tours,"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Tours,35K Ã  45K â‚¬,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Envie de changement, dâ€™une nouvelle opportunitÃ© professionnelle et dâ€™un cadre oÃ¹ il fait bon vivre ? Alors câ€™est bon, tu peux continuer Ã  lire, câ€™est chez SII que Ã§a se passe !
Dans le cadre du dÃ©veloppement de notre agence, nous recherchons un ou une Data Engineer (H/F) pour mettre Ã  profit son expertise au service de nos clients.
IntÃ©grÃ©(e) au sein des Ã©quipes clients, tes futures missions sont :   
<li>RÃ©solution dâ€™incidents (niveau 2 ou 3) et mise en Å“uvre dâ€™actions prÃ©ventives</li>
<li>Conseil, assistance et expertise auprÃ¨s des utilisateurs.  </li>
<li>Maintien en condition opÃ©rationnelle des outils ou systÃ¨mes (RUN)</li>
<li>Participation Ã  lâ€™Ã©volution des cibles et trajectoires du SI (BUILD) </li>
Tes atouts pour le poste sont la maÃ®trise des technologies Big Data et notamment lâ€™Ã©cosystÃ¨me Hadoop ((Kafka, Solr, Hbase, Hive, Spark), Cloudera (Sentry, Kudu, Impala)
De formation BAC +5 (Ã©cole dâ€™ingÃ©nieurs ou universitaires), tu justifies dâ€™une premiÃ¨re expÃ©rience significative dans le domaine de la Data et tu possÃ¨des Ã©galement de bonnes connaissances dans le dÃ©veloppement informatique et notamment sur la stack Java.
CompÃ©tences techniques requises :
SystÃ¨me et OS : Linux/Unix (RedHat, CentOS)
ETL : Talend, Talend Big Data Edition, TeraData.
Cloud (DataBricks,  DeltaLake), Azure, Amazon, PAAS (Open-Shift, Kubernetes), Confluent
DotÃ©(e) dâ€™un bon relationnel et apprÃ©ciant le travail en Ã©quipe, tu aimes transmettre ton savoir sur ton domaine dâ€™expertise.
Notre ADN
DerniÃ¨re-nÃ©e de lâ€™agence SII Atlantique, SII Tours intervient dans les domaines de l'embarquÃ©, des systÃ¨mes d'informations, du web, ou de la gestion de projet.
Fort de lâ€™expertise du groupe, nous rejoindre te permettra une Ã©volution au sein de nos projets (Grands comptes, PME, ETI).
Nous sommes situÃ©s au sein de locaux modernes dans le centre-ville de Tours (proche gare).
Le Groupe SII est au cÅ“ur de lâ€™innovation au service de grands comptes dans des secteurs dâ€™ingÃ©nierie variÃ©s.
En 2022, nous avons Ã©tÃ© labellisÃ©s Great Place To Work pour la 5e annÃ©e consÃ©cutive et reconnus 3 e entreprise de Â« + de 2500 salariÃ©s Â» oÃ¹ il fait bon vivre. Nous sommes trÃ¨s fiers dâ€™obtenir cette reconnaissance de nos salariÃ©s !
Ce succÃ¨s est le reflet de notre culture basÃ©e sur notre volontÃ© de proposer Ã  tous nos salariÃ©s un cadre de travail Ã©panouissant pour le dÃ©veloppement de leurs compÃ©tences et carriÃ¨res.
Rejoint le mouvement #fungenieur dans lequel la passion pour la technologie, la crÃ©ativitÃ©, la proximitÃ© et lâ€™esprit dâ€™Ã©quipe sont mis Ã  lâ€™honneur.
Notre nouvel accord tÃ©lÃ©travail permet de lâ€™appliquer jusquâ€™Ã  50% de notre temps de travail en fonction de la mission.
Le Groupe SII est une sociÃ©tÃ© handi-accueillante, signataire de la Charte de la diversitÃ© en entreprise.
Ces valeurs te parlent ? Alors rejoins-nous !
Elodie, Julien et Lucas seront ravis de te rencontrer et de tâ€™en dire plus.
Tu peux Ã©galement nous suivre sur les rÃ©seaux sociaux : Facebook, Linkedin, Viadeo ou Twitter :@SII_Atlantique.
Voir moins","Profil recherchÃ©
CompÃ©tences requises : Hadoop, Hive, JAVA, Spark.
QualitÃ©s dÃ©sirÃ©es : AdaptabilitÃ©, CapacitÃ©s d'analyse, Autonomie, Bon relationnel.
Avantages : TrÃ¨s bon CSE, Participation aux bÃ©nÃ©fices de l'entreprise, TÃ©lÃ©travail."
Data Engineer GCP,"{'name': 'MERITIS', 'sector': 'IT / Digital, Finance', 'employees': '900 collaborateurs', 'creation_year': '2007', 'turnover': '87Mâ‚¬', 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,,
Data Engineer (H/F),"{'name': 'MERITIS', 'sector': 'IT / Digital, Finance', 'employees': '900 collaborateurs', 'creation_year': '2007', 'turnover': '87Mâ‚¬', 'mean_age': '30 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,,
Data Engineer F/H,"{'name': 'ELDO', 'sector': 'SaaS / Cloud Services, BÃ¢timent / Travaux publics, Digital', 'employees': '56 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '30 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail total,03 avril 2023,> 5 ans,Bac +5 / Master,"Descriptif du poste
Eldo, câ€™est la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et sâ€™amÃ©liorer au quotidien pour dÃ©velopper leur activitÃ© ğŸš€ğŸ’š
Ã€ propos
Eldo accompagne depuis 2016 les professionnels et marques du secteur de lâ€™amÃ©lioration de lâ€™habitat dans la digitalisation de leur communication et gestion commerciale.
Notre mission : partager les savoirs qui construisent les belles histoires.
Nous construisons la premiÃ¨re plateforme europÃ©enne de solutions digitales Ã  destination des professionnels, marques et consommateurs du secteur de lâ€™amÃ©lioration de lâ€™habitat.
Nous sommes une Ã©quipe de passionnÃ©s qui souhaitent rÃ©volutionner le secteur de lâ€™amÃ©lioration de lâ€™habitat (76 milliards dâ€™â‚¬).
Avec notre suite SaaS nous accompagnons les pros et marques du secteur Ã  dÃ©velopper leur activitÃ© en optimisant chaque Ã©tape du cycle de vente avec leurs clients. Du moment oÃ¹ ils les trouvent sur le web, jusquâ€™Ã  leur satisfaction Ã  la fin des travaux.
Sur notre site B2C, nous aidons les particuliers Ã  trouver des pros de confiance grÃ¢ce aux avis et photos de leurs voisins, pour rÃ©aliser les travaux de leurs rÃªves.
Nous avons un positionnement et un service unique avec :
ğŸ’»ğŸ“² une suite applicative SaaS, dÃ©veloppÃ©e avec et pour les pros et marques du bÃ¢timent
ğŸ“·ğŸ’¬ + 100 000 avis accompagnÃ©s de photos, vidÃ©os ;
ğŸ‘¨â€ğŸ”§ des milliers d'entreprises rÃ©fÃ©rencÃ©es avec un taux de renouvellement/satisfaction de 90%.
ğŸ¡ğŸ’° un partenariat avec Google et une certification AFNOR encore renouvelÃ©e cette annÃ©e ! (processus de collecte, modÃ©ration et restitution des avis)
LaurÃ©ats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs Ã  succÃ¨s comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir dâ€™ici 2030 la premiÃ¨re plateforme mondiale de solutions digitales Ã  destination des professionnels de lâ€™amÃ©lioration de lâ€™habitat.
 Descriptif du poste
Chez Eldo notre Dream Team sâ€™agrandit ! ğŸ‘©â€ğŸš€
Dans un environnement fantastique, notre team Product Engineering a besoin de nouvelles recrues, et en ce sens, nous recherchons un(e) Data Engineer.
Si tu aimes la donnÃ©e et que les statistiques nâ€™ont aucun secret pour toiâ€¦ alors Alessandro et la team nâ€™attendent que toi !
Regarde par la fenÃªtre de lâ€™Ã©quipe Product Engineering ! ğŸ‘
La Team Product Engineering, câ€™est plus d'une dizaine de collaborateurs passionnÃ©s et ambitieux accompagnÃ©s par nos Ã©quipes marketing, sales, grands comptesâ€¦!
Ton rÃ´le chez Eldo
Tu travailleras quotidiennement Ã  lâ€™amÃ©lioration de nos applications (modifications de lâ€™actuel et crÃ©ation) en proposant des architectures, des pipelines data et des algorithmes sur de larges sets de data en assurant une qualitÃ© et granularitÃ© de cette derniÃ¨re, le tout, en Ã©tant un support pour les Ã©quipes en interne.
Pour la partie â€œEngineerâ€, tu seras attendu sur la scalabilitÃ© de la partie Data, la mise en place dâ€™architecture dÃ©diÃ©e, la gestion de la sÃ©curitÃ© de la data, la connexion entre lâ€™architecture data et la partie applicative et dÃ©veloppement produit.
Pour la partie â€œAnalysteâ€, tu seras en charge de recueillir les donnÃ©es internes (bases de donnÃ©es, fichiersâ€¦) et externes (HubSpot, Google Analytics, Partooâ€¦), puis de les centraliser au sein dâ€™un datawarehouse pour ensuite permettre leur restitution via un outil dÃ©diÃ© Ã  la Business Intelligence (tu seras force de proposition sur les outils Ã  utiliser).
Tu devras bien Ã©videmment documenter et spÃ©cifier les Ã©lÃ©ments de services ou modÃ¨les dÃ©veloppÃ©s, ainsi que maintenir une veille active sur les services utilisÃ©s et plus largement sur ton secteur d'expertise afin de pouvoir proposer les meilleures et plus adÃ©quates solutions.
Ayant un rÃ´le fortement orientÃ© et drivÃ© par lâ€™Impact business et utilisateur, tu seras naturellement au sein de lâ€™Ã©quipe Produit, composÃ©e de Product Manager, Product Designer.
Tes Ã©changes quotidiens seront bien Ã©videmment avec cette Ã©quipe, mais pas que.
Les dÃ©veloppeurs et toutes les autres Ã©quipes seront pour toi des stakeholders privilÃ©giÃ©s afin de rÃ©pondre au mieux au besoin de la stratÃ©gie Produit et Entreprise.
Les Ã©quipes Product Engineering (PE) travaillent en utilisant la mÃ©thodologie Agile.
Ton environnement de travail sera le suivant: 
MySQL, PostgreSQL
ETL/ELT, Jobs Talend orchestrÃ©s par Airflow, Hevo data pour la partie no code.
APIs dâ€™outils externes Ã  une entreprise (ex : Google Analytics, HubSpotâ€¦).
Outils de reporting/dashboarding (Amazon QuickSightÂ°. Toucan Toco pour la partie embed dans lâ€™application)
Outils de documentation, Confluence, et outils de suivi des tÃ¢ches/incidents, JIRA.
Environnement cloud (AWS)
 Cela pour Ãªtre un super fit si en plus, tu as/es :
Soft skills
autonome
curieux(se)
une bonne communication
diplomate
un esprit de synthÃ¨se 
flexible 
Social skills
Ouverture dâ€™esprit
OrientÃ© Business
Bienveillance
Sens de lâ€™initiative
 ğŸ”ğŸ˜ Ce que lâ€™Ã©quipe aime par-dessus tout sur ce poste
Lâ€™humour au quotidien, via des petites blagues souvent de bonne qualitÃ© (mais pas toujours)
La team Product Engineering
Les afterworks
Lâ€™aventure dâ€™une belle croissance
Pouvoir mettre sa pierre Ã  lâ€™Ã©difice
ğŸ‘ Les petits + qui font kiffer
Contrat forfait jour + RTT
Mutuelle ALAN 100% digitale qui rembourse super vite et prise en charge Ã  70%
Un club employÃ© (billetterie, produits high-tech, voyage, etc..)
La carte tickets resto --> Swile est notre ami
Primes cooptations
Remote ponctuel oÃ¹ tu veux en France
Goodies, welcome lunch & drinks (et pas que de bienvenue)
1 break dans lâ€™annÃ©e dans une destination surprise
Eldo est la sociÃ©tÃ© quâ€™il te faut si tu aimes â€¦ ğŸ’š
Le management de proximitÃ© et impliquant
Lâ€™autonomie, les prises dâ€™initiatives, les challenges #growthmindset
Ã‰voluer au sein dâ€™une Ã©quipe fun et bienveillante
Les moments de partage en Ã©quipe
Lâ€™idÃ©e de mettre ta pierre Ã  lâ€™Ã©difice et de participer Ã  une aventure humaine et professionnelle INCROYABLE
 ğŸ” Le process de recrutement chez Eldo
1 - Ã‰change visio RH (45â€™)
2 - Use case 3 - Ã‰change avec des membres de l'Ã©quipe Product Engineering ! (60')
4 - Ã‰change avec ton futur manager, le CPTO (60')Ce poste peut-Ãªtre en 100% en full remote avec des dÃ©placements Ã  prÃ©voir 1 fois par mois sur Toulouse pris en charge par Eldo
 Alors, sÃ©duit(e) ? poste sans tarder ton CV et sors ta plus belle plume ğŸ˜
Eldo est une entreprise handi-accueillante
Voir moins",
Digital Factory - Data Engineer DevOps (M/F),"{'name': 'VEOLIA', 'sector': 'Environnement / DÃ©veloppement durable, CollectivitÃ©s publiques et territoriales, BÃ¢timent / Travaux publics, Energie', 'employees': '213000 collaborateurs', 'creation_year': '1853', 'turnover': '42,9 Mdâ‚¬', 'mean_age': '44 ans'}",CDI,Saint-Maurice,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
We are looking for an experienced data engineer to join our team on this fantastic journey, working together to ensure that our customers get the best experience possible.
We have a huge potential for analytics and machine learning, based on our IoT and enterprise data, which require solid data engineering.
Your work will have very concrete outcomes and observable value.
You will be fully integrated into the development team, which is organised in an Agile Scrum fashion, and with an excellent team spirit.
You will:
Design, develop, and test data pipeline infrastructures and database systems
Collaborate with data analysts and data scientists to build and improve data models, algorithms and predictive models according to the businesâ€™s requirements
Ensure that all current data infrastructures and processes meet industry standards
Utilise cutting edge data engineering technologies and software
Search for elements of the data collection and processing that need improvement, and improve them
Implement systems to monitor data quality for optimised accuracy and clarity
Design and implement scalable and high-performing solutions
Collaborate with several other teams: Product and Business Development teams for HUBGRADE, Corporate IS&T teams (Data Lake, Cybersecurity, ERP, Networking, FinOps, â€¦), external Digital Partners.
Continuously transfer knowledge to the Run&Support team
Take part in L3 support
Identify synergies between software components and improve efficiency of development and code maintenance
Keep the product vision in mind while working on details
Help to build flexible, future-proof solutions
Continuously improve our agile development process, architecture, and engineering practices
Mentor and coach less experienced engineers on the team
The platform being very rich and diverse, you will have the opportunity to work on different areas and projects.
Additional Information
As an inclusive company, Veolia is committed to diversity and gives equal consideration to all applications, without discrimination.
Voir moins","Profil recherchÃ©
Education & Experience
Bachelor's degree in Computer Science
5+ years of experience in software development or data-related fields (DWH, â€¦), with at least 2 years in pure data engineering / big data, using modern programming languages, frameworks, and technologies
Experience working in an agile cross-functional team
Technical skills
Skilled with Git, Python or R, Big Data frameworks (especially Spark)
Skilled with relational and NoSQL databases
Skilled with data modelling and popular data viz tools
Fully operational on public Cloud technologies, especially AWS and its managed services (Glue, Kinesis, Athena, Lambda, IoT Core, EventBridge, â€¦)
Fully operational on Agile practice
Familiar with event-driven architectures
Familiar with automation and IaC tools (CI/CD, Terraform, AWS SAM)
Voir plus"
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Tours,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Vos missions sont :
- Recueillir les besoins mÃ©tiers et des Ã©quipes data
- Concevoir et mettre en place les traitements de donnÃ©es
- RÃ©aliser les tests de validation
- Assurer lâ€™alimentation du dataware
- RÃ©aliser les ordonnancements des traitements
- ÃŠtre garant de la mise en place, du suivi et de lâ€™exploitation des outils dÃ©ployÃ©s
- Assurer une veille technologique rÃ©guliÃ¨re

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).","Profil recherchÃ©
- PassionnÃ©(e) dâ€™informatique et de donnÃ©es, vous aimez le travail en Ã©quipe, apprendre et partager. Vous Ãªtes Ã©galement dotÃ©(e) d'un esprit audacieux et ambitieux.
- Vous faites preuve dâ€™initiative et travaillez sur le long terme.
- Vous justifiez de 2 Ã  5 ans d'expÃ©rience professionnelle au sein dâ€™une entreprise de services numÃ©riques ou dâ€™un cabinet de conseil dans le domaine de la Data.
- Vous disposez d'une vision large des technologies et vous maÃ®trisez au moins une technologie Big Data.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Limoges,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,,"Descriptif du poste
Alors venez rejoindre nos Ã©quipes de Data Engineer. Vous pouvez Ãªtre amenÃ© Ã  intervenir sur tout ou partie de ces missions :

â€¢ ModÃ©lisation des Data Concepts ;
â€¢ DÃ©veloppement et maintenance des traitements d'intÃ©gration et de transformation de donnÃ©es ;
â€¢ IntÃ©gration des dÃ©veloppements dans la chaine CI/CD ;
â€¢ Documentation technique et fonctionnelle ;
â€¢ RÃ©daction de plan de tests ;
â€¢ RÃ©alisation de tests unitaires/qualifications.

Au sein de la communautÃ© Data, vous serez accompagnÃ© et vous pourrez Ã©changer avec des collÃ¨gues expÃ©rimentÃ©s et experts vous permettant de vous dÃ©velopper, de grandir et dâ€™accomplir pleinement vos missions de conseil.
Lâ€™accompagnement managÃ©rial, la communautÃ© Data et de nombreux Ã©vÃ¨nements tout au long de lâ€™annÃ©e nous permettront de vous aider Ã  atteindre vos objectifs dans un esprit de convivialitÃ©.","Profil recherchÃ©
Vous aimez travailler en Ã©quipe, vous avez une formation Bac+3/5 en informatique, au minimum 2 ans dâ€™expÃ©riences et des aptitudes sur lâ€™un ou plusieurs des domaines suivants :

â€¢ ETL : Informatica PowerCenter, PowerExchange, Talendâ€¦
â€¢ Bases de donnÃ©es : Oracle, PostGres, MySQL, Mongo db, Sybaseâ€¦
â€¢ Outils : Mantis, Jira, Confluence, Mega Hopexâ€¦
â€¢ Data Visualisation : SAP Business Object, Need4Viz â€¦
â€¢ Langages : SQL, Hadoop, Python, Râ€¦
â€¢ Technos cloud : Azure, databricks, snowflakeâ€¦

Les avantages CGI câ€™est :

- Un programme dâ€™accompagnement durant ta premiÃ¨re annÃ©e chez CGI (rÃ©fÃ©rents, sÃ©minaire dâ€™intÃ©grationâ€¦)
- Un Ã©quilibre vie pro/vie perso respectÃ© (tÃ©lÃ©travail, charte de droit Ã  la dÃ©connexionâ€¦)
- Lâ€™universitÃ© CGI permettant de dÃ©velopper et dâ€™acquÃ©rir de nouvelles compÃ©tences
- De nombreux avantages sociaux (RÃ©gime dâ€™Achat dâ€™Action, forfait mobilitÃ© durable, mutuelle Ã  100%â€¦)
- Une politique RSE ambitieuse (MÃ©cÃ©nat de CompÃ©tences, clean walkâ€¦)
- Une Mission Emploi Handicap trÃ¨s dÃ©veloppÃ©e

PrÃªt Ã  en discuter ?
Voir plus"
Senior Data Engineer AWS - Cloud Data F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Vous Ãªtes passionnÃ©(e) par le domaine de la Data et avez dÃ©jÃ  une expÃ©rience significative sur des problÃ©matiques de data engineering : construction de pipelines de donnÃ©es (batch/streaming), industrialisation dâ€™applications data science, modÃ©lisation de base de donnÃ©es, â€¦
Vous disposez de solides connaissances sur les architectures de donnÃ©es AWS et le cloud. Vous Ãªtes certifiÃ©(e) et/ou avez de lâ€™expÃ©rience sur une ou plusieurs solutions cloud data AWS.

Vous souhaitez diversifier vos compÃ©tences pour Ãªtre toujours Ã  la pointe des nouvelles technologies et souhaitez rejoindre une entitÃ© spÃ©cialisÃ©e dans la data et lâ€™innovation (> 200 consultants) ? Vous Ã©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements mÃ©tiers variÃ©s avec un niveau de responsabilitÃ© Ã©levÃ©. Vous aurez Ã©galement la possibilitÃ© de monter en compÃ©tences sur dâ€™autres outils Cloud que ceux de votre domaine de compÃ©tences initial.

En tant que Senior Data Engineer, vous serez intÃ©grÃ©(e) dans un pÃ´le de consultants spÃ©cialistes de la Data intervenants sur des projets stimulants.

Vos missions seront :
- Analyser, conseiller, et faire des recommandations de faÃ§on Ã  amÃ©liorer l'efficience et l'efficacitÃ© des solutions mises en place
- Travailler en collaboration avec les ingÃ©nieurs techniques et autres experts afin de rechercher et fournir des rÃ©ponses aux problÃ©matiques techniques
- RÃ©aliser les travaux dâ€™implÃ©mentation des solutions (prÃ©paration des donnÃ©es, industrialisation des modÃ¨les, communications entre les diffÃ©rentes technologies,â€¦)
- Produire les projets en mode agile avec des processus et outils de dÃ©veloppement de derniÃ¨re gÃ©nÃ©ration (DevOps, Git, CI/CDâ€¦)
- Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique
- Animer des formations internes. Accompagner la montÃ©e en compÃ©tences des Ã©quipes
- Assurer un support technique aux Ã©quipes Data et aux clients au quotidien

AccompagnÃ©(e) et entourÃ©(e) par une communautÃ© Data passionnÃ©e, lâ€™Ã©change, le partage et les formations vous offriront un vÃ©ritable espace pour vous Ã©panouir. La proximitÃ© et le suivi personnalisÃ© de votre manager, puis un bon nombre dâ€™Ã©vÃ©nements tout au long de l'annÃ©e, renforceront encore la convivialitÃ© et lâ€™esprit d'Ã©quipe !

Fort(e) dâ€™une intÃ©gration rÃ©ussie, de nombreuses possibilitÃ©s dâ€™Ã©volutions de carriÃ¨re sâ€™offriront rapidement Ã  vous, dans lâ€™animation de la filiÃ¨re technique ou dans le consulting de solutions Data.

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
- PassionnÃ©(e) dâ€™informatique et de donnÃ©es, vous aimez le travail en Ã©quipe, apprendre et partager.
- Vous Ãªtes Ã©galement dotÃ©(e) d'un esprit audacieux et ambitieux.
- Vous faites preuve dâ€™initiative et travaillez sur le long terme.
- Vous avez un minimum de 5 annÃ©es dâ€™expÃ©rience sur des projets Data et idÃ©alement au moins trois annÃ©es dâ€™expÃ©rience sur des projets Cloud AWS (EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB, etc.) ou autres solutions hÃ©bergÃ©es sur une architecture AWS (Snowflake, Databricks, etc.);
- Vous maÃ®trisez au minimum deux langages de programmation (Spark, Scala, Python, Java, SQL)

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer Splunk F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Vous disposez dâ€™une connaissance approfondie de lâ€™Ã©cosystÃ¨me des solutions RTM du marchÃ© (Splunk (de prÃ©fÃ©rence), ELK, Dynatrace, â€¦) ainsi quâ€™une connaissance dâ€™un ou plusieurs outils de dÃ©ploiement automatisÃ©s et DevOps (DOCKER, ANSIBLE, KUBERNETESâ€¦).
Vous savez dÃ©velopper et manipuler des donnÃ©es grÃ¢ce aux langages Python et/ou Java et Javascript.

En tant que Data Engineer Splunk, vous intÃ¨grerez un pÃ´le de consultants spÃ©cialistes du Real Time Monitoring dâ€™une quarantaine de consultants basÃ©s sur les sites de CGI Montpelier et CGI Toulouse.
Vos missions seront les suivantes :
-Mener des ateliers fonctionnels, analyser et comprendre le besoin, synthÃ©tiser les aspects techniques et fonctionnels afin de mieux dÃ©finir la trajectoire de mise en Å“uvre de la solution Splunk chez nos clients
-Travailler en collaboration avec les ingÃ©nieurs techniques et autres experts afin de rechercher et fournir des rÃ©ponses aux problÃ©matiques techniques
-RÃ©aliser les travaux dâ€™implÃ©mentation de la solution SPLUNK :
ParamÃ©trage de la collecte de donnÃ©es
Structuration et normalisation
DÃ©veloppement de dashboard
DÃ©finition de la stratÃ©gie de migration
Configuration des algorithmes, notamment en vue de les adapter au Machine Learning, Deep Learning, etc.
PrÃ©paration des donnÃ©es
Bonnes pratiques de dÃ©veloppement et respect de conventions de nommage
Conception et mise en Å“uvre de nouveaux scÃ©narios de dÃ©tection
Optimisation des requÃªtes Splunk

-Produire les projets en mode agile avec des processus et outils de dÃ©veloppement de derniÃ¨re gÃ©nÃ©ration
-Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique
-Animer des formations internes. Accompagner la montÃ©e en compÃ©tences des Ã©quipes
-Assurer un support technique Splunk aux Ã©quipes et aux clients au quotidien

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
Vous justifiez de 3 Ã  5 ans d'expÃ©rience professionnelle au sein dâ€™une entreprise de services numÃ©riques ou dâ€™un cabinet de conseil dans le Domaine du Data Monitoring.

Vous Ãªtes ou avez :
-Esprit d'Ã©quipe
-Esprit audacieux et ambitieux
-Force de proposition
-Maitrise au moins d'une technologie Real Time Monitoring, de prÃ©fÃ©rence Splunk

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer Cloud Data - Azure F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Montpellier,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Vous Ãªtes passionnÃ©(e) par le domaine de la Data et avez dÃ©jÃ  une expÃ©rience significative sur des problÃ©matiques de data engineering : construction de pipelines de donnÃ©es (batch/streaming), industrialisation dâ€™applications data science, modÃ©lisation de base de donnÃ©es, â€¦
Vous disposez de solides connaissances sur les architectures de donnÃ©es et le cloud.
Vous Ãªtes certifiÃ©(e) et/ou avez de lâ€™expÃ©rience sur le cloud Azure dans le domaine de la data et vous maitrisez un ou plusieurs services : Snowflake, Synapse, Databricks, Azure DevOps, Terraform
Vous maitrisez les deux langages suivants : SQL, Python. La connaissance de PowerBI serait un plus.

Vos missions sont :
- Analyser, conseiller, et faire des recommandations de faÃ§on Ã  amÃ©liorer l'efficience et l'efficacitÃ© des solutions mises en place
- Travailler en collaboration avec les ingÃ©nieurs techniques et autres experts afin de rechercher et fournir des rÃ©ponses aux problÃ©matiques techniques
- RÃ©aliser les travaux dâ€™implÃ©mentation des solutions (prÃ©paration des donnÃ©es, industrialisation des modÃ¨les, communications entre les diffÃ©rentes technologies,â€¦)
- Produire les projets en mode agile avec des processus et outils de dÃ©veloppement de derniÃ¨re gÃ©nÃ©ration (DevOps, Git, CI/CDâ€¦)
- Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique
- Animer des formations internes.
- Accompagner la montÃ©e en compÃ©tences des Ã©quipes
- Assurer un support technique aux Ã©quipes Data et aux clients au quotidien

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
PassionnÃ©(e) dâ€™informatique et de donnÃ©es, vous aimez le travail en Ã©quipe, apprendre et partager. Vous Ãªtes Ã©galement dotÃ©(e) d'un esprit audacieux et ambitieux. Vous faites preuve dâ€™initiative et travaillez sur le long terme. Vous justifiez de 2 Ã  5 ans d'expÃ©rience professionnelle au sein dâ€™une entreprise de services numÃ©riques ou dâ€™un cabinet de conseil dans le Domaine du Data Engineering. Vous disposez d'une vision large des technologies et vous maÃ®trisez au moins une technologie Data dans le Cloud.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Lyon,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,,"Descriptif du poste
DÃ©veloppement, traitement de haute volumÃ©trie, cloud transformation/ migration seront autant dâ€™enjeux qui rythmeront votre quotidien aux cÃ´tÃ©s de nos professionnels.
Vous intÃ©grerez une Ã©quipe de taille humaine spÃ©cialisÃ©e sur les domaines de l'Energie, de la chimie & des mÃ©tiers de la santÃ©.

Aux cÃ´tÃ©s des autres membres de lâ€™Ã©quipe et de communautÃ© Data Grand-Est , vous perfectionnerez vos compÃ©tences pour devenir un Data Engineer senior sur les technologies les plus modernes du marchÃ© Data.

Au sein de lâ€™Ã©quipe, vous serez en interaction avec toutes les parties prenantes du projet, allant du business, aux Ã©quipes dâ€™expert et de dÃ©ploiement des solutions.
Vous participerez au dÃ©veloppement stratÃ©gique dâ€™un projet dâ€™un client et vous Ã©voluerez dans un contexte international, et bÃ©nÃ©ficierez de lâ€™expertise de consultants CGI, en immersion chez le client.

A ce titre vos principales responsabilitÃ©s seront :

â€¢ ApprÃ©hender le contexte et les enjeux MÃ©tier du client ;
â€¢ Comprendre et expÃ©rimenter le cadre Agile et Lean ;
â€¢ Analyser les besoins fonctionnels et dÃ©terminer le modÃ¨le de donnÃ©es nÃ©cessaire avec lâ€™accompagnement de Consultant senior ;
â€¢ Participer au dÃ©veloppement de ces indicateurs au sein de la plateforme Cloud cible (AWS, GCP , Azure) et des outils de restitution (ex : Power BI, Qliksense) ;
â€¢ Ã‰tablir et dÃ©rouler des scÃ©narios de tests ;
â€¢ Participer Ã  la vie de la communautÃ© Data.

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
â€¢ De formation bac+5 ou de formation supÃ©rieure en informatique, vous disposez de 2 ans expÃ©riences rÃ©ussie dans le dÃ©ploiement de plateforme de type Kafka , Datalake AWS , Datalake CGP ;
â€¢ Des connaissances mÃ©tiers dans le domaine de l'Energie, de la chimie & des mÃ©tiers de la santÃ© , alliÃ©s Ã  des compÃ©tences techniques fortes sont Ã©galement des atouts pour la rÃ©ussite de ce projet ;
â€¢ Votre capacitÃ© d'adaptation, votre autonomie, votre sens du service ainsi que vos qualitÃ©s relationnelles seront vos atouts pour rÃ©ussir et Ã©voluer ;
â€¢ Vous aimez Ã©voluer dans des contextes internationaux, avec une trÃ¨s bonne maitrise du franÃ§ais et de l'anglais Ã  lâ€™Ã©crit comme Ã  lâ€™oral.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin.

Rejoindre CGI, câ€™est :

- Des suivis rÃ©guliers avec son manager ;
- Un accÃ¨s Ã  une plateforme avec de nombreuses formations disponibles dÃ¨s son arrivÃ©e ;
- De nombreuses communautÃ©s techniques et mÃ©tiers ;
- Une mobilitÃ© interne facilitÃ©e ;
- Un programme de buddy pour Ãªtre accompagnÃ©(e) durant la premiÃ¨re annÃ©e chez CGI ;
- Un Ã©quilibre vie professionnelle /vie personnelle respectÃ© (dont 0 Ã  3 j de tÃ©lÃ©travail/semaine) ;
- Des Ã©vÃ©nements rÃ©guliers (sport, afterworks,â€¦) ;
- De nombreux avantages sociaux (RÃ©gime dâ€™Achat dâ€™Action, forfait mobilitÃ© durable, mutuelle Ã  100%â€¦) ;
- Une politique RSE ambitieuse ;
- Un programme de MÃ©cÃ©nat de CompÃ©tences ;
- Une Mission Emploi Handicap trÃ¨s dÃ©veloppÃ©e ;
Voir plus"
Data Engineer Cloud Data - Azure F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Tours,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Vous Ãªtes passionnÃ©(e) par le domaine de la Data et avez dÃ©jÃ  une expÃ©rience significative sur des problÃ©matiques de data engineering : construction de pipelines de donnÃ©es (batch/streaming), industrialisation dâ€™applications data science, modÃ©lisation de base de donnÃ©es, â€¦
Vous disposez de solides connaissances sur les architectures de donnÃ©es et le cloud.
Vous Ãªtes certifiÃ©(e) et/ou avez de lâ€™expÃ©rience sur le cloud Azure dans le domaine de la data et vous maitrisez un ou plusieurs services : Snowflake, Synapse, Databricks, Azure DevOps, Terraform
Vous maitrisez les deux langages suivants : SQL, Python. La connaissance de PowerBI serait un plus.

Vos missions sont :
- Analyser, conseiller, et faire des recommandations de faÃ§on Ã  amÃ©liorer l'efficience et l'efficacitÃ© des solutions mises en place
- Travailler en collaboration avec les ingÃ©nieurs techniques et autres experts afin de rechercher et fournir des rÃ©ponses aux problÃ©matiques techniques
- RÃ©aliser les travaux dâ€™implÃ©mentation des solutions (prÃ©paration des donnÃ©es, industrialisation des modÃ¨les, communications entre les diffÃ©rentes technologies,â€¦)
- Produire les projets en mode agile avec des processus et outils de dÃ©veloppement de derniÃ¨re gÃ©nÃ©ration (DevOps, Git, CI/CDâ€¦)
- Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique
- Animer des formations internes.
- Accompagner la montÃ©e en compÃ©tences des Ã©quipes
- Assurer un support technique aux Ã©quipes Data et aux clients au quotidien

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
PassionnÃ©(e) dâ€™informatique et de donnÃ©es, vous aimez le travail en Ã©quipe, apprendre et partager. Vous Ãªtes Ã©galement dotÃ©(e) d'un esprit audacieux et ambitieux. Vous faites preuve dâ€™initiative et travaillez sur le long terme. Vous justifiez de 2 Ã  5 ans d'expÃ©rience professionnelle au sein dâ€™une entreprise de services numÃ©riques ou dâ€™un cabinet de conseil dans le Domaine du Data Engineering. Vous disposez d'une vision large des technologies et vous maÃ®trisez au moins une technologie Data dans le Cloud.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer (F/M/D),"{'name': 'VESTIAIRE COLLECTIVE', 'sector': 'Luxe, Mode, E-commerce', 'employees': '800 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': '34 ans'}",Autres,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 2 ans,,"Descriptif du poste
Vestiaire Collective is the leading global online marketplace for desirable pre-loved fashion. Our mission is to transform the fashion industry for a more sustainable future by empowering our community to promote the circular fashion movement. Vestiaire was founded in 2009 and is headquartered in Paris with offices in London, Berlin, New York, Singapore, Ho Chi Minh and Hong Kong and warehouses in Tourcoing (France), Crawley (UK), Hong Kong and New York.
We currently have a diverse global team of 800 employees representing more than 50 nationalities. Our values are community, activism, transparency, dedication and greatness. We are proud to be a BCorp.
Data Engineer (F/M/D)
Permanent position based in Paris
About the role
You will be part of the CRM team as a Data Engineer, and your objective will be to ensure that data is properly orchestrated between our internal Data Platforms, and our CRM Tool (Braze) to have proper reporting and monitoring, so that our teams have the necessary tools to take the right decisions, as well as to get the right information to our users at the right time.
What youâ€™ll be doing
Co-creating and continuously developing the technical architecture of the Vestiaire Collective Data Platform
Setting up foundational data models as well as implementing data ingestion strategies for diverse data sources, such as internal databases, third-party sources, user data trackers that will then be used by analysts and business members,
Optimize, redesign and define best practices for data transformations and data model development in dbt for our analysts.
Maintaining and improving reverse ETL to feed our external platforms with the information needed for our CRM operations
Build new automations for manual processes to improve our team efficiency and speed up decision making
Working closely with Data Scientists to ensure smooth and quick implementation of algorithms in production
Implementing tools for task scheduling, data quality controls, stability monitoring and alerting
Continuous learning and staying up-to-date with the latest developments in the data technology space in order to keep the team ahead of the curve.
Who you are
2+ years of working experience, including work with relational databases, Hadoop, NOSQL and/or cloud infrastructure (e.g. AWS)
Educational background in Computer Science / Data Engineering / Data Science / Data analytics fields
Solid understanding of database concepts and experience with data processing tools (SQL, dbt...) - mandatory
Hands-on experience with at least one of the following: Python, Airflow, Kafka, K8S, Git and curiosity to learn others. Tableau & Braze are a plus.
Creative approach toward problem solving, passion for exploring new technologies
Experience with version control technology (Git)
Experience in creating and maintaining high volume data models
Experience designing and implementing a data warehouse, with modern BI architecture
Excellent communication skills
You do not need to be micromanaged; to accomplish team and company goals, you can wear multiple hats and pick up new technologies and languages.
You need to be able to defend your technical choice in English. French is a huge plus.
What we offer
A meaningful job with an impact on the way people consume fashion and promote sustainability
The opportunity to do career defining work in a fast growing French-born scale up
The possibility to work as part of a global diverse team with more than 50 nationalities
2 days to help Project - reinforcing your activist journey and volunteer for an association
Significant investment in your learning and growth
Competitive compensation and benefits package
Vestiaire Collective is an equal opportunities employer
Voir moins",
Senior Data Engineer (H/F),"{'name': 'PUBLICIS FRANCE', 'sector': 'Marketing / Communication, PublicitÃ©, Digital, Relations publiques, AdTech / MarTech, EvÃ©nementiel, Design', 'employees': '5000 collaborateurs', 'creation_year': '1926', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,,"Descriptif du poste
Capability
L'Ã©quipe Data est composÃ©e d'une quinzaine de collaborateurs regroupant Data Scientists, Data Engineers, Data Analysts et Data Strategists, travaillant sur la co-construction d'outils gÃ©nÃ©rant de la valeur Ã  partir de la donnÃ©e de nos clients.
Si vous aussi, vous partagez cette vision et souhaitez profiter et contribuer Ã  notre communautÃ© internationale sur le sujet, rejoignez-nous !
Vous interviendrez chez nos clients et serez en charge des missions suivantes : 
Travailler Ã©troitement avec les parties prenantes Ã  la comprÃ©hension fonctionnelle de leurs projets au travers dâ€™ateliers de spÃ©cification et de modÃ©lisation 
Construire des pipelines dâ€™ingestion, de transformation et de valorisation de leurs donnÃ©es au service de la rÃ©alisation de produits dÃ©cisionnels (BI), de data science/machine learning ou dâ€™analytique opÃ©rationnelle 
Sâ€™assurer de la qualitÃ© du code rÃ©alisÃ© en adÃ©quation avec les normes et standards du projet et mettre en place les tests de validation  
Documenter ces projets jusquâ€™Ã  leur industrialisation opÃ©rationnelle et le support nÃ©cessaire Ã  la vie du produit. 
Vous contribuerez Ã©galement Ã  la veille collective et Ã  lâ€™Ã©mulation commune lors de nos journÃ©es de partage au sein de la craft Data engineer, Ã  la rÃ©daction dâ€™articles ou Ã  la participation de projets internes.
Voir moins","Profil recherchÃ©
Vous disposez de plus de 3 ans dâ€™expÃ©rience dans la rÃ©alisation de pipelines de donnÃ©es, dans des contextes de construction de la plateforme data Ã  lâ€™Ã©chelle, dont notammentâ€¯dans lâ€™usage des technologies suivantesâ€¯: 
Python 3â€¯: programmation de traitement de la donnÃ©e sous la forme de Notebook, utilisant des librairies orientÃ©es data et analytique tels que PySpark et/ou Panda, en mode batch ou streaming 
SQL pour manipuler les donnÃ©es stockÃ©es et rÃ©aliser des traitements de transformation avancÃ©es et Ã  lâ€™Ã©chelle 
Collecte et publication utilisant les protocoles de brokers de messages en streaming tels que Kafka, API REST, GRPC, fichiers avec SFTP ou Objet (S3, GCS, ADLS) 
Formatage de la donnÃ©e JSON, Avro ou Parquet et SQL Apache Iceberg, Delta Lake 
Cloud native platform AWS (S3, Glue, Athena, RDS, Kinesis, ...), GCP (Cloud Storage, Big Query, Pub/Sub, Data Flow), Azure (ADLS, Synapse, Stream Analytics) 
Principes dâ€™automatisation et de gestion de release, usage dâ€™outillage de gestion de configuration et de pipeline de CI/CD. 
Enfin, vous Ãªtes force de proposition, vous travaillez avec exigence de qualitÃ©, ouverture et bienveillance. 
Voir plus"
Senior Data Engineer (H/F),"{'name': 'PUBLICIS SAPIENT', 'sector': 'IT / Digital', 'employees': '300 collaborateurs', 'creation_year': '1996', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,,"Descriptif du poste
Capability
L'Ã©quipe Data est composÃ©e d'une quinzaine de collaborateurs regroupant Data Scientists, Data Engineers, Data Analysts et Data Strategists, travaillant sur la co-construction d'outils gÃ©nÃ©rant de la valeur Ã  partir de la donnÃ©e de nos clients.
Si vous aussi, vous partagez cette vision et souhaitez profiter et contribuer Ã  notre communautÃ© internationale sur le sujet, rejoignez-nous !
Vous interviendrez chez nos clients et serez en charge des missions suivantes : 
Travailler Ã©troitement avec les parties prenantes Ã  la comprÃ©hension fonctionnelle de leurs projets au travers dâ€™ateliers de spÃ©cification et de modÃ©lisation 
Construire des pipelines dâ€™ingestion, de transformation et de valorisation de leurs donnÃ©es au service de la rÃ©alisation de produits dÃ©cisionnels (BI), de data science/machine learning ou dâ€™analytique opÃ©rationnelle 
Sâ€™assurer de la qualitÃ© du code rÃ©alisÃ© en adÃ©quation avec les normes et standards du projet et mettre en place les tests de validation  
Documenter ces projets jusquâ€™Ã  leur industrialisation opÃ©rationnelle et le support nÃ©cessaire Ã  la vie du produit. 
Vous contribuerez Ã©galement Ã  la veille collective et Ã  lâ€™Ã©mulation commune lors de nos journÃ©es de partage au sein de la craft Data engineer, Ã  la rÃ©daction dâ€™articles ou Ã  la participation de projets internes.
Voir moins","Profil recherchÃ©
Vous disposez de plus de 3 ans dâ€™expÃ©rience dans la rÃ©alisation de pipelines de donnÃ©es, dans des contextes de construction de la plateforme data Ã  lâ€™Ã©chelle, dont notammentâ€¯dans lâ€™usage des technologies suivantesâ€¯: 
Python 3â€¯: programmation de traitement de la donnÃ©e sous la forme de Notebook, utilisant des librairies orientÃ©es data et analytique tels que PySpark et/ou Panda, en mode batch ou streaming 
SQL pour manipuler les donnÃ©es stockÃ©es et rÃ©aliser des traitements de transformation avancÃ©es et Ã  lâ€™Ã©chelle 
Collecte et publication utilisant les protocoles de brokers de messages en streaming tels que Kafka, API REST, GRPC, fichiers avec SFTP ou Objet (S3, GCS, ADLS) 
Formatage de la donnÃ©e JSON, Avro ou Parquet et SQL Apache Iceberg, Delta Lake 
Cloud native platform AWS (S3, Glue, Athena, RDS, Kinesis, ...), GCP (Cloud Storage, Big Query, Pub/Sub, Data Flow), Azure (ADLS, Synapse, Stream Analytics) 
Principes dâ€™automatisation et de gestion de release, usage dâ€™outillage de gestion de configuration et de pipeline de CI/CD. 
Enfin, vous Ãªtes force de proposition, vous travaillez avec exigence de qualitÃ©, ouverture et bienveillance. 
Voir plus"
Data Engineer,"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, CybersÃ©curitÃ©', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232Mâ‚¬', 'mean_age': None}",CDI,Sophia-Antipolis,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,,"Descriptif du poste
ğŸ’¥ DÃ©couvrez la Vie Apsidienne ğŸ“¹ et vous aussi, devenez Apsidien //
On aurait pu demander Ã  Chat GPT de vous dÃ©montrer en quoi Apside est lâ€™ESN quâ€™il vous faut, mais on prÃ©fÃ¨re que vous le dÃ©couvriez vous-mÃªmes ğŸ‘‡ğŸ˜
ğŸ”¥ DÃ©couvrez votre future missionâ€¯//
ğŸ‘‰ Contexte
Collaborateur(rice) Apsidien(ne) de lâ€™agence de Sophia-Antipolis, vous accompagnez lâ€™un de nos clients en tant que Data Engineer (F/H).
ğŸ˜ Mission
IntÃ©grÃ©(e) au sein d'une Ã©quipe Agile, vous Ãªtes responsable de la collecte, du stockage, du traitement et de la distribution des donnÃ©es chez le client.
Collecter et stocker les donnÃ©es provenant de diffÃ©rentes sources
PrÃ©parer les donnÃ©es pour les analyses
DÃ©velopper et maintenir les pipelines de donnÃ©es
Construire et maintenir les bases de donnÃ©es
Partager les donnÃ©es avec les utilisateurs finaux
ğŸ“ Localisation
TechnopÃ´le de Sophia-Antipolis
TÃ©lÃ©travail hybride
ğŸ’° Le package salarial que nous vous proposons //
Contratâ€¯: CDI
RÃ©munÃ©rationâ€¯: selon profil
(Dâ€™abord on Ã©change, on comprend vos compÃ©tences/aspirations professionnelles et ensuite on sâ€™entend sur le salaire.â€¯ğŸ˜Š)
Avantages groupeâ€¯: carte ticket restaurant Swile, prime de mobilitÃ©, RTT, accord tÃ©lÃ©travail, Mutuelle, prime de cooptationâ€¦
Formationâ€¯: certifications techniques, cours particuliers dâ€™anglais en interne, accÃ¨s Ã  un catalogue de formations grÃ¢ce Ã  notre plateforme en e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherchÃ©
ğŸ”® Ã” vous futur Apsidien, qui Ãªtes-vousâ€¯? //
Issu(e) dâ€™une Grande Ecole avec un parcours spÃ©cialisÃ© Data, ou Master Data avec 3 ans d'expÃ©rience
Une expÃ©rience rÃ©ussie est fortement apprÃ©ciÃ©e
CompÃ©tences techniques :
Kafka, Spark, Spark Streaming â€¦
Hadoop
SQL, PostgreSQL, MongoDB, APIs
Connaissances Scala apprÃ©ciÃ©es
Anglais courant obligatoire
Travail en contexte agile, scrum
ğŸ˜ Apside a suscitÃ© votre curiositÃ©â€¯?//
Dans un environnement marquÃ© par une accÃ©lÃ©ration des Ã©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients Ã  crÃ©er de la valeur et Ã  adresser leurs enjeux stratÃ©giques en leur mettant Ã  disposition des expertises technologiques () et une expÃ©rience sectorielle (). Pour un accompagnement global, le groupe propose des offres transverses autour du (Apsidâ€™EA), du , et du .
Voir plus"
,,,,,,,,,,
Data Engineer Splunk F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Vous disposez dâ€™une connaissance approfondie de lâ€™Ã©cosystÃ¨me des solutions RTM du marchÃ© (Splunk (de prÃ©fÃ©rence), ELK, Dynatrace, â€¦) ainsi quâ€™une connaissance dâ€™un ou plusieurs outils de dÃ©ploiement automatisÃ©s et DevOps (DOCKER, ANSIBLE, KUBERNETESâ€¦).
Vous savez dÃ©velopper et manipuler des donnÃ©es grÃ¢ce aux langages Python et/ou Java et Javascript.

En tant que Data Engineer Splunk, vous intÃ¨grerez un pÃ´le de consultants spÃ©cialistes du Real Time Monitoring dâ€™une quarantaine de consultants basÃ©s sur les sites de CGI Montpelier et CGI Toulouse.
Vos missions seront les suivantes :
-Mener des ateliers fonctionnels, analyser et comprendre le besoin, synthÃ©tiser les aspects techniques et fonctionnels afin de mieux dÃ©finir la trajectoire de mise en Å“uvre de la solution Splunk chez nos clients
-Travailler en collaboration avec les ingÃ©nieurs techniques et autres experts afin de rechercher et fournir des rÃ©ponses aux problÃ©matiques techniques
-RÃ©aliser les travaux dâ€™implÃ©mentation de la solution SPLUNK :
ParamÃ©trage de la collecte de donnÃ©es
Structuration et normalisation
DÃ©veloppement de dashboard
DÃ©finition de la stratÃ©gie de migration
Configuration des algorithmes, notamment en vue de les adapter au Machine Learning, Deep Learning, etc.
PrÃ©paration des donnÃ©es
Bonnes pratiques de dÃ©veloppement et respect de conventions de nommage
Conception et mise en Å“uvre de nouveaux scÃ©narios de dÃ©tection
Optimisation des requÃªtes Splunk

-Produire les projets en mode agile avec des processus et outils de dÃ©veloppement de derniÃ¨re gÃ©nÃ©ration
-Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique
-Animer des formations internes. Accompagner la montÃ©e en compÃ©tences des Ã©quipes
-Assurer un support technique Splunk aux Ã©quipes et aux clients au quotidien

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
Vous justifiez de 3 Ã  5 ans d'expÃ©rience professionnelle au sein dâ€™une entreprise de services numÃ©riques ou dâ€™un cabinet de conseil dans le Domaine du Data Monitoring.

Vous Ãªtes ou avez :
-Esprit d'Ã©quipe
-Esprit audacieux et ambitieux
-Force de proposition
-Maitrise au moins d'une technologie Real Time Monitoring, de prÃ©fÃ©rence Splunk

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Niort,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Vos responsabilitÃ©s seront les suivantes:

-Maintenir et dÃ©velopper des solutions basÃ©es sur les services AWS pour le stockage, le traitement et l'analyse de donnÃ©es
-Utiliser les services AWS appropriÃ©s tels que Amazon EC2, S3, RDS, Lambda, etc., pour rÃ©pondre aux exigences du projet.
-CrÃ©er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS
-Participer Ã  la maintenance et Ã  la mise en place d'environnements OpenShift pour l'hÃ©bergement d'applications et de services
-GÃ©rer et administrer les clusters Kafka pour garantir la disponibilitÃ©, la performance et la sÃ©curitÃ© du systÃ¨me de messagerie
Participer Ã  lâ€™assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data
-Travailler avec les projets et les devOps pour assurer un traitement efficace des donnÃ©es

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
Ayant une premiÃ¨re expÃ©rience en tant que Data Engineer, vous avez une premiÃ¨re expÃ©rience relative aux points suivants:
-DÃ©veloppement et intÃ©gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop
-Connaissance avancÃ©e de l'administration Kafka, y compris la configuration, la gestion et la rÃ©solution des problÃ¨mes
-Mise en Å“uvre de l'infrastructure en tant que code Ã  l'aide de Terraform
-Bonne comprÃ©hension des bonnes pratiques de sÃ©curitÃ© pour les systÃ¨mes cloud, les clusters Kafka et les plateformes Hadoop

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer Microsoft Azure F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Lyon,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Le poste de Data Engineer est Ã  pourvoir dans notre Ã©quipe de 6 personnes basÃ©e Ã  LYON. Câ€™est une mission Ã  durÃ©e indÃ©terminÃ©e dans un contexte internationale car les clients sont suisses ou hollandais. Pas de prÃ©sence sur le site client, cela se dÃ©roulera dans les locaux de lâ€™agence CGI de Lyon;

En tant que Data Engineer, vous serez au cÅ“ur de la transformation digitale des entreprises et de la sociÃ©tÃ©.
DÃ©veloppement, ingestion et traitement de donnÃ©es, cloud transformation/ migration seront autant dâ€™enjeux qui rythmeront votre quotidien aux cÃ´tÃ©s de nos professionnels.
Vous intÃ©grerez une Ã©quipe de taille humaine spÃ©cialisÃ©e sur les domaines de la chimie & du manufacturing.
Aux cÃ´tÃ©s des autres membres de lâ€™Ã©quipe et de la communautÃ© Data Grand-Est, vous perfectionnerez vos compÃ©tences pour devenir un Data Engineer senior sur les technologies les plus modernes du marchÃ© Data Ã  lâ€™internationale.
Au sein de lâ€™Ã©quipe de support, vous serez en interaction avec toutes les parties prenantes du client, allant du business, aux Ã©quipes dâ€™expert et de dÃ©ploiement des solutions.
Vous participerez au maintien en condition opÃ©rationnelle de la plateforme data de nos clients et vous Ã©voluerez dans un contexte international, et bÃ©nÃ©ficierez de lâ€™expertise de consultants CGI

ResponsabilitÃ©s et tÃ¢ches principales :

â€¢ ApprÃ©hender le contexte client ;
â€¢ Comprendre et expÃ©rimenter le cadre Agile ;
â€¢ Traiter les demandes clients et la maintenance du pÃ©rimÃ¨tre cloud data en place ;
â€¢ Analyser les besoins fonctionnels et dÃ©terminer le modÃ¨le de donnÃ©es nÃ©cessaire avec lâ€™accompagnement de Consultants seniors ;
â€¢ Participer au dÃ©veloppement de ces indicateurs au sein de la plateforme Cloud cible (Azure et AWS) et des outils de restitution (ex : Power BI, Tableau, Qliksense) ;
â€¢ Ã‰tablir et dÃ©rouler des scÃ©narios de tests ;
â€¢ Participer Ã  la vie de la communautÃ© Data.


Environnement technique :

â€¢ Cloud provider : Azure, AWS
â€¢ Data Acquisition : Spark, Azure Data Factory, Synapse, Talend
â€¢ Base de donnÃ©es : SQL Server, PostgreSQL
â€¢ Script : JSON, SQL, Python, Shell, Javascript
â€¢ Environnement : Linux, Docker, Kubernetes
â€¢ Outils : DevOps, GITLAB CI
â€¢ Ticketing : Service Now
â€¢ Reporting: Power BI, Tableau, Qliksense
â€¢ Langue : Anglais courant souhaitÃ©

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
De formation bac+5 ou de formation supÃ©rieure en informatique, vous disposez de 5 ans expÃ©riences rÃ©ussies dans le design et lâ€™implÃ©mentation de plateforme de type Data Warehouse ET Data LakeCloud.
Des connaissances mÃ©tiers dans le domaine de lâ€™Ã©nergie et alliÃ©s Ã  des compÃ©tences techniques fortes sont Ã©galement des atouts pour la rÃ©ussite de ce projet.
Votre capacitÃ© d'adaptation, votre autonomie, votre sens du service ainsi que vos qualitÃ©s relationnelles seront vos atouts pour rÃ©ussir et Ã©voluer.
Vous devrez Ãªtre en capacitÃ© de participer voire animer des ateliers en anglais.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Nantes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Sous la responsabilitÃ© d'un Chef de Projet / Scrum Master, vos principales missions sont :
- Analyser, conseiller, et faire des recommandations de faÃ§on Ã  amÃ©liorer l'efficience et l'efficacitÃ© des solutions techniques mises en place
- Recueillir les besoins mÃ©tiers et des Ã©quipes data
- Assurer une veille technologique rÃ©guliÃ¨re
- Concevoir et mettre en place les traitements de donnÃ©es
- Tester et valider les dÃ©veloppements rÃ©alisÃ©s
- RÃ©aliser la documentation technique des dÃ©veloppements rÃ©alisÃ©s
- Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique dans le cadre du projet
- DÃ©velopper ses compÃ©tences et connaissances des architectures Data
- Etre garant de la mise en place, du suivi et de l'exploitation des outils dÃ©ployÃ©s

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦). 
Voir moins","Profil recherchÃ©
De formation Bac +5, vous disposez d'une expÃ©rience d'au moins deux ans dans la conception et le dÃ©veloppement.

Vous maÃ®trisez un ou plusieurs ETL.

VÃ©ritable passionnÃ©, vous Ãªtes rigoureux et dotÃ© d'un bon sens de la collaboration.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer Cloud Data - Azure F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Vous Ãªtes passionnÃ©(e) par le domaine de la Data et avez dÃ©jÃ  une expÃ©rience significative sur des problÃ©matiques de data engineering : construction de pipelines de donnÃ©es (batch/streaming), industrialisation dâ€™applications data science, modÃ©lisation de base de donnÃ©es, â€¦
Vous disposez de solides connaissances sur les architectures de donnÃ©es et le cloud.
Vous Ãªtes certifiÃ©(e) et/ou avez de lâ€™expÃ©rience sur le cloud Azure dans le domaine de la data et vous maitrisez un ou plusieurs services : Snowflake, Synapse, Databricks, Azure DevOps, Terraform
Vous maitrisez les deux langages suivants : SQL, Python. La connaissance de PowerBI serait un plus.

Vos missions sont :
- Analyser, conseiller, et faire des recommandations de faÃ§on Ã  amÃ©liorer l'efficience et l'efficacitÃ© des solutions mises en place
- Travailler en collaboration avec les ingÃ©nieurs techniques et autres experts afin de rechercher et fournir des rÃ©ponses aux problÃ©matiques techniques
- RÃ©aliser les travaux dâ€™implÃ©mentation des solutions (prÃ©paration des donnÃ©es, industrialisation des modÃ¨les, communications entre les diffÃ©rentes technologies,â€¦)
- Produire les projets en mode agile avec des processus et outils de dÃ©veloppement de derniÃ¨re gÃ©nÃ©ration (DevOps, Git, CI/CDâ€¦)
- Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique
- Animer des formations internes.
- Accompagner la montÃ©e en compÃ©tences des Ã©quipes
- Assurer un support technique aux Ã©quipes Data et aux clients au quotidien

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
PassionnÃ©(e) dâ€™informatique et de donnÃ©es, vous aimez le travail en Ã©quipe, apprendre et partager. Vous Ãªtes Ã©galement dotÃ©(e) d'un esprit audacieux et ambitieux. Vous faites preuve dâ€™initiative et travaillez sur le long terme. Vous justifiez de 2 Ã  5 ans d'expÃ©rience professionnelle au sein dâ€™une entreprise de services numÃ©riques ou dâ€™un cabinet de conseil dans le Domaine du Data Engineering. Vous disposez d'une vision large des technologies et vous maÃ®trisez au moins une technologie Data dans le Cloud.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Alors venez rejoindre nos Ã©quipes de Data Engineer. Vous pouvez Ãªtre amenÃ© Ã  intervenir sur tout ou partie de ces missions :

- ModÃ©lisation des Data Concepts d'un DataLake
- DÃ©veloppement et maintenance des traitements d'intÃ©gration et de transformation de donnÃ©es
- IntÃ©gration des dÃ©veloppements dans la chaine CI/CD
- Documentation technique et fonctionnelle
- RÃ©daction de plan de tests
- RÃ©alisation de tests unitaires/qualifications

Au sein de la communautÃ© Data, vous serez accompagnÃ© et vous pourrez Ã©changer avec des collÃ¨gues expÃ©rimentÃ©s et experts vous permettant de vous dÃ©velopper, de grandir et dâ€™accomplir pleinement vos missions de conseil.
Lâ€™accompagnement managÃ©rial, la communautÃ© Data et de nombreux Ã©vÃ¨nements tout au long de lâ€™annÃ©e nous permettront de vous aider Ã  atteindre vos objectifs dans un esprit de convivialitÃ©.

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
Vous avez une formation Bac+3/5 en informatique, au minimum 1 an dâ€™expÃ©rience et des aptitudes sur lâ€™un ou plusieurs des domaines suivants :

Vous maitrisez :
- Data Visualisation : Power BI, MicroStrategy, Tableau, Cognosâ€¦
- Langages : SQL, Python, DAX, Râ€¦
- Applications Cloud : Azure, Snowflake, Databricks, AWSâ€¦
- Bases de donnÃ©es : Oracle, PostgreSQL, MySQL, Mongo db, Sybaseâ€¦
- ETL : Datastage, Talend, Informatica (PowerCenter) â€¦

Vous avez/ Vous Ãªtes :
- PassionnÃ© du monde de la data
- Curieux et apprÃ©ciez le travail en Ã©quipe

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin.
Voir plus"
Data Engineer - Financial Services F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 3 ans,,"Descriptif du poste
Vos responsabilitÃ©s sont les suivantes :

- Concevoir, dÃ©velopper et dÃ©ployer des pipelines de transformations de donnÃ©es en environnement Big Data
- DÃ©finir des solutions globales permettant de rÃ©pondre aux besoins mÃ©tiers en prenant en compte les problÃ©matiques de performances, dâ€™industrialisation, dâ€™exploitation et de sÃ©curitÃ©.
- ParamÃ©trer et maintenir des clusters Big Data (MapR, Cloudera), ou des composants connexes (Nifi, Kafka, â€¦)
- Faire des prototypes sur des technologies et de la veille technologique sur le Big Data
- Accompagner & supporter les Ã©quipes projet en coaching et expertise
- Animer et faire progresser des juniors et stagiaires
- Assurer le rÃ´le de Lead Tech dans une Ã©quipe

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
De formation Bac+5 option informatique en Ã©cole dâ€™IngÃ©nieurs ou Ã©quivalent avec une expÃ©rience dâ€™au moins 3 ans dâ€™expÃ©rience sur des fonctions IT de conception / dÃ©veloppement en environnement Big Data.

Vous maÃ®trisez les compÃ©tences suivantes autour des produits Data / Big Data :
- Solution Hadoop (HDFS, YARN, Hive, Hue, Oozieâ€¦) et outillage associÃ©
- PySpark, Python
- Bases NoSQL (Mongo, HBase, Couchbase, Marklogicâ€¦)
- Anglais niveau B2
- CompÃ©tences de Tech Lead apprÃ©ciÃ©es : une capacitÃ© Ã  coacher des juniors voire dâ€™encadrer une Ã©quipe

Vous avez :
- Une excellente organisation
- Un sens des prioritÃ©s

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin.
Voir plus"
Senior Data Engineer AWS - Cloud Data F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Tours,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Vous Ãªtes passionnÃ©(e) par le domaine de la Data et avez dÃ©jÃ  une expÃ©rience significative sur des problÃ©matiques de data engineering : construction de pipelines de donnÃ©es (batch/streaming), industrialisation dâ€™applications data science, modÃ©lisation de base de donnÃ©es, â€¦
Vous disposez de solides connaissances sur les architectures de donnÃ©es AWS et le cloud. Vous Ãªtes certifiÃ©(e) et/ou avez de lâ€™expÃ©rience sur une ou plusieurs solutions cloud data AWS.

Vous souhaitez diversifier vos compÃ©tences pour Ãªtre toujours Ã  la pointe des nouvelles technologies et souhaitez rejoindre une entitÃ© spÃ©cialisÃ©e dans la data et lâ€™innovation (> 200 consultants) ? Vous Ã©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements mÃ©tiers variÃ©s avec un niveau de responsabilitÃ© Ã©levÃ©. Vous aurez Ã©galement la possibilitÃ© de monter en compÃ©tences sur dâ€™autres outils Cloud que ceux de votre domaine de compÃ©tences initial.

En tant que Senior Data Engineer, vous serez intÃ©grÃ©(e) dans un pÃ´le de consultants spÃ©cialistes de la Data intervenants sur des projets stimulants.

Vos missions seront :
- Analyser, conseiller, et faire des recommandations de faÃ§on Ã  amÃ©liorer l'efficience et l'efficacitÃ© des solutions mises en place
- Travailler en collaboration avec les ingÃ©nieurs techniques et autres experts afin de rechercher et fournir des rÃ©ponses aux problÃ©matiques techniques
- RÃ©aliser les travaux dâ€™implÃ©mentation des solutions (prÃ©paration des donnÃ©es, industrialisation des modÃ¨les, communications entre les diffÃ©rentes technologies,â€¦)
- Produire les projets en mode agile avec des processus et outils de dÃ©veloppement de derniÃ¨re gÃ©nÃ©ration (DevOps, Git, CI/CDâ€¦)
- Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique
- Animer des formations internes. Accompagner la montÃ©e en compÃ©tences des Ã©quipes
- Assurer un support technique aux Ã©quipes Data et aux clients au quotidien

AccompagnÃ©(e) et entourÃ©(e) par une communautÃ© Data passionnÃ©e, lâ€™Ã©change, le partage et les formations vous offriront un vÃ©ritable espace pour vous Ã©panouir. La proximitÃ© et le suivi personnalisÃ© de votre manager, puis un bon nombre dâ€™Ã©vÃ©nements tout au long de l'annÃ©e, renforceront encore la convivialitÃ© et lâ€™esprit d'Ã©quipe !

Fort(e) dâ€™une intÃ©gration rÃ©ussie, de nombreuses possibilitÃ©s dâ€™Ã©volutions de carriÃ¨re sâ€™offriront rapidement Ã  vous, dans lâ€™animation de la filiÃ¨re technique ou dans le consulting de solutions Data.

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
- PassionnÃ©(e) dâ€™informatique et de donnÃ©es, vous aimez le travail en Ã©quipe, apprendre et partager.
- Vous Ãªtes Ã©galement dotÃ©(e) d'un esprit audacieux et ambitieux.
- Vous faites preuve dâ€™initiative et travaillez sur le long terme.
- Vous avez un minimum de 5 annÃ©es dâ€™expÃ©rience sur des projets Data et idÃ©alement au moins trois annÃ©es dâ€™expÃ©rience sur des projets Cloud AWS (EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB, etc.) ou autres solutions hÃ©bergÃ©es sur une architecture AWS (Snowflake, Databricks, etc.);
- Vous maÃ®trisez au minimum deux langages de programmation (Spark, Scala, Python, Java, SQL)

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Data Engineer Cloud Data - Azure F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Vous Ãªtes passionnÃ©(e) par le domaine de la Data et avez dÃ©jÃ  une expÃ©rience significative sur des problÃ©matiques de data engineering : construction de pipelines de donnÃ©es (batch/streaming), industrialisation dâ€™applications data science, modÃ©lisation de base de donnÃ©es, â€¦
Vous disposez de solides connaissances sur les architectures de donnÃ©es et le cloud.
Vous Ãªtes certifiÃ©(e) et/ou avez de lâ€™expÃ©rience sur le cloud Azure dans le domaine de la data et vous maitrisez un ou plusieurs services : Snowflake, Synapse, Databricks, Azure DevOps, Terraform
Vous maitrisez les deux langages suivants : SQL, Python. La connaissance de PowerBI serait un plus.

Vos missions sont :
- Analyser, conseiller, et faire des recommandations de faÃ§on Ã  amÃ©liorer l'efficience et l'efficacitÃ© des solutions mises en place
- Travailler en collaboration avec les ingÃ©nieurs techniques et autres experts afin de rechercher et fournir des rÃ©ponses aux problÃ©matiques techniques
- RÃ©aliser les travaux dâ€™implÃ©mentation des solutions (prÃ©paration des donnÃ©es, industrialisation des modÃ¨les, communications entre les diffÃ©rentes technologies,â€¦)
- Produire les projets en mode agile avec des processus et outils de dÃ©veloppement de derniÃ¨re gÃ©nÃ©ration (DevOps, Git, CI/CDâ€¦)
- Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique
- Animer des formations internes.
- Accompagner la montÃ©e en compÃ©tences des Ã©quipes
- Assurer un support technique aux Ã©quipes Data et aux clients au quotidien

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
PassionnÃ©(e) dâ€™informatique et de donnÃ©es, vous aimez le travail en Ã©quipe, apprendre et partager. Vous Ãªtes Ã©galement dotÃ©(e) d'un esprit audacieux et ambitieux. Vous faites preuve dâ€™initiative et travaillez sur le long terme. Vous justifiez de 2 Ã  5 ans d'expÃ©rience professionnelle au sein dâ€™une entreprise de services numÃ©riques ou dâ€™un cabinet de conseil dans le Domaine du Data Engineering. Vous disposez d'une vision large des technologies et vous maÃ®trisez au moins une technologie Data dans le Cloud.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Senior Data Engineer AWS - Cloud Data F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds â‚¬ en 2022', 'mean_age': '36 ans'}",CDI,Montpellier,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Vous Ãªtes passionnÃ©(e) par le domaine de la Data et avez dÃ©jÃ  une expÃ©rience significative sur des problÃ©matiques de data engineering : construction de pipelines de donnÃ©es (batch/streaming), industrialisation dâ€™applications data science, modÃ©lisation de base de donnÃ©es, â€¦
Vous disposez de solides connaissances sur les architectures de donnÃ©es AWS et le cloud. Vous Ãªtes certifiÃ©(e) et/ou avez de lâ€™expÃ©rience sur une ou plusieurs solutions cloud data AWS.

Vous souhaitez diversifier vos compÃ©tences pour Ãªtre toujours Ã  la pointe des nouvelles technologies et souhaitez rejoindre une entitÃ© spÃ©cialisÃ©e dans la data et lâ€™innovation (> 200 consultants) ? Vous Ã©voluerez sur des projets d'envergure nationaux et internationaux, dans des environnements mÃ©tiers variÃ©s avec un niveau de responsabilitÃ© Ã©levÃ©. Vous aurez Ã©galement la possibilitÃ© de monter en compÃ©tences sur dâ€™autres outils Cloud que ceux de votre domaine de compÃ©tences initial.

En tant que Senior Data Engineer, vous serez intÃ©grÃ©(e) dans un pÃ´le de consultants spÃ©cialistes de la Data intervenants sur des projets stimulants.

Vos missions seront :
- Analyser, conseiller, et faire des recommandations de faÃ§on Ã  amÃ©liorer l'efficience et l'efficacitÃ© des solutions mises en place
- Travailler en collaboration avec les ingÃ©nieurs techniques et autres experts afin de rechercher et fournir des rÃ©ponses aux problÃ©matiques techniques
- RÃ©aliser les travaux dâ€™implÃ©mentation des solutions (prÃ©paration des donnÃ©es, industrialisation des modÃ¨les, communications entre les diffÃ©rentes technologies,â€¦)
- Produire les projets en mode agile avec des processus et outils de dÃ©veloppement de derniÃ¨re gÃ©nÃ©ration (DevOps, Git, CI/CDâ€¦)
- Participer Ã  l'Ã©laboration et la rÃ©vision de normes / documentation technique
- Animer des formations internes. Accompagner la montÃ©e en compÃ©tences des Ã©quipes
- Assurer un support technique aux Ã©quipes Data et aux clients au quotidien

AccompagnÃ©(e) et entourÃ©(e) par une communautÃ© Data passionnÃ©e, lâ€™Ã©change, le partage et les formations vous offriront un vÃ©ritable espace pour vous Ã©panouir. La proximitÃ© et le suivi personnalisÃ© de votre manager, puis un bon nombre dâ€™Ã©vÃ©nements tout au long de l'annÃ©e, renforceront encore la convivialitÃ© et lâ€™esprit d'Ã©quipe !

Fort(e) dâ€™une intÃ©gration rÃ©ussie, de nombreuses possibilitÃ©s dâ€™Ã©volutions de carriÃ¨re sâ€™offriront rapidement Ã  vous, dans lâ€™animation de la filiÃ¨re technique ou dans le consulting de solutions Data.

En rejoignant CGI, vous bÃ©nÃ©ficiez notamment dâ€™une offre complÃ¨te de formations (techniques, mÃ©tiers, dÃ©veloppement personnel,â€¦), de flexibilitÃ© grÃ¢ce Ã  notre accord tÃ©lÃ©travail (jusquâ€™Ã  3 jours de tÃ©lÃ©travail par semaine), dâ€™une politique de congÃ©s avantageuse (27 jours de congÃ©s payÃ©s, RTT, congÃ©s anciennetÃ© et enfant malade,â€¦) et dâ€™un package dâ€™avantages intÃ©ressant (rÃ©gime dâ€™achats dâ€™actions, participation, CSE,â€¦).
Voir moins","Profil recherchÃ©
- PassionnÃ©(e) dâ€™informatique et de donnÃ©es, vous aimez le travail en Ã©quipe, apprendre et partager.
- Vous Ãªtes Ã©galement dotÃ©(e) d'un esprit audacieux et ambitieux.
- Vous faites preuve dâ€™initiative et travaillez sur le long terme.
- Vous avez un minimum de 5 annÃ©es dâ€™expÃ©rience sur des projets Data et idÃ©alement au moins trois annÃ©es dâ€™expÃ©rience sur des projets Cloud AWS (EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB, etc.) ou autres solutions hÃ©bergÃ©es sur une architecture AWS (Snowflake, Databricks, etc.);
- Vous maÃ®trisez au minimum deux langages de programmation (Spark, Scala, Python, Java, SQL)

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, Ã  lâ€™Ã©volution de carriÃ¨res des hommes et des femmes et au bien-Ãªtre de nos salariÃ©s LGBT+. Dans un souci dâ€™accessibilitÃ© et de clartÃ©, le point mÃ©dian nâ€™est pas utilisÃ© dans cette annonce. Tous les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin."
Big Data Engineer,"{'name': 'EQUATIV', 'sector': 'AdTech / MarTech', 'employees': '600 collaborateurs', 'creation_year': '2001', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
ğŸ‘« About the team
At Equativ, weâ€™re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.
Our innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.
Our data engineering team is composed of 10 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 140+ engineers spread across Paris, Nantes, Limoges, KrakÃ³w and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.
Our Mission ğŸ‘‡
Data Engineering team is central to Equativâ€™s data centric business and is responsible to ingest, transform, model and redistribute all data coming from our adtech platform.
We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle massive log ingestion (tens of billions per day), short & long term data storage, complex data modelling, real-time and batch ELT as well as providing external access through dedicated APIs.
Data Engineers serve Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science algorithms (clustering and optimization), customer reporting, invoicing and more.
Equativ Data Engineering team is engaged in an ambitious migration of its main data stack (Hadoop on-premise) to GCP with the objective to increase reporting features, lower maintenance time, improve performances and simplify the access to our raw data.
What you'll do âœï¸
As a Big Data Engineer, youâ€™ll primarily focus on maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIs
Design, develop, test, promote and industrialize all data components from data ingestion to datawarehouse delivery (ClickHouse, BigQuery)
- Propose and develop innovative solutions to achieve the best levels of scalability and performance for our Big Data engines
- Automate and streamline our real-time and batch data pipelines (on-premise and in the cloud) in order to simplify access to our data by other teams and lower amount of work spent by other teams on ETL processes
- Perform end-to-end monitoring to ensure high availability of production data processing, data quality and reliability
- Apply best in class Devops guidelines and secure deployments
Brainstorm with other team members working on our data backend (datawarehouse modelling and data exposure through our reporting APIs) on optimizing our architecture and support them in the use of our pipelines
Contribute to data roadmap definition in coordination with other R&D and product teams in order to build a best in class data infrastructure that will generate insights for Equativâ€™s analytics
Take part in improving and deploy data engineering standards, procedures, processes and operational guidelines around target data components at Equativ
ğŸ’ª About you
Master degree in Computer Science or similar technical field of study
3+ years of software development with open source technologies
Fluent in Java and/or in Scala. SQL mastery
Very good understanding of Devops principles (Gitlab, Docker, Kubernetes, Gradle, ci/cd)
Experience with large-scale data engineering technologies (ClickHouse, Flink, Kafka, Hadoop, Spark, Hbase)
Experience on building data pipelines on Google Cloud Platform (BigQuery, Dataflow, GCS, Cloud Run, Airflow â€¦) would be a big plus
Experience in working with high QPS Rest APIs is a plus
Entrepreneurial spirit and know-how to identify opportunities of improvement
Working proficiency and communication skills in verbal and written English
Passion for playing with large volume of data
ğŸš€ How you'll grow
Within 1 month:
You'll be just finishing your onboarding.
You'll probably have tackled a few small tasks in peer-coding
Within 4 months:
You'll have an overview of 50% of the stack, CI/CD and teamâ€™s main processes. Youâ€™ll be able to work on more complex developments
You'll now have enough knowledge to participate to deployments of chosen applications
Within 9 months:
You'll be autonomous on most of our stack and will have participated to major projects
Youâ€™ll be helping the team on production matters
ğŸ‘‹ About us 
Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus â€” four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.
Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.
The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Timesâ€™ FT 1000: Europeâ€™s Fastest-Growing Companies.
Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.
Come and lead the charge with us in building a transparent ecosystem based on quality!
----------------------
Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com
Voir moins",
Stage - Data Engineer,"{'name': 'EXOTEC', 'sector': 'Logistique, Objets connectÃ©s, Robotique', 'employees': '600 collaborateurs', 'creation_year': '2015', 'turnover': '126 Mâ‚¬', 'mean_age': '31 ans'}",Stage,Lille,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Au sein du pÃ´le Data, de la DSI d'Exotec, votre rÃ´le sera de participer au dÃ©veloppement de l'environnement et de l'infrastructure Data d'Exotec.
Pour cela :
Vous participez Ã  la mise en Å“uvre des composants techniques de la plateforme de donnÃ©es d'Exotec
Vous travaillez sur la collecte dans la plateforme de donnÃ©es provenant de sources multiples : Salesforce, ERP, logiciels dÃ©veloppÃ©s en interne
Vous nettoyez, mettez en qualitÃ© et prÃ©parez les donnÃ©es afin de les rendre disponibles pour les diffÃ©rents cas d'usage qui en ont besoin
Vous migrez des reportings existants vers la plateforme de donnÃ©es et mettez en Å“uvre de nouveaux cas d'usage pour rÃ©pondre aux besoins de l'entreprise
Vous travaillerez au sein de l'Ã©quipe data et en Ã©troite collaboration avec la software factory, ainsi quâ€™avec les utilisateurs des mÃ©tiers qui ont besoin de rendre intelligibles les donnÃ©es disponibles
Requirements
Vous Ãªtes Ã©tudiant(e) dâ€™une Ã©cole dâ€™IngÃ©nieur gÃ©nÃ©raliste avec une spÃ©cialisation programmation ou informatique
Vous recherchez un stage de fin dâ€™Ã©tudes dâ€™une durÃ©e de 4 Ã  6 mois
Vous avez idÃ©alement une premiÃ¨re expÃ©rience en Data Engineering et le dÃ©veloppement de pipeline de donnÃ©es
Vous maitrisez Python, l'ETL et SQL,
Curieux(se) et rigoureux(se), vous souhaitez rejoindre une Ã©quipe jeune et dynamique ainsi que vous investir dans des projets complexes et excitants
Vous avez un niveau dâ€™anglais courant

Chez Exotec, nous garantissons lâ€™Ã©galitÃ© des chances dans notre processus de recrutement. Lâ€™ensemble des candidatures reÃ§ues sont Ã©tudiÃ©es indÃ©pendamment de lâ€™Ã¢ge, du genre, de lâ€™origine, de la religion, de la couleur de peau, de la nationalitÃ©, du sexe, du handicap, de lâ€™orientation sexuelle ou de toute autre distinction protÃ©gÃ©e par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les diffÃ©rences. En rejoignant le Pacte ParitÃ©, Exotec sâ€™engage pour un Ã©cosystÃ¨me French Tech plus paritaire.
Voir moins",
R&D Data Engineer,"{'name': 'EXOTEC', 'sector': 'Logistique, Objets connectÃ©s, Robotique', 'employees': '600 collaborateurs', 'creation_year': '2015', 'turnover': '126 Mâ‚¬', 'mean_age': '31 ans'}",CDI,Lille,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,Bac +5 / Master,"Descriptif du poste
Exotec is at the forefront of technological excellence, redefining the relationship between humans and robots. Our solutions are contributing to the success of some of the largest brands in retail and e-Commerce by revolutionizing the way they fulfill their orders to the end consumers, all while mitigating labor constraints and increasing workplace safety.
Through the unification of artificial intelligence and high-performance hardware, our robotic solutions are now deployed across the globe and our exponential growth has led us to become the first industrial unicorn in France.
Working at Exotec is an exciting opportunity to give purpose to your skills. Learn and grow with over 600 ExoPeople around the world to help turn your ideas into a reality.
The robotics revolution is just the beginning at Exotec. Will you be part of it?
 We are seeking a talented and experienced Data Engineer to join our team in the Product Department.
As a Data Engineer at Exotec, you will play a key role in designing, developing and maintaining our data infrastructure.
 Responsibilities
Collaborate with cross-functional teams to understand data requirements and design scalable data solutions.
Collect data coming from our different client sites
Design and implement an event driven data lake
Provide the data to applications and end user
Requirements
IT/Software Engineer or related field.
Proven experience as a Data Engineer or similar role
Strong proficiency in Python
Hands-on experience with Terraform for Infrastructure as Code
Knowledge of containerization and orchestration tools like Docker and Kubernetes
Familiarity with AWS
Strong problem-solving and analytical skills
Excellent communication and collaboration skills
Nice to have:
Familiarity with Kafka or other message queuing system
Hands-on experience with Apache Airflow or Dagster
Familiarity with machine learning frameworks and concepts
Voir moins",
Data Engineer - F/H,"{'name': 'CS', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, AÃ©ronautique / Spatiale, Energie', 'employees': '2700 collaborateurs', 'creation_year': '1968', 'turnover': '300 000 000â‚¬', 'mean_age': '40 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Nous recrutons un.e IngÃ©nieur Data Engineer pour rejoindre notre Business Unit INDUSTRIE au sein de la Business Line Data Intelligence. Elle accompagne nos clients dans leurs problÃ©matiques associÃ©es Ã  la transformation digitale. Nos offres se dÃ©clinent autour de la data intelligence & de la maintenance prÃ©dictive.
Votre mission :
Dans le cadre de nos projets, vous rejoindrez notre Ã©quipe et participerez aux missions suivantes :
- Concevoir,  dÃ©velopper, industrialiser et dÃ©ployer des outils de traitements de donnÃ©es

- Monitoring et analyse de flux de donnÃ©es

- Accompagner nos clients sur les conceptions d'architecture des systÃ¨mes

- RÃ©diger les rapports dâ€™analyse de donnÃ©es, et assurer la prÃ©sentation au client
Environnement technique :

MÃ©thodologie: Agile, Kanban, SAFe

Framework: Hadoop, Hortonworks, Spark

Base de donnÃ©es: Relationnelle & NoSQL

Langages: Python, Scala

Outils : Git, connaissance en containerisation (Docker)
Voir moins","Profil recherchÃ©
Qui Ãªtes-vous ?
Vous avez une premiÃ¨re expÃ©rience (a minima 1 an sur un poste similaire) en Data Engineering, idÃ©alement dans le secteur aÃ©ronautique.
La connaissance des techniques et mÃ©thodes de dÃ©veloppement logiciel serait un plus dans lâ€™exercice de votre fonction. 
Un niveau dâ€™anglais professionnel est requis.

Vous Ãªtes autonome et rigoureux,  et vous savez faire preuve de capacitÃ© dâ€™analyse ? Vous Ãªtes bon communiquant et crÃ©atif ? Alors vous Ãªtes la pÃ©pite que nous recherchons !
A compÃ©tences Ã©gales, ce poste est ouvert aux personnes en situation de handicap."
Senior Data Engineer,"{'name': 'DOCTRINE', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Service juridique', 'employees': '120 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Notre mission âš–ï¸
Nous nous engageons pour un enjeu dÃ©mocratique majeur : rendre le droit plus accessible et transparent aux justiciables et aux professionnels du droit.
Doctrine est la premiÃ¨re plateforme d'intelligence juridique. Nous centralisons et organisons toute l'information juridique disponible pour permettre aux avocats et juristes de mieux conseiller et dÃ©fendre leurs clients. Plus d'un million de personnes viennent tous les mois sur Doctrine se renseigner sur leurs droits, et dÃ©jÃ  12 000 professionnels du droit nous font confiance.
Nos valeurs ğŸ¤
Challenge the status quo. Nous dÃ©fendons les idÃ©es audacieuses et la prise de risque intelligente.
Liberty and responsibility. Nous promouvons lâ€™autonomie, lâ€™impact de chacunÂ·e et lâ€™ownership.
Knowledge is power. L'information est au cÅ“ur de la mission de Doctrine, et nous voulons toujours apprendre plus.
Release early, release often and listen to your customers. Nous croyons au pouvoir de lâ€™itÃ©ration et Ã  lâ€™importance dâ€™Ã©couter en permanence notre marchÃ©, nos clientÂ·eÂ·s et leurs problÃ©matiques.
Le contexte
Nous sommes actuellement Ã  la recherche d'un Senior Data Engineer pour rejoindre lâ€™une de nos squads et participer Ã  la construction de la premiÃ¨re plateforme dâ€™intelligence juridique.
Tu rejoindras une squad dont la mission est de permettre le scale Ã  la fois en terme de quantitÃ© mais aussi de diversitÃ© de donnÃ©es de notre plateforme.
Tu peux trouver des dÃ©tails sur lâ€™ensemble de la stack sur Github !
A savoir : il nâ€™est pas nÃ©cessaire dâ€™avoir une expÃ©rience professionnelle dans le domaine du droit, cependant lâ€™envie de sâ€™investir et de monter en compÃ©tence dans la comprÃ©hension des documents juridiques est importante :)
Les missions ğŸ› 
Concevoir, dÃ©velopper, monitorer les pipelines de donnÃ©es et les scripts d'acquisition utilisÃ©es pour tous les contenus de notre plateforme
Assurer la qualitÃ© de la donnÃ©e et son monitoring
Travailler main dans la main avec des ingÃ©nieurs data et machine learning en charge des parties Ã©quivalentes de leur cÃ´tÃ©
Contribuer Ã  lâ€™Ã©volution de nos outils de pipeline de donnÃ©es (Airflow, Kubernetes, Dask, Amazon S3, PostgreSQL, Terraform, etc...), et faire en sorte dâ€™en tirer le meilleur profit au quotidien
Faire monter en compÃ©tence les autres ingÃ©nieurs de l'Ã©quipe
Au sein du Chapter Data Engineering, participer Ã  l'Ã©laboration de nos pratiques de modÃ©lisation et de traitement des donnÃ©es.
Le profil idÃ©al ğŸ‘€
De bonnes compÃ©tences en programmation Python
Une expÃ©rience des pratiques d'acquisition et de modÃ©lisation des donnÃ©es
Une bonne connaissance de SQL, NoSQL, Elasticsearch et du stockage objet
Lâ€™envie de partager tes connaissances pour participer Ã  la progression de chacun.e
La maÃ®trise de la langue franÃ§aise, car tu seras amenÃ©.e Ã  manipuler des donnÃ©es juridiques en franÃ§ais.
Les Ã  cÃ´tÃ©s du poste ğŸ‘
Comme tous les ingÃ©nieurs de Doctrine, tu participeras Ã  un de nos chapters transverses, en lâ€™espÃ¨ce le chapter Data Engineering. Au sein de ce chapter, tu contribueras Ã  des projets internes pour amÃ©liorer nos process et notre vision long-terme. Le chapter se rÃ©unit toutes les deux semaines pour :
ğŸ¤ Partager des connaissances : amÃ©lioration continue, bonnes pratiques,â€¦
ğŸ¯ Proposer des Ã©volutions : nouveaux outils Ã  expÃ©rimenter, nouveaux process Ã  mettre en Å“uvre
Tu participeras Ã©galement au ğŸ‘©â€ğŸ’» recrutement : tous les contributeurs individuels rencontrent des candidats Ã  lâ€™occasion de tests techniques ou dâ€™entretiens.
Ce qui t'attend si tu rejoins Doctrine ğŸ¤—
- Contribuer Ã  un projet ambitieux, avec un impact rÃ©el et positif sur la sociÃ©tÃ© : rendre le droit plus accessible et plus ouvert.
- Un accompagnement sur mesure dÃ¨s ton arrivÃ©e sur l'Ã©cosystÃ¨me juridique pour t'aider Ã  naviguer trÃ¨s vite dans cet environnement stimulant.
- Une aventure dans laquelle tu apprendras sans cesse et partageras tes connaissances Ã  lâ€™ensemble de tes collÃ¨gues (talks internes/externes, meetups, Tech & Sales Monthly, blog Medium, etc.)
- Travailler au sein dâ€™une Ã©quipe en Ã©bullition qui cherche sans cesse Ã  se renouveler : de la place pour innover et mener des projets en autonomie ou en Ã©quipe.
Nos avantages pour faire la diffÃ©rence â˜€ï¸
ğŸ¡ Une politique de tÃ©lÃ©travail flexible, avec 2 jours de prÃ©sence au bureau par semaine (mardi et jeudi)
ğŸŒ± De nombreuses options pour ta carriÃ¨re, et des mobilitÃ©s internes ouvertes Ã  toutes et tous chez Doctrine
ğŸŒ´ Des vacances flexibles et illimitÃ©es
ğŸ“š Un vrai accent sur la formation individuelle et collective, avec un budget annuel de 750â‚¬ en usage libre et des formations en Ã©quipe et pour toute l'entreprise rÃ©guliÃ¨rement
ğŸ„â€â™‚ï¸ Des Ã©vÃ¨nements collectifs rÃ©guliers
ğŸ‘©â€âš•ï¸ Une bonne assurance santÃ© avec Alan
ğŸš² Un forfait mobilitÃ© durable Ã  hauteur de 66 euros par mois
ğŸ‹ï¸â€â™€ï¸ Un abonnement Gymlib pour les activitÃ©s sportives et bien-Ãªtre
ğŸ± Une carte Swile pour tes tickets restaurants
ğŸ§˜ Un accÃ¨s gratuit Ã  la plateforme d'accompagnement Ã  la santÃ© mentale Moka.care
ğŸ’¡ Des centaines de rÃ©ductions et avantages nÃ©gociÃ©s grÃ¢ce Ã  notre CSE
ğŸ Un Ã©quipement de travail neuf chez Apple
Notre processus de recrutement ğŸš€
- Un premier Ã©change de 30 min avec lâ€™un.e de nos Talent Acquisition Manager pour bien comprendre ton projet professionnel et te prÃ©senter ce qu'on construit chez Doctrine
- Une rencontre dâ€™1h avec ton/ta futur.e manager, pour dÃ©tailler le poste et le scope de lâ€™Ã©quipe, mais aussi rÃ©pondre Ã  toutes tes questions.
- Un ou deux tests techniques pour Ã©valuer concrÃ¨tement tes compÃ©tences
- Un dÃ©jeuner avec 3 personnes de diffÃ©rents dÃ©partements chez Doctrine, pour te donner un aperÃ§u de tes futur.e.s collÃ¨gues
- Un Ã©change sur les valeurs de lâ€™entreprise pour te partager notre vision
- Une rencontre avec Guillaume, notre CEO.
(si nÃ©cessaire le processus pourra Ãªtre adaptÃ© pour rÃ©pondre Ã  tes contraintes personnelles et professionnelles)
Mesdames, autorisez-vous Ã  candidater !
Certaines Ã©tudes scientifiques montrent qu'en particulier les femmes ont moins tendance Ã  postuler Ã  une offre d'emploi quand elles n'ont pas toutes les qualifications. Si cela peut vous rassurer, sachez que cette fiche de poste est indicative donc prenez la comme telle : c'est un guide, ni plus ni moins.
Si Doctrine vous intÃ©resse, sachez que nous aurons plaisir Ã  recevoir votre candidature !
Voir moins",
Data Engineer Senior H/F,"{'name': 'MEILLEURTAUX', 'sector': 'FinTech / InsurTech, Immobilier commercial, Immobilier particulier', 'employees': '2000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Vous souhaitez rejoindre la fintech leader en crÃ©dit et en assurance, en forte croissance, innovante, dynamique et dÃ©bordante de projets ? Ce qui suit va vous intÃ©resser !
Contexte de ce recrutement ğŸš€
Nous sommes engagÃ©s dans le dÃ©veloppement dâ€™une Customer Data Platform. 
Cette plateforme de donnÃ©es est au cÅ“ur de la stratÃ©gie de croissance de lâ€™entreprise va nous permettre de :
- Augmenter la Customer Lifetime Value (CLTV) de nos clients,
- D'intÃ©grer dans tous nos produits des composants IA innovants, 
- RÃ©duire nos coÃ»ts dâ€™acquisition,
- Faciliter le pilotage du business Ã  travers une optimisation de nos outils de BI.
Vous vous Ã©panouirez dans notre environnement en Ã©volution rapide, oÃ¹ l'adaptabilitÃ© est essentielle. Au-delÃ  de la rÃ©solution de dÃ©fis techniques, nous souhaitons que vous contribuiez activement Ã  la construction de la culture d'ingÃ©nierie de Meilleurtaux, Ã  l'amÃ©lioration des pratiques et Ã  la promotion d'un environnement collaboratif et innovant.
Vos missions ğŸ“
CrÃ©er et maintenir une infrastructure de donnÃ©es de pointe en permettant aux utilisateurs finaux d'accÃ©der Ã  de la donnÃ©e prÃ©cise et de qualitÃ© ;
DÃ©velopper de nouveaux modÃ¨les de donnÃ©es et des pipelines.
Ils ont auront pour objectif de prendre en charge une grande variÃ©tÃ© de cas d'utilisation (de l'analyse et du reporting Ã  l'apprentissage automatique et Ã  l'innovation de produits) ;
Explorer en permanence de nouvelles technologies de donnÃ©es ;
Tester les solutions les plus innovantes et prometteuses du marchÃ© en vue de pouvoir amÃ©liorer nos capacitÃ©s en matiÃ¨re de donnÃ©es ;
Recruter, encadrer et accompagner votre Ã©quipe de Data Engineers au quotidien ;
Partager et dÃ©fendre vos meilleures pratiques d'ingÃ©nierie de donnÃ©es au sein des principaux organes de dÃ©cision de l'entreprise.
Notre stack technique ğŸ›  
DÃ©veloppement : Python, React, java, Salesforce
CI-CD :  Git, Docker
Infrastructure cloud : GCP et Azure
Bases de donnÃ©es : Google BigQuery et Databricks
BI : Qliqsense
Ce poste nÃ©cessite d'interagir avec de nombreuses Ã©quipes au sein de Meilleurtaux que ce soit sur le plan technique (Ã©quipes IT, Data Scientist et BI) et/ou fonctionnel (Product Managers).
Ceci nâ€™est quâ€™un avant-goÃ»t de la superbe aventure que vous vous apprÃªtez Ã  rejoindre, le poste Ã©tant Ã©videmment amenÃ© Ã  Ã©voluer en fonction de vous et vos propositions.
Voir moins","Profil recherchÃ©
Pourquoi Ãªtes-vous notre TOP candidat ? ğŸ§
Avec une expÃ©rience d'au moins 8 ans dans la Data, vous aviez Ã©tÃ© amenÃ©(e) Ã  manager une petite Ã©quipe (entre 1 Ã  3 personnes) de Data Engineers.
Vous savez crÃ©er des architectures de donnÃ©es efficaces, Ã©volutives et robustes.
Vous concevez des systÃ¨mes adaptÃ©s au prÃ©sent mais Ã©galement Ã  l'avenir et qui rÃ©sistent Ã  l'Ã©preuve du temps.
Bien entendu, il est important que vous ayez de trÃ¨s bonnes compÃ©tences techniques que ce soit en Python ; SQL et les autres outils pouvant exister en ingÃ©nierie de donnÃ©es.
La Big Data n'a plus de secret pour vous. Spark & Hadoop sont vos plateformes de rÃ©fÃ©rence sur ce domaine.
Vous avez dÃ©jÃ  participÃ© au dÃ©ploiement d'infrastructure en Big Data.
IdÃ©alement, vous faÃ®tes partie d'une communautÃ© de professionnels de la Data vous permettant d'Ãªtre toujours au fait des derniÃ¨res actualitÃ©s.
Le must : cette expertise a Ã©tÃ© acquise au sein de l'industrie Fintech / Assurtech ou secteur Ã©quivalent. 
Voir plus"
Consultant Senior Data Engineer (H/F) - Paris - 2024,"{'name': 'MAZARS ET LA TECH', 'sector': 'IT / Digital', 'employees': '28000 collaborateurs', 'creation_year': '1945', 'turnover': '2,1 milliards', 'mean_age': '30 ans'}",CDI,Courbevoie,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Rejoindre lâ€™Ã©quipe Data Services de Mazars, câ€™est rejoindre une Ã©quipe de plus de 30 consultants spÃ©cialistes de la data, rÃ©partis sur 2 hubs (Paris La DÃ©fense, New-York).  
Au sein du DataLab, nos domaines dâ€™expertises couvrent lâ€™ensemble de la chaÃ®ne de valeur de la donnÃ©e : Data Strategy et qualification de cas dâ€™usage, Gouvernance et qualitÃ© des donnÃ©es, Gestion des donnÃ©es de rÃ©fÃ©rence (MDM), Data transformation, Data Architecture, Data Engineering, Data Science, Data Visualisation et Analytics,
Formation Ã  tous niveaux sur ces prÃ©cÃ©dents sujets.  
Vous serez formÃ©(e) Ã  nos mÃ©thodologies et aurez l'opportunitÃ© de travailler au sein d'Ã©quipes pluridisciplinaires, y compris les Ã©quipes de R&D qui dÃ©veloppent et maintiennent nos outils d'Analytics ainsi que notre infrastructure interne (GitLab-CI, Cloud privÃ© OpenNebula, CephFS, etc...).

Vous interviendrez de faÃ§on opÃ©rationnelle sur des missions de conseil data ambitieuses et innovantes pour nos clients du CAC40 et SBF120, en France et Ã  l'international. Vous participerez notamment Ã  :

â€¢ L'amÃ©lioration de la performance opÃ©rationnelle de nos clients au travers de lâ€™exploitation et la valorisation de donnÃ©es sur des cas dâ€™usage mÃ©tier concrets (stratÃ©gie, marketing et vente, R&D, finance, etc..).
â€¢ Lâ€™interaction directe avec nos clients dont nous analysons les problÃ©matiques pour les aider Ã  implÃ©menter des solutions technologiques sur-mesure.
â€¢ Le dÃ©veloppement de bout en bout de flux de donnÃ©es, depuis l'extraction et la transformation des donnÃ©es de nos clients, jusquâ€™Ã  leur consommation par des systÃ¨mes ou applications web et tableaux de bord que nous concevons pour eux, en passant par les datalake, data-warehouse, data-marts ou API qui exposent ces donnÃ©es.
â€¢ DÃ©ploiement de pipelines de donnÃ©es dans le paradigme serverless cloud (AWS Lambdas, Azure Functions, GC Functions, etc.) mais aussi utilisation de techniques DevOps et de virtualisation bare-metal avancÃ©es au sein d'une Ã©quipe pionniÃ¨re du MLOps (Ã©quipe opÃ©rationnelle en CI/CD depuis 2013).
Voir moins","Profil recherchÃ©
Profil recherchÃ©

De formation Bac+5 type Ã©cole dâ€™ingÃ©nieur gÃ©nÃ©raliste ou spÃ©cialisÃ©e, ou d'un 3Ã¨me cycle dans un domaine connexe Ã  la data (systÃ¨mes dâ€™informations, traitements de donnÃ©es, big data, statistiques, gÃ©nie logiciel, etc.) :
Vous avez dÃ©jÃ  montrÃ© un intÃ©rÃªt pour le domaine du dÃ©veloppement applicatif intÃ©grant une composante Data, Ã  travers des stages, cours ou projets personnels impliquant le dÃ©veloppement back-end et/ou front-end dâ€™une application.
 Vous avez une expÃ©rience pratique et une bonne connaissance de :
Un ou plusieurs langages de programmation analytique (Python, SQL, R, etc.)
Une ou plusieurs couches de persistance (SGBD relationnel : MySQL / MSSQL / PostgreSQL, No- SQL : MongoDB / ElasticSearch / Node4j, ou encore S3)
La conception et/ou lâ€™implÃ©mentation et/ou la manipulation de datalakes, data warehouses ou data- marts
Voir plus"
[SFR] Stage Data Engineer - PrÃ©visions & Analyse RÃ©seaux,"{'name': 'ALTICE FRANCE SFR RMC BFM', 'sector': 'MÃ©dia, TÃ©lÃ©vision / Production audiovisuelle, Electronique / TÃ©lÃ©communications', 'employees': '11000 collaborateurs', 'creation_year': '1987', 'turnover': '11 milliards en 2022', 'mean_age': None}",Stage,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
IntitulÃ© du poste
Au sein de la Direction DÃ©veloppement RÃ©seaux, vous intÃ©grerez l'Ã©quipe ""PrÃ©visions et Analyses RÃ©seaux"".
L'Ã©quipe a pour principales missions de : 
- donner - en fonction de la stratÃ©gie ""group"" adoptÃ©e - la vision des Ã©volutions de trafics des rÃ©seaux fixe et mobile Ã  court et moyen terme (1 Ã  5 ans),
- comprendre les habitudes et les Ã©volutions de consommation des services voix/data/vidÃ©o de ses clients,
- anticiper les changements ou ruptures technologiques,
- maitriser les investissements rÃ©seaux,
 - dÃ©tecter des leviers actionnables par des analyses data rÃ©seau afin de garantir la meilleure qualitÃ© de service Ã  ses clients.
Vos rÃ´les et missions sont, dans le cadre de la rationalisation de l'infrastructure BigData existante et de sa migration dans le Cloud, de :
- analyser la structure des bases de donnÃ©es existantes (Cloudera/Teradata/Oracle) et leur utilisation,
- transformer / organiser / structurer et documenter les donnÃ©es du rÃ©seau exploitÃ©es par ces bases,
- contribuer Ã  la dÃ©finition du processus de migration des scripts existants,
- rÃ©aliser la migration des reportings et dataviz d'aide Ã  la dÃ©cision dans le nouvel environnement,
- automatiser les imports de donnÃ©es internes Ã  la sociÃ©tÃ© ou disponibles en open data (csv, json, ...),
- explorer l'eco-systeme Cloud et prototyper de nouvelles fonctionnalitÃ©s (IA, cartographie, ...).
Profil
Etudiant(e) Bac+4 ou 5 en Ã©cole d'ingÃ©nieur ou universitaire, spÃ©cialisÃ©(e) en Informatique, vous avez envie d'effectuer votre stage, durant le premier semestre 2024, dans un environnement technique bigdata riche et novateur.
Vous maitrisez les principales bases de donnÃ©es (Hive/Impala/Teradata/Oracle), le SQL et les environnements de BigData dans le Cloud, tel que Google Cloud.
Vous connaissez le langage R et des outils de Dataviz (Tableau Software / R-Shiny).
Vous avez des connaissances en ETL, en robots d'indexation et savez structurer des donnÃ©es.
Vous Ãªtes rigoureux(se), curieux(se), force de proposition, avez le sens de l'organisation, aimez travailler en Ã©quipe et relever des dÃ©fis.
Voir moins",
Data Engineer (F/H),"{'name': 'ASI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '500 collaborateurs', 'creation_year': '1993', 'turnover': '42,5 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Lyon,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
VOS MISSIONS 
Analyser et comprendre les besoins client
Participer aux diffÃ©rentes phases :
           - Conception dâ€™architecture dÃ©cisionnelle et technique
           - RÃ©daction des spÃ©cifications fonctionnelles et techniques
           - Traitement de la donnÃ©e, concevoir et spÃ©cifier les jobs dâ€™alimentation
           - Construction de cubes de donnÃ©es
           - DÃ©veloppement des rapports
           - Tests et recettes
           - Mise en production","Profil recherchÃ©
Vous Ãªtes prÃªt Ã  monter en compÃ©tences sur de nouvelles solutions, vous avez envie dâ€™Ã©largir votre spectre technologique.
Vous Ãªtes curieux, rigoureux, analytique, dynamique et dotÃ© d'une grande capacitÃ© d'adaptation.
Vous avez de l'appÃ©tence et/ou connaissance des nouveaux concepts de la data (Data Mining, Data Visualisation, Data Lake, â€¦)
De formation supÃ©rieure, vous avez une expÃ©rience rÃ©ussie sur un poste similaire avec les compÃ©tences suivantes :
           - Travailler sur des projets de Data Intelligence, de faÃ§on autonome ou au sein dâ€™une Ã©quipe
           - MaÃ®trise dâ€™une ou plusieurs solutions du marchÃ©
           - Alimentation et stockage de donnÃ©es : SSIS, Talend, Oracle Data Integrator, SAP Data Services, â€¦
           - Analyse : SSAS, SAS, â€¦
            - Restitution : SSRS, SAP BO, QlikView, Qlik Sense, Power BI
Ã€ compÃ©tences Ã©gales ce poste est ouvert aux personnes en situation de handicap
Ensemble, nous saurons dÃ©velopper vos compÃ©tences et enrichir votre expÃ©rience ! 
Voir plus"
Data Engineer / Azure (H/F),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'â‚¬"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 4 ans,Bac +5 / Master,"Descriptif du poste
En rÃ©sumÃ© :
Poste : Data Engineer /Azure
LocalitÃ© : Levallois-Perret
Type de contrat : CDI
Niveau dâ€™expÃ©rience : au moins 3 ans
Vous Ãªtes passionnÃ©(e)s par la data ? Vous Ãªtes convaincus que lâ€™optimisation du patrimoine data des entreprises est la clÃ© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider Ã  se transformer pour prÃ©parer dÃ¨s Ã  prÃ©sent leur futur ? Vous Ãªtes au fait des derniÃ¨res tendances et prÃªt Ã  explorer de nouveaux territoires ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez rÃ©pondu Â«â€¯Ouiâ€¯Â» Ã  chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.
Alors, prÃªt Ã  rejoindre lâ€™aventure Micropole ? Nâ€™attendez plus !
Vous accompagnez nos clients Ã  travers toutes les Ã©tapes de leur transformation numÃ©rique dans un environnement Microsoft Azure : De la dÃ©finition des axes stratÃ©giques d'adoption du cloud, du design, au dÃ©ploiement des outils, Ã  la migration des applications et services. Vous aidez nos clients Ã  gagner en performance, agilitÃ©, flexibilitÃ© du SI et Ã  intÃ©grer les Innovations les plus avancÃ©es.
Dans vosâ€¯missions quotidiennes, vous serez amenÃ©(e) Ã â€¯: 
Apporter votre expertise Ã  nos clients pour garantir une valeur ajoutÃ©e rigoureuse et innovante
Participer activement Ã  la rÃ©alisation technique des projets de nos clients
Accompagner et conseiller les clients sur les meilleures pratiques, les technologies et outils les plus adaptÃ©s au contexte.
RÃ©aliser des prÃ©sentations, dÃ©monstrations, POC ou Pilotes pour mettre en lumiÃ¨re les recommandations technologiques.
ÃŠtre constamment en veille technologique
TransfÃ©rer des compÃ©tences spÃ©cifiques aux Ã©quipes techniques de nos clients
Voir moins","Profil recherchÃ©
Vous avez un minimum de 3 annÃ©es dâ€™expÃ©rience sur des projets Data dont au moins une sur des projets Cloud Microsoft Azure ou Ã  dÃ©faut une certification Azure avec lâ€™ambition de vous prÃ©parer Ã  dâ€™autres. 
Vous maÃ®trisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R)â€¯; 
Vous avez une maitrise des thÃ©ories et outils de modÃ©lisation de donnÃ©es, 
Vous maitrisez des outils et framework dâ€™industrialisation, IaC, CI/CD et/ou gestion de version, 
Solide ExpÃ©rience Technique Dans Les Domaines Suivants
Azure Data Factory
Azure Synapse Pipeline
Spark/Scala
pyspark
Python
SQL, PL-SQL
Azure Databricks
Les plus selon lâ€™expÃ©rience
Voir plus"
Data Engineer / Talend Big Data (H/F),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'â‚¬"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 4 ans,Bac +5 / Master,"Descriptif du poste
En rÃ©sumÃ© :
Poste : Data Engineer Talend Big Data
LocalitÃ© : Levallois-Perret
Type de contrat : CDI
Niveau dâ€™expÃ©rience : au moins 3 ans
Vous Ãªtes passionnÃ©(e)s par la data ? Vous Ãªtes convaincus que lâ€™optimisation du patrimoine data des entreprises est la clÃ© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider Ã  se transformer pour prÃ©parer dÃ¨s Ã  prÃ©sent leur futur ? Vous Ãªtes au fait des derniÃ¨res tendances et prÃªt Ã  explorer de nouveaux territoires ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez rÃ©pondu Â«â€¯Ouiâ€¯Â» Ã  chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.
Alors, prÃªt Ã  rejoindre lâ€™aventure Micropole ? Nâ€™attendez plus !
Au sein de notre agence basÃ©e Ã  Levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer - Talend Big Data (F/H) , vous accompagnerez les directions mÃ©tiers dans l'Ã©valuation de l'efficacitÃ© de leur processus et dans leur stratÃ©gie pour optimiser leur performance. 
Dans vosâ€¯missions quotidiennes, vous serez amenÃ©(e) Ã â€¯: 
DÃ©velopper et maintenir des cas dâ€™usages clients avec les outils et les infrastructures Big Data. ModÃ©liser et analyser des donnÃ©es dans le Cloud. Garantir la sÃ©curitÃ© / compliance des donnÃ©esâ€¯; 
Apporter votre rÃ©flexion sur des problÃ©matiques mÃ©tiers Ã  travers lâ€™exploitation et la comprÃ©hension des donnÃ©es. Identifier les sources de donnÃ©es les plus pertinentes et restituer des rÃ©sultats de faÃ§on concise et visuelleâ€¯; 
RÃ©aliser une veille technologique pour Ãªtre Ã  la pointe sur les solutions Cloud & Dataâ€¯; 
Participer au dÃ©veloppement de notre centre dâ€™excellence. 
Voir moins","Profil recherchÃ©
Vos compÃ©tences techniquesâ€¯: 
Vous avez un minimum de 3 annÃ©es dâ€™expÃ©rience sur des projets Data avec Talend Spark ou SSIS. 
Vous maÃ®trisez au minimum un langage de programmation (Spark, Scala ou SQL)â€¯; 
Vous avez une maitrise des thÃ©ories et outils de modÃ©lisation de donnÃ©es, 
Vous maitrisez des outils et framework dâ€™industrialisation, IaC, CI/CD et/ou gestion de version, 
Vosâ€¯ atouts: 
Vous Ãªtes passionnÃ©(e), rigoureux(se), curieux(se) et Ã  lâ€™Ã©couteâ€¯; 
Vous avez un bon niveau dâ€™anglais qui vous permet dâ€™intervenir sur des projets Ã  dimension internationaleâ€¯; 
Vous dÃ©velopperez votre crÃ©ativitÃ© et votre curiositÃ© grÃ¢ce Ã  une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. 
Vous souhaitez vous impliquer dans le dÃ©veloppement dâ€™Ã©quipes et de communautÃ©s techniques autour du Cloud et des solutions Data. 
Devenir #INNOVATIVE PEOPLE Câ€™est :
IntÃ©grer une communautÃ© de 1200 experts passionnÃ©s rÃ©partis entre la France, la Belgique, le Luxembourg, la Suisse, lâ€™Espagne et la Chine.
#LI-LL3
Voir plus"
Data Engineer ConfirmÃ© (F/H),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'â‚¬"", 'mean_age': '36 ans'}",CDI,Niort,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,,"Descriptif du poste
Comme nous, vous Ãªtes passionnÃ©(e) par la donnÃ©e et convaincu(e) que la validation du patrimoine data des entreprises est la clÃ© de leur performance ? Vous voulez accompagner les entreprises dans leur stratÃ©gie data driver et les aider Ã  se transformer grÃ¢ce aux nouvelles technologies qu'amÃ¨ne le Cloud, pour prÃ©parer dÃ¨s Ã  prÃ©sent leur futur ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitales, au sein dâ€™une agence Ã  taille humaine oÃ¹ rÃ¨gnent entraide et convivialitÃ© et engagÃ©e en faveur dâ€™un numÃ©rique plus responsable au service de clients principalement implantÃ©s rÃ©gionalement ? 
Rejoignez l'aventure Micropole Ã  Niort !
Vous viendrez renforcer une Ã©quipe niortaise soudÃ©e qui porte lâ€™esprit dâ€™Ã©quipe, ayant Ã  cÅ“ur de faire de votre intÃ©gration un succÃ¨s et de vous accompagner dans votre montÃ©e en compÃ©tences. 
En intÃ©grant Micropole vous aurez l'opportunitÃ© d'intervenir sur des projets data innovants, riches et variÃ©s et participerez activement au rayonnement de l'agence sur le bassin niortais.
Dans vos missions quotidiennes, vous serez amenÃ©(e) Ã :
Participer au recueil des besoins des mÃ©tiers ;
RÃ©diger les dossiers de conception technique ;
ModÃ©liser les entrepÃ´ts de donnÃ©es ;
DÃ©velopper des flux de donnÃ©es via des ETL,
Concevoir des tableaux de bord via des outils de reporting et datavisualisation ;
Accompagner la maÃ®trise dâ€™ouvrage dans la validation de livrables, les tests, lâ€™assistance Ã  la recette et la conduite du changement sur le projet.
Voir moins","Profil recherchÃ©
Vos compÃ©tences techniques : 
Vous maÃ®trisez la manipulation des donnÃ©es (prÃ©paration, modÃ©lisation, restitution),
Vous maÃ®trisez parfaitement au moins un ETL du marchÃ© (Informatica, Talend, BigQuery, Datafactory,...) et la crÃ©ation de tableaux de bord (Power BI, Tableau, QlikSense, SAP BO, ...),
Python ou SQL nâ€™ont plus de secrets pour vous,
Vos atouts : 
DiplÃ´mÃ©(e) dâ€™une formation supÃ©rieure en Informatique parcours BI, Data, Aide Ã  la DÃ©cision,
Vous possÃ©dez une expÃ©rience d'au moins 3 ans dans la fonction,
Votre esprit dâ€™analyse, de synthÃ¨se, votre organisation et vos capacitÃ©s rÃ©dactionnelles sont souvent reconnus,
Vous apprÃ©ciez travailler en Ã©quipe, dans un contexte multi-projets.
DEVENIR #INNOVATIVE PEOPLE Câ€™ESTâ€¯: 
IntÃ©grer une communautÃ© de 1200 experts passionnÃ©s rÃ©partis entre la France, la Belgique, le Luxembourg, la Suisse, lâ€™Espagne et la Chine.
Construire ensemble les solutions stratÃ©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale.
Voir plus"
Data Engineer F/H,"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'â‚¬"", 'mean_age': '36 ans'}",CDI,Villeurbanne,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 4 ans,Bac +5 / Master,"Descriptif du poste
EnrÃ©sumÃ© :
Poste: Data Engineer F/H
Secteur de l'entreprise :experts conseil dans les secteurs de la banque-assurance, le luxe-retail etlâ€™Industrie
LocalitÃ© : Lyon
Type de contrat : CDI
Niveau dâ€™expÃ©rience :au moins 3 ans
Vous Ãªtes passionnÃ©(e)s par la data ? Vous Ãªtesconvaincus que lâ€™optimisation du patrimoine data des entreprises est laclÃ© de leur performance ? Vous voulez rendre les entreprises data drivenet les aider Ã  se transformer pour prÃ©parer dÃ¨s Ã  prÃ©sent leur futur? Vous Ãªtes au fait des derniÃ¨res tendances et prÃªt Ã  explorer de nouveauxterritoires ?
Vous souhaitez rejoindre un groupe pionnier des grandesinnovations data et digitale ?
Si vous avez rÃ©pondu Â«â€¯Ouiâ€¯Â» Ã  chacune de cesquestions alors devenez Data Engineer pour nos clients grands-comptesdans les secteurs de le luxe/retail, la banque/assurance et lâ€™industrie/services.
Alors,prÃªt Ã  rejoindre lâ€™aventure Micropole ? Nâ€™attendez plus !
EN TANT QUE DATA ENGINEER :
Vous rejoignez notre entitÃ© Data Analytics basÃ©e Ã  Lyon, oÃ¹vous interviendrez sur lâ€™intÃ©gralitÃ© de plusieurs projets avec une visionÂ« Data 360Â° Â», mÃªlant Conseil, Architecture, IntÃ©gration et DataScience. En tant que Data Engineer, vous accompagnerezles directions mÃ©tiers dans l'Ã©valuation de l'efficacitÃ© de leur processus etdans leur stratÃ©gie pour optimiser leur performance.  Vous serez rattachÃ©(e) Ã  lâ€™Ã©quipe Data Analytics,composÃ©e de 50 #InnovativePeople.
Dans vos missions quotidiennes, vous serezamenÃ©s :
A comprendrele besoin de nos clients au travers de missions de type : aide aux choixdâ€™outils, cadrage des besoins, Proof Of Concept ;
Accompagnerles Ã©quipes commerciales sur des rendez-vous client et en phase dâ€™avant-vente ;
Recueilliret analyser les besoins et proposer une architecture technique adaptÃ©e aux casdâ€™usage des clients ;
A rÃ©alisernos projets de construction de Data Platform au travers des activitÃ©s : refonte,migration ou dÃ©veloppement de tableaux de bord dans le respect des exigences dequalitÃ© et sÃ©curitÃ© ;
RÃ©diger ladocumentation des livrables pour rendre les utilisateurs autonomes et lesformer ;
RÃ©diger ladocumentation permettant Ã  l'IT d'assurer la maintenance ;
Accompagnerles consultants moins expÃ©rimentÃ©s dans leur montÃ©e en compÃ©tence ;
Capitaliseret partager les bonnes pratiques, connaissances et retours dâ€™expÃ©rience ;
Voir moins","Profil recherchÃ©
Vos compÃ©tences techniques :
Vous avez un minimum de 3annÃ©es dâ€™expÃ©rience sur des projets Data sur les outils ETL (Talend, SQLServer) et Reporting (Power BI, Tableau Software).
IdÃ©alement au moins unepremiÃ¨re expÃ©rience sur des projets Cloud AWS ou Azure
Vous maÃ®trisez au minimumun langage de programmation (Python, Spark, Scala, R)â€¯;
Vous avez une maitrise desthÃ©ories et outils de modÃ©lisation de donnÃ©es,
Vous maitrisez des conceptsdâ€™industrialisation, Ia C, CI/CD et/ou gestion de version, 
Vos atouts :
VÃ©ritablecoÃ©quipier, vous avez Ã  cÅ“ur de contribuer Ã  la montÃ©e en compÃ©tence de votreÃ©quipe,
Vousrecherchez la variÃ©tÃ© et lâ€™excellence dans votre travail. Autonome et impliquÃ©(e),vous avez le goÃ»t du challenge,
DotÃ©(e) dâ€™unexcellent relationnel et du sens du service, vous avez la capacitÃ© de gÃ©rer unerelation client,
VousdÃ©velopperez votre crÃ©ativitÃ© et votre curiositÃ© grÃ¢ce Ã  une veilletechnologique accrue qui vous permettra de challenger les besoins de vosclients.
Voir plus"
Data Engineer / Databricks (H/F),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'â‚¬"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 4 ans,Bac +5 / Master,"Descriptif du poste
En rÃ©sumÃ© :
Poste : Data Engineer / Databricks
LocalitÃ© : Levallois-Perret
Type de contrat : CDI
Niveau dâ€™expÃ©rience : au moins 3 ans
Vous Ãªtes passionnÃ©(e)s par la data ? Vous Ãªtes convaincus que lâ€™optimisation du patrimoine data des entreprises est la clÃ© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider Ã  se transformer pour prÃ©parer dÃ¨s Ã  prÃ©sent leur futur ? Vous Ãªtes au fait des derniÃ¨res tendances et prÃªt Ã  explorer de nouveaux territoires ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez rÃ©pondu Â«â€¯Ouiâ€¯Â» Ã  chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.
Alors, prÃªt Ã  rejoindre lâ€™aventure Micropole ? Nâ€™attendez plus !
Au sein de notre agence basÃ©e Ã  levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer Databricks (F/H) , vous accompagnerez les directions mÃ©tiers dans l'Ã©valuation de l'efficacitÃ© de leur processus et dans leur stratÃ©gie pour optimiser leur performance. 
Dans vosâ€¯missions quotidiennes, vous serez amenÃ©(e) Ã â€¯: 
DÃ©velopper et maintenir des cas dâ€™usages clients avec les outils et les infrastructures Big Data / Databricks. ModÃ©liser et analyser des donnÃ©es dans le Cloud. Garantir la sÃ©curitÃ© / compliance des donnÃ©esâ€¯; 
Apporter votre rÃ©flexion sur des problÃ©matiques mÃ©tiers Ã  travers lâ€™exploitation et la comprÃ©hension des donnÃ©es. Identifier les sources de donnÃ©es les plus pertinentes et restituer des rÃ©sultats de faÃ§on concise et visuelleâ€¯; 
RÃ©aliser une veille technologique pour Ãªtre Ã  la pointe sur les solutions cloud & Dataâ€¯; 
Participer au dÃ©veloppement de notre centre dâ€™excellence. 
Voir moins","Profil recherchÃ©
Vos compÃ©tences techniquesâ€¯: 
Vous avez un minimum de 3 annÃ©es dâ€™expÃ©rience sur des projets Data dont au moins une sur des projets Databricks (sur GCP et/ou Azure), ou Ã  dÃ©faut une certification Databricks avec lâ€™ambition de vous prÃ©parer Ã  dâ€™autres. 
Vous maÃ®trisez au minimum un langage de programmation (Spark, Scala ou SQL)â€¯; 
Vous avez une maitrise des thÃ©ories et outils de modÃ©lisation de donnÃ©es, 
Vous maÃ®trisez des outils et framework dâ€™industrialisation, IaC, CI/CD et/ou gestion de version, 
Vosâ€¯ atouts: 
Vous Ãªtes passionnÃ©(e), rigoureux(se), curieux(se) et Ã  lâ€™Ã©couteâ€¯; 
Vous avez un bon niveau dâ€™anglais qui vous permet dâ€™intervenir sur des projets Ã  dimension internationaleâ€¯; 
Vous dÃ©velopperez votre crÃ©ativitÃ© et votre curiositÃ© grÃ¢ce Ã  une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. 
Vous souhaitez vous impliquer dans le dÃ©veloppement dâ€™Ã©quipes et de communautÃ©s techniques autour du Cloud et des solutions Data. 
#LI-LL3
Voir plus"
Cloud & Data Engineer (F/H),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'â‚¬"", 'mean_age': '36 ans'}",CDI,Nantes,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 4 ans,Bac +5 / Master,"Descriptif du poste
Micropole accompagne les entreprises Ã  devenir Data Driven grÃ¢ce Ã  la puissance du Cloud. Forte de ses consultants, experts techniques et architectes spÃ©cialisÃ©s dans les solutions AWS, Azure et GCP, Micropole aide les entreprises Ã  devenir plus agiles, et Ã  amÃ©liorer leur niveau de performance.â€¯ 
Au sein de notre agence situÃ©e dans le centre-ville de Nantes, vous accompagnerez les directions mÃ©tiers dans l'Ã©valuation de l'efficacitÃ© de leur processus et dans leur stratÃ©gie pour optimiser leur performance en tant que Cloud & Data Engineer (F/H).
 Dans vosâ€¯missions quotidiennes, vous serez amenÃ©(e) Ã â€¯: 
DÃ©velopper et maintenir des cas dâ€™usages clients avec les outils et les infrastructures Big Data/Cloud
ModÃ©liser et analyser des donnÃ©es dans le Cloud ;
Garantir la sÃ©curitÃ© et la compliance des donnÃ©esâ€¯; 
Apporter votre rÃ©flexion sur des problÃ©matiques mÃ©tiers Ã  travers lâ€™exploitation et la comprÃ©hension des donnÃ©es. 
Identifier les sources de donnÃ©es les plus pertinentes et restituer des rÃ©sultats de faÃ§on concise et visuelleâ€¯; 
RÃ©aliser une veille technologique pour Ãªtre Ã  la pointe sur les solutions Cloud & Dataâ€¯; 
Participer au dÃ©veloppement de notre centre dâ€™excellence GCP
Voir moins","Profil recherchÃ©
Vos compÃ©tences techniquesâ€¯: 
Vous avez un minimum de 3 annÃ©es dâ€™expÃ©rience en tant que Data Engineer dont au moins une premiÃ¨re sur des projets  Azure et GCP ou AWS ;
Vous Ãªtes idÃ©alement certifiÃ©(e) ou Ã  dÃ©faut avez lâ€™ambition de le devenir ;
Vous Ãªtes Ã  l'aise avec un langage de programmation (Spark, Scala, Python, Java ou R)â€¯; 
Vous maitrisez les thÃ©ories et outils de modÃ©lisation de donnÃ©es ;
Des connaissances en industrialisation, CI/CD et/ou gestion de version seront particuliÃ¨rement apprÃ©ciÃ©es 
Vosâ€¯ atouts: 
Vous Ãªtes passionnÃ©(e), rigoureux(se), curieux(se) et Ã  lâ€™Ã©couteâ€¯; 
Vous dÃ©velopperez votre crÃ©ativitÃ© et votre curiositÃ© grÃ¢ce Ã  une veille technologique accrue qui vous permettra de challenger les besoins de vos clients ;
Vous souhaitez vous impliquer dans le dÃ©veloppement de communautÃ©s techniques autour du Cloud GCP et des solutions Data. 
DEVENIR #INNOVATIVEPEOPLE, C'ESTâ€¯: 
Voir plus"
SENIOR DATA ENGINEER AWS (F/H),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'â‚¬"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 7 ans,,"Descriptif du poste
Vous Ãªtes convaincus que lâ€™optimisation duâ€¯patrimoine data des entreprisesâ€¯est la clÃ© de leur performanceâ€¯?â€¯Vous voulez aider les entreprisesâ€¯Ã  devenir plus agiles,et Ã  amÃ©liorer leur niveau de performanceâ€¯grÃ¢ceÃ â€¯la puissance du Cloudâ€¯?â€¯Vous voulez rendre les entreprisesâ€¯data intelligentesâ€¯etles aider Ã  se transformer au travers des nouvelles technologies quâ€™amÃ¨ne leâ€¯cloudâ€¯?â€¯Vous souhaitez rejoindre un groupe pionnier desgrandes innovations data, cloud et digitalesâ€¯? 
 Si vous avezâ€¯rÃ©ponduÂ«â€¯Ouiâ€¯Â»â€¯Ã  chacune de ces questions alorsdevenezâ€¯Consultant Seniorâ€¯pour lâ€™un de nosâ€¯clientsgrands-comptes. 
PrÃªt(e) Ã  rejoindre lâ€™aventureâ€¯ Micropole ?â€¯Nâ€™attendezplusâ€¯! 
Dans le cadre du dÃ©veloppement de notreentitÃ© Cloud4Data, nous recherchons nos futurs collaborateurs souhaitantdevelopper leur carriÃ¨re professionnelle dans les enjeux de la Data.Cloud4Data est spÃ©cialisÃ©e dans la transformation des entreprises par la Dataen utilisant toute la puissance des solutions Cloud. 
Nous accompagnons nos clients par du conseil(stratÃ©gie de transformation par la Data) et par de l'expertise (projet de DataPlatform) sur leurs principaux enjeux BI, dÃ©cisionnelles, analytiques, BigData, AI/ML/GenAI. Nos expertises sont principalement sur AWS, GCP, MicrosoftAzure, Snowflake et Databricks. Nos Ã©quipes sont principalement constituÃ©esd'architecte Data/Cloud, Data ingÃ©nieur, Data analyste, Data scientiste etDevOps/SRE.
En tant que Consultant SÃ©nior : 
 Au sein de notre agence basÃ©e Ã  Levallois-Perret, vousrejoindrez nos experts Cloud4Data . En tant que Senior Data Engineer AWS, vousaccompagnerez les directions mÃ©tiers dans l'Ã©valuation de l'efficacitÃ© de leurprocessus et dans leur stratÃ©gie pour optimiser leur performance. 
Dans vosâ€¯missionsquotidiennes, vous serez amenÃ©(e) Ã â€¯: 
Â·       40%â€¯: dÃ©velopperet maintenir des cas dâ€™usages clients avec les outils et les infrastructuresBig Data / Cloud AWS. ModÃ©liser et analyser des donnÃ©es dans le Cloud. Garantirla sÃ©curitÃ© / compliance des donnÃ©esâ€¯; 
Â·       40%â€¯: apportervotre rÃ©flexion sur des problÃ©matiques mÃ©tiers Ã  travers lâ€™exploitation et lacomprÃ©hension des donnÃ©es. Identifier les sources de donnÃ©es les pluspertinentes et restituer des rÃ©sultats de faÃ§on concise et visuelleâ€¯; 
Â·       10%â€¯: rÃ©aliserune veille technologique pour Ãªtre Ã  la pointe sur les solutions cloud &Dataâ€¯; 
Â·       10%â€¯: participerau dÃ©veloppement de notre entitÃ© Cloud4Data
Voir moins","Profil recherchÃ©
Vos compÃ©tences techniques :
Vous avez un minimum de 3 annÃ©es dâ€™expÃ©rience sur des projets Data et idÃ©alement au moins une annÃ©e dâ€™expÃ©rience sur des projets Cloud AWS (EC2, RDS, Lambda, Kinesis, Redshift, EMR, Connect, SageMaker etc), 
Vous maÃ®trisez au minimum un langage de programmation (Spark, Scala, Python, Java, R)â€¯; 
Vous avez une maitrise des thÃ©ories et outils de modÃ©lisation de donnÃ©es, 
Vous maitrisez des outils et framework dâ€™industrialisation, IaC, CI/CD et/ou gestion de version,  
Vous avez passÃ© au moins une certification AWS technique, et vous avez lâ€™ambition de vous prÃ©parer Ã  dâ€™autres. 
Vosâ€¯atouts : 
Vous Ãªtes passionnÃ©(e), rigoureux(se), curieux(se) et Ã  lâ€™Ã©couteâ€¯; 
Vous avez un bon niveau dâ€™anglais qui vous permet dâ€™intervenir sur des projets Ã  dimension internationaleâ€¯; 
Vous dÃ©velopperez votre crÃ©ativitÃ© et votre curiositÃ© grÃ¢ce Ã  une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. 
Voir plus"
Data Engineer / GCP (H/F),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'â‚¬"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 4 ans,Bac +5 / Master,"Descriptif du poste
En rÃ©sumÃ© :
Poste : Data Engineer / GCP
LocalitÃ© : Levallois-Perret
Type de contrat : CDI
Niveau dâ€™expÃ©rience : au moins 3 ans
Vous Ãªtes passionnÃ©(e)s par la data ? Vous Ãªtes convaincus que lâ€™optimisation du patrimoine data des entreprises est la clÃ© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider Ã  se transformer pour prÃ©parer dÃ¨s Ã  prÃ©sent leur futur ? Vous Ãªtes au fait des derniÃ¨res tendances et prÃªt Ã  explorer de nouveaux territoires ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez rÃ©pondu Â«â€¯Ouiâ€¯Â» Ã  chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.
Alors, prÃªt Ã  rejoindre lâ€™aventure Micropole ? Nâ€™attendez plus !
Au sein de notre agence basÃ©e Ã  levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions mÃ©tiers dans l'Ã©valuation de l'efficacitÃ© de leur processus et dans leur stratÃ©gie pour optimiser leur performance. 
Dans vosâ€¯missions quotidiennes, vous serez amenÃ©(e) Ã â€¯: 
DÃ©velopper et maintenir des cas dâ€™usages clients avec les outils et les infrastructures Big Data / Cloud GCP. ModÃ©liser et analyser des donnÃ©es dans le Cloud. Garantir la sÃ©curitÃ© / compliance des donnÃ©esâ€¯; 
Apporter votre rÃ©flexion sur des problÃ©matiques mÃ©tiers Ã  travers lâ€™exploitation et la comprÃ©hension des donnÃ©es. Identifier les sources de donnÃ©es les plus pertinentes et restituer des rÃ©sultats de faÃ§on concise et visuelleâ€¯; 
RÃ©aliser une veille technologique pour Ãªtre Ã  la pointe sur les solutions cloud & Dataâ€¯; 
Participer au dÃ©veloppement de notre centre dâ€™excellence GCP. 
Voir moins","Profil recherchÃ©
Vos compÃ©tences techniquesâ€¯: 
Vous avez un minimum de 3 annÃ©es dâ€™expÃ©rience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou Ã  dÃ©faut une certification GCP avec lâ€™ambition de vous prÃ©parer Ã  dâ€™autres. 
Vous maÃ®trisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R)â€¯; 
Vous avez une maitrise des thÃ©ories et outils de modÃ©lisation de donnÃ©es, 
Vous maitrisez des outils et framework dâ€™industrialisation, IaC, CI/CD et/ou gestion de version, 
Vosâ€¯ atouts: 
Vous Ãªtes passionnÃ©(e), rigoureux(se), curieux(se) et Ã  lâ€™Ã©couteâ€¯; 
Vous avez un bon niveau dâ€™anglais qui vous permet dâ€™intervenir sur des projets Ã  dimension internationaleâ€¯; 
Vous dÃ©velopperez votre crÃ©ativitÃ© et votre curiositÃ© grÃ¢ce Ã  une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. 
Vous souhaitez vous impliquer dans le dÃ©veloppement dâ€™Ã©quipes et de communautÃ©s techniques autour du Cloud GCP et des solutions Data. 
#LI-LL3
Voir plus"
DATA ENGINEER AWS (F/H),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'â‚¬"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 4 ans,,"Descriptif du poste
Vous Ãªtes convaincus que lâ€™optimisation duâ€¯patrimoine data des entreprisesâ€¯est la clÃ© de leurperformanceâ€¯?â€¯Vous voulez aider lesentreprisesâ€¯Ã  devenir plus agiles, etÃ  amÃ©liorer leur niveau de performanceâ€¯grÃ¢ce Ã â€¯la puissance du Cloudâ€¯?â€¯Vous voulez rendre lesentreprisesâ€¯data intelligentesâ€¯et lesaider Ã  se transformer au travers des nouvelles technologies quâ€™amÃ¨ne leâ€¯cloudâ€¯?â€¯Voussouhaitez rejoindre un groupe pionnier des grandes innovations data, cloud etdigitalesâ€¯? 
 Si vous avezâ€¯rÃ©ponduÂ«â€¯Ouiâ€¯Â»â€¯Ã  chacune de ces questions alors devenezâ€¯Consultant ConfirmÃ© pour lâ€™un de nosâ€¯clients grands-comptes. 
PrÃªt(e) Ã  rejoindrelâ€™aventureâ€¯ Micropole ?â€¯Nâ€™attendez plusâ€¯! 
Dans le cadre du dÃ©veloppement de notre entitÃ© Cloud4Data, nous recherchons nos futurscollaborateurs souhaitant developper leur carriÃ¨re professionnelle dansles enjeux de la Data. Cloud4Data est spÃ©cialisÃ©e dans la transformation desentreprises par la Data en utilisant toute la puissance des solutionsCloud. 
Nous accompagnons nos clients par du conseil (stratÃ©gie detransformation par la Data) et par de l'expertise (projet de Data Platform) surleurs principaux enjeux BI, dÃ©cisionnelles, analytiques, Big Data, AI/ML/GenAI.Nos expertises sont principalement sur AWS, GCP, Microsoft Azure, Snowflake etDatabricks. Nos Ã©quipes sont principalement constituÃ©es d'architecteData/Cloud, Data ingÃ©nieur, Data analyste, Data scientiste et DevOps/SRE.
En tant que ConsultantConfirmÃ© : 
Au sein de notre agence basÃ©e Ã  Levallois-Perret, vousrejoindrez nos experts Cloud4Data . En tant que Data Engineer ConfirmÃ© AWS,vous accompagnerez les directions mÃ©tiers dans l'Ã©valuation de l'efficacitÃ© deleur processus et dans leur stratÃ©gie pour optimiser leur performance. 
Dans vosâ€¯missionsquotidiennes, vous serez amenÃ©(e) Ã â€¯: 
Â·       40%â€¯: dÃ©velopper etmaintenir des cas dâ€™usages clients avec les outils et les infrastructures BigData / Cloud AWS. ModÃ©liser et analyser des donnÃ©es dans le Cloud. Garantir lasÃ©curitÃ© / compliance des donnÃ©esâ€¯; 
Â·       40%â€¯: apporter votrerÃ©flexion sur des problÃ©matiques mÃ©tiers Ã  travers lâ€™exploitation et lacomprÃ©hension des donnÃ©es. Identifier les sources de donnÃ©es les pluspertinentes et restituer des rÃ©sultats de faÃ§on concise et visuelleâ€¯; 
Â·       10%â€¯: rÃ©aliser une veilletechnologique pour Ãªtre Ã  la pointe sur les solutions cloud & Dataâ€¯; 
Â·       10%â€¯: participer audÃ©veloppement de notre entitÃ© Cloud4Data.
Voir moins","Profil recherchÃ©
VoscompÃ©tences techniques :
Â·   
Vousavez un minimum de 2 annÃ©es dâ€™expÃ©rience sur des projets Data et idÃ©alement aumoins une premiÃ¨re expÃ©rience sur des projets Cloud AWS (EC2, RDS, Lambda,Kinesis, Redshift, EMR, Connect, SageMaker etc), 
Â·       VousmaÃ®trisez au minimum un langage de programmation (Spark, Scala, Python, Java,R)â€¯; 
Â·       Vousavez une maitrise des thÃ©ories et outils de modÃ©lisation de donnÃ©es, 
Â·       Vousmaitrisez des outils et framework dâ€™industrialisation, IaC, CI/CD et/ou gestionde version,  
Â·       Vousavez passÃ© au moins une certification AWS technique, et vous avez lâ€™ambition devous prÃ©parer Ã  dâ€™autres. 
Vosâ€¯atouts : 
Â·       VousÃªtes passionnÃ©(e), rigoureux(se), curieux(se) et Ã  lâ€™Ã©couteâ€¯; 
Â·       Vousavez un bon niveau dâ€™anglais qui vous permet dâ€™intervenir sur des projets Ã dimension internationaleâ€¯; 
Â·       VousdÃ©velopperez votre crÃ©ativitÃ© et votre curiositÃ© grÃ¢ce Ã  une veilletechnologique accrue qui vous permettra de challenger les besoins de vos clients. 
Voir plus"
Senior Data Engineer (H/F),"{'name': 'EPSILON FRANCE', 'sector': 'Digital Marketing / Data Marketing, Big Data, AdTech / MarTech', 'employees': '600 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '38 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,Bac +4,,
Expert Python-Data Engineer H/F,"{'name': 'OPEN', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '4000 collaborateurs', 'creation_year': '1989', 'turnover': '420M', 'mean_age': '40 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
ğŸ’¡ Qui sommes-nous ? 
 Rejoindre la BU Cloud & DevOps, câ€™est rejoindre la communautÃ© d'experts techniques qui accompagne des sujets stratÃ©giques et transverses pour Open France. 
 Afin d'accompagner nos clients dans la mise en Å“uvre de leur transformation digitale, et dans le cadre de leurs projets Ã  forte valeur ajoutÃ©e, nous recrutons un.e Expert Python-Data Engineer   H/F !  ğŸ“Œ Vos missions dÃ©taillÃ©es  
Etablir ou challenger le cahier des charges,  
RÃ©diger les spÃ©cifications techniques,  
DÃ©finir lâ€™architecture de la librairie,  
DÃ©velopper, documenter, tester et maintenir ces librairies en sâ€™appuyant sur des pratiques de dÃ©veloppement Ã  lâ€™Ã©tat de lâ€™art,  
Optimiser le traitement de jeux de donnÃ©es de grande taille (plusieurs tÃ©raoctets) pour minimiser les coÃ»ts et dÃ©lais de traitement,  Adapter les librairies pour permettre le traitement de donnÃ©es diverses   (comptes-rendus mÃ©dicaux, images dâ€™IRM, bases hospitaliÃ¨res, bases nationales),   Mentorer des profils dÃ©veloppeurs moins expÃ©rimentÃ©s,   Collaborer avec les Ã©quipes Produit, de la Direction Technique et de la Direction des   donnÃ©es en suivant la mÃ©thodologie agile (scrum ou kanban) (gestion d'un backlog, rituels, etc.),  
 âš™ Votre environnement Technique 
 python3, R, designs patterns, pytest, NumPy, Pandas, (Py)Spark Airflow, Dask, AWS S3, Azure Blob Storage...  
ğŸŒŸ Vous Ãªtes 
 PassionnÃ©.e de technique et justifiez de 3 Ã  6 ans dâ€™expÃ©rience en dÃ©veloppement Back end python, permettant dâ€™avoir une connaissance approfondie du langage, y compris ses fonctionnalitÃ©s avancÃ©es, ses bibliothÃ¨ques standard et ses meilleures pratiques
MaÃ®trisez bien dans un environnement cloud de lâ€™utilisation du stockage objet (eg.AWS S3 ou Azure Blob Storage),
 Nous recherchons de la technique mais aussi de la passion et du dynamisme ! 
 ğŸ¤ Vous Ãªtes mettre de votre carriÃ¨re : Comment ?  
 IntÃ©grer des projets transverses et stratÃ©giques : outils internes, meetups, summits, formations, avant-ventes, chiffrage, veille, audit SI â€¦  
Evoluer vers un rÃ´le de leader Technique grÃ¢ce Ã  un accompagnement personnalisÃ© et un parcours de formation et certifications adaptÃ©es.  
 ğŸ’¬ Notre Process De Recrutement 
ğŸ“ Bref Ã©change tÃ©lÃ©phonique 
ğŸ—¨ Rencontre RH pour parler de vous, de vos aspirations professionnelles et vous prÃ©senter Open, 
ğŸ’­ Echange avec lâ€™un des experts 
ğŸ†— Temps de partage avec votre futur manager. 
âœ…AprÃ¨s vous avoir souhaitÃ© la bienvenue vous bÃ©nÃ©ficiez dâ€™un parcours dâ€™intÃ©gration sur-mesure. 
  CODE REC : ACH23516  
   Quâ€™attendez-vous pour Ãªtre Open ?
Voir moins",
Data Engineer H/F,"{'name': 'BETCLIC GROUP', 'sector': 'Application mobile', 'employees': '1050 collaborateurs', 'creation_year': '2005', 'turnover': '835Mâ‚¬', 'mean_age': '33 ans'}",CDI,Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail total,,,,"Descriptif du poste
WE ARE BETCLIC
            <p>Betclic est une sociÃ©tÃ© tech de jeu en ligne et leader du pari sportif dans plusieurs pays EuropÃ©ens. Tous les jours Betclic s&#39;engage Ã  satisfaire la passion du sport en fournissant la meilleure expÃ©rience de divertissement Ã  ses joueurs grÃ¢ce Ã  des technologies de pointe innovantes qui leur assurent un environnement de jeu sÃ»r et sain. </p>
            <p>Betclic, dont le siÃ¨ge franÃ§ais est Ã  Bordeaux, est une entreprise multiculturelle et internationale comptant prÃ¨s de 950 collaborateurs rÃ©partis dans 5 pays d&#39;Europeâ€¯: France, Italie, Malte, Pologne, et Portugal.  </p>
            <p>L&#39;univers du sport et du jeu te fait vibrer ? Tu aimes les dÃ©fis, tu es passionnÃ© par la tech et participer Ã  l&#39;effort collectifâ€¯? Rejoins l&#39;aventureâ€¯! </p>
            <p><strong>NO TECH NO GAME </strong> </p>
            <p>Betclic place la performance technologique au cÅ“ur de ses activitÃ©s :  </p>
            <ul><li>Des applications entiÃ¨rement dÃ©veloppÃ©es en interne pour une maÃ®trise optimale de la chaÃ®ne de valeur : segmentation en temps rÃ©el, sensibilisation et intÃ©gration de rÃ¨gles pour protÃ©ger les joueurs, dÃ©tection des risques â€¦  </li></ul>
            <ul><li>Des interfaces conÃ§ues pour une expÃ©rience joueur immersive : hautement sÃ©curisÃ©es, capables de gÃ©rer de forts pics de connexion et d&#39;intÃ©grer les Ã©vÃ©nements sportifs en streaming. </li><li>Des Ã©quipes Tech organisÃ©es en squads et tribus autonomes, chacune responsable d&#39;un domaineâ€¯fonctionnelâ€¯et technique qui permettent de gÃ©rer des projets de A Ã  Zâ€¯: dÃ©veloppement, test de charge, livraison, suivi de production (monitoring, alerting).  </li></ul>
            <p><strong>ENTER THE GAME</strong></p>
            <p>En tant que Data Engineer, tu intÃ©greras une Ã©quipe agile IT afin de construire les pipelines de transformation data. Dans ce cadre, tu travailleras Ã©troitement avec les dÃ©veloppeurs et le PO de l&#39;Ã©quipe ainsi que les Data Architect sur la partie modÃ©lisation. </p>
            <p><strong>YOUR ROLE WITHIN BETCLIC</strong></p>
            <p>Au sein d&#39;une tribe Betclic et accompagnÃ© par une guild de data engineers DBT, tes missions principales seront deâ€¯: </p>
            <ul><li>Participer aux phases de conception et de dÃ©veloppement des projets de transformation data </li></ul>
            <ul><li>DÃ©velopper l&#39;ensemble de la chaÃ®ne de transformation (Extract Load Transform / Extract Transform Load) au sein du Data Lake (Snowflake). Construction du Lake House et des couches Silver/Gold Ã  partir de la couche Bronze du Lake. </li><li>Automatiser le dÃ©ploiement des pipelines data (DBT cloud, CICD Jenkins) </li><li>GÃ©rer l&#39;Ã©volution des solutions proposÃ©es, et en assurer la maintenance </li><li>RÃ©diger la documentation relative aux projets </li></ul>
            <p></p>
            <p><strong>TECHNICAL ENVIRONMENT</strong></p>
            <ul><li>Snowflake</li><li>DBT Core / DBT Cloud AWS</li><li>Jenkins </li><li>Github</li></ul>

            <p><strong>WHO WE ARE LOOKING FOR?</strong></p>
            <p>Des collaborateurs avec une bonne dose d&#39;humour, du respect et de la bienveillance, un amour pour la tech, un peu de zÃ¨le et une rÃ©elle passion pour leur mÃ©tier !</p>
            <p>Ce job est fait pour toi si :</p>
            <ul><li>Tu es diplÃ´mÃ©(e) d&#39;une Ã©cole d&#39;ingÃ©nieur, Ã©cole informatique, MIAGE</li><li>Tu disposes d&#39;une expÃ©rience professionnelle rÃ©ussie de 3 ans minimum en tant que Data Engineer / Data Ops / ML Ops dans un environnement Cloud Public</li><li>Tu es dotÃ©(e) de fortes compÃ©tences en dÃ©veloppement, d&#39;une appÃ©tence pour l&#39;automatisation (CI/CD) et le scripting et tu souhaites rejoindre un environnement professionnel challengeant. </li><li>Tu es sensible Ã  la performance, la fiabilitÃ©, la maintenabilitÃ© et la scalabilitÃ© de votre code et des architectures que tu conÃ§ois</li><li>Tu maÃ®trises impÃ©rativement un des langages de dÃ©veloppement Python, Scala, Java et tu as une expÃ©rience rÃ©ussie avec l&#39;Infrastructure As Code</li><li>Et enfin, tu parles anglais couramment</li></ul>
            <p></p><p><strong>WHAT ARE THE RECRUITMENT </strong><strong>STEPS?</strong> </p>
            <ul><li>Si ta candidature est sÃ©lectionnÃ©e, tu seras contactÃ© par Maxime sous une semaine pour une prÃ©qualification RH (30 minutes) </li></ul>
            <ul><li>Nous te demanderons ensuite de rÃ©aliser le Test AssessFirst (personnalitÃ©, motivations et rÃ©flexion) </li><li>Tu rencontreras ensuite ton futur manager puis Laurent le manager de la Data Platform qui t&#39;Ã©valuera techniquement.</li><li>Enfin, Maxime te recevra en entretien final RH et vous dÃ©brieferez ensemble ton Test AssessFirst </li></ul>
            <p>Afin d&#39;offrir une expÃ©rience candidat idÃ©ale, le processus de recrutement Betclic dure, en moyenne, 4 Ã  6 semaines. </p>
            <p><strong>WHAT CAN YOU EXPECT?</strong></p>

            <ul><li>25 jours de congÃ©s payÃ©s et 10 jours de Â«â€¯RTTâ€¯Â» </li><li>Une carte Ticket RestaurantÂ® crÃ©ditÃ©e de 10â‚¬ par jour (financÃ©e Ã  hauteur de 50%) </li><li>Une mutuelle prise en charge Ã  100% pour toi et tes enfants  </li><li>Un abonnement de transport pris en charge Ã  hauteur de 50% ou une prime annuelle de mobilitÃ© durable (200â‚¬ pour les trajets domicile â€“ travail en transport durable) </li><li>Un accord de tÃ©lÃ©travail avantageux </li></ul>
            <ul><li>Un programme de formation annuel personnalisÃ© </li><li>Des locaux hors du commun avec un rooftop pour profiter de pauses et de dÃ©jeuners au soleil face Ã  la CitÃ© du Vin </li><li>Des animations internes pour pimenter ton quotidien  </li><li>Des cours de sports gratuits dans nos locaux </li></ul>
            <p>Et surtout, l&#39;opportunitÃ© de travailler dans une atmosphÃ¨re jeune, conviviale et funâ€¯! </p>

            <p><strong>Poste en CDI Ã  pourvoir dÃ¨s que possible Ã  Bordeaux</strong></p>
            <p>Betclic Group - 117 quai de Bacalan 33300 BORDEAUX</p>
            <p>Tous nos postes sont ouverts aux personnes en situation de handicap.</p>
Voir moins",
Stage - LLM Data Engineer (H/F),"{'name': 'WITHINGS', 'sector': 'Objets connectÃ©s', 'employees': '400 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",Stage,Issy-les-Moulineaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Chez Withings, nous souhaitons redonner aux individus le contrÃ´le de leur santÃ©.
Nous avons lâ€™obsession de crÃ©er des produits beaux et intuitifs, afin que chacun puisse les utiliser facilement au quotidien; nos balances connectÃ©es, montres hybrides, tensiomÃ¨tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourdâ€™hui utilisÃ©s par des millions dâ€™utilisateurs.
Notre objectif : permettre la prÃ©vention, le dÃ©pistage et lâ€™accompagnement dâ€™un certain nombre de maladies chroniques via des produits et des services innovants, afin de rÃ©volutionner la maniÃ¨re dont on prend soin de notre santÃ©.
Sur ce poste Ã  mi-chemin entre le traitement du langage naturel et le Data Engineering, tes responsabilitÃ©s seront les suivantes :
DÃ©velopper des pipelines de donnÃ©es utilisant des modÃ¨les de langage via API (OpenAI notamment)
Participer Ã  l'ingÃ©nierie des prompts pour optimiser l'utilisation de ces modÃ¨les
EntraÃ®ner les modÃ¨les de langage pour amÃ©liorer leur performance
Tester, entraÃ®ner et dÃ©ployer des modÃ¨les de langage open-source pour une utilisation on-premise
DÃ©velopper et tester des pipelines dâ€™agents (Langchain)
IntÃ©grer des bases de connaissances (Langchain, Llama Index)
Participer Ã  la maintenance et lâ€™administration de base de donnÃ©es (ClickHouse / PostgresSQL / ElasticSearch)
ModÃ©lisation de donnÃ©es en SQL (SQL - dbt)
Maintenance et administration de machines virtuelles (Unix)
Soutien technique Ã  l'Ã©quipe et formation des Ã©quipes mÃ©tiers aux bases de SQL
Challenger les Ã©quipes mÃ©tier sur les usages qui peuvent Ãªtre faits des LLM (notamment Support Client et Marketing)
Requirements
Fortes compÃ©tences informatiques : SQL, Python, Linux, dÃ©veloppement de connexions APIâ€¦
ExpÃ©rience ou intÃ©rÃªt marquÃ© pour le traitement du langage naturel (NLP) et les Large Language Models
AppÃ©tence forte pour les challenges techniques : stack on-premise, outils open-source, contraintes physiques des serveurs, sÃ©curitÃ© forte liÃ©e Ã  lâ€™utilisation de donnÃ©es de santÃ©â€¦
Rigueur, autonomie, prise d'initiatives, curiositÃ©...
MaÃ®trise parfaite de la communication en franÃ§ais et en anglais, aussi bien Ã  lâ€™Ã©crit quâ€™Ã  lâ€™oral
Stage de cÃ©sure ou stage de fin dâ€™Ã©tudes uniquement
Benefits
Rejoindre lâ€™aventure Withings, câ€™est :
IntÃ©grer un des pionniers et leaders mondiaux de la santÃ© connectÃ©e, plusieurs fois primÃ© au Consumer Electronic Show
Contribuer Ã  des projets innovants et ambitieux pour la santÃ© de demain dans un environnement agile et en constante Ã©volution
IntÃ©grer une entreprise internationale, membre de la FrenchTech 120, dont les Ã©quipes sont basÃ©es Ã  Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer Ã  lâ€™amÃ©lioration continue de nos produits et services en les bÃªta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collÃ¨gues
BÃ©nÃ©ficier de nombreux avantages : RÃ©ductions pour des activitÃ©s culturelles et sportives, restaurant dâ€™entreprise, et bien plus encore
Participer Ã  la Withings Med Academy en assistant Ã  des confÃ©rences de professionnels de santÃ© afin de renforcer ses connaissances dans le domaine mÃ©dical
Collaborer avec des collÃ¨gues passionnÃ©s et cÃ©lÃ©brer ensemble chacune de nos rÃ©ussites !
Toutes les candidatures reÃ§ues sont Ã©tudiÃ©es indÃ©pendamment de lâ€™origine ethnique, des croyances, de la religion, du genre, de lâ€™orientation sexuelle ou de la santÃ© des candidats. Withings aspire Ã  offrir et garantir lâ€™Ã©galitÃ© des chances aux candidats et seules les personnes habilitÃ©es (RH et Management) auront accÃ¨s aux informations concernant votre candidature.
Voir moins",
Data Engineer - Machine Learning (H/F),"{'name': 'WITHINGS', 'sector': 'Objets connectÃ©s', 'employees': '400 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",CDI,Issy-les-Moulineaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Withings is on a mission to be the trusted leader in clinical-grade smart health devices. Already the leading innovator of smart scales, our product portfolio includes connected scales, connected blood pressure monitors, sleep monitors, thermometers, and health/activity wearables.
The mission of the Machine Learning team is to craft algorithms that leverage sensor data from our products to identify heart diseases, categorize sleep stages, estimate heart rate, among other functions. Given that many of these algorithms are integrated directly into our products and must adhere to strict requirements in terms of performance, speed, and memory usage, the team is actively seeking to enhance its expertise in software development.
Reporting directly to the Head of Machine Learning, the primary role of the Data Engineer in the Machine Learning team is to structure
the data flow from the sensors to the user end
the data storage within the Machine Learning team
As a Data Engineer, you will be responsible for:
Design and maintenance of the data structures which embed the measures and algorithms acquired or computed by our devices, and sent through our servers to the user end 
Guidelines and processes to ensure proper usage of these data structures
Design and maintenance of the storage system of the ML datasets
Design of the internal structure of the ML datasets 
Design and maintenance of the storage system of the ML models
Provide regular support to the MLOps tasks within the team
Requirements
Master's degree in computer science or engineering with an track record of at least 2 years in a similar role.
Highly skilled in Python and SQL programming (excellent coding practices)
Excellent knowledge of data structures
Familiar with ML or other related algorithmic field.
Benefits
Joining the Withings adventure means :
Joining one of the world's pioneers and leaders in connected health, winner of several awards at the Consumer Electronic Show,
Contributing to innovative and ambitious projects for the health of tomorrow in an agile and constantly evolving environment,
Join an international company, member of the FrenchTech 120, with teams based in Issy-les-Moulineaux, Boston, Hong-Kong and Shenzhen,
Participate in the continuous improvement of our products and services by beta-testing them before their release, especially during our numerous sports sessions with colleagues,
Benefit from numerous advantages: Stock Options, smartphone and computer of your choice, discounts for cultural and sports activities, company restaurant, and much more,
Participate in the Withings Med Academy by attending lectures by healthcare professionals to strengthen your knowledge in the medical field,
Collaborate with passionate colleagues and celebrate each of our successes together!
At Withings, we know that diversity, equity and inclusivity are paramount to fostering innovation. We rely on the unique skill sets, life experiences and perspectives of each team member to accomplish our missionâ€”creating technology that people love, to make better health part of everyday life.
Voir moins",
Stage - Data Engineer - ML (H/F),"{'name': 'WITHINGS', 'sector': 'Objets connectÃ©s', 'employees': '400 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",Stage,Issy-les-Moulineaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Chez Withings, nous dÃ©veloppons des appareils de santÃ© connectÃ©e : nos balances connectÃ©es, montres hybrides, tensiomÃ¨tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourdâ€™hui utilisÃ©s par des millions dâ€™utilisateurs. Notre objectif est de permettre la prÃ©vention, le dÃ©pistage et lâ€™accompagnement dâ€™un certain nombre de maladies chroniques via des produits et des services innovants afin de rÃ©volutionner la maniÃ¨re dont on prend soin de notre santÃ©.
Au sein de lâ€™Ã©quipe Machine Learning, nous dÃ©veloppons des algorithmes pour extraire des informations physiologiques et mÃ©dicales pour nos utilisateurs tels que le SPO2, la frÃ©quence cardiaque, la dÃ©tection de diverses pathologies comme la fibrillation atriale, lâ€™apnÃ©e du sommeilâ€¦
IntÃ©grÃ©.e au sein de lâ€™Ã©quipe Machine Learning, tu auras une ou plusieurs des responsabilitÃ©s suivantes :
DÃ©velopper un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de sÃ©curitÃ© ;
Construire des dashboards de visualisation ;
Construire un systÃ¨me dâ€™alerte pour notifier les contributeurs dâ€™Ã©ventuels problÃ¨mes ;
DÃ©velopper des outils permettant de corriger les Ã©ventuels problÃ¨mes de faÃ§on automatisÃ©e ;
Requirements
Ã€ la recherche d'un stage d'une durÃ©e de 3 Ã  6 mois ;
PrÃ©paration dâ€™un Master en Ã©cole dâ€™ingÃ©nieur ou Ã©quivalent / annÃ©e de cÃ©sure possible ;
MaÃ®trise de Python ;
MaÃ®trise de Debian ou de Ubuntu, de Shell et de lâ€™environnement Linux ;
PremiÃ¨re expÃ©rience sur du dÃ©veloppement logiciel ;
Culture DevOps (omniprÃ©sence du monitoring, automatisation des tÃ¢ches, â€¦)
ComprÃ©hension de la culture et des besoins des diffÃ©rents membres de lâ€™Ã©quipe ;
Rigueur, autonomie, prise dâ€™initiative, curiositÃ©.
Benefits
Rejoindre lâ€™aventure Withings, câ€™est :
IntÃ©grer un des pionniers et leaders mondiaux de la santÃ© connectÃ©e, plusieurs fois primÃ© au Consumer Electronic Show
Contribuer Ã  des projets innovants et ambitieux pour la santÃ© de demain dans un environnement agile et en constante Ã©volution
IntÃ©grer une entreprise internationale, membre de la FrenchTech 120, dont les Ã©quipes sont basÃ©es Ã  Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer Ã  lâ€™amÃ©lioration continue de nos produits et services en les bÃªta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collÃ¨gues
Participer Ã  la Withings Med Academy en assistant Ã  des confÃ©rences de professionnels de santÃ© afin de renforcer ses connaissances dans le domaine mÃ©dical
Collaborer avec des collÃ¨gues passionnÃ©s et cÃ©lÃ©brer ensemble chacune de nos rÃ©ussites !
Toutes les candidatures reÃ§ues sont Ã©tudiÃ©es indÃ©pendamment de lâ€™origine ethnique, des croyances, de la religion, du genre, de lâ€™orientation sexuelle ou de la santÃ© des candidats. Withings aspire Ã  offrir et garantir lâ€™Ã©galitÃ© des chances aux candidats et seules les personnes habilitÃ©es (RH et Management) auront accÃ¨s aux informations concernant votre candidature.
Voir moins",
Creative Tech - FINANCE - Data Engineer F/H,"{'name': 'DEVOTEAM CREATIVE TECH', 'sector': 'IT / Digital, Transformation, SaaS / Cloud Services', 'employees': '850 collaborateurs', 'creation_year': '2021', 'turnover': '100Mâ‚¬', 'mean_age': '30 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Tu auras pour mission dâ€™accompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data. 
IntÃ©grÃ©(e) Ã  une Ã©quipe dâ€™experts techniques, tu auras pour missions de :
Analyser les besoins clients
Animer des ateliers afin dâ€™Ã©tudier et cadrer les besoins clients
PrÃ©coniser les solutions et architectures cibles
DÃ©finir les mÃ©thodologies de dÃ©ploiement et plans de migration
RÃ©diger les dossiers dâ€™architecture et spÃ©cifications techniques
Construire les architectures de donnÃ©es
Concevoir et mettre en place des systÃ¨mes de donnÃ©es rÃ©silients et sÃ©curisÃ©s (data warehouse, data lake, systÃ¨mes temps-rÃ©els)
Construire et dÃ©ployer les pipelines de donnÃ©es (ETL)
Assurer la migration des donnÃ©es vers les nouveaux environnements
Analyser les donnÃ©es
Analyser les donnÃ©es sources afin dâ€™identifier et Ã©valuer des cas dâ€™usage mÃ©tier
Mettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudioâ€¦)
SÃ©lectionner, entraÃ®ner, Ã©valuer et dÃ©ployer des modÃ¨les prÃ©dictifs en sâ€™appuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn)
Accompagner et former
Assurer une veille technologique continue sur les solutions cloud
Accompagner et former les Ã©quipes clients aux mÃ©thodes et concepts du cloud
Tu seras accompagnÃ©(e) en interne pour monter rapidement en compÃ©tences sur GCP dans lâ€™objectif de devenir certifiÃ© Google sur ta practice.
Voir moins","Profil recherchÃ©
DiplÃ´mÃ©(e) d'une Ã©cole d'ingÃ©nieurs ou d'un Master 2 en Informatique, tu disposes d'une expÃ©rience significative au sein de projets Data : architecture, traitement ou analyse de donnÃ©es.
Tu maÃ®trises au minimum un langage de programmation appliquÃ© Ã  lâ€™analyse de donnÃ©es (Scala, R, Python).
Tu as de bonnes compÃ©tences dans de lâ€™architecture des systÃ¨mes, bases de donnÃ©es, mÃ©thodologies dâ€™analyse
Tu es passionnÃ©(e) par la Business Intelligence, le Big Data, lâ€™Internet des objets (IoT) et le Machine Learning
Une connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, â€¦) est un plus.
Tu as une solide comprÃ©hension de la dimension technique et fonctionnelle des projets IT
Curieux(se), autonome et Ã  lâ€™Ã©coute, tu possÃ¨des un rÃ©el esprit dâ€™analyse
Ta maÃ®trise de l'anglais te permettra de gÃ©rer des projets en contexte international"
Data Engineer EMEA (F/M/D),"{'name': 'FLOWDESK', 'sector': 'FinTech / InsurTech, SaaS / Cloud Services, Blockchain', 'employees': '100 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Flowdesk is seeking a highly motivated Data Engineer to join the team and managed by the Quentin, the Lead Data!
The data engineer will be an integral part of the growing data team, working closely with our trading and quantitative departments to provide a platform and tools to answer their analytical needs. The data platform revolves around Dagster deployed on Kubernetes for the orchestration, dbt on BigQuery for the transformations, and Looker for the visualization.
Among our current challenges, we are currently focusing on the real-time ingestion and processing of terabytes of market data.
Responsibilities
Design, build, and maintain efficient, scalable, and reliable batch and streaming data pipelines to support Flowdesk's trading infrastructure.
Develop and maintain data warehouses, data lakes, and other data management systems with a strong focus on logical and physical modeling.
Contribute early on to the definition of the data team's data products to maximize ease of access, data quality, and related documentation.
Collaborate with the software engineering team to integrate data-related functionality into Flowdesk's trading infrastructure and other applications.
Leverage cutting-edge data engineering technologies to continually improve the speed, reliability, and scalability of Flowdesk's data processing capabilities.
Develop and maintain strong processes and procedures for data quality control, data validation, data documentation and, data integration.
Collaborate with cross-functional teams including traders, developers, and compliance officers to ensure that all data used by Flowdesk is accurate, timely, and compliant with relevant regulations and requirements.
Requirements
Bachelor's or Master's degree in Computer Science, Engineering, or related field.
3+ years of experience in data engineering or related field.
Awareness of software, data, and analytics engineering best practices (e.g. programming standards, data modelization, code idempotency....)
General understanding of systems architecture and concepts (distributed computing, lake-house architecture, ci/cd workflows...)
Experience optimizing modern data warehousing platforms (BigQuery is a plus).
Strong communication skills and ability to work collaboratively in a fast-paced international environment.
Knowledge of the data engineering ecosystem (contribution to open source projects is a plus).
Strong analytical and problem-solving skills with a keen attention to detail.
Benefits
ğŸ’¸ BSPCE
ğŸŒ International environment (English is the main language)
ğŸšƒ 50% of transportation costs & a sustainable mobility agreement
ğŸ” Swile lunch voucher (â‚¬9.25 per day, 60% covered)
ğŸ¥ 100% Alan Blue covered for you and your children
ğŸ’» Top of the range equipment: Macbook, keyboard, laptop stand, 4K monitor & headphones
ğŸ‰ Team events and offsites
ğŸ”œ Coming soon : gym memberships, international mobility & lot of other cool benefits !
Recruitment process
ğŸ‘€ Are you interested in this job but feel you haven't ticked all the boxes? Don't hesitate to apply and tell us in the cover letter section why we should meet!
ğŸ“ Here's what you can expect if you apply:
HR interview (30')
Technical test
Technical interview (60')
Chat with the Head of People (30') and the Head of Department (30')
On the agenda: discussions rather than trick questions! These moments of exchange will allow you to understand how Flowdesk works and its values. But they are also (and above all) an opportunity for you to present your career path and your expectations for your next job!
Voir moins",
Senior Data Engineer (H/F),"{'name': 'PUBLICIS FRANCE', 'sector': 'Marketing / Communication, PublicitÃ©, Digital, Relations publiques, AdTech / MarTech, EvÃ©nementiel, Design', 'employees': '5000 collaborateurs', 'creation_year': '1926', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,Bac +4,"Descriptif du poste
Dans le cadre du dÃ©veloppement de notre pÃ´le Data & Analytics Platform (cadrage fonctionnel et technique, dÃ©finition de use-cases, stratÃ©gie des moyens, accompagnement du changement, mise en Å“uvre, maintenance et commercialisation de solutions), nous recherchons un(e) Consultant SÃ©nior Data Engineer qui aura pour missions : 
-      DÃ©livrer des projets Data Lake / Big Data (ingestion de sources, pipeline de traitements de donnÃ©es, modÃ©lisation, tests, dÃ©ploiements) dans un contexte de plus en plus DevOps,
-      Comprendre les besoins des Ã©quipes digitales, principalement associÃ©es aux projets Data Science et leurs technologies / outils (Jupyter, Zeppelin, R, Python,  â€¦),
-      ÃŠtre capable de faire le lien avec les contraintes techniques (IT, sÃ©curitÃ©, accÃ¨s, outils) dâ€™une DSI,
-      Assurer la veille technologique sur les composants dâ€™une plateforme Datalake, Cloud
-      Maintenir les environnements techniques et partager ses connaissances (capitalisation, sÃ©minaires, formations, KM en ligne),
-      RÃ©diger des documents projets (design, rÃ©alisation, dÃ©ploiement, â€¦),
-      GÃ©rer lâ€™Ã©volution des solutions proposÃ©es, et possiblement en assurer la TMA.","Profil recherchÃ©
De formation Bac + 4/5 en informatique, vous avez au moins 5 ans d'expÃ©rience dâ€™un projet de type Datalake en environnement HDFS et/ou cloud (GCP, Azure), une connaissance des DWH (sur technologie traditionnelle et/ou cloud), des mÃ©thodes agiles, voire du DataOps (industrialisation de modÃ¨les de ML).
Vous possÃ©dez de bonnes compÃ©tences en Linux/Unix, Java, Spark, Scalaâ€¦ ainsi que sur les problÃ©matiques dâ€™intÃ©gration (fichiers, messages, data) avec la connaissance dâ€™au moins une plateforme Big Data Cloudera, Hortonworks (administration, configuration, monitoring, dÃ©bogage, mise en Å“uvre) et dâ€™une solution cloud (GCP ou Azure).
Vous connaissez les technologies Hadoop/HDFS, Hive, Python et le requÃªtage de donnÃ©es (Impala, Hive, ...).
Votre expÃ©rience dans le traitement de flux en streaming (KafKa) est un plus.
Votre niveau dâ€™Anglais est opÃ©rationnel."
Data Engineer,"{'name': 'AQEMIA', 'sector': 'Intelligence artificielle / Machine Learning, Pharmaceutique / Biotechnologique, SantÃ©', 'employees': '60 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 4 ans,,"Descriptif du poste
About the team youâ€™ll join ğŸ¤¼â€â™€ï¸
As a Data Engineer, you will join the Data Engineering Team and contribute to design and build a modern, reliable and scalable Data Platform for Aqemia's engineering teams. 
You will also support engineering Teams to build their Data pipeline and assets.
This way, you will be instrumental in all engineering teams' success!
Your role as a data engineer at Aqemia ğŸ‘©ğŸ¼â€ğŸ’»
Contribute in defining the relevant Data Architecture and stack for Aqemia
Contribute to build the relevant Data infrastructure for Aqemia in AWS
In a data mesh oriented organization provide engineering teams with the right tools and practices to build their own pipelines and data assets
Support engineering team in designing their Data pipelines and assets
Bring the Data Engineering expertise in engineering projects from design to delivery
The competencies we are looking for ğŸ”
4+ years experience as a Data or Software engineer in an engineering team of 4+ engineers
Knowledge of Cloud infrastructure and products (AWS, other cloud experience is a plus)
Good knowledge of Data Engineering building blocks (storage, orchestrator)
Fluent in object-oriented language development (ideally python)
Experience in delivering technical projects from start to finish
Preferred skills
Proficient in SQL
Experience in backend engineering
Experience in infrastructure-as-code techniques (ideally Terraform)
Knowledge in ML Ops and DevOps
You know how to interact with technical stakeholders
Preferred mindset
You are eager to play an active role in contributing to Aqemiaâ€™s strategy to develop drugs for patients.
You are anxious to bring your wealth of knowledge and skills to the table to inspire and coach brilliant people from diverse backgrounds.
You are keen to solve tough problems on issues that truly matter, with a proactive and a can-do attitude.
You thrive on working collaboratively in a fast-paced, interdisciplinary environment that keeps everyone on track.
Our recruitment process ğŸ¤
1 - Hiring Managerâ€™s interview: youâ€™ll meet directly with your future manager BenoÃ®t (1h, visio call)
2 - Technical assessment of your skills: live coding exercise in Python (45min, visio call)
3 - Technical assessment of your skills: system design collaborative exercise, plus a tour of our offices (1h, in office)
4 - Cultural fit interview with our co-founder and COO Emmanuelle (45min)
5 - Final interview with our co-founder and CEO Maximilien (45min)
About who we are and our workplace environment âœ¨
â€¢ We signed a contract with Sanofi of $140M to accelerate their drug discovery
â€¢ Our approach is completely unique in the industry as we use AI & deep physics to discover new drugs
â€¢ We are a team of +50 people from world-class institutions (AstraZeneca, GSK, Sanofi, Harvard, Ecole Normale SupÃ©rieure, Ecole Polytechnique, BCG)
â€¢ Our Founders boast : 10+ years experience in research at Ecole Normale SupÃ©rieure in Paris, not to mention a stint in Oxford and Cambridge / 10+ years experience in strategy consulting at BCG.
â€¢ We are located in the center of Paris (1 Bd Pasteur), with a possibility of up to 2 days of remote work.
â€¢ We are part of the French Tech 2030 program (https://lafrenchtech.com/fr/la-france-aide-les-startup/french-tech-2030/).
â€¢ Our working language is English
â€¢ We work for a mission: joining us means bringing your own impact on changing the way medicines are discovered and be involved in shaping the direction of our fast growing business and team.
If you feel that you fit only 70% to 80% of this job description but youâ€™re still excited to join, then please get in touch! 
â€
Aqemia is an Equal Employment Opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender perception or identity, national origin, age, marital status, disability status or any other basis under applicable law.
Voir moins",
DATA ENGINEER SQL -H/F (Stage Avril/Mai 2024),"{'name': 'SHOWROOMPRIVE.COM', 'sector': 'Application mobile, Mode, E-commerce', 'employees': '1050 collaborateurs', 'creation_year': '2006', 'turnover': '697.5Mâ‚¬', 'mean_age': '33 ans'}",Stage,Saint-Denis,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,,
Data engineer H/F,"{'name': 'EXTIA', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, IT / Digital, StratÃ©gie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,,
Data Engineer H/F,"{'name': 'EXTIA', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, IT / Digital, StratÃ©gie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Lille,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,,
Data Engineer Devops H/F,"{'name': 'EXTIA', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, IT / Digital, StratÃ©gie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,,
Data Engineer (H/F),"{'name': 'EXTIA', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, IT / Digital, StratÃ©gie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Lyon,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Vous aurez le rÃ´le de support technique aux Ã©quipes dâ€™analyse : structurer les donnÃ©es, rÃ©aliser des analyses Â« statistiques Â» ou Â« techniques Â» sur les donnÃ©es, dÃ©velopper des outils dâ€™analyseâ€¦
Vous mÃ¨nerez des Ã©tudes afin dâ€™Ã©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin dâ€™identifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer Ã  la dÃ©finition des besoins et Ã  la rÃ©daction des User Stories,
Collaborer avec les Data Scientists au dÃ©veloppement des modules dâ€™analyse de donnÃ©e,
Concevoir et construire des architectures de donnÃ©es,
IntÃ©grer des sources de donnÃ©es,
S'assurer que les donnÃ©es sont facilement accessibles et que leur exploitation fonctionne comme demandÃ©, mÃªme dans des circonstances hautement Ã©volutives,
ExÃ©cuter des processus ETL (extraire / transformer / charger) Ã  partir d'ensembles de donnÃ©es complexes et / ou volumineux.
Profil recherchÃ© :
Maitrise de lâ€™Ã©cosystÃ¨me Microsoft Azure Data Factory, Azure Data Lake est un plus
Maitrise Technologie autour de la data : Power BI, Spark, Airflow, Python, Scalaâ€¦
Maitrise des bonnes pratiques de dÃ©veloppement et mÃ©thodes agiles
Base de donnÃ©es : SQL, PostgrÃ© SQL (Paas) et modÃ©lisation de la donnÃ©e
Connaissance des systÃ¨mes de gestionnaire de conteneur (Kubernetes,â€¦)
Connaissance des outils de dÃ©ploiements : Jenkins, Git, maven, Ansible
QualitÃ©s relationnelles et capacitÃ© Ã  gÃ©rer nombreuses interactions
Dynamisme, autonomie et envie de dÃ©couvrir des maniÃ¨res diffÃ©rentes/innovantes de faire
#LI-YKH
Voir moins","Profil recherchÃ©
Rigoureux, vous ne laissez rien au hasard,
Efficace, vous ne remettez pas Ã  demain ce qui peut Ãªtre fait dÃ¨s aujourdâ€™hui,
Autonome, vous savez mener vos missions Ã  bien sans aide."
Data engineer H/F,"{'name': 'EXTIA', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, IT / Digital, StratÃ©gie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Vous aurez le rÃ´le de support technique aux Ã©quipes dâ€™analyse : structurer les donnÃ©es, rÃ©aliser des analyses Â« statistiques Â» ou Â« techniques Â» sur les donnÃ©es, dÃ©velopper des outils dâ€™analyseâ€¦
Vous mÃ¨nerez des Ã©tudes afin dâ€™Ã©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin dâ€™identifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer Ã  la dÃ©finition des besoins et Ã  la rÃ©daction des User Stories,
Collaborer avec les Data Scientists au dÃ©veloppement des modules dâ€™analyse de donnÃ©e,
Concevoir et construire des architectures de donnÃ©es,
IntÃ©grer des sources de donnÃ©es,
Vous assurez que les donnÃ©es sont facilement accessibles et que leur exploitation fonctionne comme demandÃ©, mÃªme dans des circonstances hautement Ã©volutives,
ExÃ©cuter des processus ETL (extraire / transformer / charger) Ã  partir d'ensembles de donnÃ©es complexes et / ou volumineux.
Profil :
Vous Ãªtes habituÃ© Ã  travailler aussi bien avec des mÃ©ta-donnÃ©es quâ€™avec des donnÃ©es non-structurÃ©es. A cet effet vous maitrisez un ou plusieurs des concepts comme lâ€™ETL, le Data mining le Machine learning, les Big data ou encore la ThÃ©orie des graphes par exemple,
Vous maitrisez les bases de lâ€™analyse statistique,
Vous Ãªtes apte Ã  rÃ©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
Vous Ãªtes familiarisÃ© avec lâ€™environnement Linux,
Une expÃ©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps rÃ©el seront aussi de rÃ©els atouts.
#LI-AL7
Voir moins","Profil recherchÃ©
Rigoureux, vous ne laissez rien au hasard
PersÃ©vÃ©rant, vous ne perdez jamais, soit vous gagnez, soit vous apprenez
Efficace, vous ne remettez pas Ã  demain ce qui peut Ãªtre fait dÃ¨s aujourdâ€™hui"
Data Engineer (H/F),"{'name': 'EXTIA', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, IT / Digital, StratÃ©gie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Montpellier,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Ensuite quoi ?
Vous aurez le rÃ´le de support technique aux Ã©quipes dâ€™analyse : structurer les donnÃ©es, rÃ©aliser des analyses Â« statistiques Â» ou Â« techniques Â» sur les donnÃ©es, dÃ©velopper des outils dâ€™analyseâ€¦
Vous mÃ¨nerez des Ã©tudes afin dâ€™Ã©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin dâ€™identifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer Ã  la dÃ©finition des besoins et Ã  la rÃ©daction des User Stories,
Collaborer avec les Data Scientists au dÃ©veloppement des modules dâ€™analyse de donnÃ©e,
Concevoir et construire des architectures de donnÃ©es,
IntÃ©grer des sources de donnÃ©es,
Vous assurez que les donnÃ©es sont facilement accessibles et que leur exploitation fonctionne comme demandÃ©, mÃªme dans des circonstances hautement Ã©volutives,
ExÃ©cuter des processus ETL (extraire / transformer / charger) Ã  partir d'ensembles de donnÃ©es complexes et / ou volumineux.
Profil recherchÃ©
Vous Ãªtes habituÃ© Ã  travailler aussi bien avec des mÃ©ta-donnÃ©es quâ€™avec des donnÃ©es non-structurÃ©es. A cet effet vous maitrisez un ou plusieurs des concepts comme lâ€™ETL, le Data mining le Machine learning, les Big data ou encore la ThÃ©orie des graphes par exemple,
Vous maitrisez les bases de lâ€™analyse statistique,
Vous Ãªtes apte Ã  rÃ©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
Vous Ãªtes familiarisÃ© avec lâ€™environnement Linux,
Une expÃ©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps rÃ©el seront aussi de rÃ©els atouts.
#LI-RP1
Voir moins","Profil recherchÃ©
D'abord qui ?
IngÃ©nieux, votre imagination dÃ©bordante vient Ã  bout de chaque problÃ©matique,
Attentif aux dÃ©tails, vous avez un Å“il de Lynx pour repÃ©rer les incohÃ©rences,
Efficace, vous ne remettez pas Ã  demain ce qui peut Ãªtre fait dÃ¨s aujourdâ€™hui."
Data Engineer (H/F),"{'name': 'EXTIA', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, IT / Digital, StratÃ©gie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,,
Senior Data Engineer,"{'name': 'MANGOPAY', 'sector': 'Logiciels, FinTech / InsurTech, Ã‰conomie collaborative', 'employees': '300 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '32 ans'}",CDI,Bouy-Luxembourg,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
At Mangopay, our mission is to power the payment infrastructure and payment operations of the world's biggest and most exciting marketplaces & platforms.
We provide marketplaces and platforms with powerful modular payment and regulatory solutions. Since 2013, we have enabled the success of some of the biggest names in e-commerce, retail, and cutting-edge platforms such as Vinted, Rakuten, Chrono24, La Redoute, Wallapop and over 2,500+ more.
Our team of 400+ is spread across Europe, with offices in Berlin, Dublin, Luxembourg, London, Madrid, Paris, and Warsaw. In an environment where marketplaces and fintech ventures are thriving, we're actively seeking exceptional individuals to tackle the challenges in our field and contribute to our growth. Our commitment to diversity is unwavering, and we are dedicated to promoting employee well-being, inclusivity, and equal opportunities. Joining Mangopay means youâ€™ll be part of a dynamic, flexible, and rapidly growing team.
With the continued growth of the business, we set our sights on additional hiring into our Platform Universe having identified the need for a talented Senior Data Engineer.
What you will be doing
[re-]Design, [re-]build, and maintain efficient, scalable, secure and auditable data pipelines for data ingestion and transformation, new and existing
Design, build and maintain right infrastructures for data processing, including Data Quality, costs management and others
Participate in team efforts to improve the quality of what we do â€“ by design/code reviews, providing internal trainings on relevant subjects,suggesting improving organisational processes, creating useful layer of documentation and similar
Work closely with analysts and other stakeholders making sure the requirements are clear, sensible and achievable
Our current tech stack
AWS
Snowflake
PySpark
Hadoop
Airflow
Sources: MS SQL, Postgres, Kafka
What we would like you to bring with you
Experience in designing of data pipelines
Experience in SQL analytics
Experience in Snowflake integration and administration, including query tuning and RBAC controls
Fluent in cloud (we work with AWS)
Experience in infrastructure-as-code (e.g. Terraform) is a plus
Experience in orchestration (e.g. Airflow) is a plus
Mindset
Proactive
Happy to challenge and to be challenged
Analytical, critical and constructive; understanding both technical and business problems
Biased for robustness, low maintenance, high automatization and performance
Recruitment process
Call with Recruitment team
HM call
Tech interview with DE Lead + HoDE
Meet with the team
If this sound like a role that would compliment your skill set, but also challenge your personal development goals, please do reach out via the apply button!
We care about equal employment opportunities, so all qualified applicants will receive equal consideration regardless of their race, colour, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status.
Voir moins",
Code Busters - Data Engineer - Practice Data Engineering (H/F),"{'name': 'CODE BUSTERS', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '35 collaborateurs', 'creation_year': '2021', 'turnover': '4.2 Mâ‚¬', 'mean_age': '29 ans'}",Autres,Paris,40K Ã  90K â‚¬,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Code Busters c'est :
ğŸ“Un espace de partage et de transmission qui permet Ã  chaque membre de la communautÃ© de se dÃ©passer. Les Busters ont des grades attribuÃ©s en fonction de leur niveau de maturitÃ© technique (l'expÃ©rience importe peu, seul le talent compte).
ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦â€ğŸ‘¦Une organisation en squads pour un management ""dev by dev"" et des moments privilÃ©giÃ©s pour apprendre des valeurs humaines fortes.
ğŸ“ˆ une communautÃ© qui prÃ´ne la transparence et proposent un modÃ¨le de rÃ©munÃ©ration redistributif et dÃ©plafonnÃ©.
L'ambition
Depuis notre crÃ©ation dÃ©but 2021, nous grandissons sans faire de compromis entre qualitÃ© d'intervention et d'accompagnement des Busters. En seulement 2 ans, nous sommes passÃ©s de 2 Ã  40 personnes et nous rÃ©alisons un chiffre dâ€™affaires de 4.2Mâ‚¬ en 2022.
Notre objectif : faire de Code Busters la rÃ©fÃ©rence franÃ§aise sur les problÃ©matiques de dÃ©veloppement applicatif grÃ¢ce Ã  lâ€™expertise de notre Ã©quipe technique.
L'organisation
Nous sommes convaincus que le langage informatique n'est qu'un outil. Pourtant, avant de devenir agnostique aux langages il est primordial de devenir un Software Engineer aguerri. Ils se sont organisÃ©s en 6 Practices technologiques (Typescript, Java, C#, C++/Rust, Python et DevOps).
âœ¨ Ta mission
Tu veilles Ã  dÃ©livrer les meilleures interventions clients :
Tu contribues au dÃ©veloppement de produits Ã  fort impact business. Tu dÃ©veloppes de nouvelles features sur divers projets clients en fournissant un code de qualitÃ©: maintenabe & scalable. Tu es proactif et tends vers une approche conseil pour tes clients en leur proposant de nouvelles technos, et nouvelles methodologies pour les rendre plus performants.
Tu aspires Ã  devenir meilleur de jour en jour :
La Tech est un environnement exigeant et en perpÃ©tuelle Ã©volution. Afin de dÃ©livrer les meilleures interventions, tu dois apprendre sans cesse et rester Ã  jour. Faire preuve d'humilitÃ© et Ãªtre capable de remettre en question tes acquis.
Tu aies de lâ€™impact au sein de la communautÃ© :
Câ€™est le rÃ´le de chaque Buster de contribuer au dÃ©veloppement de la communautÃ©. Tu pourras tâ€™impliquer sur les sujets suivants :
Construction du SI de la communautÃ© Recrutement de nouveaux Busters
Coaching et diffusion de tes compÃ©tences
DÃ©velopper des compÃ©tences transverses : coaching, recrutement, commercial, management
Ton environnement technique:
Pour intÃ©grer la Practice Data IngÃ© une grande appÃ©tence pour le back tu auras..
Back : Python ou Scala
Infrastructure/DevOps : Docker, k8s, Cloud, Jenkins
Tes Managers
Durant les 10 derniÃ¨res annÃ©es, Laurent & Valmon ont travaillÃ© dans le domaine de la finance de marchÃ© avec diffÃ©rentes Ã©quipes techniques et mÃ©tiers pour produire des applications Ã  forte valeur ajoutÃ©e pour les utilisateurs. Ils ont pu travaillÃ© sur diffÃ©rents type de projets comme par exemple la rÃ©cupÃ©ration de donnÃ©es via des grabbers d'APIs, sur leur ingestion dans un datalake et sur leur manipulation en Scala ou Python. Ils sont toujours motivÃ©s par les possibilitÃ©s d'apprendre et de progresser et ils mettent tout en place pour transmettre au mieux leur passion et les meilleures pratiques de dÃ©veloppement.
Ce que tu vas trouver chez nous
Une communautÃ©s de dÃ©veloppeurs passionnÃ©s oÃ¹ chacun est responsabilisÃ© selon ses aspirations professionnelles.
Un systÃ¨me de grade basÃ© sur ta maturitÃ© technique et le recul que tu as sur ton mÃ©tier. On identifie ensemble tes axes dâ€™amÃ©lioration et on tâ€™offre un accompagnement personnalisÃ© dev by dev pour booster tes compÃ©tences et atteindre les grades supÃ©rieurs.
On tâ€™offre une possibilitÃ© de travailler sur des problÃ©matiques techniques variÃ©es afin de perfectionner tes compÃ©tences et chercher constamment Ã  amÃ©liorer les outils et les mÃ©thodes employÃ©es.
Un salaire transparent et mÃ©ritocratique qui Ã©volue (exponentiellement ğŸ˜) au fur et Ã  mesure de ta progression.
Et les plus de Code Busters alors ?
ğŸ’°Une rÃ©munÃ©ration transparente composÃ©e dâ€™un salaire fixe entre 40kâ‚¬ et 70kâ‚¬ qui dÃ©pend de ton grade et un bonus dÃ©plafonnÃ© dÃ©pourvu de toute subjectivitÃ© !
ğŸ’¥Un environnement de travail Ã©nergique et bienveillant
ğŸ’»Un budget formation annuel de 2000â‚¬
ğŸ¤Une ascension professionnelle Ã©paulÃ©e par ton squad leader au quotidien
ğŸ¤«Un sÃ©minaire annuel, pas besoin de tâ€™en dire plus on te laisse dÃ©couvrirâ€¦
ğŸ½ Carte tickets restaurants Swile
ğŸš‡Titre de transport pris en charge Ã  100%
ğŸ˜Assurance santÃ© prise en charge Ã  100%
Tes Perspectives d'Ã©volution
Notre ambition est de former les leaders de la tech de demain. Nous avons crÃ©er un parcours en grade pour t'aider Ã  construire ta carriÃ¨re par Ã©tapes. GrÃ¢ce au coaching et formations que lâ€™on propose, tu pourras :
DÃ©velopper de lâ€™expertise technique sur les sujets tech qui te passionnent
DÃ©velopper des compÃ©tences transverses : coaching, recrutement, commercial, management
Participer Ã  des guildes dâ€™expertises pour amÃ©liorer tes pratiques et celles de ton Ã©quipe.
Process de recrutement 
30â€™ par tÃ©lÃ©phone pour faire connaissance et tâ€™en dire plus sur Code Busters.
60â€™ en visio : pour comprendre en dÃ©tails les choix de ton parcours professionnel et tes aspirations. Câ€™est Ã©galement lâ€™occasion de poser toutes les questions que tu as sur Code Busters. 
60â€™ dâ€™Ã©change technique thÃ©orique & pratique: Lâ€™objectif est de faire un Ã©tat des lieux de tes connaissances techniques. Il nous permet dâ€™estimer le grade que tu aurais en rejoignant la communautÃ©. Tu pourras aussi en profiter pour avoir un REX dâ€™un Buster sur sa vie dans la communautÃ©. 
60â€™ de Buster Fit : Confirmer que notre modÃ¨le et tes ambitions feront de toi le prochain Buster ğŸ˜
Voir moins",
Consultant ConfirmÃ© Data Engineer on Data Platforms - F/H/N,"{'name': 'OCTO TECHNOLOGY', 'sector': 'IT / Digital, Organisation / Management, Transformation', 'employees': 'CrÃ©Ã©e en 1998', 'creation_year': 'Ã‚ge moyen : 33 ans', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
Vous faites partie de celles et ceux qui pensent que mÃªme avec plusieurs annÃ©es dâ€™expÃ©rience, on continue Ã  apprendre ? Alors nous sommes sur la mÃªme longueur d'onde ! Et si on en parlait ?
Au sein de lâ€™Atelier Data & AI, on retrouve des communautÃ©s de pratique organisÃ©es par tribus. Lâ€™idÃ©e, câ€™est de se retrouver et de partager des expertises communes, de dÃ©velopper ses compÃ©tences en Ã©quipes Ã  taille humaine. Vous aurez donc pour missions de faire du conseil, du delivery et de la R&D.
ÃŠtre Data Engineer on Data Platforms chez OCTO, câ€™est : 
1- Faire du conseil autant que du delivery : accompagner nos clients dans la mise en Å“uvre de solutions autour de la gestion et transformation de leur Data. Participer au dÃ©veloppement agile et Ã  lâ€™implÃ©mentation dâ€™applications dans le respect des bonnes pratiques. Et bien sÃ»r, qui dit conseil, dit convictions : proposer la solution la plus adaptÃ©e, câ€™est aussi savoir et oser challenger nos clients (et câ€™est dans notre ADN !) 
2- Participer aux rÃ©ponses aux appels dâ€™offres et avant-ventes
3- Participer activement Ã  la R&D â€œData & IAâ€ : au programme, veille technologique & bonnes pratiques. Quelques sujets â€œchaudsâ€ du moment ? Le Green AI , Green Data et AI4Green ğŸŒ±
4- Former & mentorer : le partage de connaissances et la montÃ©e en compÃ©tences des collaborateurs vous importent ? Nous sommes convaincus et prÃ´nons haut et fort la valeur de transmission. Mentoring et gestion de votre carriÃ¨re seront donc Ã  lâ€™honneur. Et oui, chez OCTO le savoir nâ€™est pas chasse gardÃ©e !
Voir moins","Profil recherchÃ©
Promis pas de liste Ã  rallonge, mais des compÃ©tences clÃ©s pour vous permettre de rÃ©ussir chez nous : 
1- Un socle de savoir-faire techniques et des expÃ©riences significatives sur : 
DiffÃ©rents systÃ¨mes dâ€™exploitation et systÃ¨mes de gestion de bases de donnÃ©es (SQL, NoSQL, New SQL, DWH dans le cloudâ€¦)
Plusieurs protocoles de connexion (REST, SOAP, FTP, HTTP, ODBCâ€¦)
Les outils Docker et/ou Kubernetes
Les Ã©cosystÃ¨mes cloud (AWS, Azure ou GCP)
Les plateformes de donnÃ©es dans le cloud telles que Snowflake, Dataiku, Databricks, Alteryx, SAS, Palantirâ€¦
Les langages de manipulation de donnÃ©es (SQL, Scala, Pythonâ€¦) et divers frameworks de programmation (Java, Bash/Shell, Spark, Pandasâ€¦)
Les mÃ©thodologies agiles (une connaissance des mÃ©thodologies DevOps ou DataOps est un plus  )
â€¦Last but not least : une bonne maÃ®trise de lâ€™anglais, Ã  lâ€™oral comme Ã  lâ€™Ã©crit ğŸ™‚
2- Un panel de savoir-Ãªtre : 
un esprit franc-tireur capable de (se) questionner et de challenger les idÃ©es
Voir plus"
Engineering Manager (Data Engineer) - CDI - Sicara - Paris,"{'name': 'SICARA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': '6,5Mâ‚¬', 'mean_age': '27 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,06 mai 2024,> 7 ans,Bac +5 / Master,"Descriptif du poste
PrÃ©sentation Sicara
CrÃ©Ã©e en novembre 2016 au sein du groupe M33 (Theodo group), un Ã©cosystÃ¨me de 10 filiales et +650 personnes situÃ©es Ã  Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, basÃ©e Ã  Paris.
Notre mission : aider les startups, scaleups et grands comptes Ã  rÃ©soudre leurs problÃ©matiques business grÃ¢ce Ã  la tech. Nos Ã©quipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. Lâ€™objectif : capitaliser sur le potentiel de la donnÃ©e.
Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en dÃ©veloppant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.
Pourquoi on recrute un Engineering Manager (Data Software Engineering) ?
Afin de contribuer Ã  la croissance de Sicara et pour renforcer les Ã©quipes Data Software Engineering de Sicara, nous cherchons un profil expÃ©rimentÃ© pour accroÃ®tre la montÃ©e en compÃ©tences de nos Sicariotes et pour rÃ©pondre aux attentes techniques de nos clients.
L'Ã©quipe technique de Sicara ; c'est 40 Data Engineers et Data Scientists, Tech Leads ou architectes issus des meilleures Ã©coles d'ingÃ©nieur, et en particulier 5 Engineering Manager et 1 CTO pour les faire rÃ©ussir.
A chaque lancement de projets, nous mettons en place une Ã©quipe diverse dâ€™experts techniques, dâ€™experts mÃ©tiers, et dâ€™experts de lâ€™Agile et du Lean Management. GrÃ¢ce Ã  ce fonctionnement, nous allons rapidement en production et avons un impact direct sur la rÃ©ussite des objectifs business de nos clients.
Tes missions :
AmÃ©liorer la qualitÃ© des produits rÃ©alisÃ©s par les tech leads sur leurs projets
Garantir la satisfaction du sponsor technique client, en aidant le tech lead Ã  concevoir les features qui dÃ©livrent un maximum de valeur et tout en Ã©tant intransigeant sur la qualitÃ©
Aider le tech lead sur le delivery et la conception dâ€™architectures robustes et scalables
Veiller Ã  la progression des techs en les aidant Ã  dÃ©velopper leur thought leadership et Ã  progresser en continu sur la Tech
Epauler notre CTO sur des sujets de positionnement technique, d'organisation d'Ã©quipe et d'Ã©volution des systÃ¨mes de Sicara
Les avantages
Notre Ã©cosystÃ¨me de startup tech est un vÃ©ritable tremplin pour accÃ©lÃ©rer la progression et les carriÃ¨res !
Des bureaux au coeur du quartier des Batignolles Ã  Paris, partagÃ©s avec les autres startup tech du groupe Theodo
Un coach dÃ©diÃ© pour accÃ©lÃ©rer ta progression de carriÃ¨re
La possibilitÃ© de participer Ã  des confÃ©rences techniques internationales
Des conditions de tÃ©lÃ©travail flexibles
Un budget trimestriel pour acheter ton matÃ©riel tech (laptop, smartphone, casque,...)
Des Ã©vÃ©nements rÃ©guliers de team building et un WE d'entreprise Ã  chaque annÃ©e
La possibilitÃ© de s'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les inÃ©galitÃ©s et la sÃ©curitÃ© des donnÃ©es
Tes moyens pour rÃ©ussir
Management en direct par le CTO de Sicara
Collaboration avec les EM de Sicara et du groupe M33
Formations au Lean management
Ã‰cosystÃ¨me M33 avec +500 expert(e)s tech & produit,
Plusieurs dojos (sessions de mise en pratique) par semaine : ""archi dojo"", ""projet dojo"", etc...
Ton profil
Tu disposes d'une connaissance forte de la data (marchÃ©, techno, archi)
Tu es capable de dÃ©bloquer des tech leads sur des challenges techniques complexes
Tu as une expÃ©rience significative en management d'Ã©quipe technique
Tu sais animer une Ã©quipe exigeante et performante
Tu es dotÃ© d'un excellent leadership et contact client : tu donnes envie aux autres de te suivre !
Tu es guidÃ© par une Ã©norme envie de progresser, dans un environnement startup, qui Ã©volue rapidement ? Alors Sicara pourrait Ãªtre le bon endroit pour toi !
A trÃ¨s vite !
Voir moins",
Lead Data Engineer - CDI - Sicara - Paris,"{'name': 'SICARA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': '6,5Mâ‚¬', 'mean_age': '27 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,04 mars 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
PrÃ©sentation Sicara
CrÃ©Ã©e en novembre 2016 au sein du groupe M33 (Theodo group), un Ã©cosystÃ¨me de 10 filiales et +650 personnes situÃ©es Ã  Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, basÃ©e Ã  Paris.
Notre mission : aider les startups, scaleups et grands comptes Ã  rÃ©soudre leurs problÃ©matiques business grÃ¢ce Ã  la tech. Nos Ã©quipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. Lâ€™objectif : capitaliser sur le potentiel de la donnÃ©e.
Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en dÃ©veloppant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.
Pourquoi on recrute un Lead Data Software Engineer ?
Pour contribuer Ã  la croissance de Sicara et pour renforcer les Ã©quipes Data Software Engineering de Sicara, nous cherchons un profil expÃ©rimentÃ©.
Tes missions
Analyser les donnÃ©es sources et Ã©changer avec les experts mÃ©tier afin dâ€™identifier et Ã©valuer des cas dâ€™usage mÃ©tier
Leader une Ã©quipe de 2 Ã  5 data software engineers dans le delivery de la solution Ã  implÃ©menter au quotidien
Concevoir et mettre en place des systÃ¨mes de donnÃ©es rÃ©silients et sÃ©curisÃ©s (data warehouse, data lake, systÃ¨mes temps-rÃ©els)
DÃ©finir les mÃ©thodologies de dÃ©ploiement et plans de migration
Construire et dÃ©ployer les pipelines de donnÃ©es (ETL et ELT)
Assurer la migration des donnÃ©es vers les nouveaux environnements
Choisir et mettre en oeuvre des outils de data analyse et/ou data visualisation
Mettre en place des outils de contrÃ´le de la qualitÃ© de la donnÃ©e
Accompagner et former les Ã©quipes clients
Au sein de Sicara :
Tu seras amenÃ©(e) Ã  accompagner et former les Ã©quipes au data software engineering
Tu assureras une veille technologique continue sur les solutions de lâ€™Ã©tat de lâ€™art
Tu interviendras dans la rÃ©flexion sur la stratÃ©gie technique Ã  proposer en phases dâ€™avant-vente de nos projets
EncadrÃ© par lâ€™Ã©quipe dirigeante, tu gÃ©nÃ©reras de la connaissance technique sur des sujets dâ€™expertises pour les propager au sein de Sicara
En fonction de tes envies et de tes compÃ©tences, tu auras la possibilitÃ© de :
Devenir un(e) expert(e) sur les sujets techniques qui te passionnent.
Devenir un(e) leader grÃ¢ce au dÃ©veloppement de compÃ©tences transverses : coaching, recrutement, commercial, management, marketing, etc.
Monter une tribe ou une guilde pour dÃ©velopper un nouvelle offre et amÃ©liorer nos pratiques.
Les avantages
Notre Ã©cosystÃ¨me de startup tech est un vÃ©ritable tremplin pour accÃ©lÃ©rer la progression et les carriÃ¨res !
Des bureaux au coeur du quartier des Batignolles Ã  Paris, partagÃ©s avec les autres startup tech du groupe Theodo
Un coach dÃ©diÃ© pour accÃ©lÃ©rer la progression de carriÃ¨re
La possibilitÃ© de participer Ã  des confÃ©rences techniques internationales
Des conditions de tÃ©lÃ©travail flexibles
Un budget trimestriel pour acheter ton matÃ©riel tech (laptop, smartphone, casque,...)
Des Ã©vÃ©nements rÃ©guliers de team building et un WE d'entreprise Ã  chaque annÃ©e
La possibilitÃ© de s'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les inÃ©galitÃ©s et la sÃ©curitÃ© des donnÃ©es
Ton profil
Tu as entre deux Ã  quatre ans dâ€™expÃ©rience sur des sujets de Data Software Engineering
Tu es diplÃ´mÃ© dâ€™une Ã©cole dâ€™ingÃ©nieur en Bac+5
Tu as une bonne connaissance de Python et tu as dÃ©jÃ  utilisÃ© des technologies Big Data (Spark, Hadoop, Airflow, Terraform)
Tu souhaites participer Ã  la conception de produits Ã  fort impact business
Tu veux Ãªtre accompagnÃ© pour exploiter Ã  fond ton potentiel et rÃ©aliser ton ambition
A trÃ¨s vite !
Voir moins",
Consultant.e Data Engineer ExpÃ©rimentÃ©.e,"{'name': 'THE INFORMATION LAB', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '38 collaborateurs', 'creation_year': '2015', 'turnover': '5Mâ‚¬', 'mean_age': None}",CDI,Paris,45K Ã  60K â‚¬,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Qui sommes-nous ?
VÃ©ritables passionnÃ©s de data, nous avons construit The Information Lab autour des solutions Tableau, Alteryx et Snowflake. Nous sommes convaincus que ce sont les meilleures technologies pour accomplir la transformation digitale de nos clients.
Notre spÃ©cialisation nous permet dâ€™Ãªtre les premiers partenaires de ces Ã©diteurs et dâ€™Ãªtre les experts reconnus de ces solutions en France et en Europe.
En nous rejoignant vous pourrez partager votre passion avec vos pairs, travailler dans une ambiance dÃ©contractÃ©e pour remplir notre mission : ""Helping people make sense of dataâ€.
Description du poste
RattachÃ©(e) au pÃ´le Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous mÃ©tiers. Vos missions ont pour objet le traitement, lâ€™analyse, lâ€™enrichissement des donnÃ©es de nos clients et lâ€™adoption par nos clients des technologies que nous proposons. Au sein dâ€™une Ã©quipe de 5 Ã  8 personnes, vous rÃ©alisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre â€œpod leaderâ€ (chef dâ€™Ã©quipe).
Votre rÃ´le consiste Ã  :
Intervenir en avant-vente et cadrer vos missions
Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours Ã  quelques mois
Mener des projets de bout en bout, en mÃ©thode classique ou agile, en coordination avec les Ã©quipes de nos clients, nos Ã©quipes internes et les Ã©diteurs partenaires
PrÃ©senter les livrables de vos missions et mettre en avant leur ROI
Former nos clients Ã  nos technologies
Mettre vos compÃ©tences au service de vos collÃ¨gues au-delÃ  des missions dont vous avez la charge et participer au dÃ©veloppement des compÃ©tences en partageant vos retours dâ€™expÃ©rience
Participer aux activitÃ©s dâ€™Ã©vangÃ©lisation, par exemple : rÃ©daction de posts de blogs, participation aux communautÃ©s des Ã©diteurs, interventions lors dâ€™Ã©vÃ©nements (salons, confÃ©rences, webinaires)
Participer aux projets internes (BI interne, mÃ©thodes & qualitÃ©s)
Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires.
Vos principales qualitÃ©s :
Excellentes facultÃ©s dâ€™Ã©coute et de communication, orale et Ã©crite
Aptitude Ã  travailler sur plusieurs sujets en parallÃ¨le, Ã  prioriser
HumilitÃ© et capacitÃ© Ã  apprendre ainsi quâ€™Ã  transmettre ses connaissances
Sens du service, un bon relationnel avec les clients et la rigueur nÃ©cessaire au succÃ¨s de leurs projets
Team player
CompÃ©tences mÃ©thodologiques :
Analyse du besoin et cadrage de mission
Construction dâ€™indicateurs mÃ©tiers Ã  partir de donnÃ©es brutes
IdÃ©alement connaissance dâ€™un ou plusieurs mÃ©tiers et de leurs indicateurs clÃ©s
PrÃ©paration de donnÃ©es complexes Ã  des fins dâ€™analyse
MÃ©thodes de gestion de projet (classique et agile)
CapacitÃ© prouvÃ©e Ã  rÃ©aliser des dÃ©monstrations dâ€™outils
CompÃ©tences techniques :
Connaissance dâ€™au moins Alteryx Designer ou Tableau Prep (idÃ©alement vous avez dÃ©jÃ  une expÃ©rience solide sur ces outils)
MaÃ®trise dâ€™autres outils dâ€™analyse de donnÃ©es
Connaissance de la modÃ©lisation de donnÃ©es Ã  des fins dâ€™analyse
ExpÃ©rience professionnelle : vous bÃ©nÃ©ficiez dâ€™au moins 5 ans dâ€™expÃ©rience professionnelle, dont 3 ans sur un poste similaire ou dans un poste qui vous aura permis dâ€™utiliser les technologies similaires aux nÃ´tres. IdÃ©alement, vous avez dÃ©jÃ  une expÃ©rience dans un cabinet de conseil ou une ESN.
Langues : FranÃ§ais, Anglais professionnel
Quoi dâ€™autre ?
Situation gÃ©ographique : Ile-de-France. DÃ©placements en France Ã  prÃ©voir.
RÃ©munÃ©ration : 45 Ã  60 kâ‚¬, selon expÃ©rience.
Voir moins",
Data Engineer - Energie & Retail - Lyon,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Limonest,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail : La division Â« Energie & Utilities Â» accompagne les grands acteurs du secteur en France dans les domaines de la production et la distribution thermique, hydraulique et nuclÃ©aire. Dans un contexte agile, nos Ã©quipes d'experts participent Ã  des projets autour de la transformation digitale pour conduire nos clients vers une transition Ã©cologique. Le dÃ©fi que nous vous proposons de relever ? Mettre l'Ã©nergie au service des Smart Grid & Cities ! Rejoignez les Ã©quipes et l'esprit Â« E&YOU Â» !
Votre rÃ´le et vos missions :
- Participation aux phases de dÃ©veloppement d'applications Big Data (ETL, crÃ©ation de pipelines, dÃ©veloppement de dashboards, gestion et administration des flux de donnÃ©es) - Traitement des problÃ©matiques full-stack sur des technologies JAVA - Conception architectures innovantes, basÃ©es sur AWS ou Azure - Assurer l'amÃ©lioration continue du projet et de ses membres - Travailler avec des mÃ©thodologies : SAFe, DevOps
 Votre immersion dans nos projets vous permettra d'acquÃ©rir une expÃ©rience significative aux environnements techniques et fonctionnels de nos clients et de leurs mÃ©tiers. Nous vous offrons la possibilitÃ© de capitaliser sur vos qualitÃ©s professionnelles et personnelles afin d'Ã©voluer dans un environnement dynamique et convivial, sur de nombreux projets innovants, variÃ©s et passionnants.
Informations supplÃ©mentaires
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions. 
Un package avantages intÃ©ressant : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 30 familles de mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â».
L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encoreâ€¦).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherchÃ©
Votre profil :
Vous Ãªtes diplÃ´mÃ©(e) d'une Ã©cole d'IngÃ©nieur ou Ã©quivalent Universitaire, et disposez d'une premiÃ¨re expÃ©rience significative en ingÃ©nierie de la donnÃ©e de 3 ans minimum sur une fonction similaire. 
Vous maÃ®trisez diffÃ©rentes technologies telles que Nifi, Elastic Search, Hadoop, Spark, Google Cloud Al Platform ou encore Java.
Vous avez un bon esprit dâ€™analyse et de synthÃ¨se, le sens du relationnel, vous Ãªtes polyvalent(e) et autonome.
Vous aimez travailler sur des sujets qui allient challenge technique et innovation ? Alors venez profiter dâ€™une atmosphÃ¨re propice Ã  l'entrepreneuriat et Ã  votre Ã©volution.
Vous vous reconnaissezâ€‰? Nous sommes impatients de vous rencontrerâ€‰!"
Data Engineer Senior - DataOps / AWS / Archi DistribuÃ©e (f/m/x),"{'name': 'LEBONCOIN', 'sector': 'Ã‰conomie collaborative, E-commerce', 'employees': '1500 collaborateurs', 'creation_year': '2006', 'turnover': '393 Mâ‚¬ (2018)', 'mean_age': '35 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Vous Ãªtes rattachÃ©.e Ã  l'Ã©quipe Data Engineering, composÃ©e de data engineers et de SRE. Cette Ã©quipe vous accompagne sur la stack technique data, vous permet d'Ã©changer sur des sujets transverses et de participer aux rituels data engineering (guilde, rÃ©troâ€¦). Cette Ã©quipe appartient Ã   la tribe ""Data Tools & Services"", qui regroupe les services data centrauxLa stack :
DÃ©veloppement sous Ubuntu en Java, Python et SQL avec IntelliJ, Gradle, Travis, Docker, Github, Ansible, Terraform, Concourse, Helm
Dans un environnement Ã  la pointe des technologies actuelles : Airflow, Spark, Elasticsearch, Kafka / Kafka Stream / Kafka Connect, AWS (S3, Redshift, Athena, Glue, DynamoDB), Kubernetes, Jupyter, MLFlow, Hudi
Ce que vous ferez :
DÃ©velopper des applicatifs complexes assurant une circulation optimale des donnÃ©es, et assurer leur fiabilitÃ© : API d'exposition de donnÃ©es, applications de streaming, industrialisation de modÃ¨les de machine learning
Optimiser notre architecture et notre environnement AWS : stockage, sÃ©curitÃ©, automatisation, scalabilitÃ©
Assurer la sÃ©curitÃ© des donnÃ©es de nos utilisateurs sur la data platform, dans le respect de la rÃ©glementation en vigueur (GDPR, e-privacy)
Participer activement Ã  la veille technologique et Ã  l'effort de R&D
Garantir le bon fonctionnement, la disponibilitÃ©, l'Ã©volution et la performance des outils
Assurer l'interface avec les Ã©quipes techniques du produit
Vous avez au moins 6 ans en tant que Data Engineer 
Vous connaissez les environnements Unix, et possÃ©dez un niveau avancÃ© en Java / Python.
Vous Ãªtes familier avec l'environnement cloud AWS, et avez de solides notions d'architecture distribuÃ©e et de gestion de data platform Ã  forte volumÃ©trie.
Vous Ãªtes Ã  l'aise en anglais tant Ã  l'Ã©crit qu'Ã  l'oral.
Poste basÃ© Ã  Paris 10 
Les Ã©tapes : 
Premier Ã©change avec Kader (RH)
Entretien managÃ©rial avec Thomas (Engineering Manager)
Entretien technique avec deux membres de l'Ã©quipe (Data Eng)
Entretien Fit/RH avec Julien (directeur data) et Kader (RH)
Voir moins",
Data Engineer AWS (F/H),"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, CybersÃ©curitÃ©', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232Mâ‚¬', 'mean_age': None}",CDI,La Garenne-Colombes,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
ğŸ’¥ DÃ©couvrez la Vie Apsidienne ğŸ“¹ et vous aussi, devenez Apsidien
On aurait pu demander Ã  Chat GPT de vous dÃ©montrer en quoi Apside est lâ€™ESN quâ€™il vous faut, mais on prÃ©fÃ¨re que vous le dÃ©couvriez vous-mÃªmes ğŸ‘‡ğŸ˜
ğŸ”¥ DÃ©couvrez votre future mission
ğŸ‘‰ Contexte
Rejoignez notre Practise Cloud/Data, afin dâ€™intervenir sur des sujets Ã  haute valeur ajoutÃ©e !
Lâ€™un de nos clients a lancÃ© un large programme de transformation autour des donnÃ©es et de lâ€™Intelligence Artificielle dans un contexte de transformation globale de la DSI. Le programme, pilotÃ© par le Chief Data Officer (CDO) et sous sponsoring de la Direction GÃ©nÃ©rale, comporte plusieurs objectifs, dont celui de la mise en place de la plateforme Data & IA, qui a vocation Ã  devenir le cÅ“ur du SI du client. En parallÃ¨le, le chantier de transformation Cloud en cours induit dâ€™importantes adhÃ©rences avec les travaux dâ€™industrialisation de la plateforme Data & IA. La Domaine Plateforme Data & IA, au sein de la Direction Data a la responsabilitÃ© de lâ€™industrialisation de la Plateforme Data & IA ainsi que la rÃ©alisation du comptoir de donnÃ©es pour les mÃ©tiers Finance et Risques
Secteur â€¯: Banque/Finance
MÃ©thode de travailâ€¯: SAFE
ğŸ˜ Mission
Vous serez en charge de rÃ©aliser les traitements d'intÃ©gration de donnÃ©es du pipeline d'alimentation du comptoir, ainsi que l'exposition des donnÃ©es en API.
Environnement techniqueâ€¯:
SQL
Python/Spark
Cloud AWS: AWS Glue, AWS Lambda (possibilitÃ© de vous former sur AWS)
Stockage objet (AWS S3)
Orchestration et scheduling de tÃ¢ches (Apache Airflow)
Bases analytiques et bases NoSQL (ElasticSearch, AWS Athena)
ğŸ“ Localisation
La Garenne Colombes Ã  A 10 min de la DÃ©fense Accessible via T2-ArrÃªt Charlebourg / Ligne L - ArrÃªt La Garenne Colombes
ğŸ’° Le package salarial que nous vous proposons
Contratâ€¯: CDI
Avantages groupeâ€¯: carte ticket restaurant Swile, prime de mobilitÃ©, RTT, accord tÃ©lÃ©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle Ã  100% etcâ€¦
Avantages agenceâ€¯: intÃ©gration de la Practise Cloud/Data, afterworks, communautÃ© techlead...
Formationâ€¯: certifications techniques, cours particuliers dâ€™anglais en interne, accÃ¨s Ã  un catalogue de formations grÃ¢ce Ã  notre plateforme e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherchÃ©
ğŸ”® Ã” vous futur Apsidien, qui Ãªtes-vousâ€¯?
A minima 5 ans d'expÃ©rience en tant que Data Engineer
Connaissance du monde bancaire
Maitrise de Spark, Python
Connaissance de AWS
ğŸ˜ Apside a suscitÃ© votre curiositÃ©â€¯?
Dans un environnement marquÃ© par une accÃ©lÃ©ration des Ã©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients Ã  crÃ©er de la valeur et Ã  adresser leurs enjeux stratÃ©giques en leur mettant Ã  disposition des expertises technologiques (Data / IA, Cloud, Cyber) et une expÃ©rience sectorielle (Industrie, Banque, Assurance, Service, Secteur Public). Pour un accompagnement global, le groupe propose des offres transverses autour du Handicap (Apsidâ€™EA), du Digital Learning, et du Conseil.
ğŸ¤” Et votre place dans tout Ã§aâ€¯?
ğŸ‘‰ Notre volontÃ© est de vous accompagner dans la construction et lâ€™Ã©panouissement de votre carriÃ¨re en nous appuyant notamment sur 3 piliers :
Voir plus"
,,,,,,,,,,
Data Engineer - Energie & Retail - Lyon,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Limonest,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Description de lâ€™entreprise
Sopra Steria, lâ€™un des leaders europÃ©ens de la Tech reconnu pour ses activitÃ©s de conseil, de services numÃ©riques et dâ€™Ã©dition de logiciels, aide ses clients Ã  mener leur transformation digitale et Ã  obtenir des bÃ©nÃ©fices concrets et durables. Il apporte une rÃ©ponse globale aux enjeux de compÃ©titivitÃ© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs dâ€™activitÃ© et des technologies innovantes Ã  une approche rÃ©solument collaborative.
Sopra Steria place lâ€™humain au centre de son action et sâ€™engage auprÃ¨s de ses clients Ã  tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 50 000 collaborateurs dans prÃ¨s de 30 pays, le Groupe a rÃ©alisÃ© un chiffre dâ€™affaires de 5,1 milliards dâ€™euros en 2022.
The world is how we shape it
Description du poste
Notre promesse :
â€œAvoir lâ€™opportunitÃ© dâ€™Ã©voluer et de dÃ©velopper expertises et compÃ©tences grÃ¢ce Ã  des expÃ©riences variÃ©es au sein dâ€™un Groupe multi-mÃ©tiers et multisectoriels, intervenant auprÃ¨s des plus grandes entreprises EuropÃ©ennesâ€.
Dans ce cadre, pourquoi ne pas devenir Architecte ou encore Directeur/rice technique dans lâ€™avenir ?
Votre futur environnement de travail :
Vous intÃ©grez une Ã©quipe de data engineerâ€™s, directement chez notre client basÃ© dans le 7e arrondissement de Lyon.
Notre client est spÃ©cialisÃ© dans les mÃ©tiers de lâ€™Ã©nergie. Vous travaillez sur diffÃ©rents contextes mÃ©tier comme la production, le transport ou encore la fourniture de gaz et dâ€™Ã©lectricitÃ© :
Solution de supervision de la production et consommation dâ€™Ã©lectricitÃ© en temps rÃ©el, afin de contrÃ´ler lâ€™Ã©quilibre offre / demande ;
Solution Â« big data Â» qui permet Ã  notre client de stocker, exploiter et valoriser lâ€™ensemble des donnÃ©es collectÃ©es et gÃ©rÃ©es dans le cadre de son activitÃ©.
Votre rÃ´le et vos missions :
Participer aux phases de dÃ©veloppement dâ€™applications Big Data (ETL, crÃ©ation de pipelines, dÃ©veloppement de dashboards, gestion et administration des flux de donnÃ©es) ;
Traiter des problÃ©matiques full-stack ;
Concevoir des architectures innovantes ;
Assurer lâ€™amÃ©lioration continue du projet et de ses membres ;
Travailler avec des mÃ©thodologies SAFe ou DevOps.
Vous travaillez autour des technologies Spark, Hadoop, Nifi, Elastic search, Java, AWS et Azure.
Qualifications
Votre profil :
Vous Ãªtes diplÃ´mÃ©(e) dâ€™une Ã©cole dâ€™IngÃ©nieur ou Ã©quivalent Universitaire, et disposez dâ€™une premiÃ¨re expÃ©rience significative en ingÃ©nierie de la donnÃ©e de 3 ans minimum sur une fonction similaire ;
Vous maÃ®trisez diffÃ©rentes technologies telles que Nifi, Elastic Search, Hadoop, Spark, Google Cloud Al Platform ou encore Java ;
Vous avez un bon esprit dâ€™analyse et de synthÃ¨se, le sens du relationnel, vous Ãªtes polyvalent(e) et autonome.
Informations supplÃ©mentaires
Les avantages Ã  nous rejoindre :
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressant : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 30 familles de mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de sâ€™engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â».
Lâ€™opportunitÃ© de rejoindre le collectif Techâ€™Me UP (formations, confÃ©rences, veille, et bien plus encoreâ€¦).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
Voir moins",
Data Engineer (Internship),"{'name': 'WIREMIND', 'sector': 'Logiciels, MobilitÃ©, SaaS / Cloud Services', 'employees': '91 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '29 ans'}","Stage
(6 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,"Descriptif du poste
At Wiremind, the Data Science team is responsible for the development, monitoring and evolution of all ML-powered forecasting and optimization algorithms in use in our Revenue Management systems. Our algorithms are divided in 2 parts:
A modelling of the unconstrained demand using ML models (e.g. deep learning, boosted trees) trained on historical data in the form of time-series
Constrained optimizations problems solved using linear programming techniques
The team is now entering a scaling phase where we will face the challenge to stay agile in terms of innovation while supporting and closely monitoring deployed algorithms.
This rapid growth comes with a multiplication of data sources and deployed predictive models. In order to maintain high prediction accuracies and ascertain data quality, we are looking for a Data Engineer Intern with a passion for software engineering and rigorous mind.
You will be joining a team shaped to have all profiles necessary to constitute an autonomous departement (devops, software and data engineering, data science, AIML, operational research).
There, you will support the ML engineers by improving our MLOps platform, work closely with software engineers to implement the data science algorithms in the client applications and exchange with the platform team to keep the infrastructure debt at a minimum.
As a Data Engineer Intern, you will be responsible for :
Help the team deploy our algorithms in production in a safe, scalable and maintainable way
Support the ML team in their use of the MLOPs framework
Technical stack:
Backend: Python 3.7+ with SQLAlchemy, Remoulade, Flask/FastAPI
Argo over an auto-scaled Kubernetes cluster for orchestration
Data-store: Postgresql, Elasticsearch, Redis
Gitlab for continuous delivery
Common ML libraries: TensorFlow, LightGBM, XGBooost, Pandas, Dask, Dash
THE BENEFITS OF THE JOB ğŸš€
International environment ğŸŒ
Hyper-growth start-up: strong growth in our turnover and workforce ğŸ“ˆ
Joining a committed team that offers you opportunities for development ğŸ§‘â€ğŸ’»
Variety of tasks and a high degree of autonomy
Position based in the heart of Paris (Bd PoissonniÃ¨re) âœ¨
Attractive remuneration indexed to performance ğŸ’ª
Luncheon vouchers ğŸŒ®
A hybrid policy: 2 daysâ€™ remote a week and the possibility of occasionally working from abroad ğŸ’»
Start date: as soon as possible
Type of contract: internship
Voir moins","Profil recherchÃ©
Above average in terms of rigor and autonomy, you are proactive and curious.
Good general culture in computer science and you are looking for a quick progression perspective in an environment with best development practices.
Interested in solving business problems through technological solutions."
ConsultantÂ·e Cloud Data Engineer GCP/Azure,"{'name': 'SAEGUS', 'sector': 'IT / Digital, StratÃ©gie', 'employees': '120 collaborateurs', 'creation_year': '2014', 'turnover': '14Mâ‚¬', 'mean_age': '30 ans'}",CDI,Paris,42K Ã  60K â‚¬,TÃ©lÃ©travail occasionnel,26 fÃ©vrier 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
ConcrÃ¨tement, quelle sera la mission et les rÃ©alisations attendues â“
En tant que ConsultantÂ·e Data Engineer, tu seras intÃ©grÃ©Â·e Ã  lâ€™Ã©quipe Smart Data dont la mission est dâ€™aider ses clients Ã  tirer profit des technologies les plus innovantes pour valoriser leurs donnÃ©es. De lâ€™acquisition Ã  la restitution, tu interviens sur chaque Ã©tape du processus dâ€™aide Ã  la dÃ©cision.
Tu participeras aux missions de conseil et dâ€™expertise afin de contribuer Ã  lâ€™atteinte des objectifs majeurs de nos clients et contribueras Ã  la rÃ©alisation de projets tels que :
âš¡ï¸ Le design dâ€™une plateforme Azure Cloud et la mise en place de pipeline dâ€™ingestion et exposition de donnÃ©es pour la mise Ã  disposition de donnÃ©es mÃ©tiers, rafraichies toutes les 30mn
âš¡ï¸ La mise en place des bonnes pratiques et lâ€™initialisation du Datalab pour un grand groupe dâ€™assurance, et lâ€™accompagnement Ã  lâ€™industrialisation des algorithmes pour les usages mÃ©tiers
âš¡ï¸ Lâ€™ensemble des traitements dâ€™ingestion et prÃ©paration des datasets afin dâ€™alimenter des Dashboard de monitoring de lâ€™activitÃ© digitale Worldwide dâ€™un grand groupe cosmÃ©tique afin de mesurer lâ€™empreinte des marques sur les mÃ©dias et rÃ©seaux sociaux
âš¡ï¸ Lâ€™accompagnement Ã  la crÃ©ation et lâ€™activitÃ© dâ€™une Data Factory pour traiter lâ€™ensemble des donnÃ©es dâ€™un grand groupe de distribution et mettre Ã  disposition des donnÃ©es qualifiÃ©es pour les diffÃ©rents use cases mÃ©tiers
Nous recherchons un.e passionnÃ©.e possÃ©dant une envie de de fÃ©dÃ©rer et faire monter en valeur les consultants autour des thÃ©matiques Data Engineering recouvrant la mise en place de Plateforme de donnÃ©es, des bonnes pratiques de dÃ©veloppements et des process DataOps, lâ€™industrialisation de pipeline de traitements de donnÃ©es pouvant aller jusquâ€™Ã  la Data Visualisation.
âœ Dans quel environnementâ€¯?
En fonction de tes missions et rÃ©alisations projet, tu seras amenÃ©Â·e Ã  intÃ©grer des Ã©quipes composÃ©es de Data Engineer, Data Scientist, Data Architects, organisÃ©es en mode agile. Tes activitÃ©s sâ€™appuieront sur les mÃ©thodes et savoir-faire de Saegus et sur son catalogue dâ€™outils et technologies sur lesquels tu as une maÃ®trise sur plusieurs dâ€™entre euxâ€¯:
âœ… Bonnes connaissances sur les architectures data et cloud (connaissance dâ€™un environnement Cloud)â€¯:
Azure (Data Factory, Synapse, ADLS, Databricks)
Google GCP (BigQuery, Composer, Data Studio)
âœ… SQL, Python
âœ… Spark, PySpark
âœ… Airflow, Kafka, Jenkins
âœ… Solides connaissances des processus collaboratifs et outils de dÃ©veloppement (DevOps, Git, CI/CDâ€¦)
Les connaissances suivantes seraient un plus â¤µï¸
OpenShift, Docker, Kubernetes
Data visualisation
Bases NoSQL
Certification Data Engineer (Azure Data Engineer, Google Professional Data Engineer ou Snowflake SnowPro)
Ce que nous tâ€™apportons
ğŸ’« FORMATIONS ET DÃ‰VELOPPEMENT DE CARRIÃˆRE
Une journÃ©e de formation incluse dans ton parcours dâ€™onboarding lors de ton premier mois dâ€™arrivÃ©e pour partager sur les fondamentaux et rÃ©pondre Ã  tes questions
AccÃ¨s Ã  un coach interne et consultant comme toi pour tâ€™accompagner dans ton quotidien (questions en particulier, aide, montÃ©e en compÃ©tences)
Un plan de formations et de certifications ambitieux (minimum 1 certification offerte par an)
â­ï¸ AVANTAGES
Remboursement de tes frais de transports (remboursement Ã  100% de ton pass navigo ou forfait mobilitÃ© durable jusquâ€™Ã  700â‚¬ par an pour lâ€™utilisation et lâ€™aide Ã  lâ€™achat de matÃ©riel de mobilitÃ© douce)
Titres restaurant Ã  hauteur de 216â‚¬/mois pris en charge Ã  60% par Saegus (Carte Swile)
Prime vacances (versÃ©e en juin)
Prime tÃ©lÃ©phone 25â‚¬/mois
Prime dâ€™intÃ©ressement aux rÃ©sultats de lâ€™entreprise
Prise en charge par Saegus de la mutuelle Ã  la hauteur de 75%
ğŸ‘‹ COHÃ‰SION ET CONVIVIALITÃ‰
Organisation de deux activitÃ©s par mois (fun, solidaire ou excellence) par notre Team Anim
Un sÃ©minaire annuel pour favoriser la cohÃ©sion entre Saegusiens
AccÃ¨s aux locaux de Saegus, trÃ¨s accueillants dans le centre de Paris notamment lors de nos SaegUp mensuel
Voir moins","Profil recherchÃ©
ğŸ¯ IdÃ©alement, en termes de compÃ©tences, nous recherchons :
Un profil de formation supÃ©rieure (Bac + 5 minimum), ingÃ©nieur ou Ã©quivalent, avec une expÃ©rience dâ€™au moins 3 ou 4 ans minimum dans le domaine du Big Data.
Tu as dÃ©jÃ  menÃ© avec succÃ¨s plusieurs projets Big Data avec des rÃ©fÃ©rences significatives dans la mise en place de flux de donnÃ©es et de traitement de lâ€™information.
Tu interviens en autonomie sur tes projets et as une premiÃ¨re expÃ©rience dâ€™encadrement technique.
Tu es motivÃ©.e pour intÃ©grer une structure alliant lâ€™exigence dâ€™un cabinet de conseil et le dynamisme et lâ€™agilitÃ© dâ€™une start-up.
Tu es unÂ·e trÃ¨s bonÂ·ne communiquantÂ·e et as un fort esprit dâ€™initiative, un goÃ»t prononcÃ© pour les nouvelles technologies et un bon esprit de synthÃ¨se.
Ton sens du service et ton Ã©coute client te permettront de tâ€™inscrire parfaitement dans la culture de notre cabinet de conseil.
La maÃ®trise de lâ€™anglais et du franÃ§ais Ã  lâ€™Ã©crit et Ã  lâ€™oral est indispensable.
ğŸ‰ DÃ©couvre SAEGUS avec Martin, Manager Data et Thomas, Consultant Data."
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 Mâ‚¬', 'mean_age': '34 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©",TÃ©lÃ©travail frÃ©quent,,,,,"Descriptif du poste
Rejoignez la plus grosse Ã©quipe SNOWFLAKE certifiÃ©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intÃ©grer une ESN Ã  taille humaine vous permettant de travailler sur des projets challengeant et de monter en compÃ©tences ? Ce poste est pour vous ! 
Vous serez amenÃ© Ã  travailler sur :
Elaboration dâ€™architectures optimisÃ©es dans un contexte Snowflake,
Conception et mise en place des ingestions de donnÃ©es (temps rÃ©el, Kafka, Snowpipe),
ModÃ©lisation de donnÃ©es (Star SchÃ©ma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des donnÃ©es (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coÃ»ts d utilisation Snowflake (FinOps)","Profil recherchÃ©
Vous Ãªtes issu dâ€™une Ã©cole dâ€™ingÃ©nieur ou dâ€™un Master 2 
 Vous avez une premiÃ¨re expÃ©rience sur du Snowflake ou au moins 2  ans de SQL"
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Saint-Herblain,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Rejoignez la plus grosse Ã©quipe SNOWFLAKE certifiÃ©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intÃ©grer une ESN Ã  taille humaine vous permettant de travailler sur des projets challengeant et de monter en compÃ©tences ? Ce poste est pour vous ! 
Vous serez amenÃ© Ã  travailler sur :
Elaboration dâ€™architectures optimisÃ©es dans un contexte Snowflake,
Conception et mise en place des ingestions de donnÃ©es (temps rÃ©el, Kafka, Snowpipe),
ModÃ©lisation de donnÃ©es (Star SchÃ©ma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des donnÃ©es (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coÃ»ts d utilisation Snowflake (FinOps)","Profil recherchÃ©
Vous Ãªtes issu dâ€™une Ã©cole dâ€™ingÃ©nieur ou dâ€™un Master 2 
 Vous avez une premiÃ¨re expÃ©rience sur du Snowflake ou au moins 2  ans de SQL"
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 Mâ‚¬', 'mean_age': '34 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©",TÃ©lÃ©travail frÃ©quent,,,,,"Descriptif du poste
Rejoignez la plus grosse Ã©quipe SNOWFLAKE certifiÃ©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intÃ©grer une ESN Ã  taille humaine vous permettant de travailler sur des projets challengeant et de monter en compÃ©tences ? Ce poste est pour vous ! 
Vous serez amenÃ© Ã  travailler sur :
Elaboration dâ€™architectures optimisÃ©es dans un contexte Snowflake,
Conception et mise en place des ingestions de donnÃ©es (temps rÃ©el, Kafka, Snowpipe),
ModÃ©lisation de donnÃ©es (Star SchÃ©ma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des donnÃ©es (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coÃ»ts d utilisation Snowflake (FinOps)","Profil recherchÃ©
Vous Ãªtes issu dâ€™une Ã©cole dâ€™ingÃ©nieur ou dâ€™un Master 2 
 Vous avez une premiÃ¨re expÃ©rience sur du Snowflake ou au moins 2  ans de SQL"
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Rejoignez la plus grosse Ã©quipe SNOWFLAKE certifiÃ©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intÃ©grer une ESN Ã  taille humaine vous permettant de travailler sur des projets challengeant et de monter en compÃ©tences ? Ce poste est pour vous ! 
Vous serez amenÃ© Ã  travailler sur :
Elaboration dâ€™architectures optimisÃ©es dans un contexte Snowflake,
Conception et mise en place des ingestions de donnÃ©es (temps rÃ©el, Kafka, Snowpipe),
ModÃ©lisation de donnÃ©es (Star SchÃ©ma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des donnÃ©es (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coÃ»ts d utilisation Snowflake (FinOps)","Profil recherchÃ©
Vous Ãªtes issu dâ€™une Ã©cole dâ€™ingÃ©nieur ou dâ€™un Master 2 
 Vous avez une premiÃ¨re expÃ©rience sur du Snowflake ou au moins 2  ans de SQL"
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Villeurbanne,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Rejoignez la plus grosse Ã©quipe SNOWFLAKE certifiÃ©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intÃ©grer une ESN Ã  taille humaine vous permettant de travailler sur des projets challengeant et de monter en compÃ©tences ? Ce poste est pour vous ! 
Vous serez amenÃ© Ã  travailler sur :
Elaboration dâ€™architectures optimisÃ©es dans un contexte Snowflake,
Conception et mise en place des ingestions de donnÃ©es (temps rÃ©el, Kafka, Snowpipe),
ModÃ©lisation de donnÃ©es (Star SchÃ©ma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des donnÃ©es (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coÃ»ts d utilisation Snowflake (FinOps)","Profil recherchÃ©
Vous Ãªtes issu dâ€™une Ã©cole dâ€™ingÃ©nieur ou dâ€™un Master 2 
 Vous avez une premiÃ¨re expÃ©rience sur du Snowflake ou au moins 2  ans de SQL"
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 Mâ‚¬', 'mean_age': '34 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Rejoignez la plus grosse Ã©quipe SNOWFLAKE certifiÃ©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intÃ©grer une ESN Ã  taille humaine vous permettant de travailler sur des projets challengeant et de monter en compÃ©tences ? Ce poste est pour vous ! 
Vous serez amenÃ© Ã  travailler sur :
Elaboration dâ€™architectures optimisÃ©es dans un contexte Snowflake,
Conception et mise en place des ingestions de donnÃ©es (temps rÃ©el, Kafka, Snowpipe),
ModÃ©lisation de donnÃ©es (Star SchÃ©ma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des donnÃ©es (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coÃ»ts d utilisation Snowflake (FinOps)","Profil recherchÃ©
Vous Ãªtes issu dâ€™une Ã©cole dâ€™ingÃ©nieur ou dâ€™un Master 2 
 Vous avez une premiÃ¨re expÃ©rience sur du Snowflake ou au moins 2  ans de SQL"
Data engineer (H/F),"{'name': 'EKINOX', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, Incubateur / AccÃ©lÃ©rateur', 'employees': '20 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
A propos de votre mission :
Avec nous, vous travaillerez en Ã©quipe. Vous vous entraÃ®nerez avec des coÃ©quipiers Ã  votre image (et donc Ã  notre image) dans un cadre agile (souvent Scrum), jusquâ€™Ã  entrer en rÃ©sonance avec eux. Lorsque vous travaillez pour votre client, votre sens de lâ€™empathie vous pousse Ã  toujours mieux comprendre ses problÃ©matiques de fond. Votre socle mÃ©thodologique sera sÃ©rieusement constituÃ© de TDD, BDD, pair programming et autres principes Ã©tablis de qualitÃ© tirÃ©es notamment des pratiques prÃ´nÃ©es par Extreme Programming ou du Craftsmanship Manifesto. Fortement impliquÃ© dans la vision produit, vous considÃ©rez le Product Manager au mÃªme titre que nâ€™importe quel autre de vos coÃ©quipiers.","Profil recherchÃ©
Ce quâ€™Ekinox recherche chez vous :
Vous avez une expÃ©rience de 2 ans ou plus (mais on peut toujours en discuter)
Vous vous sentez concernÃ©Â·e par le software craftsmanship et faites de la veille technologique
Vous aimez travailler en Ã©quipe et partager vos connaissances
Vous Ãªtes ouvertÂ·e aux autres et acceptez leurs points de vue avec bienveillance
Vous contribuez Ã  la progression des personnes qui vous entourent
CompÃ©tences techniques :
Voici une liste non-exhaustive des technologies que nous utilisons. Vous aurez pour mission de produire de la valeur avec un certain nombre dâ€™entre elles:
Langages de programmation suivants : Python, Java, Scala
Outils dâ€™industrialisation : Gitlab CI / Github Actions / Google Cloud Build
Infrastructure et dÃ©ploiement : Docker / Kubernetes, Terraform
Travail en Ã©quipe : Git
Web : Spring et autres frameworks
Services cloud : AWS / GCP / Azure
Voir plus"
Stagiaire Data Engineer - Caen,"{'name': 'JAKALA', 'sector': 'Digital Marketing / Data Marketing, Big Data, E-commerce', 'employees': '150 collaborateurs', 'creation_year': '2023', 'turnover': '15Mâ‚¬', 'mean_age': '31 ans'}","Stage
(6 mois)",Caen,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
En tant que Stagiaire Data Engineer, vous Ã©voluez au sein dâ€™une Ã©quipe dâ€™une vingtaine de dÃ©veloppeurs, ingÃ©nieurs en science des donnÃ©es, algorithmiciens, intÃ©grateurs et graphistes.
Sujet 1 : Streaming
Vous avez pour mission de concevoir et dâ€™implÃ©menter diffÃ©rents frameworks dans des environnements cloud permettant de traiter en temps rÃ©el  des donnÃ©es provenant dâ€™objets connectÃ©s (IOT).
Ces frameworks seront Ã  implÃ©menter sur les diffÃ©rents environnements cloud (AWS, GCP, Azure, OVH).
Sujet 2 : DÃ©veloppement ETL - Kedro
Vous avez pour mission de dÃ©velopper des pipelines Python en utilisant lâ€™outil Kedro sur diffÃ©rents environnements cloud.
ThÃ©matiques abordÃ©es :
pipelines
multi threading
algorithmie
data catalog
CICD
Viz
Voir moins","Profil recherchÃ©
En derniÃ¨re annÃ©e dâ€™Ã©cole dâ€™IngÃ©nieur ou universitaire, vous avez une grande appÃ©tence pour lâ€™environnement Big Data.
CompÃ©tences attendues:
Bonne connaissance dans le dÃ©veloppement logiciel 
Bon niveau en Python 
API REST
scripts et logiciel
data visualisation
prÃ© Ã©tude via Notebooks Jupyter
Bon niveau en Java
Bonne connaissance de lâ€™environnement container Docker (Kubernetes est un plus)
Bonne connaissance de SQL et dâ€™un systÃ¨me de SGBDr (PostgreSQL, MySQL)
Connaissance des environnements cloud (VM, Containers)
Connaissance de Git et travail en Ã©quipe
Curieux.se, passionnÃ©.e et rigoureux.se, vous Ã©voluez dans un contexte innovant, challengeant et bienveillant.
Voir plus"
Data Engineer,"{'name': 'INDY', 'sector': 'FinTech / InsurTech', 'employees': '266 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '29 ans'}",CDI,Lyon,55K Ã  65K â‚¬,TÃ©lÃ©travail frÃ©quent,05 fÃ©vrier 2024,> 4 ans,Bac +5 / Master,"Descriptif du poste
En raison de notre forte croissance, nous avons la volontÃ© de mettre en place une stack robuste, performante et scalable.
Nous avons besoin de mieux utiliser les donnÃ©es en prÃ©sence, et câ€™est une super opportunitÃ© pour toi : cela te permettra de crÃ©er de la valeur pour lâ€™entreprise !
Aujourdâ€™hui, lâ€™Ã©quipe Data est composÃ©e de 4 personnes, dans une Ã©quipe Tech globale de 45 personnes.
Tu rejoindras :
Benoit, Lead Data Engineer
EloÃ¯se, Data Engineer
Maud, Data Engineer
Maxime, Data Scientist
Les missions de lâ€™Ã©quipe:
Fournir des donnÃ©es up-to-date, utiles et fiables aux Ã©quipes Business de Indy pour leur permettre dâ€™analyser et piloter leur activitÃ©.
AmÃ©liorer notre systÃ¨me de catÃ©gorisation automatique des transactions bancaires.
Lâ€™un de nos challenges du moment est que la BI soit la source de vÃ©ritÃ© et alimente directement les outils des Ã©quipes Customer Support, Sales et Marketing.
Avec la croissance de notre base utilisateur, notre volume de donnÃ©es augmente. Nous en avons plus Ã  rÃ©cupÃ©rer, Ã  traiter, Ã  stockerâ€¦ Tu vas pouvoir intervenir sur les pipelines de donnÃ©es pour amÃ©liorer leur robustesse et la vitesse de traitement. De plus, tu participeras Ã  lâ€™Ã©volution de notre stack technique pour relever ces challenges. En dâ€™autres termes, la scalabilitÃ© de nos outils et de notre stack data!
Notre stack actuelle se compose de: PostgreSQL, Airbyte, DBT, Metabase, Dagster, Census, Python, Heroku, AWS ECS, DataDog
Plus concrÃ¨tement, tes missions seront:
DÃ©velopper, puis passer Ã  lâ€™Ã©chelle et monitorer notre plateforme de traitement et de visualisation de donnÃ©es.
ÃŠtre garant du cycle de vie des donnÃ©es.
DÃ©finir, dÃ©velopper, documenter et maintenir les pipelines de donnÃ©es pour la B.I.
Faire le lien entre les Ã©quipes de consommation de la donnÃ©e et lâ€™Ã©quipe de R&D applicative.
Participer aux dÃ©finitions dâ€™architecture systÃ¨me des Ã©quipes de dÃ©veloppement.
Former les Ã©quipes techniques aux bonnes pratiques de gestion de la donnÃ©e.
Assurer la sÃ©curitÃ© des donnÃ©es.
Voir moins","Profil recherchÃ©
Le candidat idÃ©al pour rejoindre notre Ã©quipe Data
Tu as une expÃ©rience confirmÃ©e en tant que Data Engineer (4~8 ans) et tu cherches Ã  avoir plus dâ€™impact Ã  travers tes contributions
Tu as dÃ©jÃ  travaillÃ© sur diffÃ©rents types de bases de donnÃ©es, et Ã©galement sur des sujets de volumÃ©trie et modÃ©lisation.
Tu maitrises la programmation Python et SQL
Tu es orientÃ© rÃ©sultats et tu as une bonne comprÃ©hension des enjeux business
Tu as envie de rÃ©soudre des problÃ¨mes, en toute autonomie, en prenant des initiatives et en sachant prendre des dÃ©cisions
Tu es un bon communicant, tu sais interagir avec diffÃ©rents interlocuteurs, y compris non techniques
Nous portons une attention particuliÃ¨re Ã  la diversitÃ© dans notre processus de recrutement. Nous savons que certaines personnes nâ€™osent parfois pas rÃ©pondre sans cocher toutes les cases : Venez nous en parler.
Dans le cadre de nos valeurs dâ€™inclusions, nous accordons chez Indy une attention particuliÃ¨re aux personnes en situation de handicap.
Voir plus"
DATA ENGINEER (F/H),"{'name': 'ACTINVISION', 'sector': 'Intelligence artificielle / Machine Learning, Transformation, Big Data', 'employees': '50 collaborateurs', 'creation_year': '2014', 'turnover': '5Mâ‚¬', 'mean_age': '29 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Vous serez amenÃ©(e) Ã  travailler sur diffÃ©rents projets innovants, pour des clients de toute taille, dans des secteurs divers et variÃ©s tels que lâ€™agroalimentaire, le commerce, la distribution, la banque, la finance, le luxe, lâ€™Ã©nergie, lâ€™industrie, la pharma/chimie ou encore la santÃ©.
En tant que Data Engineer passionnÃ©(e), vous aiderez nos clients Ã  relever les challenges dâ€™aujourdâ€™hui et de demain en intÃ©grant leurs donnÃ©es au sein dâ€™infrastructures, On-Premise et Cloud. A la suite dâ€™une pÃ©riode dâ€™intÃ©gration destinÃ©e Ã  vous familiariser avec la mÃ©thodologie Actinvision, vous interviendrez dans toutes les phases de projets, de lâ€™analyse du besoin client Ã  la livraison de la solution technique en passant par le chiffrage et les dÃ©veloppements. Vous Ã©voluerez en Ã©quipe mais Ã©galement de maniÃ¨re autonome dans un environnement technique porteur dâ€™innovations incluant par exemple la modÃ©lisation et la construction dâ€™entrepÃ´ts de donnÃ©es (Data Warehouses), le design de flux dâ€™intÃ©gration au moyen dâ€™outils (Matillion etc. ) permettant lâ€™alimentation de ces derniers, ou encore la mise en place et lâ€™optimisation dans le respect des bonnes pratiques dâ€™architectures Data, notamment Cloud (e.g. Snowflake ou Azure).
Le dÃ©veloppement des compÃ©tences est un aspect primordial. Ce dÃ©veloppement continu est appuyÃ© par les ressources officielles mises Ã  disposition par lâ€™ensemble des Ã©diteurs partenaire dâ€™Actinvision et complÃ©tÃ© par des ressources internes. Les compÃ©tences acquises pourront Ãªtre valorisÃ©es aux travers de certifications Ã©diteurs hautement qualifiantes.
MISSIONS PRINCIPALES : â€¢ Participer en Ã©quipe ou de faÃ§on autonome Ã  la mise en Å“uvre de projets Data/Business Intelligence (BI), en se focalisant principalement sur les partie intÃ©gration et stockage de la donnÃ©e â€¢ Recueil du besoin client technico-fonctionnel permettant la mise en place dâ€™architectures pour la collecte et lâ€™extraction de donnÃ©es depuis diverses sources (bases de donnÃ©es Cloud, applications mÃ©tier, API, etc.), la manipulation et la transformation de ces donnÃ©es, puis le chargement de ses derniÃ¨res au sein de base de donnÃ©es de type Data Warehouses (DWH) â€¢ Design des infrastructures/architectures Data et modÃ©lisation des DWH cibles, lesquels seront principalement utilisÃ©s dans le cadre dâ€™opÃ©rations de Reporting et/ou de Data Visualisation â€¢ RÃ©alisation de flux dâ€™intÃ©gration et transformation de donnÃ©e
Voir moins","Profil recherchÃ©
De formation Bac+5 en informatique, vous disposez de minimum 1 an dâ€™expÃ©rience sur un poste similaire.
Savoir-faire, compÃ©tences techniques requises :
â€¢ Langage SQL et modÃ©lisation DWH
â€¢ Pratique dâ€™un outil dâ€™intÃ©gration ETL / ELT
â€¢ Connaissances en bases de donnÃ©es relationnelles (e.g. SQL Server ou MySQL)
â€¢ Connaissances sur une plateforme Cloud Data (Snowflake, Azure, AWS ou GCP)
â€¢ Connaissances de la chaÃ®ne de valeur de la Data, et particuliÃ¨rement de la BI
Savoir-faire, compÃ©tences techniques apprÃ©ciÃ©es :
â€¢ Connaissances en architectures Cloud (sÃ©curitÃ©, performances, maÃ®trise des coÃ»ts, etc.)
â€¢ Programmation procÃ©durale, e.g. T-SQL ou PL/SQL
â€¢ Un langage de programmation orientÃ© objet, e.g. Java ou Python
â€¢ A lâ€™aise avec lâ€™utilisation dâ€™API / de Web Services
â€¢ Notions sur lâ€™ESB
Savoir-Ãªtre, compÃ©tences fonctionnelles :
â€¢ Passion pour la Data
â€¢ Autonomie / Travail et esprit dâ€™Ã©quipe (incluant le partage des connaissances)
â€¢ Force de proposition / CapacitÃ© Ã  rechercher et trouver des solutions
â€¢ CrÃ©ativitÃ© et curiositÃ©
â€¢ Dynamisme et rÃ©activitÃ©
â€¢ Sens du service
â€¢ CapacitÃ© Ã  participer Ã  lâ€™animation de la communautÃ© (interne et externe)
â€¢ Anglais technique
â€¢ Pour un poste confirmÃ© : ExpÃ©rience probante dans les domaines du DWH et de lâ€™intÃ©gration de donnÃ©es (cloud et/ou on-prem)
Voir plus"
DATA ENGINEER (F/H),"{'name': 'ACTINVISION', 'sector': 'Intelligence artificielle / Machine Learning, Transformation, Big Data', 'employees': '50 collaborateurs', 'creation_year': '2014', 'turnover': '5Mâ‚¬', 'mean_age': '29 ans'}",CDI,Strasbourg,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Vous serez amenÃ©(e) Ã  travailler sur diffÃ©rents projets innovants, pour des clients de toute taille, dans des secteurs divers et variÃ©s tels que lâ€™agroalimentaire, le commerce, la distribution, la banque, la finance, le luxe, lâ€™Ã©nergie, lâ€™industrie, la pharma/chimie ou encore la santÃ©.
En tant que Data Engineer passionnÃ©(e), vous aiderez nos clients Ã  relever les challenges dâ€™aujourdâ€™hui et de demain en intÃ©grant leurs donnÃ©es au sein dâ€™infrastructures, On-Premise et Cloud. A la suite dâ€™une pÃ©riode dâ€™intÃ©gration destinÃ©e Ã  vous familiariser avec la mÃ©thodologie Actinvision, vous interviendrez dans toutes les phases de projets, de lâ€™analyse du besoin client Ã  la livraison de la solution technique en passant par le chiffrage et les dÃ©veloppements. Vous Ã©voluerez en Ã©quipe mais Ã©galement de maniÃ¨re autonome dans un environnement technique porteur dâ€™innovations incluant par exemple la modÃ©lisation et la construction dâ€™entrepÃ´ts de donnÃ©es (Data Warehouses), le design de flux dâ€™intÃ©gration au moyen dâ€™outils (Matillion etc. ) permettant lâ€™alimentation de ces derniers, ou encore la mise en place et lâ€™optimisation dans le respect des bonnes pratiques dâ€™architectures Data, notamment Cloud (e.g. Snowflake ou Azure).
Le dÃ©veloppement des compÃ©tences est un aspect primordial. Ce dÃ©veloppement continu est appuyÃ© par les ressources officielles mises Ã  disposition par lâ€™ensemble des Ã©diteurs partenaire dâ€™Actinvision et complÃ©tÃ© par des ressources internes. Les compÃ©tences acquises pourront Ãªtre valorisÃ©es aux travers de certifications Ã©diteurs hautement qualifiantes.
MISSIONS PRINCIPALES : â€¢ Participer en Ã©quipe ou de faÃ§on autonome Ã  la mise en Å“uvre de projets Data/Business Intelligence (BI), en se focalisant principalement sur les partie intÃ©gration et stockage de la donnÃ©e â€¢ Recueil du besoin client technico-fonctionnel permettant la mise en place dâ€™architectures pour la collecte et lâ€™extraction de donnÃ©es depuis diverses sources (bases de donnÃ©es Cloud, applications mÃ©tier, API, etc.), la manipulation et la transformation de ces donnÃ©es, puis le chargement de ses derniÃ¨res au sein de base de donnÃ©es de type Data Warehouses (DWH) â€¢ Design des infrastructures/architectures Data et modÃ©lisation des DWH cibles, lesquels seront principalement utilisÃ©s dans le cadre dâ€™opÃ©rations de Reporting et/ou de Data Visualisation â€¢ RÃ©alisation de flux dâ€™intÃ©gration et transformation de donnÃ©e
Voir moins","Profil recherchÃ©
De formation Bac+5 en informatique, vous disposez de minimum 1 an dâ€™expÃ©rience sur un poste similaire.
Savoir-faire, compÃ©tences techniques requises :
â€¢ Langage SQL et modÃ©lisation DWH
â€¢ Pratique dâ€™un outil dâ€™intÃ©gration ETL / ELT
â€¢ Connaissances en bases de donnÃ©es relationnelles (e.g. SQL Server ou MySQL)
â€¢ Connaissances sur une plateforme Cloud Data (Snowflake, Azure, AWS ou GCP)
â€¢ Connaissances de la chaÃ®ne de valeur de la Data, et particuliÃ¨rement de la BI
Savoir-faire, compÃ©tences techniques apprÃ©ciÃ©es :
â€¢ Connaissances en architectures Cloud (sÃ©curitÃ©, performances, maÃ®trise des coÃ»ts, etc.)
â€¢ Programmation procÃ©durale, e.g. T-SQL ou PL/SQL
â€¢ Un langage de programmation orientÃ© objet, e.g. Java ou Python
â€¢ A lâ€™aise avec lâ€™utilisation dâ€™API / de Web Services
â€¢ Notions sur lâ€™ESB
Savoir-Ãªtre, compÃ©tences fonctionnelles :
â€¢ Passion pour la Data
â€¢ Autonomie / Travail et esprit dâ€™Ã©quipe (incluant le partage des connaissances)
â€¢ Force de proposition / CapacitÃ© Ã  rechercher et trouver des solutions
â€¢ CrÃ©ativitÃ© et curiositÃ©
â€¢ Dynamisme et rÃ©activitÃ©
â€¢ Sens du service
â€¢ CapacitÃ© Ã  participer Ã  lâ€™animation de la communautÃ© (interne et externe)
â€¢ Anglais technique
â€¢ Pour un poste confirmÃ© : ExpÃ©rience probante dans les domaines du DWH et de lâ€™intÃ©gration de donnÃ©es (cloud et/ou on-prem)
Voir plus"
Data Engineer - Services Financiers - Ile de France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Courbevoie,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Description de lâ€™entreprise
Sopra Steria, acteur majeur de la Tech en Europe, reconnu pour ses activitÃ©s de conseil, de services numÃ©riques et dâ€™Ã©dition de logiciels, aide ses clients Ã  mener leur transformation digitale et Ã  obtenir des bÃ©nÃ©fices concrets et durables. Il apporte une rÃ©ponse globale aux enjeux de compÃ©titivitÃ© des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs dâ€™activitÃ© et des technologies innovantes Ã  une approche rÃ©solument collaborative.
Sopra Steria place lâ€™humain au centre de son action et sâ€™engage auprÃ¨s de ses clients Ã  tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 50 000 collaborateurs dans prÃ¨s de 30 pays, le Groupe a rÃ©alisÃ© un chiffre dâ€™affaires de 5,1 milliards dâ€™euros en 2022.
The world is how we shape it
Description du poste
Votre futur environnement de travail :
Sous la supervision dâ€™un Chef de Projet, vous Ãªtes pleinement impliquÃ©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi Ã  leur succÃ¨s. Vous avez lâ€™occasion de dÃ©velopper vos compÃ©tences techniques et fonctionnelles de maniÃ¨re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.
Votre rÃ´le et vos missions :
Vous avez pour rÃ´le la mise en place de pipelines de donnÃ©es fiables, sÃ©curisÃ©s et Ã  lâ€™Ã©chelle pour soutenir la mise Ã  disposition des donnÃ©es aux cas dâ€™usage mÃ©tier qui en ont besoin.
Vos activitÃ©s principales sont les suivantes :
Vous travaillez avec le client pour Ã©valuer, concevoir, dÃ©ployer, amÃ©liorer et maintenir les pipelines de donnÃ©es ;
Vous vous assurez que les pipelines de donnÃ©es crÃ©Ã©s sont rÃ©silients, sÃ©curisÃ©s et accessibles ;
Vous dÃ©finissez le modÃ¨le opÃ©rationnel pour monitorer et supporter les pipelines de donnÃ©es
Vous fournissez une expertise Ã  nos clients sur leurs donnÃ©es pour assurer leur optimisation et leur sÃ©curitÃ© par rapport Ã  leurs besoins ;
Vous apportez un savoir en gestion de la qualitÃ© et la gouvernance de la donnÃ©e pour assurer le suivi de la conformitÃ© Ã  la gouvernance de la donnÃ©e
Vous faites de la veille technologique dans le domaine afin dâ€™enrichir les roadmaps technologiques et fournir des solutions modernes Ã  nos clients.
Qualifications
Votre profil :
De formation Master 2 Ecole dâ€™IngÃ©nieurs ou Informatique, ou Ã©quivalent, vous justifiez dâ€™une expÃ©rience technique de 3 ans minimum et souhaitez Ã©voluer rapidement dans un contexte motivant.
Vous avez au moins lâ€™une de ces compÃ©tences requises :
MaÃ®trise des technologies de bases de donnÃ©es Relationnelles et NoSQL
MaÃ®trise dâ€™au moins un outil dâ€™ETL/ELT (Informatica, datastage, etc.)
MaÃ®trise des technologies de traitement distribuÃ© de donnÃ©es (spark, Hadoop)
MaÃ®trise dâ€™au moins un framework de streaming de donnÃ©es (Kafka, RabbitMQ, etc.)
MaÃ®trise de chaines CI/CD et de des bonnes pratiques de DataOps
MaÃ®trise de solution de Virutualisation de donnÃ©es (Denodo, Dremio, etc.)
MaÃ®trise dâ€™au moins un environnement cloud public ou privÃ© (Azure, AWS, Outscale, etc.)
Vous Ãªtes attirÃ©(e) par le monde du numÃ©rique, le Cloud et des technologies innovantes.
Vous avez un bon esprit dâ€™analyse, Ãªtes curieux(se) et passionnÃ©(e) et vous avez le sens du travail en Ã©quipe.
Informations supplÃ©mentaires
Ce que nous vous proposons :
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressants : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 50 mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
.La possibilitÃ© de sâ€™engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â».
Lâ€™opportunitÃ© de rejoindre le collectif Techâ€™Me UP (formations, confÃ©rences, veille, et bien plus encore).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
Voir moins",
Senior Data Engineer â€“ CDI â€“ Paris,"{'name': 'IODA GROUP', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, StratÃ©gie', 'employees': '39 collaborateurs', 'creation_year': '2010', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Le Job ğŸ’»
En tant que Senior Data Engineer chez IODA Group, tu seras aux commandes des missions suivantes :
Â·       DÃ©velopper de nouveaux modÃ¨les de donnÃ©es et des pipelines
Â·       Tester les solutions les plus innovantes et prometteuses du marchÃ© en vue de pouvoir amÃ©liorer nos capacitÃ©s en matiÃ¨re de donnÃ©es
Â·       Comprendre les enjeux business et savoir les traduire dans un environnement technique
Â·       Assister nos clients dans le cadrage des projets et contribuer au design fonctionnel et technique avec une vision avant-gardiste
Â·       Assumer le rÃ´le de rÃ©fÃ©rent, coacher les consultants juniors et faire Ã©voluer son Ã©quipe
CompÃ©tences techniques requises ğŸ”§
Pour ce poste, nous recherchons une personne aux compÃ©tences multiples avec :
Â·       Une expÃ©rience approfondie des technologies liÃ©es aux donnÃ©es, y compris les modÃ¨les dâ€™architecture Big Data (Spark, Hive, Impalaâ€¦)
Â·       Une expÃ©rience approfondie des services Cloud (AWS / Azure / GCP)
Â·       Une expertise en langages de programmation : Python, Java, et si possible Scala
Â·       Une mise en production de cas dâ€™usage Data, notamment en Machine Learning
Â·       Une capacitÃ© Ã  mettre en place des modÃ¨les de donnÃ©es flexibles et Ã©volutifs (optimisation de stockage et traitement, regroupement, agrÃ©gation, partitionnementâ€¦)
Â·       Une maitrise des bases de donnÃ©es SQL (conception, exploitation â€¦)
Â·       Une connaissance en DevOps et en dÃ©veloppement de flux de donnÃ©es (data pipelines) avec une maÃ®trise de Docker/Kubernetes et des chaÃ®nes CI/CD seraient un plus
Voir moins","Profil recherchÃ©
Profil recherchÃ© ğŸŒŸ
Si tu es diplÃ´mÃ©(e) dâ€™une Ã©cole dâ€™ingÃ©nieur / gÃ©nie informatique Bac+5, que tu as Ã  minima 4 ans dâ€™expÃ©rience et que tu as une expÃ©rience solide dans le monde de la Data, alors nous voulons te rencontrer !
Si tu es une personne entreprenante, capable de travailler en Ã©quipe en sâ€™adaptant Ã  divers profils, de superviser, de prioriser et de gÃ©rer plusieurs actions, dâ€™avoir dâ€™excellentes compÃ©tences en communication, prÃ©sentation et coordination, nous souhaitons toujours te rencontrer !
De plus, si tu as des compÃ©tences avÃ©rÃ©es en analyse et rÃ©solution de problÃ¨mes, associÃ©es Ã  une aptitude Ã  assimiler rapidement de nouvelles technologies, tu es bien la personne quâ€™il nous faut !
Ce qui tâ€™attend chez IODA Group ğŸŒˆ
En nous rejoignant, tu auras droit Ã  :
Â·       Une Ã©quipe dynamique et motivÃ©e qui reconnaÃ®tra et encouragera tes talents et tes idÃ©es
Â·       Une diversitÃ© de projets stimulants dans diffÃ©rents secteurs dâ€™activitÃ©s
Â·       Des plateformes internes de R&D pour toujours Ãªtre Ã  la pointe de la technologie
Â·       Des perspectives dâ€™Ã©volution concrÃ¨tes pour faire dÃ©coller ta carriÃ¨re
Â·       Un CDI avec une rÃ©munÃ©ration fixe attractive et une part variable selon ton profil (voire des bonus complÃ©mentaires si tu surperformes !)
Â·       Deux jours de tÃ©lÃ©travail par semaine aprÃ¨s la pÃ©riode dâ€™essai
Â·       Des avantages tels que des tickets restaurants, une participation au titre de transport, une mutuelleâ€¦
Â·       Une participation active Ã  la vie de lâ€™entreprise avec des afterworks, des Ã©vÃ©nements, des sÃ©minaires et bien plus encore !
Voir plus"
Stage - 6 mois - Market Risk IT Data Engineer F/H,"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards â‚¬ de PNB', 'mean_age': None}","Stage
(6 mois)",Charenton-le-Pont,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,< 6 mois,Bac +5 / Master,"Descriptif du poste
Votre MISSION & bien plus encoreâ€¦
Vous rejoignez notre Ã©quipe ""Risk DPM Sensitivities"" de Natixis , qui recherche un DÃ©veloppeur Hadoop Scala, pour un stage de 6 mois dÃ¨s maintenant.
Cela se traduit par des calculs et intÃ©grations de sensibilitÃ©s de marchÃ©s quotidiens, des problÃ©matiques de stockage, et de distribution des donnÃ©es.
En collaboration avec votre tuteur vos missions principales seront :
Comprendre le positionnement de l'application dans le systÃ¨me d'information de Natixis et ses fonctionnalitÃ©s ;
Etudier les besoins de monitoring des diffÃ©rentes Ã©quipes (DÃ©partement des risques, Ã©quipe support Ã  Lisbonne, Equipes projets Ã  Paris) ;
Etudier les outils similaires dÃ©jÃ  utilisÃ©s chez Natixis ;
Etudier la faisabilitÃ© de certaines solutions de visualisation des donnÃ©es afin de choisir la plus appropriÃ©e ;
Designer les Ã©crans de monitoring qui devront Ãªtre mis en Å“uvre ;
#FinanceTransformative
En tant que Top Employer, nous plaÃ§ons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilitÃ© interne, dÃ©veloppement de carriÃ¨re et de formation vous permettent de grandir et de vous Ã©panouir tout au long de votre parcours.
Vous Ã©voluez dans un environnement de travail inclusif et favorisant le collaboratif qui vous donnera toutes les chances de rÃ©ussir cette nouvelle mission.
Vous avez Ã©galement la possibilitÃ© de vous engager en faveur de la sociÃ©tÃ© et de causes qui vous tiennent Ã  cÅ“ur via notre fondation d'entreprise.
Vous bÃ©nÃ©ficiez d'une indemnitÃ© de stage en fonction de votre formation et de votre niveau d'Ã©tudes, Ã©galement d'un remboursement de votre titre de transport Ã  hauteur de 60 %, d'un jour d'absence autorisÃ© payÃ© pour chaque mois travaillÃ© et de l'accÃ¨s au restaurant de l'entreprise.




Voir moins","Profil recherchÃ©
Ã‰tudiant de niveau BAC+5, vous prÃ©parez un diplÃ´me d'Ã©cole d'ingÃ©nieur en informatique ou un master 2 universitaire.
Vous Ãªtes curieux et proactif et vous vous challengez constamment et cherchez Ã  toujours dÃ©velopper de nouvelles compÃ©tences.
And last but not least, you are perfectly fluent in English.
Vous serez contactÃ© par l'un de nos recruteurs avant de rencontrer nos experts mÃ©tier. Un moment d'Ã©change idÃ©al pour mettre en avant votre personnalitÃ© ainsi que votre projet."
Data Engineer AWS,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Paris,45K Ã  60K â‚¬,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Nous recherchons un Data Engineer expÃ©rimentÃ© pour rejoindre notre Ã©quipe. En tant que Data Engineer, vous serez responsable de la conception, du dÃ©veloppement et de la mise en Å“uvre de pipelines de traitement de donnÃ©es en temps rÃ©el Ã  grande Ã©chelle. Vous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les donnÃ©es.
Vos responsabilitÃ©s :
Utiliser Kafka pour le traitement de flux de donnÃ©es en temps rÃ©el Ã  grande Ã©chelle, en travaillant avec les producteurs, les consommateurs et les topics.
Mettre en Å“uvre des pipelines de traitement de donnÃ©es en streaming avec Flink, en appliquant des transformations complexes et en gÃ©rant les Ã©tats.
Ã‰crire du code efficace et maintenable en Java / Python pour manipuler et analyser les donnÃ©es en temps rÃ©el.
Utiliser Kubernetes pour dÃ©ployer et gÃ©rer des applications conteneurisÃ©es Ã  grande Ã©chelle, en assurant la rÃ©silience et lâ€™Ã©volutivitÃ© des services.
Utiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des donnÃ©es en temps rÃ©el.
Suivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des coÃ»ts, la sÃ©curitÃ© des donnÃ©es et la disponibilitÃ© des services.
Collaborer avec lâ€™Ã©quipe de dÃ©veloppement logiciel et la gestion de projets pour assurer un flux de dÃ©veloppement fluide et une livraison efficace des fonctionnalitÃ©s.
Voir moins","Profil recherchÃ©
Formation de niveau Bac +5 en informatique, en data science, ou en statistiques.
ExpÃ©rience pratique dans le traitement en temps rÃ©el avec Kafka, Flink, et les services AWS.
MaÃ®trise de Java / python et expertise dans lâ€™Ã©criture et lâ€™optimisation du code SQL.
ExpÃ©rience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc."
Cloud Data Engineer Azure,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,02 janvier 2023,> 6 mois,> Bac +5 / Doctorat,"Descriptif du poste
Nous recrutons un(e) Cloud Data Engineer (H/F) afin de travailler pour un client, acteur majeur du secteur des transports. Vous interviendrez au sein du DÃ©partement Data Platform (environ 15 Data Engineers et DÃ©veloppeurs).
Vous travaillerez sur la totalitÃ© des phases projet :
Proposer des architectures et orienter le choix des technologies adaptÃ©es aux besoins de diffÃ©rents projets Data
Concevoir et mettre en Å“uvre les traitements dâ€™alimentation du DataLake et de transformation des donnÃ©es
Garantir la qualitÃ© des donnÃ©es en mettant en place les outils de mesure et de suivi adÃ©quats
Identifier, collecter, explorer, comprendre et intÃ©grer les donnÃ©es nÃ©cessaires Ã  la rÃ©solution de problÃ©matiques mÃ©tier et opÃ©rationnelles
Assurer le suivi de la production
Participer, avec lâ€™Ã©quipe, au dÃ©veloppement de la plateforme sur Azure et Ã  la dÃ©finition des bonnes pratiques de dÃ©veloppement
Accompagner les Ã©quipes mÃ©tier dans la prise en main de la plateforme Azure et les aider Ã  monter en compÃ©tences en programmation en sâ€™assurant du respect des standards internes
Environnement technique : Spark, Python, SQL, Microsoft Azure, DataBricks Docker, Kubernetes, Teradata
Voir moins","Profil recherchÃ©
Profil IngÃ©nieur Grande Ã‰cole
CompÃ©tences :
Python, SQL
Microsoft Azure (DataFactory, Azure DevOps, Databricks)
Bonnes connaissances sur les architectures de donnÃ©es et le cloud
Connaissance de lâ€™approche DevOps : Git, CI/CDâ€¦
Vous avez envie de participer Ã  une mission Data passionnante avec les marqueurs â€œQualitÃ© de Vie au Travailâ€ (QVT) et â€œResponsabilitÃ© SociÃ©tale et Environnementaleâ€ (RSE) au centre de notre stratÃ©gie de dÃ©veloppement (sÃ©minaires, Ã©vents fun et pro, partenariat associatif, â€¦)."
Data Engineer (F/H),"{'name': 'FINAXYS', 'sector': 'Banque, Logiciels, SaaS / Cloud Services, Big Data', 'employees': '400 collaborateurs', 'creation_year': '2008', 'turnover': '40 Mâ‚¬', 'mean_age': '32 ans'}",CDI,Puteaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 3 ans,Bac +5 / Master,,
Data Engineer - STAGE (F/H),"{'name': 'CARREFOUR', 'sector': 'Grande distribution, E-commerce, Grande consommation', 'employees': '100000 collaborateurs', 'creation_year': '1959', 'turnover': None, 'mean_age': None}","Stage
(1 mois)",Oloron-Sainte-Marie,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,15 janvier 2024,< 6 mois,Bac +4,"Descriptif du poste
Nous rejoindre, c'est rejoindre l'un des leaders mondiaux de la distribution qui met l'accent au quotidien sur la diversitÃ©, la RSE et le digital, pour satisfaire nos clients et nos collaborateurs. En tant que partenaire premium des Jeux Olympiques et Paralympiques de Paris 2024, nous partageons les valeurs du sport en permettant Ã  nos Ã©quipes de se dÃ©passer et encourageons une alimentation saine au juste prix pour tous.
Vous cherchez Ã  travailler dans une entreprise dynamique oÃ¹ votre travail rime avec impact social et environnemental ? Bienvenue chez nous !
Porteuse de cette ambition, la Direction StratÃ©gie et Transformation Groupe et France recrute un(e) :
Data Engineer (F/H)- stage
DATE DEBUT STAGE : JANVIER 2024


ğŸ¯ Vos Missions
Le stagiaire se verra confier le dÃ©veloppement du dashboard v1 afin de :
- Continuer Ã  automatiser et fiabiliser les principaux KPIs
marketing qui alimentent le tableau de bord de suivi.
- Optimiser son fonctionnement et amÃ©liorer son interface
utilisateur pour le faire Ã©voluer vers sur une v2
Il travaillera avec les diffÃ©rents pays du groupe afin de 1) rÃ©cupÃ©rer les
donnÃ©es dans un data lake central et de continuer Ã  construire et
2) d'analyser les indicateurs business, media et marketing : ventes, part
de marchÃ©, Ã©volution du poids promotionnelle et prix, investissement et
performance mÃ©dia, Ã©volution du nombre de clients, panier moyen,
frÃ©quence d'achat et segments clients prioritaires.


ActivitÃ© du poste:
- DÃ©velopper des solutions techniques de collecte de la donnÃ©e
(automatisation de la collecte des donnÃ©es)
- Travailler sur les Ã©volutions du dashboard de suivi groupe
- Collaborer avec les diffÃ©rents pays du groupe (8 pays) afin de
rÃ©cupÃ©rer les donnÃ©es et les insÃ©rer dans un data lake central et les
updater de maniÃ¨re automatique
- Analyser et interprÃ©ter les donnÃ©es rÃ©coltÃ©es
- Reporter l'activitÃ© auprÃ¨s du chef de projet
Voir moins","Profil recherchÃ©
ğŸ‘¥ Votre profil
Vous prÃ©parez un diplÃ´me d'ingÃ©nieurs
Manipulation de bases de donnÃ©es (Google cloud, et datalake de
chaque pays)
- Connaissance des langages de programmation
- Analyse et interprÃ©tation de donnÃ©es
- MaÃ®trise de l'anglais"
Un(e) assistant(e) Data Engineer/Data Scientist(e),"{'name': 'FRANCE TÃ‰LÃ‰VISIONS PUBLICITÃ‰', 'sector': 'MÃ©dia, TÃ©lÃ©vision / Production audiovisuelle, PublicitÃ©', 'employees': '300 collaborateurs', 'creation_year': '1989', 'turnover': '425Mâ‚¬', 'mean_age': '40 ans'}","Alternance
(12 Ã  24 mois)",Boulogne-Billancourt,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,04 mars 2024,,Bac +3,"Descriptif du poste
Lâ€™alternant Data Engineer joue un rÃ´le clÃ© au sein du pÃ´le de data de lâ€™entreprise.
Il est responsable de la collecte, du traitement, du stockage et de la mise Ã  disposition des donnÃ©es pour rÃ©pondre aux besoins de lâ€™entreprise en matiÃ¨re dâ€™analyse de donnÃ©es. Lâ€™alternant Data Engineer travaille en Ã©troite collaboration avec les Ã©quipes Data et dâ€™autres Ã©quipes pour garantir la qualitÃ© et lâ€™intÃ©gritÃ© des donnÃ©es
ResponsabilitÃ©s clÃ©s :
Collecte de donnÃ©es : Extraire des donnÃ©es Ã  partir de diffÃ©rentes sources, telles que des bases de donnÃ©es, des API, des fichiers CSV, etc.
Transformation des donnÃ©es : Nettoyer, normaliser et transformer les donnÃ©es brutes en un format utilisable pour lâ€™analyse.
Stockage des donnÃ©es : Concevoir et gÃ©rer des bases de donnÃ©es pour stocker efficacement les donnÃ©es, en utilisant des technologies telles que SQL, NoSQL ou des solutions de Big Data.
Automatisation des flux de donnÃ©es : Mettre en place des processus dâ€™ETL (Extract, Transform, Load) automatisÃ©s pour garantir la mise Ã  jour rÃ©guliÃ¨re des donnÃ©es.
  QualitÃ© des donnÃ©es : Mettre en place des mÃ©canismes de validation et de contrÃ´le de la qualitÃ© des donnÃ©es pour garantir leur exactitude et leur cohÃ©rence.
SÃ©curitÃ© des donnÃ©es : Assurer la sÃ©curitÃ© des donnÃ©es en mettant en place des mesures de protection et de conformitÃ© avec les rÃ©glementations en vigueur.
Documentation : Tenir Ã  jour une documentation complÃ¨te sur les flux de donnÃ©es, les schÃ©mas de bases de donnÃ©es, les procÃ©dures, etc.
Analyse de donnÃ©es : Utiliser des techniques statistiques et dâ€™apprentissage automatique pour analyser les donnÃ©es et identifier des tendances, des modÃ¨les et des relations.
ModÃ©lisation prÃ©dictive : DÃ©velopper des modÃ¨les prÃ©dictifs et des algorithmes pour rÃ©soudre des problÃ¨mes dâ€™entreprise, tels que la prÃ©vision des inventaires etc.
Ã‰valuation des modÃ¨les : Ã‰valuer la performance des modÃ¨les et ajuster les paramÃ¨tres pour amÃ©liorer leur prÃ©cision.
Voir moins","Profil recherchÃ©
Formation en informatique, en gÃ©nie logiciel, en mathÃ©matiques, en statistiques ou dans un domaine connexe.
Connaissance des langages de programmation, tels que Python, Java, ou Scala.
MaÃ®trise des technologies de base de donnÃ©es, telles que SQL, NoSQL, Hadoop, ou Spark.
ComprÃ©hension des techniques dâ€™ETL (Extract, Transform, Load) et des outils associÃ©s.
CapacitÃ© Ã  travailler avec des outils de gestion de version comme Git.
Connaissance des bonnes pratiques en matiÃ¨re de sÃ©curitÃ© des donnÃ©es.
Fortes compÃ©tences en rÃ©solution de problÃ¨mes et en communication.
CapacitÃ© Ã  travailler en Ã©quipe et Ã  apprendre rapidement.
Lâ€™alternant Data Engineer joue un rÃ´le essentiel dans la crÃ©ation de bases de donnÃ©es de qualitÃ©, essentielles Ã  la prise de dÃ©cisions basÃ©es sur les donnÃ©es au sein de lâ€™entreprise. Il contribue Ã©galement Ã  lâ€™amÃ©lioration des processus et des flux de donnÃ©es, contribuant ainsi Ã  la croissance et au succÃ¨s de lâ€™entreprise dans lâ€™Ã©conomie axÃ©e sur les donnÃ©es dâ€™aujourdâ€™hui."
Senior Data engineer F/M,"{'name': 'ACC - AUTOMOTIVE CELLS COMPANY', 'sector': 'IngÃ©nieries SpÃ©cialisÃ©es, Energie, Automobile', 'employees': '1200 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '38 ans'}",CDI,Bruges-Capbis-Mifaget,Non spÃ©cifiÃ©,TÃ©lÃ©travail total,01 avril 2024,> 5 ans,Bac +5 / Master,"Descriptif du poste
Job description

Data engineers collect, transform and store data using pipelines and storage systems. This involves extracting data from various data source systems, transforming it into the staging area, and loading it into database, data warehouse or datalake systems.
The Data Engineer ensures quantitative and qualitative access to data sources. He/she ensures availability of data and guarantees the quality of its use in-order-to facilitate its exploitation by Data analysts and Data scientists.
His/her scope of intervention is focused on application systems around data management and processing and on Big Data, IoT platforms.

MAIN MISSIONS, OBJECTIVES AND KPIS RELATED
- Analyze and organize raw data
- Build data systems and pipelines
- Evaluate business needs and objectives on data processing
- Conduct report on data pipelines and data consumption
- Prepare data for prescriptive and predictive modeling
- Combine raw information from different sources
- Explore ways to enhance data quality and reliability
- Identify opportunities for data acquisition
- Develop analytical tools and programs
- Collaborate with data scientists and architects on several projects

Voir moins","Profil recherchÃ©
EXPERIENCE
5 years of experience as a data engineer or in a similar role
Technical expertise with data models, data mining
Hands-on experience with Cloud Data Platform
Specific knowledge  : SQL database, Data bricks, Architecture mÃ©daillon, Node-red, Docker, Apache Airflow, Hive, Spark, Git
QUALIFICATIONS
Degree in Computer Science, IT, or similar field
A Masterâ€™s is a plus Data engineering certification (e.g IBM Certified Data Engineer) is a plus

KEY BEHAVIOURS
To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources.
 
Some extra skills which make the difference
Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods.
If you are detail-oriented, with excellent organizational skills and experience in this field, weâ€™d like to hear from you.
 Voir plus"
Data Engineer (H/F) | Stage,"{'name': 'DATASCIENTEST', 'sector': 'SaaS / Cloud Services, EdTech, Formation', 'employees': '130 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}","Stage
(6 mois)",Puteaux,"< 1,5K â‚¬ par mois",TÃ©lÃ©travail occasionnel,01 septembre 2023,,,"Descriptif du poste
Au sein de lâ€™Ã©quipe data-science, votre rÃ´le sâ€™articule autour des axes suivants :
Contribution active au dÃ©veloppement dâ€™un produit de formation Ã  venir. Câ€™est lâ€™occasion rÃªvÃ©e pour acquÃ©rir les compÃ©tences de demainâ€¦ avant tout le monde
Mentorat et accompagnement sur des produits existants
(Si souhaitÃ©) Participation Ã  la stratÃ©gie R&D du dÃ©partement Tech","Profil recherchÃ©
Chez Datascientest, nous valorisons la diversitÃ© des profils et sommes convaincus par la force du collectif. Cette offre dâ€™emploi est ouverte Ã  tous, quel que soit votre niveau dâ€™expÃ©rience.
Issu(e) dâ€™une formation orientÃ©e data-engineering vous Ãªtes :
Capable de gÃ©rer des charges de travail parfois Ã©levÃ©es.
Bonne maÃ®trise de Python.
La maÃ®trise de la programmation orientÃ© objet, de SQL, de technologies NoSQL et/ou du cloud computing est un plus.
La connaissance de Spark, Docker, Git, Airflow ou encore Kubernetes est apprÃ©ciÃ©e
Bonne culture informatique et attrait pour lâ€™actualitÃ© relative au data-engineering au sens large.
Bon niveau rÃ©dactionnel et oral en franÃ§ais/anglais.
PrÃªt Ã  Ã©normÃ©ment apprendre et Ã  vivre une expÃ©rience unique dans un environnement start-up.
Attrait pour la polyvalence et capacitÃ© Ã  gÃ©rer plusieurs projets de front."
Data Engineer (H/F) | CDI,"{'name': 'DATASCIENTEST', 'sector': 'SaaS / Cloud Services, EdTech, Formation', 'employees': '130 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}",CDI,Puteaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,01 septembre 2023,> 6 mois,Bac +5 / Master,"Descriptif du poste
En tant que Data Engineer, vous maÃ®trisez les technologies dâ€™acquisition, de traitement, et dâ€™extraction de donnÃ©es et avez des connaisisances scientifiques qui vous permettent de dialoguer avec des Ã©quipes Data.
Missions et activitÃ©s principales :
CrÃ©ation et dÃ©veloppement de contenus
CrÃ©ation environnement de formation et contribution au dÃ©veloppement de notre plateforme de formation
Accompagnement et mentorat sur des sujet dâ€™engineering
Participation et organisation dâ€™Ã©vÃ¨nements data
Participation Ã  la stratÃ©gie R&D du dÃ©partement Tech","Profil recherchÃ©
Chez Datascientest, nous valorisons la diversitÃ© des profils et sommes convaincus par la force du collectif. Cette offre dâ€™emploi est ouverte Ã  tous, quel que soit votre niveau dâ€™expÃ©rience.
CompÃ©tences requises :
Excellente maitrise de Python
Bonne maitrise de la programmation orientÃ© objet
La maitrise de Scala (Spark) est un +
Attrait pour lâ€™actualitÃ© relative au machine learning, lâ€™engineering et Ã  lâ€™open-source.
Bon niveau en Anglais.
La connaissance dâ€™un provider cloud est trÃ¨s apprÃ©ciÃ©e (AWS, Azure, GCP)
ETL
Bonne connaissance des diffÃ©rents SystÃ¨mes de Gestion de Bases de DonnÃ©es
Bonnes connaissances en script Bash
Attrait pour lâ€™actualitÃ© relative au machine learning
Outils de mise en production: Docker, Kubernetes, FastAPI, Airflow
Savoir faire
Voir plus"
Stage -Cloud Data Engineer Junior (H/F),"{'name': 'DATASCIENTEST', 'sector': 'SaaS / Cloud Services, EdTech, Formation', 'employees': '130 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}","Stage
(6 mois)",Puteaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,,,"Descriptif du poste
Nous proposons un stage passionnant de Cloud Data Engineer Junior spÃ©cialisÃ© dans lâ€™Ã©cosystÃ¨me Azure, dâ€™une durÃ©e de 6 mois minimum. Ce stage vous permettra de dÃ©velopper vos compÃ©tences en Data Engineering sur le cloud tout en Ã©tant intÃ©grÃ©(e) au sein dâ€™une Ã©quipe dynamique et expÃ©rimentÃ©e. En tant que stagiaire Cloud Data Engineer Junior, vous serez impliquÃ©(e) dans le dÃ©veloppement de cours de Cloud Data Engineering sur Azure, ainsi que dans lâ€™animation de travaux dirigÃ©s pour promouvoir les technologies du Data Engineer Azure.
ResponsabilitÃ©s principales :
Participer Ã  la crÃ©ation de cours et de supports de formation sur les technologies de Data Engineering sur Azure.
Animer des travaux dirigÃ©s et des sessions de formation pour les apprenants afin de promouvoir les compÃ©tences en Cloud Data Engineering.
Collaborer avec les Data Scientists et les Ã©quipes mÃ©tiers pour comprendre leurs besoins en matiÃ¨re de donnÃ©es et apporter des solutions appropriÃ©es.
Assister le dÃ©veloppement et le dÃ©ploiement de pipelines ETL/ELT performants sur Azure, selon les besoins et les opportunitÃ©s.
AcquÃ©rir une expertise sur les principaux outils de Data Engineering tels quâ€™Apache Spark, Azure Data Factory, Azure Databricks, etc.
Contribuer Ã  la mise en place de solutions de stockage et de gestion des donnÃ©es en utilisant les services cloud dâ€™Azure.
Participer Ã  lâ€™optimisation des performances et de la scalabilitÃ© des pipelines pour traiter de grands volumes de donnÃ©es en temps rÃ©el ou en batch.
Assister Ã  la mise en place de mÃ©canismes de contrÃ´le et de validation pour assurer la qualitÃ© et la fiabilitÃ© des donnÃ©es.
Voir moins","Profil recherchÃ©
Formation en informatique, gÃ©nie logiciel, gÃ©nie des donnÃ©es ou domaine connexe.
Connaissances en programmation Python pour le dÃ©veloppement de scripts et dâ€™automatisations.
IntÃ©rÃªt pour les technologies de Data Engineering et le cloud computing, en particulier sur Azure.
CuriositÃ© et volontÃ© dâ€™apprendre pour dÃ©velopper vos compÃ©tences en Data Engineering sur le cloud Azure.
Bonnes compÃ©tences en communication, en franÃ§ais et en anglais, pour travailler en Ã©quipe et Ã©changer avec des collaborateurs multilingues.
Ce stage vous offrira une expÃ©rience pratique prÃ©cieuse dans le domaine du Cloud Data Engineering sur Azure, avec des opportunitÃ©s uniques dâ€™implication dans le dÃ©veloppement de cours et de travaux dirigÃ©s. Vous serez encadrÃ©(e) par des experts du domaine, et vos contributions joueront un rÃ´le essentiel dans la rÃ©ussite des projets de formation sur les technologies du Data Engineer Azure. Vous aurez Ã©galement la possibilitÃ© de vous impliquer dans le dÃ©veloppement et le dÃ©ploiement de pipelines ETL/ELT en fonction des besoins de lâ€™Ã©quipe et des projets en cours. Votre motivation, votre implication et votre adaptabilitÃ© seront des atouts essentiels pour tirer le meilleur parti de cette opportunitÃ© de stage enrichissante."
Data Engineer,"{'name': 'EP STUDIO', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, Incubateur / AccÃ©lÃ©rateur', 'employees': '45 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '33 ans'}",CDI,Nantes,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 2 ans,,"Descriptif du poste
EP recherche un(e) Data Engineer en CDI !
Notre PÃ´le Data conÃ§oit, dÃ©veloppe et supervise une architecture transverse Ã  nos plateformes, optimisÃ©e pour la la collecte, le stockage et le traitement de donnÃ©es. Dans une dÃ©marche scientifique, des modÃ¨les sont entraÃ®nÃ©s, permettant de crÃ©er des connaissances actionnables que nous mettons Ã  disposition de nos utilisateurs et de nos Produits. Dans le cadre du dÃ©veloppement du pÃ´le, nous recherchons aujourdâ€™hui un(e) Data Engineer prÃªt(e) Ã  rejoindre EP, en CDI, Ã  Nantes.
Votre day-to-day
RattachÃ©(e) au CDO, au sein dâ€™une Ã©quipe Data Engineering, vous travaillez avec nos Data Scientists mais aussi nos DevOps et nos Product Managers, pour rÃ©aliser les missions suivantes :
ÃŠtre le rÃ©fÃ©rent technique de lâ€™architecture Data, pour toutes nos plateformes
Contribuer Ã  lâ€™animation technique, la veille technologique et lâ€™innovation de la roadmap Data Engineering.
Concevoir et dÃ©velopper des pipelines scalables de donnÃ©es, pour de lâ€™ingestion ou de la transformation.
ÃŠtre garant des schÃ©mas des bases de donnÃ©es au sein de notre architecture Produit micro-services.
Industrialiser les modÃ¨les dâ€™IA dÃ©veloppÃ©s avec les Data Scientists.
Veiller Ã  lâ€™intÃ©gritÃ© et la sÃ©curitÃ© des donnÃ©es.
Tester, recetter, rÃ©diger et transmettre de la documentation.
Voir moins","Profil recherchÃ©
Vous tel que nous vous imaginons
Vous avez Ã©voluÃ© dans un environnement Cloud, idÃ©alement Azure : Data Factory, Databricks, Functions.
Vous maÃ®trisez au moins lâ€™un des langages de programmation suivants : Python, R, Scala, Spark.
Vous savez requÃªter dans des bases SQL et NoSQL : SQL Server, PostgreSQL, MongoDB, Elastic.
Vous avez dÃ©jÃ  travaillÃ© avec lâ€™une des technologies suivantes : Airflow, Kafka, Salesforce.
Petit plus si vous avez une appÃ©tence pour les systÃ¨mes dâ€™informations gÃ©ographiques : QGIS, Geo Server
Votre profil
Vous disposez dâ€™une expÃ©rience rÃ©ussie dâ€™au moins 2 ans en tant que Data Engineer.
Vous aimez travailler en feature team agile, avec une bonne culture du dÃ©veloppement, portant attention au code, Ã  la qualitÃ© et aux tests.
Vous comprenez le cycle de vie de la donnÃ©e, de son ingestion jusquâ€™Ã  sa restitution.
Vous Ãªtes en veille technologique permanente sur le Big Data, lâ€™Open Data, la Data Science, lâ€™IA et lâ€™IoT.
Voir plus"
Data engineer/analyst (stage) H/F,"{'name': 'PADOA', 'sector': 'Logiciels, SaaS / Cloud Services, SantÃ©', 'employees': '240 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '29 ans'}","Stage
(5 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,Bac +5 / Master,"Descriptif du poste
Tu cherches Ã  donner du sens Ã  ton talent et Ã  avoir un impact positif sur le monde ?
NÃ©e en 2016, padoa câ€™est 240 collaborateurs passionnÃ©s autour dâ€™un logiciel et une offre de services conÃ§us pour moderniser les services de santÃ© au travail. Sur notre logiciel SaaS, nous gÃ©rons les dossiers mÃ©dicaux de 5,5 millions de salariÃ©s en France. Avec une nouvelle levÃ©e de fonds de 80Mâ‚¬ en 2022, nous sommes prÃªts Ã  rÃ©aliser notre mission :
Faire du monde du travail un univers de prÃ©vention afin dâ€™amÃ©liorer la santÃ© de millions de personnes !

Pour ce faire, nous proposons une solution technologique innovante :
- Une application de prÃ©-visite et des objets connectÃ©s : pour simplifier lâ€™expÃ©rience de visite avant la rencontre avec le professionnel de santÃ©.
- Une plate-forme web repensÃ©e : pour que tous les acteurs de la santÃ© au travail puissent gagner du temps et amÃ©liorer le suivi des salariÃ©s.
- Une plateforme dâ€™analyse de donnÃ©es : lâ€™ensemble des actifs franÃ§ais sont vus en visite mÃ©dicale tous les 2 Ã  5 ans ; exploiter ces donnÃ©es est une occasion formidable pour repenser la prÃ©vention et le bien-Ãªtre au travail.
Pour atteindre notre objectif, nous renforÃ§ons rÃ©guliÃ¨rement nos Ã©quipes avec les meilleurs talents. Aujourdâ€™hui, nous recherchons diffÃ©rentes compÃ©tences (stratÃ©gie, design, tech, data, mÃ©decine et vente) pour concevoir, amÃ©liorer, dÃ©velopper, promouvoir et dÃ©ployer padoa.
Tes missions
Tu rejoindras lâ€™Ã©quipe BI (Business Intelligence) de 9 personnes, composÃ©e de Data Analysts et de Data Engineers. Cette Ã©quipe travaille au quotidien sur la construction, le dÃ©ploiement et la maintenance de rapports et dâ€™analyse statistiques avancÃ©es pour permettre Ã  nos clients de bien visualiser les donnÃ©es.
En tant que membre de lâ€™Ã©quipe, tu travailleras sur lâ€™ensemble de la chaine de valeur entourant la data, de la mise en place dâ€™ETL Ã  la crÃ©ation de dashboard de visualisation de donnÃ©es.
Tu pourras Ã©galement Ãªtre amenÃ© Ã  travailler avec nos clients pour recueillir leurs besoins en reporting opÃ©rationnel et tu participeras Ã  la construction, au dÃ©ploiement et Ã  la maintenance de ce reporting.
Principales missions :
Recueillir et analyser les besoins BI (Business Intelligence) des clients.
Construire les rapports et dâ€™analyses statistiques avancÃ©s pour les clients.
Conception et amÃ©liorations fonctionnelles de lâ€™entrepÃ´t de donnÃ©es padoa suivant les besoins, en lien avec les Data Engineers de lâ€™Ã©quipe.
Qualifications clÃ©s
Ton profil :
Tu es dans une grande Ã©cole dâ€™ingÃ©nieur ou dâ€™informatique (Polytechnique, centrale, mines, ponts, ENSTA, Telecom, ENSIMAG, INSA Lyon etc.) / ou en master scientifique (de prÃ©fÃ©rence en informatique) et tu cherches un stage de fin dâ€™Ã©tudes ou une cÃ©sure de minimum 5 mois.
Tu as une bonne maÃ®trise dâ€™Excel, de lâ€™analyse de donnÃ©es et tu souhaites participer au dÃ©veloppement de lâ€™activitÃ© de nos clients grÃ¢ce aux outils statistiques.
Tu es Ã  lâ€™aise avec les langages Python, SQL et avec Git.

Pourquoi venir chez padoa ?
Pour te perfectionner Ã  fond sur la tech
Tu rejoindras une Ã©quipe extrÃªmement solide et seras encadrÃ© par des profils expÃ©rimentÃ©s
Tu travailleras sur les problÃ©matiques techniques complexes dâ€™une startup en plein scale
Tu Ã©volueras dans un Ã©cosystÃ¨me tech trÃ¨s riche avec plus de 120 dÃ©veloppeurs travaillant sur la plupart des domaines tech : devops, data engineering, dev full stack, architecture etc.
Pour apprendre le dÃ©veloppement backend, lâ€™architecture et lâ€™infrastructure :
Tu rejoindras une squad (~10 personnes) avec un excellent niveau technique, dont les dÃ©veloppeurs et les Devops se challengent et travaillent main dans la main
Tu seras ainsi exposÃ© trÃ¨s vite aux enjeux DevOps et tu pourras Ã©galement monter en compÃ©tence sur cet aspect
Pour participer Ã  un projet concret avec un vrai enjeu sociÃ©tal et voir lâ€™impact concret de la technologie sur les gens
padoa suit aujourdâ€™hui plus de 5,3 millions de salariÃ©s FranÃ§ais, des centaines de milliers dâ€™entreprises et accompagne des milliers de mÃ©decins et professionnels de santÃ© dans leur travail
Nos mises en prod quotidiennes et notre focus permanent sur la prise de retours te permettront de voir lâ€™impact de ce que tu dÃ©veloppes chaque jour
Pour nos valeurs : excellence dans le travail, bienveillance, agilitÃ© et convivialitÃ©.
Et aussi pour lâ€™ambiance de travail au quotidien ! 
Bon Ã  savoir
Carte Swile (ticket de 10â‚¬/jour pris en charge Ã  60%). Abonnement transport remboursÃ© Ã  moitiÃ© Ã©videmment ou IK vÃ©lo pour les plus sportifs avec un parking vÃ©lo au pied des bureaux. Des locaux bien desservis (place de lâ€™Ã©toile / Ternes). 2 jours de tÃ©lÃ©travail.
Des Ã©vÃ©nements dâ€™entreprise nombreux par Ã©quipe et all-staff. De nombreuses initiatives internes (green team, club de jeux de sociÃ©tÃ©, Ã©vÃ©nements sportifs et caritatifsâ€¦). Une bonne mutuelle et des petit-dejs Ã  dispo tous les jours !
Dans un souci de clartÃ©, lâ€™Ã©criture inclusive nâ€™est pas utilisÃ©e dans cette annonce. Les termes employÃ©s se rÃ©fÃ¨rent aussi bien au genre fÃ©minin que masculin.
Voir moins",
Data Engineer expÃ©rimentÃ©,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©",TÃ©lÃ©travail occasionnel,,,,,"Descriptif du poste
MP DATA, recrute un Data Engineer afin de travailler pour nos clients au cÅ“ur de lâ€™industrie franÃ§aise.
Vos missions seront les suivantes :
Proposer des architectures et orienter le choix des technologies adaptÃ©es aux besoins de diffÃ©rents projets Data,
Ã‰tablir le dÃ©veloppement de solutions dâ€™ingestion de donnÃ©es et de Data IngÃ©nierie,
Concevoir et mettre en Å“uvre les traitements et transformations des donnÃ©es,
CrÃ©ation de pipelines de donnÃ©es, traitement et transformation de la donnÃ©e,
Garantir la qualitÃ© des donnÃ©es en mettant en place les outils de mesure et de suivi adÃ©quats,
Identifier, collecter, explorer, comprendre et intÃ©grer les donnÃ©es nÃ©cessaires Ã  la rÃ©solution de problÃ©matiques mÃ©tier et opÃ©rationnelles,
Assurer le suivi de la production.","Profil recherchÃ©
De formation Bac+5 (ou plus) en dÃ©veloppement informatique / Data Engineering, vous justifiez dâ€™une expÃ©rience professionnelle significative au cours de laquelle vous avez pu dÃ©velopper les compÃ©tences techniques suivantes :
EcosystÃ¨me Big Data:
Cloudera
Hadoop
Spark
Kafka
PySpark
Bases de donnÃ©es relationnelles (SQL Serverâ€¦).
CompÃ©tences ou connaissances qui seraient un plus :
Secteur de la mÃ©tallurgie et de lâ€™environnement (Air, CO2â€¦)
Data visualisation
Talend
Maitrise de lâ€™anglais"
Data Engineer ExpÃ©rimentÃ©,"{'name': 'CASTLE BEE - DATA, CLOUD & CYBER FOUNDRY', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, CybersÃ©curitÃ©', 'employees': '25 collaborateurs', 'creation_year': '2021', 'turnover': '1Mâ‚¬', 'mean_age': '27 ans'}",CDI,"Salaire :
45K Ã  56K â‚¬","DÃ©but :
29 janvier 2024",TÃ©lÃ©travail occasionnel,,> 2 ans,Bac +5 / Master,,
Senior Data Engineer R&I - L'OrÃ©al France,"{'name': ""L'ORÃ‰AL FRANCE"", 'sector': 'Luxe, CosmÃ©tique, E-commerce', 'employees': '88000 collaborateurs', 'creation_year': '1909', 'turnover': '27,99 Mds â‚¬', 'mean_age': None}",CDI,Clichy,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 4 ans,Bac +5 / Master,"Descriptif du poste
As a Senior Data Engineer inside the R&I Beauty Tech Data Team, you will build the end-to-end data integration pipeline from input layer to exposition layer in respecting the best practices. With other members of the team, you guarantee an optimum functioning of the platform by always optimizing the existing and proposing adapted architecture design for the new needs. You will also cooperate with the experts from the Global Beauty Tech Data Team and our partners like Google, Microsoft, Databricks to leverage the most updated knowledge. 
In addition, for a concrete data product development lifecycle, you will be in contact with the delivery team to ensure the delivery roadmap, work with the mÃ©tier to understand their requirement and support the Data Analyst or Data Scientist for their data consumption. 
IF YOU WANT TO GO FURTHER IN DETAILS, THIS IS WHAT YOU COULD EXPECT TO DO 
Build the data pipeline with existing template to ingest data with the best practices (CI/CD, Code Quality, Test coverage etc.) and monitor the production environment once deployed. 
Design the data modelling and data exposition to use case with Data Architect and ensure the security of data with AmaaS (Access Management As A Service) 
Optimize in continual improvement of the architecture using serverless or managed services on top of Google Cloud Platform 
Participate in the workshops with the different stakeholders: Data Product Owner, Data Analyst, Data Scientist to promote the data usage and to leverage the value of data 
Work in an international environment and cooperate with hubs based in China, US, Brazil, Japan and India 
Pilot the project implementation with externals resources: contractor, nearshore outsourcing 
Aware of new technology innovation and realize them with the PoC project.
Voir moins","Profil recherchÃ©
First and foremost,â€¯we love people that are curious, collaborative, eager to have an impact and who value innovation, autonomy, and team spirit. 
Requirements: 
4+ years IT technical experience in Data Engineering or Software Engineering with a first experience in architecture design in Cloud environment GCP 
Experience designing data models and data warehouses and using SQL and NoSQL database management systems 
Good Experience with one general purpose programming language (e.g., Python, Java, C#, TypeScript, etc) and success in implementing applications or APIs 
Good understanding of the DevSecOPS
Ability to communicate with both technical and non-technical audiences. 
Curiosity to new technologies with good ability to learn quickly 
Good resilience to face the challenge and resolve the difficulty 
Engineerâ€™s degree (Bac+5) or equivalentâ€¯ 
Verbal and written communications skills (French and English) 
Voir plus"
Data Engineer - Madonne Core (H/F),"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards â‚¬ de PNB', 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous rejoignez l'Ã©quipe Core en charge de la maintenance Ã©volutive des applications Madonne (RÃ©colte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiÃ©e au coeur de l'IT Risque).

Au quotidien vous avez pour missions de :

Participer Ã  l'adaptation de nos applications en adÃ©quation avec les besoins mÃ©tiers (nouveaux produits, nouvelles rÃ¨glementations, nouveaux SI Front) ;
Participer activement Ã  la modernisation de nos outils, modernisation de notre chaÃ®ne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;
Monter en compÃ©tences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous dÃ©velopperez une comprÃ©hension globale des chaÃ®nes de traitements ;
Participer Ã  tous les travaux de modernisation de notre SI, et Ãªtre donc engagÃ© dans la migration de nombreux process vers le DataLake Risk.





#TransformativeFinance
Ce poste est basÃ© Ã  Paris avec la possibilitÃ© de tÃ©lÃ©travailler.
En tant que Top Employer, nous plaÃ§ons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilitÃ© interne, dÃ©veloppement de carriÃ¨re et de formation vous permettent de grandir et de vous Ã©panouir tout au long de votre parcours.
Vous Ã©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.
Vous avez Ã©galement la possibilitÃ© de vous engager en faveur de la sociÃ©tÃ© et de causes qui vous tiennent Ã  cÅ“ur via notre fondation d'entreprise.
A propos du processus de recrutement
Vous serez contactÃ© par l'un de nos recruteurs avant de rencontrer nos experts mÃ©tier (manager, membre de l'Ã©quipe ou de la filiÃ¨re mÃ©tier).
Voir moins","Profil recherchÃ©
Qui Ãªtes-vous ? Si vous vous reconnaissez dans la description suivante vous Ãªtes fait pour travailler avec nous : Vous souhaitez bÃ©nÃ©ficier d'une premiÃ¨re expÃ©rience significative en dÃ©veloppement Spark et Scala. Vous maitrisez : * Les mÃ©thodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appÃ©tence pour la manipulation de la data. Vous Ãªtes : * Reconnu par votre esprit d'Ã©quipe ; * Capable de communiquer avec des publics diffÃ©rents, notamment avec le mÃ©tier ; * Autonome et ntÃ©ressÃ© par l'environnement finance de marchÃ©. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous Ãªtes intÃ©ressÃ© en rÃ©pondant Ã  cette annonce."
Lead Data Engineer - F/H,"{'name': 'NIJI', 'sector': 'IT / Digital', 'employees': '1000 collaborateurs', 'creation_year': '2001', 'turnover': '98 millions', 'mean_age': None}",CDI,Lyon,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Nous sommes plus quâ€™un simple cabinet de conseil, qu'une agence de design et qu'une sociÃ©tÃ© de mise en Å“uvre technologique. Nous sommes le partenaire de la transformation digitale de nos clients grands-comptes et ETI, que nous accompagnons de lâ€™idÃ©e Ã  la rÃ©alitÃ©.
Nous associons, dans une mÃªme chaÃ®ne de valeur, conseil en stratÃ©gie, design de service et design Ã©motionnel, management et valorisation de la donnÃ©e, ingÃ©nierie et conseil technologique, rÃ©alisation logicielle et expertise en cybersÃ©curitÃ©.
Notre singularitÃ© repose sur les talents pluriels de nos Ã©quipes, au service de la satisfaction et de la performance de nos clients.
Le pÃ´le Data de Niji c'est avant tout une Ã©quipe Ã  taille humaine et pluridisciplinaire, composÃ©e de consultants et experts qui conseillent et appuient nos clients sur toutes les Ã©tapes du cycle des donnÃ©es :
de la collecte Ã  la valorisation dans des services innovants,
en passant par les architectures de stockage et de services.
Nos consultants sont basÃ©s en Ile-de-France et en rÃ©gions (Nantes, Rennes, Lille, Lyon et Bordeaux).
Nos 3 directeurs : experts confirmÃ©s de la gouvernance des donnÃ©es, de la data science de l'IA et des mÃ©thodologies d'industrialisation de l'IA (MLOps, DataOps), recherchent de nouveaux talents tous complÃ©mentaires avec plusieurs niveaux de qualification et sÃ©nioritÃ©, qui travailleront en synergie avec la large palette de compÃ©tences de Niji en dÃ©veloppement, communication, cybersÃ©curitÃ© et en conseil.
IntÃ©grer le PÃ´le Data de Niji c'est avoir l'assurance d'Ãªtre accompagnÃ© dans sa progression et le dÃ©veloppement rapide de ses compÃ©tences ,vous suivez un parcours de formation riche et diversifiÃ©, visant Ã  vous faire rapidement monter en expertise et Ã  vous certifier. 
En tant que Data Engineer, vos principales missions seront les suivantes :
Concevoir, dÃ©velopper et maintenir une architecture de donnÃ©es robuste, Ã©volutive et sÃ©curisÃ©e, en tenant compte des besoins spÃ©cifiques des clients.
Participer activement Ã  la rÃ©daction de propositions commerciales, en contribuant aux aspects techniques (outils, make or buy â€¦) et en fournissant des estimations de projet.
GÃ©rer et optimiser les pipelines de donnÃ©es, en assurant la collecte, le stockage, le traitement et la mise Ã  disposition des donnÃ©es de maniÃ¨re fiable et performante.
Assurer la qualitÃ© des donnÃ©es en mettant en place des contrÃ´les de qualitÃ©, des tests et des processus de validation, conformÃ©ment aux exigences des clients.
Encadrer les projets de bout en bout, en veillant Ã  ce qu'ils soient livrÃ©s Ã  temps, dans les limites du budget afin dâ€™assurer la satisfaction des clients.
Assurer la documentation technique, les bonnes pratiques et les standards de dÃ©veloppement au sein de l'Ã©quipe.

 Profil recherchÃ©
Si vous :
Avez obtenu un diplÃ´me en universitÃ©, Ã©cole de commerce ou Ã©quivalent type bac +5
MaÃ®trisez l'anglais Ã  l'Ã©crit comme Ã  l'oral
Avez de solides connaissances en architecture et en modÃ©lisation des donnÃ©es
MaÃ®trisez des technologies et des outils liÃ©s au Big Data (Hadoop, Spark, Hive, etc.)
MaÃ®trisez les outils dâ€™industrialisation des pipelines data tel que docker, kubernetes, Dataiku, Jenkinsâ€¦
Avez une expÃ©rience avec les langages de programmation utilisÃ©s dans le domaine des donnÃ©es, tels que : Python,R, Scala, SQL, etc.
Avez une expÃ©rience dans la conception et la mise en Å“uvre de pipelines de donnÃ©es
Avez des compÃ©tences en gestion d'Ã©quipe et en leadership technique
Avez des capacitÃ©s Ã  rÃ©diger des propositions commerciales convaincantes
Alorsâ€¦ Venez participer au dynamisme de notre site en rejoignant notre Team Data Lyonnaise !

L'aventure Niji :
Process de recrutement : premier contact RH puis rencontre avec nos opÃ©rationnels.
Rejoindre l'expÃ©rience Niji c'est avoir l'assurance de participer Ã  une aventure humaine dans un environnement de travail motivant, challengeant et innovant.
NijiU: notre plateforme de formation digital learning contenant prÃ¨s de 3 000 modules en accÃ¨s libre.
Nos valeurs : Audace - Bienveillance - Performance â€“ Talent. 
Si ces mots vous parlent, venez faire la diffÃ©rence chez Niji !
En rejoignant Niji, vous intÃ©grez une entreprise dont la politique RSE contribue Ã  la promotion de la diversitÃ© et de lâ€™Ã©galitÃ© des chances, notamment pour les personnes en situation de handicap.
Voir moins",
Azure Data Engineer (H/F),"{'name': 'DECILIA', 'sector': 'IT / Digital', 'employees': '40 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",CDI,Rouen,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,01 aoÃ»t 2023,> 3 ans,Bac +5 / Master,"Descriptif du poste
Poste : Azure Data Engineer (H/F)Type de contrat : CDI Ã  plein tempsLieu : NormandieNiveau dâ€™expÃ©rience : confirmÃ© (Minimum 3 ans)Salaire : selon profil
DÃ©cilia est une ESN Gold Partner Microsoft. SpÃ©cialiste de la data depuis 14 ans, nous accompagnons nos clients dans la rÃ©alisation de projets complexes et innovants. Dans le cadre de la croissance de nos activitÃ©s, nous recrutons 2 Azure Data Engineer.
En tant que Azure Data Engineer, vous serez amenÃ©(e) pour le compte de nos clients Ã  :
DÃ©velopper et optimiser des pipelines de donnÃ©es (ETL, ELT) : DataFactory, Datalake/Databricks, Synapse Analytics, Azure Blob Storage / Azure BUS Service, Azure Functions,
Assurer le recueil du besoin client
Participer Ã  la conception de Datalake,
Travailler en Ã©troite collaboration avec lâ€™Ã©quipe architectes,
Industrialiser des modÃ¨les de Machine Learning issus de notre entitÃ© DÃ©cilia Science
Utiliser au quotidien la mÃ©thodologie SCRUM et DEVOPS
Pourquoi nous rejoindre ?
DÃ©cilia favorise la consolidation des connaissances de ses consultants par la formation et la multiplication des certifications ;
Devenez rÃ©fÃ©rent dâ€™une brique technologique, et Ã  terme, animez une de nos squads !
Vous serez accompagnÃ© personnellement par un coach et boosterez vos compÃ©tences relationnelles ;
Un grand nombre de vos missions seront en tÃ©lÃ©travail ;
BÃ©nÃ©ficiez dâ€™un cadre de travail stimulant et bienveillant :
2 agences idÃ©alement situÃ©es Ã  Boulogne-Billancourt (Les Passages) et Ã  Rouen Centre (Palais de Justice)
Plusieurs Ã©vÃ©nements internes organisÃ©s : sÃ©minaires, tech lunch, afterworks, team building,â€¦
Et intÃ©grez une entreprise certifiÃ©e Â« Happy at Work Â» depuis 4 ans !
Environnement technique :
Cloudâ€¯: Microsoft Azure (ADF, Azure Datalake Store, Azure Storage Queue, SQL DB Azure, Synapse Analytics, Azure Machine Learning)
Langages: Python, Scala, SQL, C#
Big Dataâ€¯: Spark, Databricks
Voir moins","Profil recherchÃ©
Niveau dâ€™expÃ©rience : confirmÃ© (3ans dâ€™expÃ©rience minimum)"
Azure Data Engineer (H/F),"{'name': 'DECILIA', 'sector': 'IT / Digital', 'employees': '40 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",CDI,Boulogne-Billancourt,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Dans le cadre de la croissance de nos activitÃ©s, nous recrutons un(e) Azure Data Engineer.
En tant que Azure Data Engineer, vous serez amenÃ©(e) pour le compte de nos clients Ã  :
ğŸ”¹ DÃ©velopper et optimiser des pipelines de donnÃ©es (ETL, ELT) : DataFactory, Datalake/Databricks, Synapse Analytics, Azure Blob Storage / Azure BUS Service, Azure Functions,
ğŸ”¹ Assurer le recueil du besoin client
ğŸ”¹ Participer Ã  la conception de Datalake,
ğŸ”¹ Travailler en Ã©troite collaboration avec lâ€™Ã©quipe architectes,
ğŸ”¹ Industrialiser des modÃ¨les de Machine Learning issus de notre entitÃ© DÃ©cilia Science
ğŸ”¹ Utiliser au quotidien la mÃ©thodologie SCRUM et DEVOPS
ğŸ¯ Pourquoi nous rejoindre ? ğŸ¯
DÃ©cilia favorise la consolidation des connaissances de ses consultants par la formation et la m rtifications ;
Devenez rÃ©fÃ©rent dâ€™une brique technologique, et Ã  terme, animez une de nos squads !
Vous serez accompagnÃ© personnellement par un coach et boosterez vos compÃ©tences relationnelles ;
Un grand nombre de vos missions seront en tÃ©lÃ©travail ;
BÃ©nÃ©ficiez dâ€™un cadre de travail stimulant et bienveillant :
ğŸ”¹2 agences idÃ©alement situÃ©es Ã  Boulogne-Billancourt (Les Passages) et Ã  Rouen (ThÃ©Ã¢tre des arts)
ğŸ”¹Plusieurs Ã©vÃ©nements internes organisÃ©s : sÃ©minaires, tech lunch, afterworks, team building,â€¦
Et intÃ©grez une entreprise certifiÃ©e Â« Happy at Work Â» depuis 4 ans !
Voir moins","Profil recherchÃ©
Environnement technique :
ğŸ”¹Cloudâ€¯: Microsoft Azure (ADF, Azure Datalake Store, Azure Storage Queue, SQL DB Azure, Synapse Analytics, Azure Machine Learning)
ğŸ”¹Langages: Python, Scala, SQL, C#
ğŸ”¹Big Dataâ€¯: Spark, Databricks
Si vous aimez les challenges, lâ€™esprit dâ€™Ã©quipe, la bonne humeur, rejoignez une sociÃ©tÃ© Ã  taille humaine en postulant dÃ¨s maintenant !! ğŸš€"
DATA ENGINEER (F/H),"{'name': 'RS2I', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '160 collaborateurs', 'creation_year': '1992', 'turnover': '23 millions â‚¬', 'mean_age': '33 ans'}",CDI,Levallois-Perret,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Nous recrutons un Consultant Data / Data Engineer qui Ã©voluera au sein dâ€™un environnement Data & Analytics, dâ€™une culture DevOps et des contextes fonctionnant en mode Agile.
En tant que Consultant Data, vous intervenez sur des problÃ©matiques mÃ©tiers autour de la gestion des donnÃ©es. En collaboration avec les architectes data, les data analysts, les teams DevSecOps, infra et cloud, vous serez amenÃ© Ã  mettre en place des solutions et des plateformes data (datahub, datalake, streaming platform, event-driven pipeline, â€¦), dÃ©velopper, dÃ©ployer et maintenir des chaines de transformations data.
La rÃ¨gle dâ€™or : collecte et intÃ©gration, stockage, traitement et stockage, mise Ã  disposition pour analyse et reporting.
Vous maitrisez java, python et/ou scala et avez une expÃ©rience significative sur un projet data. VÃ©ritable adepte des pratiques devops et cloud, la maitrise de kafka serait un atout.","Profil recherchÃ©
BAC+5 de type Ecole dâ€™IngÃ©nieur ou Universitaire,
De nature curieuse avec une soif dâ€™apprendre,
CapacitÃ© Ã  sâ€™adapter et Ã  travailler en Ã©quipe,
Bonne aisance technique et relationnelle,
Etre force de proposition de solutions techniquement innovantes et fiables."
Consultant.e Data Engineer ExpÃ©rimentÃ©.e,"{'name': 'THE INFORMATION LAB', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '38 collaborateurs', 'creation_year': '2015', 'turnover': '5Mâ‚¬', 'mean_age': None}",CDI,Paris,45K Ã  60K â‚¬,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
Qui sommes-nous ?
VÃ©ritables passionnÃ©s de data, nous avons construit The Information Lab autour des solutions Tableau, Alteryx et Snowflake. Nous sommes convaincus que ce sont les meilleures technologies pour accomplir la transformation digitale de nos clients.
Notre spÃ©cialisation nous permet dâ€™Ãªtre les premiers partenaires de ces Ã©diteurs et dâ€™Ãªtre les experts reconnus de ces solutions en France et en Europe.
En nous rejoignant vous pourrez partager votre passion avec vos pairs, travailler dans une ambiance dÃ©contractÃ©e pour remplir notre mission : ""Helping people make sense of dataâ€.
Description du poste
RattachÃ©(e) au pÃ´le Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous mÃ©tiers. Vos missions ont pour objet le traitement, lâ€™analyse, lâ€™enrichissement des donnÃ©es de nos clients et lâ€™adoption par nos clients des technologies que nous proposons. Au sein dâ€™une Ã©quipe de 5 Ã  8 personnes, vous rÃ©alisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre â€œpod leaderâ€ (chef dâ€™Ã©quipe).
Votre rÃ´le consiste Ã  :
Intervenir en avant-vente et cadrer vos missions
Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours Ã  quelques mois
Mener des projets de bout en bout, en mÃ©thode classique ou agile, en coordination avec les Ã©quipes de nos clients, nos Ã©quipes internes et les Ã©diteurs partenaires
PrÃ©senter les livrables de vos missions et mettre en avant leur ROI
Former nos clients Ã  nos technologies
Mettre vos compÃ©tences au service de vos collÃ¨gues au-delÃ  des missions dont vous avez la charge et participer au dÃ©veloppement des compÃ©tences en partageant vos retours dâ€™expÃ©rience
Participer aux activitÃ©s dâ€™Ã©vangÃ©lisation, par exemple : rÃ©daction de posts de blogs, participation aux communautÃ©s des Ã©diteurs, interventions lors dâ€™Ã©vÃ©nements (salons, confÃ©rences, webinaires)
Participer aux projets internes (BI interne, mÃ©thodes & qualitÃ©s)
Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires.
Vos principales qualitÃ©s :
Excellentes facultÃ©s dâ€™Ã©coute et de communication, orale et Ã©crite
Aptitude Ã  travailler sur plusieurs sujets en parallÃ¨le, Ã  prioriser
HumilitÃ© et capacitÃ© Ã  apprendre ainsi quâ€™Ã  transmettre ses connaissances
Sens du service, un bon relationnel avec les clients et la rigueur nÃ©cessaire au succÃ¨s de leurs projets
Team player
CompÃ©tences mÃ©thodologiques :
Analyse du besoin et cadrage de mission
Construction dâ€™indicateurs mÃ©tiers Ã  partir de donnÃ©es brutes
IdÃ©alement connaissance dâ€™un ou plusieurs mÃ©tiers et de leurs indicateurs clÃ©s
PrÃ©paration de donnÃ©es complexes Ã  des fins dâ€™analyse
MÃ©thodes de gestion de projet (classique et agile)
CapacitÃ© prouvÃ©e Ã  rÃ©aliser des dÃ©monstrations dâ€™outils
CompÃ©tences techniques :
Connaissance dâ€™au moins Alteryx Designer ou Tableau Prep (idÃ©alement vous avez dÃ©jÃ  une expÃ©rience solide sur ces outils)
MaÃ®trise dâ€™autres outils dâ€™analyse de donnÃ©es
Connaissance de la modÃ©lisation de donnÃ©es Ã  des fins dâ€™analyse
ExpÃ©rience professionnelle : vous bÃ©nÃ©ficiez dâ€™au moins 5 ans dâ€™expÃ©rience professionnelle, dont 3 ans sur un poste similaire ou dans un poste qui vous aura permis dâ€™utiliser les technologies similaires aux nÃ´tres. IdÃ©alement, vous avez dÃ©jÃ  une expÃ©rience dans un cabinet de conseil ou une ESN.
Langues : FranÃ§ais, Anglais professionnel
Quoi dâ€™autre ?
Situation gÃ©ographique : Ile-de-France. DÃ©placements en France Ã  prÃ©voir.
RÃ©munÃ©ration : 45 Ã  60 kâ‚¬, selon expÃ©rience.
Voir moins",
Alternance (Bac +5) - Data Engineer (F/H/X),"{'name': 'IADVIZE', 'sector': 'IT / Digital, Ã‰conomie collaborative, E-commerce', 'employees': '220 collaborateurs', 'creation_year': '2010', 'turnover': None, 'mean_age': '33 ans'}",Alternance,Nantes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 6 mois,,"Descriptif du poste
Vous rejoindrez l'Ã©quipe Data (4 personnes) au sein du dÃ©partement Product & Engineering. Vous serez sous la responsabilitÃ© du Senior Data Engineer et l'aiderez Ã  concevoir, construire, amÃ©liorer et maintenir la stack Data.
Vous aurez l'opportunitÃ© de participer Ã  une gamme Ã©tendue de tÃ¢ches, allant de la surveillance de l'infrastructure de donnÃ©es Ã  la mise en Å“uvre de changements critiques, ainsi que de la collecte de donnÃ©es pour rÃ©pondre aux dÃ©fis business.
Votre travail implique des actions Ã  plus long terme ainsi que des interventions opÃ©rationnelles quotidiennes, vous offrant ainsi une expÃ©rience rÃ©aliste du rÃ´le de Data Engineer.
Vous collaborez avec des Data Scientists et des Analystes, ainsi qu'avec l'Ã©quipe Engineering Platform et Ã©ventuellement avec des parties prenantes commerciales.
Vous acquerrez de l'expÃ©rience dans un environnement technique riche, notamment sur Google Big Query, Apache Airflow, Amazon Athena, Elasticsearch, Tableauâ€¦
Vos missions :
Surveiller l'exÃ©cution des pipelines de donnÃ©es.
Participer Ã  la migration des processus ETL.
ImplÃ©menter des Ã©volutions dans la stack d'ingÃ©nierie des donnÃ©es (par exemple, automatisations, systÃ¨mes d'alerte, traÃ§abilitÃ©, documentation).
Contribuer Ã  la mise Ã  jour ou Ã  la configuration de nouveaux pipelines de collecte.
Effectuer des extractions ad hoc et/ou des corrections BI pour rÃ©pondre aux besoins urgents de l'entreprise.
Voir moins","Profil recherchÃ©
Profil recherchÃ©
En derniÃ¨re annÃ©e d'Ã©tudes (Bac +5), vous recherchez pour 2024/2025 un terrain propice pour vous forger une expÃ©rience valorisante.
Vous disposez dâ€™au moins une premiÃ¨re expÃ©rience en programmation, de compÃ©tences en manipulation de donnÃ©es ainsi que de connaissances de base des environnements cloud. Enfin, vous Ãªtes Ã  l'aise avec la gestion de plusieurs tÃ¢ches et des dÃ©lais.
 CompÃ©tences techniques
Bonne connaissance de Python (usage gÃ©nÃ©ral, avec un accent sur la manipulation de structures de donnÃ©es).
Bonne connaissance de SQL.
FamiliaritÃ© avec les environnements Linux et la ligne de commande (CLI).
ComprÃ©hension des processus et de l'orchestration ELT/ETL.
Bonus 1 : ExpÃ©rience avec au moins un fournisseur de Cloud majeur (AWS, GCP, Azure, â€¦).
Bonus 2 : Connaissance d'Airflow, Docker, Terraform, Big Query.
Voir plus"
Margo Analytics - Data Engineer - H/F,"{'name': 'MARGO', 'sector': 'Logiciels, IT / Digital', 'employees': '400 collaborateurs', 'creation_year': '2005', 'turnover': '43M', 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
Margo Analytics est l'entitÃ© experte de Margo Group des problÃ©matiques Data, Cloud et DevOps crÃ©Ã©e en 2020 par leurs fondateurs RaphaÃ«l et Mounir. Aujourdâ€™hui 60 consultants ont intÃ©grÃ© l'entitÃ© et nous avons commencÃ© Ã  travailler avec 18 nouveaux clients (Banque, Industrie, Assurance, Ã‰nergie, E commerce, SantÃ©). A leurs cÃ´tÃ©s, vous pourrez Ã©voluer rapidement et dÃ©velopper de nouvelles compÃ©tences. 
Deux ADN fondateurs forts et spÃ©cifiques Ã  Margo Analytics Ã  lâ€™origine de lâ€™entitÃ© :
- Toujours se positionner sur les plus beaux sujets et sur les missions Ã  fortes valeurs ajoutÃ©es
- Recruter des consultants passionnÃ©s et curieux qui cherchent Ã  Ãªtre challengÃ©s
Aujourdâ€™hui, Margo Analytics possÃ¨de 4 communautÃ©s de compÃ©tences : 
- Data engineer 
- Data Science/ IA 
- Galaxy OPS (devOps, dataOps, cloudOps)
- Architecte Big Data 
Ainsi en rejoignant Margo Analytics vous aurez le choix des missions (#consultantfirst) sur lesquelles vous souhaitez travailler. Vous serez accompagnÃ© par les deux fondateurs ainsi que par le leader de votre communautÃ©, dont les rÃ´les sont de rechercher le projet qui correspondra le plus Ã  vos attentes et de vous accompagner dans votre carriÃ¨re.
ğŸ¯Les missions Margo Analytics : 
Au sein de la communautÃ© Data Engineer vos missions seront : 
- DÃ©velopper en mode agile les cas dâ€™usages mÃ©tier 
- Mettre en place des processus de collecte, dâ€™organisation, de stockage et de modÃ©lisation des donnÃ©es 
- DÃ©velopper des traitements de transformation et de production de donnÃ©es
- Assurer la mise en production des modÃ¨les de prÃ©diction crÃ©Ã©s par les Data Scientists
- Participer Ã  lâ€™amÃ©lioration continue et au refactoring de code
Besoin de projection ? Voici un exemple de mission : 
Camille accompagne un grand compte dans le domaine de lâ€™industrie sur son projet de mise en place dâ€™un nouveau datalake en Azure databricks. Lâ€™objectif de cette mission est dâ€™assurer la distribution de la donnÃ©e de maniÃ¨re optimisÃ©e pour crÃ©er une couche de distribution et permettre aux Data Scientists dâ€™implÃ©menter les use cases. Camille apporte son expertise sur les technologies suivantes : Spark, Scala, Azure, Databricks.
Nos stack Technique : 
- Langage : Python/Scala/Java
- Framework : Spark/Hadoop
- Cloud: Azure/ AWS/ GCP 
ğŸ™Œ Les avantages : 
- Tickets restaurants Swile
- Mutuelle Alan prise en charge Ã  100%
- Pass Navigo pris en charge Ã  100%
- TÃ©lÃ©travail
- Formations illimitÃ©es
- Locaux en plein coeur de Paris
- Places en crÃ¨ches
ğŸ¤Notre processus de recrutement : 
Notre processus de recrutement se fait en 3 Ã©tapes, rÃ©parties sur 7 Ã  15 jours maximum :
- PremiÃ¨re rencontre ! Vous Ã©changez avec un RH et un dirigeant sur votre parcours, vos aspirations professionnelles ainsi que sur Margo Analytics et les opportunitÃ©s que nous proposons
- Challengez-vous dans le cadre dâ€™un entretien technique avec lâ€™un de nos experts. Câ€™est Ã©galement lâ€™occasion pour vous dâ€™avoir son retour dâ€™expÃ©rience
- Dernier entretien de motivation : pour finir, vous rencontrez un membre du board de Margo Analytics pour un entretien final
ğŸ” Vous Ãªtes un(e) futur(e) Margo Analytics si : 
Must-Have
Vous Ãªtes issu(e) dâ€™une Ã©cole dâ€™ingÃ©nieur ou dâ€™un cursus universitaire Ã©quivalent niveau Bac + 5 / Master
Vous aimez coder et vous Ãªtes passionnÃ©(e) dâ€™informatique et de Data
Vous Ãªtes curieux(se) et vous vous intÃ©ressez aux derniÃ¨res technologies du marchÃ©
Vous justifiez dâ€™une premiÃ¨re expÃ©rience en tant que Data Engineer
Nice to Have
Vous Ãªtes ambitieux(se) et nâ€™avez pas peur de travailler sur des projets challengeants dans des environnements Ã  fortes contraintes techniques . Vous parlez et comprenez lâ€™anglais. 
Voir moins",
Data Engineer Junior H/F,"{'name': 'MEILLEURTAUX', 'sector': 'FinTech / InsurTech, Immobilier commercial, Immobilier particulier', 'employees': '2000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Vous souhaitez rejoindre la fintech leader en crÃ©dit et en assurance, en forte croissance, innovante, dynamique et dÃ©bordante de projets ? Ce qui suit va vous intÃ©resser !
Nous sommes engagÃ©s dans le dÃ©veloppement de la plateforme Data du Groupe incluant notamment des problÃ©matiques mÃ©tiers clefs telles que la Customer Data Platform.â€¯ 
Cette plateforme de donnÃ©es est au cÅ“ur de la stratÃ©gie de croissance de lâ€™entreprise et va nous permettre de : 
- Augmenter la Customer Lifetime Value (CLTV) de nos clients, 
- D'intÃ©grer dans tous nos produits des composants IA innovants,â€¯ 
- RÃ©duire nos coÃ»ts dâ€™acquisition, 
- Faciliter le pilotage du business Ã  travers une optimisation de nos outils de BI. 
Au sein de lâ€™Ã©quipe Data, vous vous Ã©panouirez dans notre environnement en Ã©volution rapide, oÃ¹ l'adaptabilitÃ© est essentielle. Au-delÃ  de la rÃ©solution de dÃ©fis techniques, nous souhaitons que vous contribuiez activement Ã  la construction de la culture d'ingÃ©nierie de Meilleurtaux, Ã  l'amÃ©lioration des pratiques et Ã  la promotion d'un environnement collaboratif et innovant. Lâ€™Ã©quipe est en pleine construction donc nous nâ€™attendons plus que vous pour participer Ã  cette belle aventure. 
Vos missions ğŸ“
CrÃ©er et maintenir une infrastructure de donnÃ©es de pointe en permettant aux utilisateurs finaux d'accÃ©der Ã  de la donnÃ©e prÃ©cise et de qualitÃ© ; 
DÃ©velopper de nouveaux modÃ¨les de donnÃ©es et des pipelines ; 
Ils auront pour objectif de prendre en charge une grande variÃ©tÃ© de cas d'utilisation (de l'analyse et du reporting Ã  l'apprentissage automatique et Ã  l'innovation de produits) ; 
Explorer en permanence de nouvelles technologies de donnÃ©es ; 
Tester les solutions les plus innovantes et prometteuses du marchÃ© en vue de pouvoir amÃ©liorer nos capacitÃ©s en matiÃ¨re de donnÃ©es.
Notre stack technique  
DÃ©veloppementâ€¯: Python, java, Salesforce.
CI-CDâ€¯:â€¯ Git, Docker.
Infrastructure cloudâ€¯: GCP et Azure. 
Bases de donnÃ©esâ€¯: Google BigQuery, SQL Server.
BIâ€¯: Qlik Sense. 
Ce poste nÃ©cessite d'interagir avec de nombreuses Ã©quipes au sein de Meilleurtaux que ce soit sur le plan technique (Ã©quipes IT, Data Scientist et BI) et/ou fonctionnel (Product Managers). 
Ceci nâ€™est quâ€™un avant-goÃ»t de la superbe aventure que vous vous apprÃªtez Ã  rejoindre, le poste Ã©tant Ã©videmment amenÃ© Ã  Ã©voluer en fonction de vous et vos propositions.
Voir moins","Profil recherchÃ©
Pourquoi Ãªtes-vous notre TOP candidat ? ğŸ§
Une premiÃ¨re expÃ©rience rÃ©ussie sur des sujets Data, idÃ©alement de 2 ans.  
Vous savez modÃ©liser la donnÃ©e et monitorer sa qualitÃ©. 
Bien entendu, il est important que vous ayez de trÃ¨s bonnes bases dans les compÃ©tences techniques nÃ©cessaires pour une plateforme data, que ce soit en Python, SQL ou les technologies du Cloud. 
Vous avez dÃ©jÃ  utilisÃ© des plateformes data. 
Vous vous tenez au fait des derniÃ¨res actualitÃ©s et suivez les communautÃ©s data. 
Le must : vous avez dÃ©jÃ  des connaissances sur l'industrie Fintech / Assurtech ou secteur Ã©quivalent.â€¯ 
Les soft-skills attendus pour rÃ©ussir chez Meilleurtaux ? 
De la curiositÃ© et de l'apprentissage continu : dans un domaine en constante Ã©volution, nous recherchons une personne connectÃ©e aux nouvelles technologies et aux derniÃ¨res innovations. 
Lâ€™esprit dâ€™Ã©quipe : travailler chez Meilleurtaux câ€™est pratiquer un sport dâ€™Ã©quipe, chacun collabore avec ses collÃ¨gues pour aller jusquâ€™Ã  une victoire collective. 
Voir plus"
Data Engineer,"{'name': 'ADVANCED SCHEMA', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '220 collaborateurs', 'creation_year': '2001', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 1 an,Bac +3,,
Data Engineer - Banque Data Factory - Nantes,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Nantes,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Votre environnement de travail :
La division Â« Services Financiers Â» sâ€™est dÃ©veloppÃ©e autour des mÃ©tiers de la banque de dÃ©tail, de la banque privÃ©e et des services financiers spÃ©cialisÃ©s. Nous participons Ã  la rÃ©volution digitale grÃ¢ce Ã  notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compÃ©tences dans les domaines fonctionnels des CrÃ©dits, des Risques/ConformitÃ© et des Moyens de Paiement.
Si vous Ãªtes passionnÃ©(e) par la valorisation de la donnÃ©e, rejoignez notre Data Factory localisÃ©e Ã  Nantes et les quelques 100 Data IngÃ©nieurs qui la composent. Vous y rencontrerez des experts de la mise en Å“uvre de Plateforme de DonnÃ©es, des Data Architectes ou autres experts solution autour des problÃ©matiques de valorisation de la donnÃ©e.
Vous Ãªtes accompagnÃ©(e) au dÃ©veloppement de vos connaissances aux travers de diffÃ©rents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnÃ©e, la modÃ©lisation et mise Ã  disposition.
Rejoindre la Data Factory Sopra Steria, c'est rejoindre une communautÃ© de Data IngÃ©nieurs fiers de partager leur savoir et ouverts aux nouvelles expÃ©riences et expÃ©rimentations de la donnÃ©e.
Votre rÃ´le et vos missions :
Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expÃ©rience et votre appÃ©tence pour l'un de nos chapitres Data ci-dessous, vous participez Ã  :
La comprÃ©hension des besoins mÃ©tiers et la traduction solution de data ingÃ©nierie et ou data analysis ;
La mise en Å“uvre de solution d'ingestion des donnÃ©es quelles soit en batch et/ou en streaming dans un contexte Cloud ;
La structuration du DataLake, la mise en place des processus de gouvernance et de sÃ©curisation des donnÃ©es ;
Le traitement de la donnÃ©e jusqu'Ã  l'exposition au mÃ©tier ;
La mise en place de la chaine CI/CD et de sa supervision ;
La veille technologie avec nos partenaires Ã©diteurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idÃ©ation pour nos clients.
Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, R
Informations supplÃ©mentaires
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions. 
Un package avantages intÃ©ressant : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor.
Des opportunitÃ©s de carriÃ¨res multiples : plus de 30 familles de mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â».
L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encoreâ€¦).
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
> 
Voir moins","Profil recherchÃ©
Votre profil :
DiplÃ´mÃ©(e) d'une Ecole d'ingÃ©nieur ou formation Ã©quivalente, vous avez dÃ©jÃ  participÃ© Ã  un projet Data (Big Data, BI) et vous avez une expÃ©rience de minimum 2 ans.
Vous accordez une importance particuliÃ¨re au dÃ©veloppement de vos compÃ©tences sur plusieurs technologies. Vous souhaitez une Ã©volution rÃ©elle de carriÃ¨re Ã  travers l'expÃ©rience projet. Vous Ãªtes soucieux de l'apport de valeur pour vos clients. Et vous voulez transmettre votre savoir auprÃ¨s de collaborateurs moins expÃ©rimentÃ©s. Alors, n'attendez-plus, ce poste est fait pour vous !"
Data Engineer Talend F/H,"{'name': 'ORANGE', 'sector': 'Objets connectÃ©s, Big Data, Electronique / TÃ©lÃ©communications', 'employees': '136000 collaborateurs', 'creation_year': '1994', 'turnover': '43,5 milliards â‚¬', 'mean_age': '44 ans'}",CDI,Villeneuve-d'Ascq,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Afin de dÃ©velopper notre Ã©quipe lilloise, nous recherchons aujourdâ€™hui, un IngÃ©nieur DATA Ã  mÃªme dâ€™accompagner nos clients dans la structuration de leurs SI autour de la donnÃ©e.

Vos principales missions seront les suivantes :

- Concevoir des solutions de traitement et collecter des volumes importants de donnÃ©es.
- Participer Ã  des Ã©tudes de cadrage pour collecter le besoin mÃ©tier et concevoir les solutions qui rÃ©pondent au besoin du client.
- Apporter son expertise sur des problÃ©matiques prÃ©cises rencontrÃ©es chez les clients.
- Participer Ã  la veille techno
- Rester informer et former sur les nouvelles solutions DATA
- Contribuer aux phases dâ€™avant-vente et au dÃ©veloppement business.
- Participer Ã  la conception, lâ€™Ã©volution et la prÃ©sentation de nos offres DATA.","Profil recherchÃ©
Vous :
- ÃŠtes issu(e) de formation bac+5
- Vous justifiez dâ€™au moins 4 ans dâ€™expÃ©riences en qualitÃ© dâ€™IngÃ©nieur DATA sur la solution TALEND Enterprise (Data Integration) et avez idÃ©alement une connaissance des solutions Cloud dâ€™AWS et dâ€™AZURE
- Vous Ãªtes intervenus sur des projets intÃ©grant des pratiques DevOps et AGILE
Alors postulez, ce poste est fait pour vous !
 
Vos compÃ©tences clÃ©s :
- Expertise sur lâ€™outil ETL TALEND Enterprise (administration et dÃ©veloppement)
- Fortes connaissances des solutions de bases de donnÃ©es (SQL, NoSQLâ€¦)
- Connaissances en langages objets ou scripts (notamment Java mais aussi Javascript, Scala, Pythonâ€¦)
- Divers systÃ¨mes dâ€™exploitation : UNIX, Windows
 
Autonomie, rigueur, curiositÃ©, dynamisme et sens du service sont des qualitÃ©s nÃ©cessaires pour ce poste.
 
Les compÃ©tences complÃ©mentaires qui seraient apprÃ©ciÃ©es :

- Connaissances dâ€™autres modules Talend (MDM, ESB, Data Quality, Cloudâ€¦)
- MaÃ®trise des technologies du Big Data (Hadoop, Spark, Kafkaâ€¦)
- Expertise sur dâ€™autres outils ETL (Informatica, SSIS, DataStageâ€¦)
- Notions en architecture des SystÃ¨mes dâ€™Information
- MaÃ®trise de lâ€™anglais (oral et Ã©crit)
Voir plus"
Data Engineer (H/F),"{'name': 'MELTONE ADVISORY', 'sector': 'Logiciels, IT / Digital, Transformation', 'employees': '150 collaborateurs', 'creation_year': '2014', 'turnover': '17Mâ‚¬', 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
Chez MeltOne Advisory, il nâ€™y a pas les fonctions mÃ©tiers dâ€™un cÃ´tÃ© et la technologie de lâ€™autre. Tous les consultants sont polyvalents et ont un parcours qui leur confÃ¨re une expertise indÃ©niable Ã  la fois sur vos problÃ©matiques mÃ©tiers mais aussi sur la dimension IT.
Tu interviendras en collaboration Ã©troite avec nos managers et sur diffÃ©rents types de projet :
Transformations digitales,
Optimisation des processus,
AmÃ©lioration de la qualitÃ© de lâ€™information,
Mise en oeuvre et Ã©volution de systÃ¨mes dâ€™information,
Assistance Ã  la gestion de projet
Tes missions seront :
Concevoir des solutions pertinentes et innovantes en tenant compte de tous les enjeux du contexte client
ImplÃ©menter et optimiser ces solutions dans les rÃ¨gles de lâ€™art
Conseiller les clients dans leurs choix
Transmettre ton savoir-faire et participer Ã  la capitalisation de connaissance des utilisateurs
Notre structure Ã  taille humaine est un cadre parfait pour te permettre dâ€™Ã©voluer rapidement en tâ€™offrant lâ€™opportunitÃ© dâ€™intervenir Ã  la fois sur les diffÃ©rentes phases dâ€™un projet : cadrage / conception et mise en oeuvre / conduite de projet et encadrement dâ€™Ã©quipe, mais Ã©galement sur des activitÃ©s Ã  dominante commerciale : conception dâ€™offres / rÃ©daction de proposition / soutenance en clientÃ¨le.
Voir moins","Profil recherchÃ©
Tu as une expÃ©rience projets avec Snowflake
Tu maitrises le domaine fonctionnel de la finance ou de la logistique
Tu souhaites intervenir sur des projets Ã  forte valeur ajoutÃ©e
Tu as un goÃ»t prononcÃ© pour les nouvelles technologies
Tu as un fort esprit dâ€™Ã©quipe, et aime partager des moments conviviaux avec tes collÃ¨gues
Tu es dotÃ©(e) dâ€™un bon relationnel et tu maÃ®trises lâ€™anglais
Tu recherches une entreprise Ã  taille humaine avec un management de proximitÃ© pour accompagner ton dÃ©veloppement de carriÃ¨re, et un environnement oÃ¹ lâ€™autonomie et lâ€™esprit dâ€™initiative sont mis en avant.
Si en lisant cela, tu te dis que câ€™est tout toi (ou presque), câ€™est que tu as lâ€™Ã©toffe dâ€™un futur MeltOner et que tu dois postuler Ã  cette offre."
Data Engineer,"{'name': 'ADVANCED SCHEMA', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '220 collaborateurs', 'creation_year': '2001', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,Bac +3,,
Data Engineer (H/F) - CDI - Paris,"{'name': 'LE COLLECTIONIST', 'sector': 'HÃ´tellerie, Tourisme, Immobilier particulier', 'employees': '330 collaborateurs', 'creation_year': '2012', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 6 mois,Bac +5 / Master,"Descriptif du poste
At LC, The Data team is composed of 2 Data Analysts (1 Lead and 1 IC) and 1 Lead Data Engineer reporting to the CTPO, and is thus part of the Tech & Product team.
The goal of the Data team is to unlock and democratize the usage of data in other teamsâ€™ everyday activity and decision making process.
The Data Engineer is responsible for the companyâ€™s Data Platform: from the infrastructure setup to the release and management of the Warehouse trusted data model.
As of today, this Data Platform is mainly used for BI & Analytics use cases to help teams work more efficiently and make better decisions by providing a consolidated view of LC business performance through dashboards, data extractions and analysis.
In 2024, we will work on building a more Self-service oriented Data platform for business users to be less dependent on the central Data team AND why not, explore some Machine Learning use cases later.
By joining us, you will be part of a Data team that, while still in its early stages of development, made the effort of building a strong basis and setting up a lot of best practices.
It will be the opportunity for you to grow and develop your Data Engineering skills on a Modern Data Stack, be mentored by an experienced Data Engineer and have a lot of impact on the Data Platform and team development.
ğŸš€ Key missions
As a Data Engineer, you will report directly to the Lead Data Engineer and will:
Build and maintain data ingestion and processing pipelines (cleaning, curation, data quality checks, etc.)
Provide and maintain consumption-ready trusted data for Data Analyst or Business users
Deploy, monitor and optimize components of the Data Platform
Provide and maintain tools for Data Analysts
Write and maintain the Data Platform documentation
At LC, the Data Engineer role has a mix of Data Platform Engineer and Analytics Engineer responsibilities.
ğŸ­ Our technical stack
Cloud provider : Google Cloud Platform
Data Warehouse : BigQuery
Ingestion tool : Airbyte (self-hosted, on Kubernetes)
Orchestration & Transformation : Cloud Composer (Apache Airflow), Dataform
BI tool : Looker Studio
Infra-as-Code : Terraform, Terragrunt
Main coding language : Python, SQL
Perks :
ğŸšŒ 50% reimbursement of the transportation passğŸ‚ 1 day off for your birthday (excluding weekends and public holidays)
ğŸ½ï¸ Meal vouchers up to â‚¬8
ğŸ’» A laptop
ğŸŠ Year-round events (Christmas Party, Raclette Party, Summer Partyâ€¦)
ğŸ’µ Unlimited referrals (up to â‚¬1000 for a permanent position)
â˜€ï¸ A surprise experience worth â‚¬150 to be won every quarter
ğŸ¡ 2 remote days per week
ğŸ‹ğŸ½ Gymlib subscription (activities and sports in France)
âœ¨ Happypal account for cultural activities
Voir moins","Profil recherchÃ©
Preferred background/experience
Bac+5 with specialization in Data
Internship and/or 1st experience as Data/Analytics/BI Engineer in a startup/scaleup company is preferred
Hard skills
Basic knowledge of Software and Data Engineering principles
Experience with any RDBMS (PostgreSQL, MySQL, SQL Server, etc.)
Experience with git
Good experience with SQL 
Knowledge of Python and CLI
Soft skills
Team player 
Strong interest in using best practices 
Not afraid to talk to business people"
Data Engineer - Madonne Core (H/F),"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards â‚¬ de PNB', 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous rejoignez l'Ã©quipe Core en charge de la maintenance Ã©volutive des applications Madonne (RÃ©colte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiÃ©e au coeur de l'IT Risque).

Au quotidien vous avez pour missions de :

Participer Ã  l'adaptation de nos applications en adÃ©quation avec les besoins mÃ©tiers (nouveaux produits, nouvelles rÃ¨glementations, nouveaux SI Front) ;
Participer activement Ã  la modernisation de nos outils, modernisation de notre chaÃ®ne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;
Monter en compÃ©tences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous dÃ©velopperez une comprÃ©hension globale des chaÃ®nes de traitements ;
Participer Ã  tous les travaux de modernisation de notre SI, et Ãªtre donc engagÃ© dans la migration de nombreux process vers le DataLake Risk.





#TransformativeFinance
Ce poste est basÃ© Ã  Paris avec la possibilitÃ© de tÃ©lÃ©travailler.
En tant que Top Employer, nous plaÃ§ons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilitÃ© interne, dÃ©veloppement de carriÃ¨re et de formation vous permettent de grandir et de vous Ã©panouir tout au long de votre parcours.
Vous Ã©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.
Vous avez Ã©galement la possibilitÃ© de vous engager en faveur de la sociÃ©tÃ© et de causes qui vous tiennent Ã  cÅ“ur via notre fondation d'entreprise.
A propos du processus de recrutement
Vous serez contactÃ© par l'un de nos recruteurs avant de rencontrer nos experts mÃ©tier (manager, membre de l'Ã©quipe ou de la filiÃ¨re mÃ©tier).
Voir moins","Profil recherchÃ©
Qui Ãªtes-vous ? Si vous vous reconnaissez dans la description suivante vous Ãªtes fait pour travailler avec nous : Vous souhaitez bÃ©nÃ©ficier d'une premiÃ¨re expÃ©rience significative en dÃ©veloppement Spark et Scala. Vous maitrisez : * Les mÃ©thodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appÃ©tence pour la manipulation de la data. Vous Ãªtes : * Reconnu par votre esprit d'Ã©quipe ; * Capable de communiquer avec des publics diffÃ©rents, notamment avec le mÃ©tier ; * Autonome et ntÃ©ressÃ© par l'environnement finance de marchÃ©. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous Ãªtes intÃ©ressÃ© en rÃ©pondant Ã  cette annonce."
"Senior Data Engineer - Paris, Toulouse, Montpellier - F/H/N","{'name': 'SWILE', 'sector': 'Application mobile, Restauration, FoodTech', 'employees': '1000 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '35 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©",TÃ©lÃ©travail frÃ©quent,,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Notre Ã©quipe Analytics sâ€™agrandit et nous recherchons un.e Data Engineer Senior pour dÃ©velopper notre plateforme dâ€™Analytics globale.
ğŸ˜ Tes futures missions :
DÃ©velopper et maintenir une Data Platform robuste qui permet lâ€™ingestion et la mise Ã  disposition dâ€™une grande variÃ©tÃ© de donnÃ©es
GÃ©rer nos outils SaaS (Stitch, Snowflake, â€¦) et contribuer sur notre infrastructure K8S auto-hebergÃ©e (Airflow, Kafka, â€¦)
ModÃ©liser les donnÃ©es pour les traitements Analytics
DÃ©finir avec lâ€™Ã©quipe les bonnes pratiques afin dâ€™industrialiser nos modÃ¨les dâ€™Analytics
Assurer la chaÃ®ne de traitement des donnÃ©es
Appliquer les bonnes pratiques de code pour permettre une croissance de la base de code sans augmenter notre dette technique (version control, testing, refactoring, â€¦)
Participer aux choix techniques
Documenter le code et les process pour le partage de connaissance au sein de lâ€™Ã©quipe Innovation","Profil recherchÃ©
âœ¨Ce sera un match parfait si tu as â€¦
Au moins 3 ans dâ€™expÃ©rience sur un poste en Data Engineering avec un background en Software Engineering
Bon niveau de maitrise sur notre stack technique Analytics : Stitch/Airflow, AWS S3/ Snowflake, DBT, Github, Docker/Terraform
Bon niveau de maitrise en SQL
Excellente communication et capacitÃ© Ã  prÃ©senter des sujets complexes de maniÃ¨re simple
Bonne capacitÃ© dâ€™ownership et de priorisation
Anglais courant"
Cloud Data Engineer H/F,"{'name': 'HARDIS GROUP', 'sector': 'IT / Digital, Supply Chain, SaaS / Cloud Services', 'employees': '1500 collaborateurs', 'creation_year': '1984', 'turnover': ""156 millions d'euros en 2022"", 'mean_age': '38 ans'}",CDI,Saint Herblain,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,01 novembre 2021,> 3 ans,Bac +5 / Master,"Descriptif du poste
Au sein de notre entitÃ© Business Applications nantaise et intÃ©grÃ© au sein dâ€™une Ã©quipe projet, vous contribuez Ã  lâ€™Ã©laboration et lâ€™Ã©volution des couches mÃ©tiers des applications que nous rÃ©alisons pour nos clients.
En tant que Cloud Data Engineer, vous participez Ã  des projets innovants Ã  forte valeur ajoutÃ©e pour nos clients, Ã  la fois technologique et mÃ©tier. EntourÃ© de dÃ©veloppeurs, lead dÃ©veloppeur, architecte et Scrummaster, vous travaillez en mÃ©thode agile (Scrum). Notre vision du Cloud Data Engineer :
Vous Ãªtes capable dâ€™apprÃ©hender un contexte client et dâ€™implÃ©menter une plateforme pour valoriser sa donnÃ©e
Vous avez dÃ©jÃ  une expÃ©rience sur GCP ou AWS
Vous Ãªtes Ã  lâ€™aise sur lâ€™un des langages suivants (Python, Java, JavaScript)
Vous avez dÃ©jÃ  utilisÃ© un framework de calculs distribuÃ© (Spark, Beam, â€¦)
Vous connaissez et utilisez les diffÃ©rentes solutions de stockage (SQL, NoSQL, Search Engineâ€¦)
Vous maitrisez les principes du dÃ©veloppement Cloud
Vous avez des connaissances en machine learning","Profil recherchÃ©
De formation Bac + 5, issu dâ€™une Ã©cole dâ€™ingÃ©nieur ou Ã©quivalent, vous justifiez dâ€™au moins 3 ans dâ€™expÃ©rience professionnelle rÃ©ussie dans les domaines de la Data et du Cloud en contexte agile.
Vous Ãªtes Ã  lâ€™aise avec un ou plusieurs des sujets suivants : Python, Java, JavaScript, GCP, AWS, Spark, Beam, Kafka, Airflow, ELK.
Vous Ãªtes Ã  la fois autonome et force de proposition.
Vous aimez partager vos connaissances et souhaitez Ã©voluer au sein dâ€™une Ã©quipe technophile et riche en expertises. Vous Ãªtes organisÃ©, mÃ©thodique et avez une excellente capacitÃ© dâ€™analyse. La curiositÃ©, lâ€™esprit dâ€™Ã©quipe et la bonne humeur sont indispensables pour intÃ©grer lâ€™Ã©quipe Business Applications Nantes.
Nous pouvons accompagner votre mobilitÃ© grÃ¢ce Ã  une offre globale (de la recherche de logement Ã  lâ€™accompagnement administratif, en passant par lâ€™intÃ©gration de lâ€™ensemble de la famille dans le nouvel environnement de vie) - sous condition dâ€™Ã©ligibilitÃ©"
Data Engineer,"{'name': 'SOCIÃ‰TÃ‰ GÃ‰NÃ‰RALE', 'sector': 'Banque, FinTech / InsurTech, Finance', 'employees': '117000 collaborateurs', 'creation_year': '1864', 'turnover': None, 'mean_age': None}",CDI,Fontenay-sous-Bois,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Au sein de la Direction des SystÃ¨mes d'Information de la Banque de DÃ©tail France de SociÃ©tÃ© GÃ©nÃ©rale, vous :

BÃ©nÃ©ficierez d'un cadre de travail agrÃ©able facilitant l'Ã©quilibre vie pro/vie perso notamment en permettant jusqu'Ã  3 jours de tÃ©lÃ©travail par semaine.

Evoluerez dans un environnement stimulant : intÃ©grez nos Ã©quipes afin de relever les dÃ©fis innovants qui nous animent au quotidien autour des pratiques de dÃ©veloppement green, du cloud, de la data ou encore de la CybersÃ©curitÃ©.

Baignerez dans une culture bienveillante : notre proximitÃ© avec le mÃ©tier, l'entraide et l'Ã©coute entre management et la communautÃ© des experts font notre force. Un collectif plÃ©biscitÃ© par 85% de nos collaborateurs.

Les missions seront les suivantes :
Suivre et dÃ©panner la production pour son maintien en conditions opÃ©rationnelles
Concevoir des solutions pour collecter, transformer et exploiter de gros volumes de donnÃ©es
Analyser les donnÃ©es provenant de multiples sources (exemple : croisement simple de donnÃ©es jusqu'Ã  l'analyse prÃ©dictive)
Industrialiser des traitements et participer Ã  leur amÃ©lioration continue pour qu'ils soient fiables, robustes, performants et rÃ©silients afin de rÃ©pondre aux exigences des partenaires mÃ©tiers
Travailler en Ã©troite collaboration avec les Data Architectes et Data Scientists pour industrialiser le procÃ©dÃ© et produire des analyses opÃ©rationnelles => ajouter les autres transverses + PO mÃ©tier
Tester de nouvelles fonctionnalitÃ©s, nouveaux outils et participer Ã  des confÃ©rences internationales (Flink Forward, Spark Summit)
Documenter ses travaux
Contribuer Ã  l'acculturation et Ã  la vulgarisation des sujets Big Data auprÃ¨s de ses principaux interlocuteurs


Et si câ€™Ã©tait vous ?


Vous possÃ©dez les compÃ©tences suivantes :
Connaissances des outils liÃ©s au Big Data : Spark, Hive, Hadoop, NiFi, Kafka, Elastic, Kibana
DÃ©veloppement informatique : Scala, Python, Java, Devops, Big Data, outils CI/CD, microservice, API
ModÃ©lisation des donnÃ©es ModÃ¨les de donnÃ©es : modÃ¨le en Ã©toile, modÃ¨le Data Vault
Connaissances en architecture technique Big Data
Relationnel et esprit d'Ã©quipe sens du service, capacitÃ© Ã  collaborer, Ã  communiquer et Ã  s'adapter Ã  ses interlocuteurs
Autonomie
Savoir s'adapter aux diffÃ©rentes mÃ©thodologies (prÃ©dictives, agiles, hybrides)
Forte transversalitÃ© (interactions avec des Ã©quipes variÃ©es) : Admin plate-forme, Ã©quipe DevOps, support, Expert IT : Architecte Big Data, IT Data Designer, Experts Data : Data Scientist, Data Quality Manager, Business Data Designer, MÃ©tiers, Chef de Projet

Plus qu'un poste, un tremplin


Notre vision est de jouer un rÃ´le moteur dans les transformations positives du monde et de contribuer Ã  un avenir plus Ã©cologique, respectueux de la planÃ¨te !

Choisir SociÃ©tÃ© GÃ©nÃ©rale, c'est intÃ©grer un Groupe oÃ¹ la culture d'entreprise est tournÃ©e vers l'inclusion, la diversitÃ© et l'esprit d'Ã©quipe !

C'est construire une carriÃ¨re dynamique avec la possibilitÃ© de changer de poste en moyenne tous les 4 ans, en France et Ã  l'international tout en bÃ©nÃ©ficiant de formations rÃ©guliÃ¨res !

Au regard de vos compÃ©tences, une rÃ©munÃ©ration attractive revue annuellement, composÃ©e d'un salaire fixe, d'une part variable individuelle et d'une prime d'intÃ©ressement et de participation vous sera proposÃ©e.

Vous bÃ©nÃ©ficiez Ã©galement de tarifs prÃ©fÃ©rentiels sur vos services bancaires, d'un compte Ã©pargne temps monÃ©tisable et d'un Plan d'Epargne Entreprise abondÃ©.

Attentif Ã  votre qualitÃ© de vie et conditions de travail, vous bÃ©nÃ©ficiez de nombreux avantages complÃ©mentaires :
Ã€ minima 2 jours de tÃ©lÃ©travail par semaine
26 Ã  28 jours de congÃ©s payÃ©s par an et 14 Ã  18 jours de RTT (suivant les annÃ©es), des congÃ©s liÃ©s aux Ã©vÃ©nements de la vie
Un ComitÃ© d'Entreprise (billetterie Ã©vÃ©nements sportifs & culturels, primes et subventions vacances, garde d'enfants, chÃ¨que cadeaux Ã  Noel)
Une offre variÃ©e de restaurants d'entreprise et de cafÃ©tÃ©rias Ã  tarifs compÃ©titifs ainsi que des titres restaurants dÃ©matÃ©rialisÃ©s quand vous Ãªtes en tÃ©lÃ©travail

Pourquoi nous choisir ?


Chez SociÃ©tÃ© GÃ©nÃ©rale, nous sommes convaincus que vous Ãªtes le moteur du changement et que le monde de demain sera fait de toutes vos initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques annÃ©es ou toute votre carriÃ¨re, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. CrÃ©er, oser, innover, entreprendre font partie de notre ADN.

Si vous aussi vous souhaitez Ãªtre dans l'action, Ã©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et dÃ©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !

Vous hÃ©sitez encore ?

Sachez que nos collaborateurs peuvent s'engager quelques jours par an pour des actions de solidaritÃ© sur leur temps de travail : parrainer des personnes en difficultÃ© dans leur orientation ou leur insertion professionnelle, participer Ã  l'Ã©ducation financiÃ¨re de jeunes en apprentissage ou encore partager leurs compÃ©tences avec une association. Les formats d'engagement sont multiples.

Nous sommes un employeur garantissant l'Ã©galitÃ© des chances et nous sommes fiers de faire de la diversitÃ© une force pour notre entreprise. Le groupe s'engage Ã  reconnaÃ®tre et Ã  promouvoir tous les talents, quels que soient leurs croyances, Ã¢ge, handicap, parentalitÃ©, origine ethnique, nationalitÃ©, identitÃ© de genre, orientation sexuelle, appartenance Ã  une organisation politique, religieuse, syndicale ou Ã  une minoritÃ©, ou toute autre caractÃ©ristique qui pourrait faire l'objet d'une discrimination.

RÃ©fÃ©rence: 240003CI
EntitÃ©: Banque de dÃ©tail France
Date de dÃ©but: 01/04/2024

Date de publication: 08/02/2024
Voir moins",
Data Engineer,"{'name': 'SOCIÃ‰TÃ‰ GÃ‰NÃ‰RALE', 'sector': 'Banque, FinTech / InsurTech, Finance', 'employees': '117000 collaborateurs', 'creation_year': '1864', 'turnover': None, 'mean_age': None}",Stage,Fontenay-sous-Bois,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Au sein de la Direction des SystÃ¨mes d'Information de la banque de dÃ©tail France de SociÃ©tÃ© GÃ©nÃ©rale, vous ...
BÃ©nÃ©ficierez d'un cadre de travail agrÃ©able facilitant l'Ã©quilibre vie pro/vie perso notamment en permettant jusqu'Ã  3 jours de tÃ©lÃ©travail par semaine.
Evoluerez dans un environnement stimulant : intÃ©grez nos Ã©quipes afin de relever les dÃ©fis innovants qui nous animent au quotidien autour des pratiques de dÃ©veloppement green, du cloud, de la data ou encore de la cybersÃ©curitÃ©.
Baignerez dans une culture bienveillante : notre proximitÃ© avec le mÃ©tier, l'entraide et l'Ã©coute entre management et la communautÃ© des experts font notre force. Un collectif plÃ©biscitÃ© par 85% de nos collaborateurs*.

En tant que Data Engineer, vous serez rattachÃ©(e) Ã  une Feature Team agile dÃ©diÃ©e Ã  la banque de de dÃ©tail en France.

Vous participerez au dÃ©veloppement des applications big data en Ã©quipe avec l'aide de nos meilleurs experts, rÃ©aliser des traitements data lake sur des milliards d'indicateurs quotidiens pour garantir la bonne gestion des risques de la banque ou manipuler des millions de contrats financiers pour rÃ©pondre aux demandes de nos rÃ©gulateurs, bref, devenir un(e) vrai(e) maestro de la data !

ConcrÃ¨tement, vous serez amenÃ©(e) Ã  :
Travailler sur des applications de traitement de donnÃ©es basÃ©es sur des technologies Big Data (Hadoop, Spark, Kafka) mises en place pour stocker et distribuer l'ensemble des transactions ainsi que leurs indicateurs de risques associÃ©s. Les donnÃ©es et traitements sont progressivement migrÃ© sur le cloud public Azure.
Participer aux nouveaux dÃ©veloppements requis sur l'application (ajout de nouvelles fonctionnalitÃ©s aux jobs existants, implÃ©mentation de nouveaux jobs, d'outils de non-rÃ©gression, de data quality, de continuous delivery, ou bien la conduite de tests de performances)
Concevoir des solutions pour collecter, nettoyer, organiser et synthÃ©tiser de trÃ¨s gros volumes de donnÃ©es (pour alimenter bases de donnÃ©es, datalakes et projets Big Data)
Participer Ã  l'analyse complexe de donnÃ©es provenant de diffÃ©rentes sources
Assurer une veille technologique permettant de tester de nouvelles fonctionnalitÃ©s et nouveaux outils

* RÃ©sultats enquÃªte collaborateurs IPSOS (DÃ©cembre 2021)

Et si câ€™Ã©tait vous ?


Etudiant(e) de niveau Bac +4/5 en Ecole d'ingÃ©nieur ou UniversitÃ©, avec une spÃ©cialisation en Data, Informatique
PassionnÃ©(e) de data, vous aimez travailler en mode collaboratif, partager votre savoir-faire et proposer des amÃ©liorations qui donneront du sens Ã  l'activitÃ©
Vous Ãªtes curieux(se), avec un bon esprit d'analyse et vous aimez communiquer
Incollable sur Spark et Java, vous apprÃ©ciez le code propre et appliquez les bonnes pratique du crafmanship
You're fluent in english ! Vous Ãªtes notre candidat(e) idÃ©al(e) !

Plus qu'un poste, un tremplin


DÃ¨s votre arrivÃ©e, vous serez intÃ©grÃ©(e) dans nos Ã©quipes et apprendrez chaque jour aux cÃ´tÃ©s de nos experts qui vous accompagneront dans vos missions. Progressivement, vous gagnerez en autonomie sur vos projets pour faire de cette expÃ©rience un vrai accÃ©lÃ©rateur de carriÃ¨re. Vous dÃ©couvrirez Ã©galement toute la diversitÃ© de nos mÃ©tiers, dans un secteur qui Ã©volue et innove en permanence.

A la fin de vos Ã©tudes ou de votre VIE, diverses opportunitÃ©s pourront s'offrir Ã  vous, en France et Ã  l'international.

En tant que stagiaire, vous pourrez bÃ©nÃ©ficier de jours de tÃ©lÃ©travail (pour tout stage de longue durÃ©e et selon le rythme de votre service), d'une prise en charge de 50% de votre titre de transport et de la billetterie Ã  prix rÃ©duits de notre ComitÃ© d'Entreprise (concerts, cinÃ©ma, sport...). Lors de votre prÃ©sence sur site, vous accÃ©derez Ã  une offre variÃ©e de restaurants d'entreprise et de cafÃ©terias Ã  un tarif trÃ¨s compÃ©titif.

Pourquoi nous choisir ?


Chez SociÃ©tÃ© GÃ©nÃ©rale, nous sommes convaincus que vous Ãªtes le moteur du changement et que le monde de demain sera fait de toutes vos initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques annÃ©es ou toute votre carriÃ¨re, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. CrÃ©er, oser, innover, entreprendre font partie de notre ADN.

Si vous aussi vous souhaitez Ãªtre dans l'action, Ã©voluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et dÃ©velopper ou renforcer votre expertise, nous sommes faits pour nous rencontrer !

Vous hÃ©sitez encore ?

Sachez que nos collaborateurs peuvent s'engager quelques jours par an pour des actions de solidaritÃ© sur leur temps de travail : parrainer des personnes en difficultÃ© dans leur orientation ou leur insertion professionnelle, participer Ã  l'Ã©ducation financiÃ¨re de jeunes en apprentissage ou encore partager leurs compÃ©tences avec une association. Les formats d'engagement sont multiples.

Nous sommes un employeur garantissant l'Ã©galitÃ© des chances et nous sommes fiers de faire de la diversitÃ© une force pour notre entreprise. Le groupe s'engage Ã  reconnaÃ®tre et Ã  promouvoir tous les talents, quels que soient leurs croyances, Ã¢ge, handicap, parentalitÃ©, origine ethnique, nationalitÃ©, identitÃ© de genre, orientation sexuelle, appartenance Ã  une organisation politique, religieuse, syndicale ou Ã  une minoritÃ©, ou toute autre caractÃ©ristique qui pourrait faire l'objet d'une discrimination.

RÃ©fÃ©rence: 240001R7
EntitÃ©: Banque de dÃ©tail France
Date de dÃ©but: 11/03/2024

Date de publication: 02/02/2024
Voir moins",
Data Engineer - Equipements BiomÃ©dicaux connectÃ©s,"{'name': 'APHP DSI', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, SantÃ©', 'employees': '495 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '46 ans'}","CDD / Temporaire
(12 Ã  36 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
La mission de votre Ã©quipe
Afin de permettre le dÃ©veloppement de projets de recherche innovants, en particulier dans le domaine de lâ€™intelligence artificielle, lâ€™APâ€“HP a mis en place une plateforme Big Data, infrastructure informatique propre, intÃ©grant des capacitÃ©s de stockage et de calcul pour lâ€™exploitation sÃ©curisÃ©e et performante des donnÃ©es de santÃ© dont elle est dÃ©positaire. Cette plateforme hÃ©berge notamment lâ€™entrepÃ´t de donnÃ©es de santÃ© (EDS) de lâ€™AP-HP.

Lâ€™EntrepÃ´t de DonnÃ©es de SantÃ© (EDS) de lâ€™AP-HP intÃ¨gre des donnÃ©es administratives et mÃ©dicales de plus de 8 millions de patients hospitalisÃ©s ou venus en consultation au sein des 39 Ã©tablissements de lâ€™AP-HP (20 millions de dossiers mÃ©dicaux, plus de 10 millions de diagnostics, 181 millions de rÃ©sultats de laboratoiresâ€¦). Cet entrepÃ´t permet dâ€™amÃ©liorer le pilotage de lâ€™activitÃ© hospitaliÃ¨re et de faire avancer la recherche scientifique dans le domaine de la santÃ© en favorisant la rÃ©alisation dâ€™Ã©tudes sur donnÃ©es, la mise en place dâ€™essais cliniques et le dÃ©veloppement dâ€™algorithmes dâ€™aide Ã  la dÃ©cision.

La Plateforme Big Data de lâ€™AP-HP compte actuellement +30 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po dâ€™espace disque), de machines GPU (48 Nvidia P40 / V100), de 20 machines dÃ©diÃ©es aux environnements Jupyter pour lâ€™analyse de donnÃ©es, et de nombreuses autres machines applicatives.

Votre Ã©quipe, le domaine Â« Plateforme Big Data Â», a pour mission lâ€™intÃ©gration des donnÃ©es de santÃ© massives et complexes (donnÃ©es structurÃ©s, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation Ã  grande Ã©chelle, de maniÃ¨re performante, ergonomique et sÃ©curisÃ©e dans le respect des principes et rÃ¨gles de gouvernance des donnÃ©es dÃ©finis par lâ€™AP-HP. Les donnÃ©es issues des Ã©quipements biomÃ©dicaux connectÃ©s proviennent globalement de lâ€™ensemble des services de lâ€™APHP et en particulier dans les services de soins intensifs. Selon le contexte, la frÃ©quence dâ€™acquisition et la durÃ©e dâ€™enregistrement des signaux varient dans des proportoins importantes (de quelques secondes Ã  plusieurs jours et de 0.02Hz Ã  3kHz).
Vos missions
Au sein de lâ€™Ã©quipe en charge de la Plateforme Big Data de lâ€™APHP, vous prenez en charge le dÃ©veloppement des outils ou composants rÃ©pondant aux attentes des mÃ©decins et chercheurs pour le stockage et lâ€™exploitation des donnÃ©es de type signaux physiologiques (ECG, EEG, EMG, courbes respiratoires, â€¦) collectÃ©es dans le cadre de leurs projets de recherche.
La plateforme big data cherche a se doter dâ€™une solution technique spÃ©cifique pour le stockage, le traitement et lâ€™exploitation de ces donnÃ©es sous forme de sÃ©ries temporelles. Vous serez amenÃ© Ã  analyser, Ã  proposer et Ã  mettre en oeuvre une architecture et des solutions adaptÃ©es aux diffÃ©rents besoins des projets de recherche et vous participerez Ã©galement Ã  la mise en place dâ€™un certain nombre dâ€™outils de base (visualisation, annotation, etc.) pour faciliter lâ€™exploitation et lâ€™enrichissement des donnÃ©es physiologiques par les utilisateurs de la plateforme.
En tant que data engineer spÃ©cialisÃ© en traitement du signal et idÃ©alement en systÃ¨mes biomÃ©dicaux, vous :
RÃ©aliserez la dÃ©finition des besoins et lâ€™accompagnement des mÃ©decins pour la rÃ©alisation dâ€™un projet de recherche
Analyserez les diffÃ©rents Ã©quipements biomÃ©dicaux, signaux et protocoles de communication
DÃ©velopperez, industrialiserez et maintiendrez les flux dâ€™intÃ©gration des signaux physiologiques pour permettre leur collecte au sein de la plateforme big data
Contribuerez Ã  lâ€™utilisation de ces nouvelles typologies de donnÃ©es (extraction, sÃ©lection, collecte et intÃ©gration) via des connecteurs spÃ©cifiques dÃ©veloppÃ©s en java, python ou dâ€™autres langages
Industrialiserez le code de gÃ©nÃ©ration du flux de donnÃ©es et assurer sa performance globale
Aiderez Ã  lâ€™implÃ©mentation de standards et normes de mise Ã  disposition des donnÃ©es
Mettrez en place des outils permettant lâ€™enrichissement des donnÃ©es (analyse, annotation, etc)
Travaillerez en collaboration avec des partenaires industriels dans le cadre des diffÃ©rents projets de recherche
Voir moins","Profil recherchÃ©
IdÃ©alement, vous..
Avez un diplÃ´me dâ€™ingÃ©nieur ou Ã©quivalent (bac+4/5, master2) en informatique ou sciences avec formation complÃ©mentaire en informatique
Avez une expÃ©rience de dÃ©veloppement sous Linux, des langagage Java et/ou Python et des outils EAI (Mirth, â€¦) et ETL (Talend ou autre)
Avez une expÃ©rience dans la manipulation de donnÃ©es avec le langage SQL
Connaissez les standards en informatique de santÃ© (HL7 v2, DICOM, HL7-FHIR, OMOP, â€¦)
Avez le goÃ»t de lâ€™intÃ©gration de systÃ¨mes informatiques hÃ©tÃ©rogÃ¨nes
Avez des connaissances des bonnes pratiques de sÃ©curitÃ© informatique et de la rÃ©glementation informatique et libertÃ©s
AdhÃ©rez aux valeurs du service public et vous avez un intÃ©rÃªt prononcÃ© pour le domaine de la santÃ©
Avez un niveau dâ€™anglais courant
Vous avez un savoir faire dans un de ces domaines :
Bonne maitrise du langage Python et de bash
Voir plus"
Data Engineer,"{'name': 'PICTARINE', 'sector': 'Application mobile, Logiciels, E-commerce', 'employees': '50 collaborateurs', 'creation_year': '2009', 'turnover': '14M$', 'mean_age': '32 ans'}",CDI,Toulouse,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,,> 3 ans,,"Descriptif du poste
Mission and challenges ğŸ¯
Si tu es enthousiaste Ã  embarquer dans la nouvelle Ã©quipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors câ€™est lâ€™aventure quâ€™il te faut! ğŸ”ï¸
Avec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les Ã©quipes de Pictarine ne sont jamais Ã  court dâ€™idÃ©es pour explorer de nouveaux horizons. ğŸš€
En tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toute ta crÃ©ativitÃ© pour garantir la qualitÃ© de la data, accompagner et challenger les besoins data.
Tu Ã©volueras au sein de lâ€™Ã©quipe Engineering, composÃ©e des pÃ´les dev & data. Tu rejoindras une Ã©quipe data dÃ©jÃ  composÃ©e dâ€™une data analyste, Romane, et de la data manager, Marie !
Ton rÃ´le comprendra les aspects suivants ğŸ‘‡ğŸ»
Tu es garant de la qualitÃ© de la data !
En simplifiant la structure de la data et rÃ©duisant le nombre de tables
En transformant les donnÃ©es pour les rendre facilement utilisables
En orchestrant le flux des donnÃ©es de maniÃ¨re continue et automatique
Tu accompagnes et challenges les Ã©quipes de Pictarine !
En co-construisant des solutions data appropriÃ©es
En Ã©levant le niveau de jeu des mÃ©thodes data existantes
En faisant rayonner la data autour de bonnes pratiques et dâ€™outillages adÃ©quates
Voir moins","Profil recherchÃ©
About you ğŸ’
Tu as au moins 3 ans dâ€™expÃ©rience sur un poste similaire
Tu as de bonnes connaissances dans la transformation des donnÃ©es (ETL), la conception de modÃ¨les de donnÃ©es et les stratÃ©gies dâ€™optimisation des requÃªtes
Tu as des compÃ©tences en DevOps pour le dÃ©ploiement et la gestion efficace des pipelines de donnÃ©es
Tu as une bonne maÃ®trise de Python, SQL & Github
Tu maÃ®trises lâ€™un des data warehouse suivants : BigQuery, Refshift, Snowflake, Synapse Analytics
Tu as une passion pour rÃ©soudre des problÃ¨mes business avec la programmation
Tu es curieux de tester des nouvelles technologies
Tu es organisÃ©, rigoureux et portes une grande attention aux dÃ©tails
Tu es dotÃ© dâ€™excellentes qualitÃ©s relationnelles, de communication et de vulgarisation
Tu es un team player et toujours Ã  lâ€™affÃ»t de nouvelles idÃ©es
Work @ Pictarineâœ¨
Un environnement de travail agile, collaboratif, international et multiculturel
Voir plus"
Data engineer intern,"{'name': 'EQUATIV', 'sector': 'AdTech / MarTech', 'employees': '600 collaborateurs', 'creation_year': '2001', 'turnover': None, 'mean_age': '33 ans'}",Stage,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,Bac +5 / Master,"Descriptif du poste
ğŸ‘« About the team
At Equativ, weâ€™re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.
Our innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.
At Equativ, weâ€™re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 100 billions requests per day and above 40 Gbps of network traffic. 
Our data engineering team is composed of 8 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 120+ engineers spread across Paris, Nantes, Limoges, Krakow and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.
The data engineers are split in two sub-teams working in close collaboration:
Pipeline team: Maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIs.
Feature team: Apply best in class data modeling and orchestrating data transformations in our warehouses, leading the day-to-day management of these warehouses.
Our Mission
Our Data Engineering team is central to Equativâ€™s data centric business and is responsible to ingest, transform, model and redistribute all data coming from our ad tech platform.
We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle huge volumes (15 Tb per day), short & long term data storage, complex data modeling, real-time and batch ELT as well as providing external access through dedicated APIs.
We enhance and deliver Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science models feeding, customer reporting, invoicing and more.
We rely on a top tier on-premise & cloud stack (Kafka, Flink, ClickHouse, Bigquery, Dataflow, Airflow, DBTâ€¦) and work hard to increase reporting capabilities, lower maintenance time, improve performances and simplify the access to our raw data.
What you will do
As a data engineer intern, you will be supporting one of the two sub-team (pipeline or feature) in their tasks and projects:
Take a leading part on a data engineering project such as but not limited to:
Proof of Concept of Clickhouse Cloud
Improvement of the data transformation process with DBT, BigQuery and Airflow
Development of new functionalities on our internal tools (APIs, software applications)
Setup a data lineage application (castor doc) 
Support the data engineering team in their day-to-day activities
Enhance our DevOps process with CI/CD and testing framework.
Monitor performances and workflow of our applications using reporting tool (Grafana)
Take part in improving and deploying data engineering standards, documentation and operational guidelines around data usage at Equativ
About you
Master degree in Computer Science or similar technical field of study.
Prior experience in data or software development related environment is desired.
Experience with a cloud datawarehouse (BigQuery, Snowflake, Databrick,..) is a plus.
Good knowledge of SQL and one other data programming language (Java preferred, Python, Scala..). 
Knowledge on the software development process (Git, CI/CD, test, scrum)
Working proficiency and communication skills in verbal and written English
Strong interest in big data and cloud computing technologies. 
ğŸ‘‹ About us 
Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus â€” four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.
Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.
The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Timesâ€™ FT 1000: Europeâ€™s Fastest-Growing Companies.
Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.
Come and lead the charge with us in building a transparent ecosystem based on quality!
----------------------
Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com
Voir moins",
Data Engineer,"{'name': 'NIELSENIQ GROUP INCL DATA IMPACT AND GFK', 'sector': 'Big Data, E-commerce', 'employees': '40000 collaborateurs', 'creation_year': '1923', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Weâ€™re looking for an experienced Data Engineer to join our growing Machine Learning team.Your work will entail the following :
Creating data flows
Working on data versioning
Launching flows in orchestration tools
Improve CI/CD pipelines
Dependencies management (poetry)
Deploying scripts/models created by data scientists on Notebooks
Contrat : CDI
Localisation : Paris 10e
#LI-DAIM
About NIQ
NIQ is the worldâ€™s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insightsâ€”delivered with advanced analytics through state-of-the-art platformsâ€”NIQ delivers the Full Viewâ„¢.
NIQ, is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the worldâ€™s population. For more information, visit NIQ.com.
Want to keep up with our latest updates?
Follow us on: LinkedIn | Instagram | Twitter | Facebook
  Our commitment to Diversity, Equity, and Inclusion
NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us.
We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide.
Learn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion/
NIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process.
Voir moins","Profil recherchÃ©
1-2 years of experience
Proficiency with Python
Experience with distributed systems to manipulate big data (Dask, Spark)
Experience with ML datasets is a plus
Experience creating ETL pipelines
Experience working with GCP (Google Cloud Platform) on main data services (cloud storage, bigquery, cloud build, GKE..)
Experience using orchestrators (airflow, dagster...)
Work environment (Linux, Jupyter, Python, Git, Docker, SQL, NoSQL, ...)
Significant experience with Pandas, SQL technologies and writing Dockerfiles
Professional level of French and English"
Senior Data Engineer (H/F),"{'name': 'STUDI - DIGITAL EDUCATION FOR LIFE', 'sector': 'Education, EdTech, Formation', 'employees': '1000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,PÃ©rols,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Avec plus de 1000 collaborateurs, Studi est LA grande Ã©cole en ligne franÃ§aise, acteur incontournable de lâ€™edtech et leader sur son marchÃ© de la formation en ligne et lâ€™alternance.
Filiale Edtech de Galileo Global Education - NÂ°1 groupe mondial de lâ€™enseignement supÃ©rieur privÃ© - Studi propose plus de 200 formations reconnues par lâ€™Ã‰tat du niveau CAP au BAC+5 et forme plus de 70 000 apprenants chaque jour. 
Pour y parvenir, Studi accÃ©lÃ¨re son dÃ©veloppement en France et Ã  lâ€™international ğŸŒ, et souhaite renforcer ses effectifs.
Nous recrutons continuellement de nouveaux talents passionnÃ©s qui souhaitent grandir et prendre part Ã  une belle aventure.
Join us ! ğŸ˜
 Vos missions
Sous la responsabilitÃ© du Head of Data, le Senior Data Engineer est chargÃ© de collecter, transformer et activer la data afin dâ€™accompagner la prise de dÃ©cision. Il est chargÃ© de la conception de solutions robustes, permettant le traitement de volumes importants de pipelines donnÃ©es. Par ailleurs, les solutions choisies doivent Ãªtre suffisamment sÃ©curisÃ©es et lisibles pour les Data Analysts et Data Scientists qui seront les premiers consommateurs de ces donnÃ©es stockÃ©es, nÃ©cessaires aux besoins opÃ©rationnels et dÃ©cisionnels de lâ€™entreprise.
Vous concevez, dÃ©veloppez et maintenez des pipelines de donnÃ©es robustes, Ã©volutifs et fiables pour le recueil, le traitement et la distribution des donnÃ©es. 
Vous assurez la qualitÃ© des donnÃ©es en mettant en place des processus de nettoyage, de transformation et de validation et mettez en Å“uvre des solutions de stockage adaptÃ©es et performantes. 
Vous optimisez les performances des requÃªtes et des processus liÃ©s aux donnÃ©es pour garantir une rÃ©ponse rapide aux besoins des Data Analysts. 
Vous participez Ã  la documentation des architectures, des processus et des flux de donnÃ©es et collaborez avec les Ã©quipes de sÃ©curitÃ© afin d'en garantir la confidentialitÃ© et leur conformitÃ©. 
Vous disposez d'une expÃ©rience significative en ingÃ©nierie des donnÃ©es et une solide connaissance des technologies ETC (Extract, Transform, Load).
Vous maitrisez les langages de programmation tels que Python ou autre. 
Vous avez des compÃ©tences avancÃ©es en SQLet une connaissance approfondie des concepts e modÃ©lisation de donnÃ©es et de normalisation. 
Vous avez une expÃ©rience en dans la conception et la mise en Å“uvre d'architectures de donnÃ©es distribuÃ©es. 
Vous Ãªtes force de proposition, rigoureux et disposez d'un esprit analytique et de synthÃ¨se. 
Vous aves l'esprit d'Ã©quipe et un excellent relationnel. 
Vous avez le sens de l'organisation et de la qualitÃ©. 
AUDACE : Try it! Shake it! Chez Studi nous sommes curieux, nous proposons de nouvelles solutions et sortons de notre zone de confort.
ENERGIE: Go for it! Do It! Nous donnons le meilleur de nous-mÃªme pour avancer.
SOLIDARITE: Share it! Nous favorisons la collaboration, l'entraide et la bienveillance.
RESPONSABILITE:Own it! Nous assumons une mission qui a du sens : moderniser et dÃ©mocratiser lâ€™Ã©ducation. 
Vous vous reconnaissez ?
Nous sommes impatient(e)s de vous rencontrer !
 Et puis Studi c'est aussi...
De superbes nouveaux locaux de 10 000m2
Une carte tickets restaurant SWILE
Une prime dâ€™intÃ©ressement et participation
Des jours de congÃ© conventionnels
Un CE
Une charte de 2 jours de TÃ©lÃ©travail par semaine
Une mutuelle et une prÃ©voyance dâ€™entreprise
Petit plus, vous pouvez bÃ©nÃ©ficier au cours de votre carriÃ¨re de contenus de formation Studi!
 Adressez-nous votre candidature !
 Type de contrat : CDI
Lieu : Montpellier (34 000)
Cette opportunitÃ© est ouverte aux personnes en situation de handicap.
STUDI_SJ+
Voir moins",
Alternance - Cloud Data Engineer (H/F),"{'name': 'EPSILON FRANCE', 'sector': 'Digital Marketing / Data Marketing, Big Data, AdTech / MarTech', 'employees': '600 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '38 ans'}",Alternance,Wasquehal,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 6 mois,,"Descriptif du poste
Lâ€™ambition du PÃ´le Data Management est d'offrir la meilleure expÃ©rience Ã  nos clients grÃ¢ce Ã  des solutions data-driven et cloud.
Nous les accompagnons sur des projets innovants et la crÃ©ation de modÃ¨les s'appuyant sur les nouvelles technologies.
 En tant que Cloud Data Engineer Azure et/ou Google voici vos missions : 
Contribuer Ã  la rÃ©alisation de projets Data Client, Data Lake, Data services dans un contexte de plus en plus DevOps et Agile,
Assurer la veille technologique sur les composants dâ€™une plateforme Data,  Datalake, Cloud,
RÃ©diger des documents projets (design, rÃ©alisation, dÃ©ploiement, â€¦),
GÃ©rer lâ€™Ã©volution des solutions proposÃ©es, et possiblement en assurer la TMA,
Participer aux initiatives projets et Ã  lâ€™Ã©volution de nos assets data internes.
C'est un travail passionnant et enrichissant pour nos collaborateurs qui sont amenÃ©s Ã  collaborer avec le marketing, le digital et la crÃ©ation.","Profil recherchÃ©
Vous avez une premiÃ¨re expÃ©rience sur des projets data en environnement cloud (GCP, Azure), ou une connaissance des DWH (sur technologie traditionnelle et/ou cloud), voire du DataOps.
Vous souhaitez Ã©voluer sur les technologies Big Data Hadoop/HDFS, Hive, Python et le requÃªtage de donnÃ©es (Impala, Hive, ...).
Votre expÃ©rience dans le traitement de la data, sa valorisation et sa production est un atout considÃ©rable. 
Une connaissance dâ€™un ETL (Stambia, Talendâ€¦) est un plus.
 Localisation : Campus 5.9 (Wasquehal)
RÃ©munÃ©ration : Nous savons que le salaire est un Ã©lÃ©ment essentiel pour vous ! Câ€™est pourquoi nous en parlerons sans tabou dÃ¨s les premiers Ã©changes.
Les + EPSILON France :
AccÃ¨s au Restaurant d'entreprise 
Travail Hybride grÃ¢ce Ã  notre Accord TÃ©lÃ©travail qui autorise jusquâ€™Ã  2 jours par semaine
EngagÃ© avec le Forfait MobilitÃ© Durable
Voir plus"
Data Engineer confirmÃ© - Banque - Lille,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Villeneuve-d'Ascq,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail :
Au sein dâ€™une Data Factory, vous Ãªtes pleinement impliquÃ©(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi Ã  leur succÃ¨s.
Vous avez l'occasion de dÃ©velopper vos compÃ©tences techniques et fonctionnelles de maniÃ¨re approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.
C'est tentant non ? Alors embarquez pour une nouvelle aventure professionnelle !
 Vos missions :
RattachÃ©(e) Ã  la division  Â« Banque Â», vous Ã©voluez dans un environnement challengeant et convivial, entourÃ©(e) de passionnÃ©s dotÃ©s d'expertises dans leurs domaines.
En tant que Data Engineer, vous Ã©voluez sur des projets IT Ã  forte valeur ajoutÃ©e et avez pour rÃ´le la mise en place de pipelines de donnÃ©es fiables, sÃ©curisÃ©s et Ã  lâ€™Ã©chelle pour soutenir la mise Ã  disposition des donnÃ©es aux cas dâ€™usage mÃ©tier qui en ont besoin.
Vos activitÃ©s principales sont les suivantes :
Vous travaillez avec le client pour Ã©valuer, concevoir, dÃ©ployer, amÃ©liorer et maintenir les pipelines de donnÃ©es 
Vous vous assurez que les pipelines de donnÃ©es crÃ©Ã©s sont rÃ©silients, sÃ©curisÃ©s et accessibles 
Vous dÃ©finissez le modÃ¨le opÃ©rationnel pour monitorer et supporter les pipelines de donnÃ©es 
Vous fournissez une expertise Ã  nos clients sur leurs donnÃ©es pour assurer leur optimisation et leur sÃ©curitÃ© par rapport Ã  leurs besoins 
Vous apportez un savoir en gestion de la qualitÃ© et la gouvernance de la donnÃ©e pour assurer le suivi de la conformitÃ© Ã  la gouvernance de la donnÃ©e 
Vous faites de la veille technologique dans le domaine afin dâ€™enrichir les roadmaps technologiques et fournir des solutions modernes Ã  nos clients.
  En parallÃ¨le de votre mission, vous pouvez Ã©galement intervenir sur des sujets transverses, tels que devenir formateur sur les sujets qui vous animent ou encore participer Ã  des challenges autour de l'innovation et du digital par le biais de notre communautÃ© d'experts. Vous pourrez prendre part Ã  l'accompagnement de vos collÃ¨gues dans leur montÃ©e en compÃ©tences ou encore partagez vos expertises pour enrichir nos savoir-faire.
EpaulÃ©(e) par votre manager projet et votre mentor (que vous avez choisi), vous construisez votre carriÃ¨re de maniÃ¨re active : vous pouvez par exemple vous former via notre Academy interne, ou encore Ã©voluer professionnellement par des mises en situation sur le terrain.
 Ce que nous vous proposons :
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressants : une mutuelle, un CSE, des titres restaurants, un accord dâ€™intÃ©ressement, des primes vacances et cooptation.
Un accompagnement individualisÃ© avec un mentor. Des opportunitÃ©s de carriÃ¨res multiples : plus de 50 mÃ©tiers, autant de passerelles Ã  imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis lâ€™app mobile avec Sopra Steria Academy.
La possibilitÃ© de s'engager auprÃ¨s de notre fondation ou de notre partenaire Â« Vendredi Â». - L'opportunitÃ© de rejoindre le collectif Tech'Me UP (formations, confÃ©rences, veille, et bien plus encore).
Informations supplÃ©mentaires
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
> 
Voir moins","Profil recherchÃ©
Votre profil :
DiplÃ´mÃ©(e) d'une formation supÃ©rieur en informatique type Bac + 5 (Ã©cole ingÃ©nieur, universitÃ© ou Ã©quivalent), vous avez dÃ©jÃ  acquis une expÃ©rience significative en data engineer.
Vous avez au moins l'une de ces compÃ©tences requises :
MaÃ®trise des technologies de bases de donnÃ©es Relationnelles et NoSQL
MaÃ®trise dâ€™au moins un outil dâ€™ETL/ELT (Semarchy, Informatica, Datastage, etc.)
MaÃ®trise des technologies de traitement distribuÃ© de donnÃ©es (Spark, Hadoop)
MaÃ®trise dâ€™au moins un framework de streaming de donnÃ©es (Kafka, RabbitMQ, etc.)
MaÃ®trise de chaines CI/CD et de des bonnes pratiques de DataOps
MaÃ®trise de solution de Virutualisation de donnÃ©es (Denodo, Dremio, etc.)
MaÃ®trise dâ€™au moins un environnement cloud public ou privÃ© (Azure, AWS, Outscale, etc.)
 Vous avez dÃ©veloppÃ© de solides compÃ©tences en matiÃ¨re d'autonomie, d'adaptabilitÃ© et de communication."
Data Engineer H/F/X,"{'name': 'ELEVEN LABS', 'sector': 'Logiciels, IT / Digital, Audit', 'employees': '100 collaborateurs', 'creation_year': '2011', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 2 ans,,"Descriptif du poste
Seras-tu notre furtur.e Data Engineer !
Un peu de contexte
â˜ï¸ De plus en plus de nos consultants sâ€™intÃ©ressent de prÃ¨s au sujet de la Data, ce qui nous a poussÃ© Ã  explorer ces problÃ©matiques chez nos clients et de constater un besoin fort dâ€™accompagnement de leur part.
Nous recherchons donc la personne qui ouvrira la voie Ã  cette expertise chez Eleven Labs et qui accompagnera la crÃ©ation de lâ€™escouade Data !","Profil recherchÃ©
Nos attentes
ğŸ§  Nous recherchons quelquâ€™un dâ€™expÃ©rimentÃ©/e dans la mise en place de pipeline ETL/ELT et data lake / data hub, capable de rÃ©pondre au mieux aux problÃ©matiques qui lui seront soumises, pour qui les requÃªtes SQL, NoSQL sur BDD nâ€™ont aucun secret, et qui maÃ®trise dÃ©jÃ  une ou plusieurs solutions de Data Warehouse (de type BigQuery ou SnowFlake).
ğŸ’ Cerise sur le gÃ¢teau : on cherche aussi un profil maÃ®trisant les langages type Python, Java ou Scala pour customiser les steps, avec bien entendu des connaissances solides sur des outils comme Spark, Jupyter ou encore Cloud Run comme outils de calcul distribuÃ©. Des connaissances dans lâ€™utilisation dâ€™outils ML et dâ€™environnement Cloud en gÃ©nÃ©ral sont un vrai plus.
ğŸ­ CÃ´tÃ© personnalitÃ©, et outre cet aspect expÃ©rimentÃ© et â€œouvreur de voieâ€, on cherche quelquâ€™un de moteur, avec un rÃ©el enthousiasme Ã  transmettre ses connaissances, former et Ã©changer.
Les missions
ğŸ•µï¸ Les missions proposÃ©es te feront intervenir dans des secteurs divers, avec des cas dâ€™usage variÃ©s souvent en lien avec le marketing et impliqueront principalement :
dâ€™Ãªtre force de proposition quant au choix des outils et pratiques ;
Voir plus"
STAGE / ALTERNANCE - Data Engineer @ Startup Juno,"{'name': 'OSS VENTURES', 'sector': 'SaaS / Cloud Services', 'employees': '20 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '32 ans'}","Stage
(4 Ã  12 mois)",Paris,"1,3K â‚¬ par mois",TÃ©lÃ©travail frÃ©quent,,,Bac +5 / Master,"Descriptif du poste
Mission et objectifs
En tant que data engineer, tu seras responsable de la conception, du dÃ©veloppement, de la mise en Å“uvre de stream dâ€™intÃ©gration et de transformation de donnÃ©es (ETL) et de crÃ©ation de dashboard analytics
Nous voulons faire de ton stage une vraie rÃ©ussite, que tu puisses Ã  la fois tâ€™Ã©panouir et devenir un rÃ©el pilier dans notre organisation, lâ€™objectif est de te proposer un CDI Ã  lâ€™issue de ton stage.
Tes missions
Travailler en Ã©troite collaboration avec les dÃ©veloppeurs et les Operations managers pour identifier les problÃ¨mes Ã  rÃ©soudre et concevoir des solutions de data engineering appropriÃ©.
Conception et mise en Å“uvre de pipelines de donnÃ©es robustes pour lâ€™extraction, la transformation et lâ€™ingestion des donnÃ©es (ETL).
DÃ©veloppement de solutions de stockage de donnÃ©es optimisÃ©es pour garantir lâ€™intÃ©gritÃ© et lâ€™accessibilitÃ© des donnÃ©es.
Collaboration Ã©troite avec les Ã©quipe pour dÃ©velopper des stratÃ©gies de visualisation des donnÃ©es qui traduisent les donnÃ©es complexes en insights actionnables.
Assurer la qualitÃ© et la cohÃ©rence des donnÃ©es Ã  travers des tests rigoureux et un suivi continu.
Suivre les derniÃ¨res tendances et technologies en matiÃ¨re de data engineering
Voir moins","Profil recherchÃ©
DiplÃ´me en informatique, en mathÃ©matiques, en statistiques ou dans un domaine connexe.
Tu es polyvalent(e), crÃ©atif(ve) et autonome, avec une bonne capacitÃ© dâ€™adaptation
MaÃ®trise poussÃ©e du SQL exigÃ©e (Postgres, MySql oÃ¹ autre)
MaÃ®trise dâ€™un des langages de programmation tels que Python, NodeJs, etc.
ExpÃ©rience en intÃ©gration de donnÃ©es pour les bases de donnÃ©es relationnelles et non relationnelles avec des ETLs
CapacitÃ© Ã  travailler en Ã©quipe, Ã  communiquer efficacement et Ã  gÃ©rer plusieurs tÃ¢ches simultanÃ©ment.
Tu es passionnÃ©(e) par les nouvelles technologies et/ou par lâ€™industrie"
Stagiaire / Intern Data Engineer,"{'name': 'QUANTCUBE TECHNOLOGY', 'sector': 'Intelligence artificielle / Machine Learning, FinTech / InsurTech, Big Data', 'employees': '55 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '28 ans'}","Stage
(6 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,< 6 mois,Bac +5 / Master,"Descriptif du poste
At the forefront of AI innovation and investment strategies, weâ€™re a leading company on the lookout for a passionate Junior Data Engineer to join our dynamic and rapidly expanding quantitative team. Our mission revolves around setting up cutting-edge technology, fortified infrastructure, and ingenious quantitative methodologies to drive our business and sustain a competitive advantage in the market.
Your primary responsibility will manage the freshly installed infrastructure and systems that lie at the heart of our quant desk. Picture yourself in charge of architecting ingenious trading systems, managing our databases, and maintaining seamless communication with our full-stack developers to continuously enhance and elevate our existing dashboards.
Missions:
You will be a pivotal and essential member of our team. Your assignments will immerse you in the heart of our current projects, providing you with unparalleled opportunities for growth and impact. Your daily tasks will include:
Pioneering the development, rigorous testing, and deployment of quantitative trading systems, databases, and other mission-critical software.
Playing a pivotal role in the architectural decision-making process, architecting scalable solutions to the most intricate challenges that come our way.
Coordinating role between the Quant team and the IT team (full-stack developers and DevOps engineers), ensuring the meticulous management and real-time monitoring of our trading desk dashboard.
Maintaining the pulse of our database, meticulously safeguarding its performance, availability, scalability, and security to ensure it runs like clockwork.
What we offer
At the heart of these assignments lies the opportunity to drive innovation forward in the world of AI and finance. You will have the opportunity to take part to challenging and valuable projects, to communicate directly with our IT, Product and Data Science teams, at the forefront of AI forâ€¯economics and finance.
Youâ€™ll also be joining a multicultural, warm and close-knit team that loves to organise events and activities after work.
A la pointe de lâ€™innovation en matiÃ¨re dâ€™IA et de stratÃ©gies dâ€™investissement, nous sommes une entreprise de premier plan Ã  la recherche dâ€™un ingÃ©nieur de donnÃ©es passionnÃ© pour rejoindre notre Ã©quipe dynamique dâ€™analyst quantitatifs et en pleine expansion. Notre mission consiste Ã  mettre en place une technologie de pointe, une infrastructure fortifiÃ©e et des mÃ©thodologies quantitatives ingÃ©nieuses pour stimuler notre activitÃ© et maintenir un avantage concurrentiel sur le marchÃ©.
Votre principale responsabilitÃ© sera de gÃ©rer lâ€™infrastructure nouvellement mise en place et les systÃ¨mes qui sont au cÅ“ur de notre desk quantitatif. Vous vous imaginez en charge de lâ€™architecture de systÃ¨mes de trading ingÃ©nieux, de la gestion de nos bases de donnÃ©es et du maintien dâ€™une communication transparente avec nos dÃ©veloppeurs full-stack afin dâ€™amÃ©liorer et de rehausser continuellement nos tableaux de bord existants.
Missions :
Vous serez un membre essentiel de notre Ã©quipe. Vos missions vous plongeront au cÅ“ur de nos projets actuels, vous offrant des opportunitÃ©s de croissance et dâ€™impact inÃ©galÃ©es. Vos tÃ¢ches quotidiennes consisteront notamment Ã 
ÃŠtre pionnier dans le dÃ©veloppement, les tests rigoureux et le dÃ©ploiement de systÃ¨mes de nÃ©gociation quantitative, de bases de donnÃ©es et dâ€™autres logiciels critiques.
Jouer un rÃ´le central dans le processus de prise de dÃ©cision en matiÃ¨re dâ€™architecture, en Ã©laborant des solutions Ã©volutives pour relever les dÃ©fis les plus complexes qui se prÃ©sentent Ã  nous.
RÃ´le de coordination entre lâ€™Ã©quipe Quant et lâ€™Ã©quipe IT (dÃ©veloppeurs Full-Stack et ingÃ©nieurs DevOps), assurant la gestion mÃ©ticuleuse et le suivi en temps rÃ©el du tableau de bord de notre trading desk.
Prendre le pouls de notre base de donnÃ©es, en protÃ©geant mÃ©ticuleusement ses performances, sa disponibilitÃ©, son Ã©volutivitÃ© et sa sÃ©curitÃ© afin de sâ€™assurer quâ€™elle fonctionne comme une horloge.
Ce que nous proposons
Au cÅ“ur de ces missions se trouve lâ€™opportunitÃ© de faire avancer lâ€™innovation dans le monde de lâ€™IA et de la finance. Vous aurez lâ€™occasion de participer Ã  des projets stimulants et utiles, de communiquer directement avec nos Ã©quipes IT, Produit et Data Science, Ã  la pointe de lâ€™IA pour lâ€™Ã©conomie et la finance.
Vous rejoindrez Ã©galement une Ã©quipe multiculturelle, chaleureuse et soudÃ©e qui aime organiser des Ã©vÃ©nements et des activitÃ©s aprÃ¨s le travail.
Voir moins","Profil recherchÃ©
Degree in Computer Science, Engineering, Mathematics, or a related quantitative discipline
Knowledge of python packages (requests, beautiful soup, selenium) and SQL database management systems
Strong knowledge of data structures, algorithms, and object-oriented programming
Proficiency in UNIX commands and Linux development
Good development practices: version control, testing
What is a plus :
First experience in Quantitative trading environment
Interest in Finance, trading systems and relevant technology
Strong problem-solving abilities, with an analytical mind and a keen attention to detail
Excellent written and verbal communication skills
QuantCube recruits and recognises all talents.
DiplÃ´me en informatique, ingÃ©nierie, mathÃ©matiques ou dans une discipline quantitative similaire
Connaissance des paquets Python (requests, beautiful soup, selenium) et des systÃ¨mes de gestion de bases de donnÃ©es SQL
Voir plus"
Senior Data Engineer H/F,"{'name': 'QANTEV', 'sector': 'Intelligence artificielle / Machine Learning, FinTech / InsurTech, SaaS / Cloud Services', 'employees': '46 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '29 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
What you will be doing
As a member of the data science and engineering team, alongside our technical experts, you will be able to:
Improve our OCR pipeline deployed on insurance claims data.
Work on our NLP pipelines for medical coding inference and sentiment analysis on hospital reviews.
Enhance our fraud detection machine learning models.
Scale our proprietary patient journey optimizer based on state-of-the-art optimal transport.
Implement and optimize the associated algorithms.
Integrate your contribution in our python/postgresql/elasticsearch stack.
Develop test framework for the models.
Think about the best ways to deploy our machine learning models at scale.
Continuously provide ideas to improve the solution.","Profil recherchÃ©
Preferred Experience
What you need to succeed
3+ years of experience in the field of data engineering and machine learning.
Advanced technical skills in Applied Mathematics, preferably in machine learning,
probabilistic modeling, computer sciences, statistics and/or operations research
Strong analysis and synthesis abilities, not afraid to deal with details.
Proficient knowledge of Python and Deep Learning Frameworks.
Ability to read, understand and implement research papers.
Able to write quality production code and provide coding review to improve the skills of the team.
Fluent in English.
Bonus skills
Working on production-grade projects with good software engineering insights.
Previous experience working within an agile framework.
Previous startup or health insurance experience.
Fluency in a language other than English or French.
Voir plus"
Data Engineer,"{'name': 'THE PRODUCT CREW', 'sector': 'Recrutement', 'employees': '10 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,,
Data Engineer GCP Senior (F/H),"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, CybersÃ©curitÃ©', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232Mâ‚¬', 'mean_age': None}",CDI,La DÃ©fense,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
ğŸ’¥ DÃ©couvrez la Vie Apsidienne ğŸ“¹ et vous aussi, devenez Apsidien
On aurait pu demander Ã  Chat GPT de vous dÃ©montrer en quoi Apside est lâ€™ESN quâ€™il vous faut, mais on prÃ©fÃ¨re que vous le dÃ©couvriez vous-mÃªmes ğŸ‘‡ğŸ˜
ğŸ”¥ DÃ©couvrez votre future mission
ğŸ‘‰ Contexte
Rejoignez notre Practise Cloud/Data, afin dâ€™intervenir sur des sujets Ã  haute valeur ajoutÃ©e !
Secteur â€¯: TÃ©lÃ©com
MÃ©thode de travailâ€¯: Agile Safe
Notre client a besoin dâ€™un accompagnement sur leurs projets mÃ©tiers Data/IA accostant sur un cloud public et Ã  la construction d'outils pour accÃ©lÃ©rer et faciliter cet accostage.
Cela sera rÃ©alisÃ© dans un environnement GCP et en grande majoritÃ© sur des technologies innovantes pour des services Data & IA. La mission sera partagÃ© entre le ""build"" des cas d'usage et outils, et le ""run"" de ces derniers.
ğŸ˜ Mission
Etude et dÃ©finition des architectures GCP, ainsi que leur implÃ©mentation
Mise en application des exigences opÃ©rationnelles (sÃ©curitÃ©, exploitabilitÃ© et industrialisation)
Aiguillage sur nos outils transverse et prÃ©conisations Ã  l'usage du cloud public
Construction d'outillages facilitant l'accostage de ces des projets mÃ©tiers DATA-IA
â€¦
Environnement techniqueâ€¯:
GCP
Git
Gitlab
Bash
Docker
Kubernetes
GitlabCI
ğŸ’° Le package salarial que nous vous proposons
Contratâ€¯: CDI
Avantages groupeâ€¯: carte ticket restaurant Swile, prime de mobilitÃ©, RTT, accord tÃ©lÃ©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle Ã  100% etcâ€¦
Avantages agenceâ€¯: intÃ©gration de la Practise Cloud/Data, afterworks, communautÃ© techlead...
Formationâ€¯: certifications techniques, cours particuliers dâ€™anglais en interne, accÃ¨s Ã  un catalogue de formations grÃ¢ce Ã  notre plateforme e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherchÃ©
ğŸ”® Ã” vous futur Apsidien, qui Ãªtes-vousâ€¯?
Au moins 5 ans d'expÃ©rience en tant que Data Engineer
Maitrise de lâ€™environnement cloud GCP
Force de proposition, bon relationnel et autonome
ğŸ˜ Apside a suscitÃ© votre curiositÃ©â€¯?
Dans un environnement marquÃ© par une accÃ©lÃ©ration des Ã©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients Ã  crÃ©er de la valeur et Ã  adresser leurs enjeux stratÃ©giques en leur mettant Ã  disposition des expertises technologiques (Data / IA, Cloud, Cyber) et une expÃ©rience sectorielle (Industrie, Banque, Assurance, Service, Secteur Public). Pour un accompagnement global, le groupe propose des offres transverses autour du Handicap (Apsidâ€™EA), du Digital Learning, et du Conseil.
ğŸ¤” Et votre place dans tout Ã§aâ€¯?
ğŸ‘‰ Notre volontÃ© est de vous accompagner dans la construction et lâ€™Ã©panouissement de votre carriÃ¨re en nous appuyant notamment sur 3 piliers :
Une rÃ©munÃ©ration Ã  hauteur de vos investissements et de vos compÃ©tences
Voir plus"
Data Engineer AWS Senior (F/H),"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, CybersÃ©curitÃ©', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232Mâ‚¬', 'mean_age': None}",CDI,La DÃ©fense,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
ğŸ’¥ DÃ©couvrez la Vie Apsidienne ğŸ“¹ et vous aussi, devenez Apsidien
On aurait pu demander Ã  Chat GPT de vous dÃ©montrer en quoi Apside est lâ€™ESN quâ€™il vous faut, mais on prÃ©fÃ¨re que vous le dÃ©couvriez vous-mÃªmes ğŸ‘‡ğŸ˜
ğŸ”¥ DÃ©couvrez votre future mission
ğŸ‘‰ Contexte
Rejoignez notre Practise Cloud/Data, afin dâ€™intervenir sur des sujets Ã  haute valeur ajoutÃ©e !
Dans le cadre du renforcement de leur Ã©quipe data, notre client recherche un data ingÃ©nieur qui sera amenÃ© Ã  travailler sur la mise en oeuvre de plusieurs produits data visant Ã  l'exposition et la mise en qualitÃ© des donnÃ©es de rÃ©fÃ©rences.
L'environnement de travail est sur le cloud AWS avec terraform en infra as code
Secteur â€¯: culture/mÃ©dia
MÃ©thode de travailâ€¯: Agile / Scrum
ğŸ˜ Mission
Ingestion et traitement des sources de donnÃ©es
PrÃ©paration des donnÃ©es (transformation fonctionnelle et technique)
Elaboration de systÃ¨me avancÃ© de gestion de qualitÃ© de donnÃ©es
Elaboration d'API/workflow
Exposition des donnÃ©es (Elasticsearch, RDS) via des API pour les applications front
PrÃ©paration des package de livraison en Infra as code
Gestion du cycle de livraison en production
MCO
RÃ©daction des documentations techniques
â€¦
Environnement techniqueâ€¯:
AWS (lambda, EMR, APIGateway, cognito ...)
Python
TerraForm
Git CI/CD
Elasticsearch
PySpark
JSON
SQL (PostgreSQL)
ğŸ“ Localisation
     La DÃ©fense
ğŸ’° Le package salarial que nous vous proposons
Contratâ€¯: CDI
Avantages groupeâ€¯: carte ticket restaurant Swile, prime de mobilitÃ©, RTT, accord tÃ©lÃ©travail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle Ã  100% etcâ€¦
Avantages agenceâ€¯: intÃ©gration de la Practise Cloud/Data, afterworks, communautÃ© techlead...
Formationâ€¯: certifications techniques, cours particuliers dâ€™anglais en interne, accÃ¨s Ã  un catalogue de formations grÃ¢ce Ã  notre plateforme e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherchÃ©
ğŸ”® Ã” vous futur Apsidien, qui Ãªtes-vousâ€¯?
Au moins 5 ans d'expÃ©rience en tant que Data Engineer
Maitrise de lâ€™environnement cloud AWS
Force de proposition, bon relationnel et autonome
ğŸ˜ Apside a suscitÃ© votre curiositÃ©â€¯?
Dans un environnement marquÃ© par une accÃ©lÃ©ration des Ã©volutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients Ã  crÃ©er de la valeur et Ã  adresser leurs enjeux stratÃ©giques en leur mettant Ã  disposition des expertises technologiques (Data / IA, Cloud, Cyber) et une expÃ©rience sectorielle (Industrie, Banque, Assurance, Service, Secteur Public). Pour un accompagnement global, le groupe propose des offres transverses autour du Handicap (Apsidâ€™EA), du Digital Learning, et du Conseil.
ğŸ¤” Et votre place dans tout Ã§aâ€¯?
ğŸ‘‰ Notre volontÃ© est de vous accompagner dans la construction et lâ€™Ã©panouissement de votre carriÃ¨re en nous appuyant notamment sur 3 piliers :
Une rÃ©munÃ©ration Ã  hauteur de vos investissements et de vos compÃ©tences
Voir plus"
Senior Data Engineer M/F,"{'name': 'SPLIO', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Marketing / Communication', 'employees': '250 collaborateurs', 'creation_year': '2001', 'turnover': '26Mâ‚¬', 'mean_age': '33 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,,"Descriptif du poste
About Splio
Splio is a scale-up in the Martech industry with around 30 million ARR. It is headquartered in Paris and employs 220 people (with 90 within the Product and Tech department and across 4 offices (France, Spain, Italy, Tunisia).
In 2023, Splio acquired Tinyclues to integrate their predictive marketing into Splio's CRM and become the European leader in intelligent CRM, allowing brands to easily orchestrate highly personalized marketing at scale through AI.
We are proud to include Longchamp, 3 Suisses, Cojean, Micromania, FNAC, SNCF Connect, Orange, and Samsung among a portfolio of 500 client companies from SME to larger companies across various industries (retail, catering, telecoms, etc.).
To support our growth, we are looking for a Senior Data Engineer to join our R&D team.
Your missions
Build, manage & improve several hundred data pipelines
You are a SQL guru : you are able to find the most cost-effective way to create an asset in our data layer
You are a practitioner of orchestration technologies (Airflow, Kubeflow)
Focus on :
Multi Tenancy : every client has its own data schema, ability to build flexible and configurable KPIs
Scalability : Clientâ€™s data can be big but the computation and scoring we process for our clients are even bigger
Cost efficiency : linked to the amount of data to process for each client, we maintain the cost low to make profit
Stack :
Languages : SQL, Python
Framework/Lib : dbt
Dev Env : GCP, Airflow 
Your responsibilities
Tech (80%)
Contribute to the overall engineering at Splio
Contribute to the development with your team
Proactively ensure that security, reliability, performance and cost-efficiency are included in technical and architectural discussions
Keep up to date with the latest relevant technologies, continually evaluating their use for Splio
Leadership (20%)
As a Senior Data Engineer, you provide guidance, allow teams to discover and learn independently.
You can handle high level of complexity and bring clarity on those complex problems
Actively question decisions and provide guidance and own experience to ensure no stone is left unturned and risks are identified and highlighted
Collaborate with other teams when necessary for the product youâ€™re building
Your Profile
ğŸ› Good technical architectural skills, you are Python fluent with a knowledge of Google Cloud Platform and an experience of BigQuery
ğŸ“£Excellent communication skills to build relationships, trust, and respect
âš™ï¸ A solid background in technology allowing you to handle new technologies & to challenge technical choices
âœ… A strong interest for engineering practices
ğŸ§‘ğŸ»â€ğŸ« Able to lead by example, hands-on and ownership
ğŸ” Comfortable in dealing with change and uncertainty during the software development lifecycle
ğŸ¤¸â€â™‚ï¸ Good knowledge about Agile development practices
ğŸ‡¬ğŸ‡§ Good english skills (speaking and writing)
Perks & Benefits
ğŸŒ´ 12 Splio days (days off), in addition to the 25 legal days off
ğŸ›‹ï¸ Friendly remote policy (5 days on site in one of the cities where thereâ€™s a Splio office)
ğŸ˜‹ A Swile card that you can use for lunch (10â‚¬ per worked day)
ğŸ‘¨â€ğŸ‘©â€ğŸ‘¦â€ğŸ‘¦ Possibility to attend or participate to conferences once or twice a year
Interested in joining Splio ?
30 min video-call with FranÃ§ois Bonicel, VP engineering to get to know you, present the job position and exchange on your qualifications & motivations to join Splio
1 hour technical case in our Paris office to evaluate your hard skills and deep dive into the role
30 min video-call with a member of the HR team to assess your interpersonal skills and give you more information about the company culture & benefits
30 min video-call with our CPTO or CTO for final validation
Voir moins",
Stagiaire Data Engineer,"{'name': 'NAMR', 'sector': 'Big Data', 'employees': '48 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '31 ans'}","Stage
(6 mois)",Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail occasionnel,04 mars 2024,< 6 mois,,"Descriptif du poste
En rejoignant notre Ã©quipe Data Engineering, tu auras les missions suivantes :
ImplÃ©menter et gÃ©rer CI/CD pipelines
Sourcer, analyser, nettoyer, intÃ©grer et documenter les datasets du datalake
Extraire les donnÃ©es issues de ces datasets pour construire les donnÃ©es de notre base de donnÃ©es (attributs)
Maintenir les scripts de mise Ã  jour des flux de donnÃ©es (airflow)
DÃ©velopper lâ€™outil interne de gestion et administration de nos donnÃ©es et mÃ©tadonnÃ©es (Python, SQL)
Contribuer Ã  lâ€™Ã©volution de notre infrastructure de donnÃ©es vers des technologies scalables (Postgresql, BigQuery, Kubernetes) intÃ©grant plusieurs types de donnÃ©es (structurÃ©es, gÃ©olocalisÃ©es, imagerie, texte, etc.)
maintenance de la code base + maitrise des bonnes pratiques de code (Tests unitaires, Ci/CD etc)
Effectuer une veille systÃ©matique des technos, outils et mÃ©thodes de gestion des bases de donnÃ©es","Profil recherchÃ©
Ton parcours : Tu es en Master Computer Science ou en formation dâ€™IngÃ©nieur en Informatique et recherches un stage de fin dâ€™Ã©tudes.
Ta stack technique :
Python, SQL ;
Traitement/nettoyage de donnÃ©e.
Les technologies souhaitables :
Cloud (OVH, AWS, GCS, Azur, Scaleway) ;
Docker ;
QGIS ;
Dataiku ;
Git ;
NoSQL ;
PostgreSQL, PostGIS ;
Airflow
Tes qualitÃ©s humaines :
Voir plus"
Consultant.e Data Engineer ExpÃ©rimentÃ©.e,"{'name': 'THE INFORMATION LAB', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '38 collaborateurs', 'creation_year': '2015', 'turnover': '5Mâ‚¬', 'mean_age': None}",CDI,Paris,45 Ã  60 â‚¬,TÃ©lÃ©travail frÃ©quent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Qui sommes-nous ?
VÃ©ritables passionnÃ©s de data, nous avons construit The Information Lab autour des solutions Tableau, Alteryx et Snowflake. Nous sommes convaincus que ce sont les meilleures technologies pour accomplir la transformation digitale de nos clients.
Notre spÃ©cialisation nous permet dâ€™Ãªtre les premiers partenaires de ces Ã©diteurs et dâ€™Ãªtre les experts reconnus de ces solutions en France et en Europe.
En nous rejoignant vous pourrez partager votre passion avec vos pairs, travailler dans une ambiance dÃ©contractÃ©e pour remplir notre mission : ""Helping people make sense of dataâ€.
Description du poste
RattachÃ©(e) au pÃ´le Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous mÃ©tiers. Vos missions ont pour objet le traitement, lâ€™analyse, lâ€™enrichissement des donnÃ©es de nos clients et lâ€™adoption par nos clients des technologies que nous proposons. Au sein dâ€™une Ã©quipe de 5 Ã  8 personnes, vous rÃ©alisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre â€œpod leaderâ€ (chef dâ€™Ã©quipe).
Votre rÃ´le consiste Ã  :
Intervenir en avant-vente et cadrer vos missions
Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours Ã  quelques mois
Mener des projets de bout en bout, en mÃ©thode classique ou agile, en coordination avec les Ã©quipes de nos clients, nos Ã©quipes internes et les Ã©diteurs partenaires
PrÃ©senter les livrables de vos missions et mettre en avant leur ROI
Former nos clients Ã  nos technologies
Mettre vos compÃ©tences au service de vos collÃ¨gues au-delÃ  des missions dont vous avez la charge et participer au dÃ©veloppement des compÃ©tences en partageant vos retours dâ€™expÃ©rience
Participer aux activitÃ©s dâ€™Ã©vangÃ©lisation, par exemple : rÃ©daction de posts de blogs, participation aux communautÃ©s des Ã©diteurs, interventions lors dâ€™Ã©vÃ©nements (salons, confÃ©rences, webinaires)
Participer aux projets internes (BI interne, mÃ©thodes & qualitÃ©s)
Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires.
Voir moins","Profil recherchÃ©
Vos principales qualitÃ©s :
Excellentes facultÃ©s dâ€™Ã©coute et de communication, orale et Ã©crite
Aptitude Ã  travailler sur plusieurs sujets en parallÃ¨le, Ã  prioriser
HumilitÃ© et capacitÃ© Ã  apprendre ainsi quâ€™Ã  transmettre ses connaissances
Sens du service, un bon relationnel avec les clients et la rigueur nÃ©cessaire au succÃ¨s de leurs projets
Team player
CompÃ©tences mÃ©thodologiques :
Analyse du besoin et cadrage de mission
Construction dâ€™indicateurs mÃ©tiers Ã  partir de donnÃ©es brutes
IdÃ©alement connaissance dâ€™un ou plusieurs mÃ©tiers et de leurs indicateurs clÃ©s
PrÃ©paration de donnÃ©es complexes Ã  des fins dâ€™analyse
MÃ©thodes de gestion de projet (classique et agile)
CapacitÃ© prouvÃ©e Ã  rÃ©aliser des dÃ©monstrations dâ€™outils
CompÃ©tences techniques :
Voir plus"
Lead Data Engineer - Scala (F/H/X),"{'name': 'AVIV GROUP', 'sector': 'Immobilier commercial, Immobilier particulier', 'employees': '1800 collaborateurs', 'creation_year': '2015', 'turnover': '500Mâ‚¬', 'mean_age': None}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 5 ans,,"Descriptif du poste
Rejoignez lâ€™Ã©quipe Marketplace Design AVIV
La marketplace AVIV est le lieu de rencontre privilÃ©giÃ© de tous les acteurs de lâ€™annonce immobiliÃ¨re: potentiels acquÃ©reurs ou locataires, propriÃ©taires ou agents, â€¦ Afin de garder notre position, nous devons fournir la meilleure qualitÃ© de service possible en termes de sÃ©curitÃ©,  de confiance, dâ€™efficacitÃ© et de pertinence des Ã©changes entre ces acteurs. Plusieurs facteurs entrent en ligne de compte: qualitÃ© et sÃ©rieux des prospects et des agents  ainsi que la qualitÃ© des informations affichÃ©es.
Le rÃ´le de lâ€™Ã©quipe Marketplace design est de concevoir et exÃ©cuter toutes les actions nÃ©cessaires pour assurer la satisfaction de nos utilisateurs : qualitÃ© et correction des donnÃ©es, scoring, matching, gamification, et amÃ©lioration continue. Ces actions requiÃ¨rent un usage important des donnÃ©es, lâ€™Ã©quipe Data Operations est responsable de la gouvernance, la modÃ©lisation et  la qualitÃ© des donnÃ©es ainsi que de fournir les data-sets clÃ©s et maintenir une data platform robuste et efficace pour tout le groupe AVIV.
Vos responsabilitÃ©s :
En tant que Lead Data Engineer au sein de lâ€™Ã©quipe Data Operations, vous travaillez en Ã©troite collaboration avec un Product Manager et votre Engineering Manager. Vos dÃ©veloppements respectent les bonnes pratiques en place et sont alignÃ©s avec lâ€™architecture dâ€™entreprise AVIV. Vous apportez votre expertise technique Ã  votre Ã©quipe, vous crÃ©ez, adaptez et amÃ©liorez la qualitÃ© des data-sets et des outils largement utilisÃ©s chez AVIV.
Lâ€™Ã©quipe Data Operations
Lâ€™Ã©quipe est constituÃ©e dâ€™environ 40 personnes, avec notamment:
Coach Agile
Data Engineers
Data Quality Engineers
Data Analysts & Modelers
Devops Engineers
Enterprise & Solution Architects
Product Managers
Les projets
DÃ©centraliser la data et Mettre en place le Data Mesh au sein du groupe Aviv
Fournir les insights sur les usages des diffÃ©rents sites et apps mobiles europÃ©ens  
Notre Stack Technique data
AWS (CloudFormation, EMR, S3, Glue, Athena, Redshift, SNS/SQS)
Spark
Git, CircleCI, Datadog
Scala, Java
Vous avez idÃ©alement des connaissances complÃ©mentaires telles que :
Python 
Apache Airflow, Kubernetes
Jenkins, Argo CD, Grafana, VictoriaMetrics
Voir moins","Profil recherchÃ©
Nous recherchons une personne capable de:
CrÃ©er et maintenir des datasets complexes et Ã  gros volumes selon des spÃ©cifications fonctionnelles prÃ©cises.
Participer Ã  la crÃ©ation dâ€™une infrastructure solide et optimale pour lâ€™extraction, la transformation et le chargement (ETL) de donnÃ©es Ã  partir de nombreuses sources. Utilisation de SQL et de technologies big data cloud.
Identifier, concevoir et implÃ©menter les processus internes dâ€™amÃ©lioration: automatisation, optimisation du delivery, scalabilitÃ©, etcâ€¦
Travailler avec des experts data et donnÃ©es analytiques au dÃ©veloppement de nouvelles fonctionnalitÃ©s 
Maitriser la mÃ©thodologie Agile: communication directe, adaptation, fail fast, amÃ©lioration continue et Software Craftsman
MaÃ®triser le produit et le business, impactant lâ€™amÃ©lioration du service aux clients, du produit et de lâ€™architecture
Rigueur, curiositÃ©, autonomie et Ã©tat dâ€™esprit positif 
Voir plus"
Stage - Data Engineer - Services Financiers - Ãle de France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",Stage,La DÃ©fense,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
Votre futur environnement de travail : 
IntÃ©grÃ©(e) au sein dâ€™une Ã©quipe Data dâ€™une grande banque franÃ§aise, vous Ãªtes amenÃ©(e) Ã  travailler sur des projets dâ€™intelligence artificielle et de nouveaux projets data. 
Vous intÃ©grez une Ã©quipe composÃ©e de 1 responsable de patrimoine ou CP, 1 testeur, 4 profils techniques dont le tuteur du stage et 1 alternant. 
Votre rÃ´le et vos missionsâ€¯:  
Au sein du projet, vous participez Ã â€¯lâ€™ensemble des Ã©tapes clefsâ€¯du projet : 
RÃ©alisation de dossiers de conception, 
Mise en place dâ€™architecture, 
DÃ©veloppement dâ€™algorithmes en java/Angular et/ou Spark/Scala 
RÃ©alisation et automatisation des tests unitaires, 
Phases de qualification. 
Vous intervenez sur Dataiku 
Vous faites partie intÃ©grante de lâ€™Ã©quipe projet Sopra Steria, vous participez aux rÃ©unions dâ€™Ã©quipe projet et vous Ãªtes impliquÃ©(e) dans lâ€™atteinte des objectifs pour rÃ©pondre aux besoins exprimÃ©s par le client.
Les apports du stageâ€¯: 
Participation Ã  un projet de dÃ©veloppement spÃ©cifique. 
Approfondissement de vos compÃ©tences en dÃ©veloppement sur les technologies de lâ€™application.
DÃ©couverte des outils de mÃ©thodologie industrielle dâ€™un grand groupe.
Collaboration avec diffÃ©rents acteurs : Directeurs de projets, Architectes, Consultants, DÃ©veloppeurs.â€¯ 
Encadrement par des experts techniques. 
DÃ©couverte de lâ€™Ã©cosystÃ¨me technique dâ€™un grand compte. 
DÃ©couverte dâ€™un secteur dâ€™activitÃ© en pleine mutation 
Ce que nous vous proposonsâ€¯: 
Progresser et de dÃ©velopper ses compÃ©tencesâ€¯: vous Ã©voluez Ã  travers des expÃ©riences variÃ©es auprÃ¨s des plus grandes entreprises europÃ©ennes. 
Construire un avenir positif en mettant le digital au service de lâ€™humain : grÃ¢ce Ã  la puissance du collectif, nous construisons des solutions sur-mesure ayant un impact rÃ©el.
Evoluer dans une entreprise qui encourage lâ€™audace, la curiositÃ© et la prise de responsabilitÃ©s : explorer de nouvelles voies et exploiter les technologies innovantes qui permettront de mener des transformations au bÃ©nÃ©fice de tous. 
Informations supplÃ©mentaires
Les avantages Ã  nous rejoindre :
Un accord tÃ©lÃ©travail pour tÃ©lÃ©travailler jusquâ€™Ã  2 jours par semaine selon vos missions.
Un package avantages intÃ©ressants : des titres restaurants, accÃ¨s aux subventions des activitÃ©s sociales & culturelles.
PossibilitÃ© de rejoindre la communautÃ© des stagiaires et alternants SPEAK UP pour booster son rÃ©seau.
De trÃ¨s nombreuses opportunitÃ©s en CDI peuvent vous attendre Ã  lâ€™issue du stage !
Employeur inclusif et engagÃ©, notre sociÃ©tÃ© Å“uvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. Câ€™est pourquoi, attachÃ©s Ã  la mixitÃ© et Ã  la diversitÃ©, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherchÃ©
Votre profil :
Vous Ãªtes Ã©tudiant(e) en Ã©cole dâ€™IngÃ©nieur, en Master 2 dâ€™informatique ou Ã©quivalent, et vous recherchez un stage qui allie dÃ©veloppement, intelligence artificielle et relation client.
Vous avez des connaissances dans les langages orientÃ©s objets (Java, C++, C#,...), ou plus largement Devops, Jenkins, Dataiku et les process dâ€™automatisation.
Envie de construire avec nous et nos clients ? Lâ€™esprit dâ€™entreprendre est en vous ? Le dÃ©fi vous motive ? Alors, nâ€™hÃ©sitez plus, rejoignez sans plus attendre les Ã©quipes digitales de Banque Paris !"
Data Engineer H/F,"{'name': 'CAPGEMINI', 'sector': 'IT / Digital, Organisation / Management, StratÃ©gie, Transformation', 'employees': '360000 collaborateurs', 'creation_year': '1967', 'turnover': '18 Mds â‚¬', 'mean_age': '37 ans'}",CDI,Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 3 ans,Bac +5 / Master,"Descriptif du poste
  Vous Ãªtes passionnÃ© par le domaine de la Data, vous souhaitez prendre part Ã  des projets d'envergure, concevoir des solutions, les implÃ©menter et les faire Ã©voluer?
Alors rejoignez notre Ã©quipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.
Vous avez acquis une expÃ©rience solide dans le dÃ©veloppement, la mise en Å“uvre et lâ€™optimisation de solutions pour le traitement d'un grand volume de donnÃ©es, vous Ãªtes capable de crÃ©er des solutions qui rÃ©pondent aux besoins mÃ©tiers et IT, alors rejoignez notre Ã©quipe dâ€™experts.
 En qualitÃ© de Data engineer, vos missions sont les suivantes :
â–ª Concevoir et dÃ©velopper des solutions Data/IA.
â–ª Accompagner les MÃ©tier dans la comprÃ©hension et la mise en Å“uvre de solution orientÃ©es donnÃ©es.
â–ª Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et dâ€™infrastructures axÃ©es sur les donnÃ©es.
â–ª GÃ©rer un Ã©cosystÃ¨me de partenaires data et assurer un haut niveau d'expertise
â–ª Assurer un rÃ´le de veille technologique sur tous les outils autours de la data, de lâ€™IA et de la BI.
  Avec nous, votre futur ressemblera Ã  :
Des projets dâ€™envergure, variÃ©s et passionnants
Des clients grands comptes de tous secteurs
Des Ã©volutions avec une offre de formation solide
Des Ã©changes avec une communautÃ© dâ€™experts trÃ¨s actives
Un accompagnement de proximitÃ©.
 Voir moins","Profil recherchÃ©
Description du profil :

Vous Ãªtes issu dâ€™une formation ingÃ©nieur ou Ã©quivalent bac+5 informatique spÃ©cialisÃ©e en DATA et vous justifiez dâ€™une expÃ©rience dâ€™au moins 5 ans dans un rÃ´le similaire. Expert dans une technologie de base de donnÃ©es relationnelle (PostgreSQL, Oracleâ€¦)
Expert dans une technologie de base NoSQL (MongoDB, Cassandraâ€¦)
Vous maitrisez un framework de manipulation de donnÃ©es (Hadoop, Spark, Kafkaâ€¦)
Vous maitrisez les concepts DevOps et avez de bonnes notions en scripting et dÃ©veloppement
Vous avez une expÃ©rience des outils BI et de data visualisation (Kibana, PowerBIâ€¦)
La maitrise de lâ€™anglais est nÃ©cessaire. 


Nous proposons :

Et pour (finir de) vous convaincre, on vous en dit un peu plus sur nous :
Les avantages aussi nombreux que variÃ©s :
Voir plus"
Data Engineer Senior - CDI - Paris ou Caen,"{'name': 'JAKALA', 'sector': 'Digital Marketing / Data Marketing, Big Data, E-commerce', 'employees': '150 collaborateurs', 'creation_year': '2023', 'turnover': '15Mâ‚¬', 'mean_age': '31 ans'}",CDI,"Salaire :
Non spÃ©cifiÃ©",TÃ©lÃ©travail frÃ©quent,,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Au sein de notre Data Lab, vous travaillerez conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer dÃ©jÃ  en poste et vous serez impliquÃ©.e dans la prise de dÃ©cisions liÃ©e Ã  notre solution Data et Ã  son Ã©volution.
A cet effet, vous Ãªtes en charge de :
Contribuer au dÃ©veloppement de notre offre Data et Ã  lâ€™industrialisation de plateformes data pour nos clients
Comprendre, analyser et proposer des solutions techniques rÃ©pondant aux besoins des Plateformes digitales et des projets internes,
DÃ©finir lâ€™architecture logiciel ETL / ELT en collaboration avec vos pairs
Travailler la donnÃ©e sous toutes ses formes (stockage, Ã©laboration de modÃ¨les, structuration, nettoyage),
RÃ©diger de la documentation technique (diagrammes UML, documentation dâ€™API, â€¦),
Partager votre savoir-faire entre les diffÃ©rents membres de lâ€™Ã©quipe,
Concevoir et dÃ©velopper des connecteurs entre les sources de donnÃ©es (internes et/ou externes) et la plateforme,
Concevoir et dÃ©velopper des pipelines de traitements de donnÃ©es (batch et/ou temps rÃ©el) dans un environnement Big Data,
Assurer une veille technologique et savoir mener Ã  bien un projet de R&D.
Vous assurez en autonomie les missions suivantes en interne ou auprÃ¨s de nos clients grands comptes :
Cartographier des donnÃ©es et des flux de donnÃ©es
ImplÃ©menter des algorithmes dâ€™analyse de donnÃ©es pour lâ€™industrialisation
Collecter, consolider et modÃ©liser de gros volumes de donnÃ©es (Big Data, Data Warehouses, Data Lakes)
DÃ©velopper et automatiser des flux de donnÃ©es et leurs visualisations en dashboards, reporting
Sâ€™assurer de la scalabilitÃ©, sÃ©curitÃ©, stabilitÃ© et disponibilitÃ© des donnÃ©es de la plateforme
Analyser les donnÃ©es web pour rÃ©pondre aux questions mÃ©tiers et participer Ã  la construction de lâ€™architecture Big Data
Mettre en place du sÃ©quencement et de la supervision des flux prÃ©citÃ©es en gÃ©rant les cas limites
CompÃ©tences attendues :
Bon niveau en dÃ©veloppement :
De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)
De script ELT : DBT (ex. Snowflake, PostgreSQL)
Connaissance conception et administration dâ€™entrepÃ´t de donnÃ©es : Snowflake, Big Query, PostgreSQL
LakeHouse: Delta LakeConnaissance message broker : RabbitMQ, Kafka
CompÃ©tences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)
ExpÃ©rience dâ€™architecture et de dimensionnement dâ€™une architecture cloud via des services managÃ©s
Cartographie des donnÃ©es
Voir moins","Profil recherchÃ©
DiplÃ´mÃ©Â·e dâ€™Ã©tudes supÃ©rieures dans le systÃ¨me dâ€™information, computer sciences, big data (Ã©cole dâ€™ingÃ©nieurs, Ã©cole spÃ©cialisÃ©e ou Ã©quivalent universitaire), vous justifiez dâ€™au moins 5 ans en Data engineering.
Vous avez une expertise reconnue sur la mise en place de pipelines complets de valorisation de donnÃ©es massives, de la collecte Ã  la mise Ã  disposition dâ€™applications en passant par le traitement.
La maÃ®trise de lâ€™anglais est apprÃ©ciÃ©e.
CertificationÂ·s indispensableÂ·s : GCP Professionnal Data Engineer OU Azure Data Engineer Associate OU AWS Solution Architect.
Vous Ãªtes passionnÃ©Â·e par votre mÃ©tier, aimez le faire partager."
Data Architect / Data Engineer - CDI - Paris,"{'name': 'JAKALA', 'sector': 'Digital Marketing / Data Marketing, Big Data, E-commerce', 'employees': '150 collaborateurs', 'creation_year': '2023', 'turnover': '15Mâ‚¬', 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
SOYHUCE est Ã  la recherche dâ€™unÂ·e Data architect / Data Engineer afin dâ€™accompagner techniquement et opÃ©rationnellement le Data Lab (Data Scientist, Data Engineer, Data Analystes, MLOps â€¦) et travailler Ã©troitement avec les Ã©quipes IT pour le dÃ©veloppement des projets.
Vous contribuez ainsi aux grands programmes innovants et stratÃ©gique du groupe.
Vos missions au quotidien :
GÃ©rer lâ€™environnement Big Data (GCP) et dâ€™en assurer la stabilitÃ© et  lâ€™optimisation dans le cadre des projets DATA inscrits dans la Roadmap
ImplÃ©menter des flux de collecte, de transformation et de stockage des donnÃ©es multi- sources
Automatiser le processus de structuration de la DATA en amont de lâ€™intervention dâ€™un Data Scientist (crÃ©ation et maintenance du code)
Concevoir et automatiser le processus de structuration de la DATA et des outils nÃ©cessaires permettant aux experts de lâ€™Ã©quipe un accÃ¨s facile aux donnÃ©es pour dÃ©velopper les cas dâ€™usage mÃ©tier (Data science/IA, Reporting, Analytics, Activation mÃ©dia, â€¦)
ÃŠtre lâ€™interlocuteur privilÃ©giÃ©  de lâ€™Ã©quipe Architecture IT pour assurer un avancement conjoint sur les sujets Data prioritaires
Assurer avec lâ€™IT le processus de qualitÃ© et la fiabilitÃ© des flux de donnÃ©es (scalabilitÃ©, sÃ©curitÃ©, performance, recovery) en conformitÃ© avec les standards dÃ©finis par la sÃ©curitÃ© du groupe
Assurer la rÃ©daction et la maintenance  dâ€™une documentation claire sur les diffÃ©rents projets dÃ©veloppÃ©s
Assurer la mise en production des projets DATA
Ã‰valuer lâ€™architecture et lâ€™environnement DATA actuels et prÃ©voir des mises Ã  jour nÃ©cessaires selon les besoins de lâ€™Ã©quipe. (ex. intÃ©gration nouveaux outils de Data Prep)
DÃ©velopper les APIs/ connecteurs nÃ©cessaires pour intÃ©grer notre DATA dans les plateformes AdTech 3rd (ex DSP/SSP MÃ©dia)
CompÃ©tences techniques :
MaÃ®trise des solutions Cloud GCP (BigQuery, DataProcâ€¦) et AWS (RDS, EMRâ€¦)
Langages SQL, NoSQL, Python, Râ€¦
ModÃ©lisation, traitement et transformation des donnÃ©es complexes et multi-sources
Conception et dÃ©ploiement dâ€™une architecture distribuÃ©e pour le traitement de donnÃ©es
Maitrise des aspects dâ€™authentification, de sÃ©curitÃ©, de containerisation et dâ€™orchestration
Maitrise des technologies: Spark, Kafka, Couchbase, Cassandra, Solr, Suite ELK, Redis, SQL Server, PostgreSQL, Docker, Kubernetes
Outils : Tableau et PowerBI
Voir moins","Profil recherchÃ©
DiplÃ´me Bac + 5, ingÃ©nieur ou Ã©quivalent universitaire ou ayant dÃ©montrÃ© ses compÃ©tences dans lâ€™architecture DATA.
PassionnÃ©Â·e de la data avec au moins 5 ans dâ€™expÃ©rience dans des rÃ´les Data Architect, Architecture ou similaire, vous possÃ©dez les qualitÃ©s suivantes :
Esprit dâ€™Ã©quipe et sens de lâ€™Ã©coute
Autonomie et proactivitÃ©
CuriositÃ© et crÃ©ativitÃ©
Sens relationnel et capacitÃ© dâ€™adaptation
Rigueur
Esprit dâ€™analyse"
Data Engineer GCP (H/F),"{'name': 'THALES', 'sector': 'Logiciels, CybersÃ©curitÃ©, AÃ©ronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mdsâ‚¬', 'mean_age': None}",CDI,Bordeaux,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Nos Ã©quipes de lâ€™activitÃ© SystÃ¨mes dâ€™information critiques et cybersÃ©curitÃ© fournissent des services et des solutions globales optimisant la performance, la rÃ©silience et la sÃ©curitÃ© des systÃ¨mes dâ€™information afin de faire face aux ruptures technologiques et aux cybermenaces.
THALES Bordeaux recherche un IngÃ©nieur Data / GCP (H/F) :
CDI (pas de full-remote ni freelance)
2 jours de tÃ©lÃ©travail par semaine
Site : MÃ©rignac (33700)
QUI ETES-VOUS ?
De formation supÃ©rieure en Informatique/Data (Bac+5 ou supÃ©rieur), vous disposez d'une expÃ©rience professionnelle dâ€™au moins 3 ans dans lâ€™utilisation de technologies cloud, et notamment GCP. Vous avez gÃ©rÃ© des projets industrialisÃ©s en data engineering et/ou IA, et souhaitez continuer Ã  Ã©voluer dans ces deux domaines.
Vous maÃ®trisez les outils de cloud, Data Analytics et les techniques de traitement de donnÃ©es. Vous avez une expÃ©rience du travail DevOps, de l'automatisation et la surveillance continues tout au long du cycle de vie des applications (approche CI/CD).
Vous connaissez au moins le langage de programmation PYTHON ainsi que les bases de donnÃ©es (postgreSQL) et leur langage associÃ© (SQL...). Vous savez vous adapter Ã  diverses technologies et outils, et tirer parti de la meilleure solution pour rÃ©pondre aux exigences du client.
Votre rigueur, votre esprit d'Ã©quipe et vos qualitÃ©s relationnelles sont autant d'atouts qui vous permettront de rÃ©ussir dans vos missions.
CE QUE NOUS POUVONS FAIRE ENSEMBLE :
Au sein de projets Agile, vous aurez pour mission de :
Concevoir et dÃ©velopper des pipelines de traitements de la donnÃ©e
Collaborer avec lâ€™Ã©quipe pour le respect des dÃ©lais de livraisons dans une organisation en mode Agile
Utiliser des outils comme Google Cloud Platform (GCP) pour rÃ©aliser des traitements IA et Data
RÃ©flÃ©chir Ã  la sÃ©curisation des donnÃ©es confidentielles
Contribuer au dÃ©veloppement des cas dâ€™usage mÃ©tier, apporter de la valeur et de lâ€™innovation en utilisant les outils Ã  disposition
Participer aux projets dâ€™Ã©volutions en apportant votre analyse technique et fonctionnelle
Innovation, passion, ambition : rejoignez Thales et crÃ©ez le monde de demain, dÃ¨s aujourdâ€™hui.
Voir moins",
STAGE - Data Engineer,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",Stage,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail frÃ©quent,,,,"Descriptif du poste
La mission dâ€™AXA est de Â« donner Ã  chacun les moyens de vivre une vie meilleure Â». Nous souhaitons alors passer du rÃ´le de payeur Ã  celui de partenaire. La mission de notre division, AXA Group Operations (GO), est de soutenir et responsabiliser lâ€™ensemble des Ã©quipes dâ€™AXA afin de concrÃ©tiser cette ambition commune.
Lâ€™innovation et lâ€™exÃ©cution sont nos principaux leviers pour atteindre cet objectif. Ils guident lâ€™ensemble des Ã©quipes de GO au quotidien : Innovation : crÃ©er et fournir les bases et opportunitÃ©s aux Ã©quipes dâ€™AXA qui dÃ©velopperont des solutions innovantes afin de rÃ©pondre aux besoins de nos clients actuels et futurs ;
ExÃ©cution : crÃ©er lâ€™environnement qui permettra Ã  nos Ã©quipes Ã  travers le monde, de donner vie Ã  leurs idÃ©es et de tenir les promesses faites Ã  nos clients.
Nos objectifs concrets sont de :- Renforcer la crÃ©ation de valeur pour lâ€™ensemble du groupe AXA ;- Soutenir et encourager l'innovation au sein d'AXA, en collaboration avec la division Group Business Innovation ;- Automatiser et intÃ©grer la simplicitÃ© dans notre travail quotidien, en nous assurant de contribuer efficacement Ã  la mission et stratÃ©gie dâ€™AXA.
Les Ã©quipes de Group Operations sont alors composÃ©es de :
Group IT : dÃ©finit la stratÃ©gie IT globale dâ€™AXA ; favorise la convergence de lâ€™IT au sein des entitÃ©s et leur fournit des services partagÃ©s ;
Group Security : protÃ¨ge les salariÃ©s, nos parties prenantes et la marque AXA en sÃ©curisant les informations et gÃ©rant les cyber sÃ©curitÃ©, la sÃ©curitÃ© physique ainsi que la rÃ©silience des opÃ©rations ;
REV: dÃ©finit les ambitions concernant la maturitÃ© des donnÃ©es du Groupe ; construit et gÃ¨re la communautÃ© ; conduit la recherche et lâ€™expertise ; assiste les entitÃ©s les moins matures en termes de donnÃ©es ;
Technology Innovation : identifie les technologies de pointe et en dÃ©veloppe des disruptives pour les entitÃ©s ; crÃ©e des cas dâ€™usage sur des technologies spÃ©cifiques avec les entitÃ©s ;
Group Procurement : dÃ©finit la stratÃ©gie dâ€™achats dâ€™AXA, ses lignes directrices et les normes du Groupe ; gÃ¨re les relations avec nos fournisseurs stratÃ©giques et accÃ©lÃ¨re les achats mÃ©tiers ;
Group Strategic Program Management : sâ€™assure de la cohÃ©rence des projets globaux avec la stratÃ©gie du Groupe ; veille Ã  la mise en Å“uvre et performance des projets stratÃ©giques ;
AXA Business Services : offre des services partagÃ©s alignÃ©s aux prioritÃ©s commerciales dâ€™AXA ;
Group Operations Transformation : accÃ©lÃ¨re la transformation agile au sein de Group Operations ; Ã©tablit et met en Å“uvre une communication et stratÃ©gie RH commune Ã  notre division.
Dans ce contexte, vous intÃ©grerez le dÃ©partement  Data, BI and Analytics pour rejoindre une Ã©quipe projets en charge du dÃ©veloppement de solutions data pour les entitÃ©s. Le dÃ©partement Data, BI & Analytics propose des produits aux entitÃ©s du Groupe AXA pour stocker la donnÃ©e (datalake), la transformer, lâ€™agrÃ©ger et la visualiser. Notre catalogue de services sâ€™appuie sur 3 piliers :
Le CoE (Center of Excellence) qui joue un rÃ´le dâ€™expertise et de conseil vis-Ã -vis des entitÃ©s (formation, R&D, expertise fonctionnelle et technique, UXâ€¦)
Le Delivery - projet et BAU â€“ qui implÃ©mente et maintient les produits (IT Services, qualitÃ© de service, support, Ã©volutionsâ€¦)
La Factory qui implÃ©mente et maintient les couches techniques des applications (CI/CD, monitoring de plateforme, capacity managementâ€¦).
Dans ce contexte, le dÃ©partement Data, BI & Analytics prend en charge le cycle complet des produits et services : avant-vente, delivery du projet, exploitation et maintenance des solutions.
VOS MISSIONS : 
Construire et maintenir des composents Microsoft BigData & BI
DÃ©velopper des rapports BI
Interagir avec une Ã©quipe et le tech lead
Ecrire et maintenir la document technique autour dâ€™une application
Mener de courtes missions en autonomie autour des besoins dâ€™une application (rÃ©soudre les incidents techniques)
Nous cÃ©lÃ©brons l'expertise, la diversitÃ© culturelle et la crÃ©ativitÃ© de plus de 8 000 employÃ©s de par le monde.  Nous nous engageons Ã  assurer l'Ã©galitÃ© des chances en matiÃ¨re d'emploi (paritÃ© hommes-femmes, communautÃ© LGBT+, personnes handicapÃ©es ou personnes d'origines diverses) et Ã  promouvoir la diversitÃ© et l'inclusion en crÃ©ant un environnement de travail oÃ¹ tous les employÃ©s sont traitÃ©s avec dignitÃ© et respect, et oÃ¹ les diffÃ©rences individuelles sont valorisÃ©es.
Voir moins","Profil recherchÃ©
PROFIL : Etudiant en Ã©cole d'ingÃ©nierie Ã  la recherche d'un stage de 4-6 mois.
Vous dÃ©velopperez vos compÃ©tences sur :
Le travail dans un contexte internationnal (anglais)
Vos connaissances en traitement de donnÃ©es et les bonnes pratiques
Vos capacitÃ©s Ã  travailler en Ã©quipe
Vos capacitÃ©s Ã  rÃ©soudre les problÃ¨mes et incidents techniques 
CompÃ©tences techniques / Hard skills:
Python
SQL Server
DAX (serait un plus)
Langues : FranÃ§ais (bilingue), anglais(opÃ©rationnel)
Outils informatiques :
Office 365 (EXCEL)
PowerBI
Plateforme Cloud Azure"
Data Engineer,"{'name': 'WEWYSE', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Transformation', 'employees': '60 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spÃ©cifiÃ©,TÃ©lÃ©travail non autorisÃ©,,> 1 an,Bac +5 / Master,,

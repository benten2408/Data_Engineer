
title,company,contract_type,location,salary,remote_type,starting_date,require_experience,education,description,profil_experience,publication_date,url_direct_offer,source
Consultant.e Data Engineer Expérimenté.e,"{'name': 'THE INFORMATION LAB', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '38 collaborateurs', 'creation_year': '2015', 'turnover': '5M€', 'mean_age': None}",CDI,Paris,45K à 60K €,Télétravail fréquent,,,,"Descriptif du poste
Qui sommes-nous ?
Véritables passionnés de data, nous avons construit The Information Lab autour des solutions Tableau, Alteryx et Snowflake. Nous sommes convaincus que ce sont les meilleures technologies pour accomplir la transformation digitale de nos clients.
Notre spécialisation nous permet d’être les premiers partenaires de ces éditeurs et d’être les experts reconnus de ces solutions en France et en Europe.
En nous rejoignant vous pourrez partager votre passion avec vos pairs, travailler dans une ambiance décontractée pour remplir notre mission : ""Helping people make sense of data”.
Description du poste
Rattaché(e) au pôle Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous métiers. Vos missions ont pour objet le traitement, l’analyse, l’enrichissement des données de nos clients et l’adoption par nos clients des technologies que nous proposons. Au sein d’une équipe de 5 à 8 personnes, vous réalisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre “pod leader” (chef d’équipe).
Votre rôle consiste à :
Intervenir en avant-vente et cadrer vos missions
Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours à quelques mois
Mener des projets de bout en bout, en méthode classique ou agile, en coordination avec les équipes de nos clients, nos équipes internes et les éditeurs partenaires
Présenter les livrables de vos missions et mettre en avant leur ROI
Former nos clients à nos technologies
Mettre vos compétences au service de vos collègues au-delà des missions dont vous avez la charge et participer au développement des compétences en partageant vos retours d’expérience
Participer aux activités d’évangélisation, par exemple : rédaction de posts de blogs, participation aux communautés des éditeurs, interventions lors d’événements (salons, conférences, webinaires)
Participer aux projets internes (BI interne, méthodes & qualités)
Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires.
Vos principales qualités :
Excellentes facultés d’écoute et de communication, orale et écrite
Aptitude à travailler sur plusieurs sujets en parallèle, à prioriser
Humilité et capacité à apprendre ainsi qu’à transmettre ses connaissances
Sens du service, un bon relationnel avec les clients et la rigueur nécessaire au succès de leurs projets
Team player
Compétences méthodologiques :
Analyse du besoin et cadrage de mission
Construction d’indicateurs métiers à partir de données brutes
Idéalement connaissance d’un ou plusieurs métiers et de leurs indicateurs clés
Préparation de données complexes à des fins d’analyse
Méthodes de gestion de projet (classique et agile)
Capacité prouvée à réaliser des démonstrations d’outils
Compétences techniques :
Connaissance d’au moins Alteryx Designer ou Tableau Prep (idéalement vous avez déjà une expérience solide sur ces outils)
Maîtrise d’autres outils d’analyse de données
Connaissance de la modélisation de données à des fins d’analyse
Expérience professionnelle : vous bénéficiez d’au moins 5 ans d’expérience professionnelle, dont 3 ans sur un poste similaire ou dans un poste qui vous aura permis d’utiliser les technologies similaires aux nôtres. Idéalement, vous avez déjà une expérience dans un cabinet de conseil ou une ESN.
Langues : Français, Anglais professionnel
Quoi d’autre ?
Situation géographique : Ile-de-France. Déplacements en France à prévoir.
Rémunération : 45 à 60 k€, selon expérience.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/the-information-lab/jobs/consultant-e-data-engineer-experimente-e_paris?q=b1e4ccff4b9d21c0fa151eb3db602b6b&o=be1cfe82-a153-4098-a40a-c5d04d362922&p=true,wttj
Data Engineer,"{'name': 'LESAFFRE', 'sector': 'Pharmaceutique / Biotechnologique, Agroalimentaire / Nutrition animale', 'employees': '11000 collaborateurs', 'creation_year': '1853', 'turnover': '2.7 milliards', 'mean_age': '41 ans'}",CDI,Marcq En Baroeul,Non spécifié,Télétravail occasionnel,,> 5 ans,,"Descriptif du poste
Lesaffre Digital & Data ambitions 
Lesaffre’s Digital & Data journey started some years’ ago with a strong push to encourage and cross-fertilize initiatives across the organization. Business impact of some of these first actions (Sales efficiency tools, My Lesaffre App for Bakers, digitalization of key operations etc…) have confirmed the importance of accelerating this journey.
Digital & Data are to become a fundamental transformative force for Lesaffre growth. On one hand, as a lever to increase customer centricity and user experience. On the other, to bring operational excellence across the company.
More concretely, some of these opportunities are: 
Further empower salesforce & leverage digital marketing to capture, convert and keep our future and current clients and consumers  
Leverage omnichannel strategies to sell, serve and delight our customers
Turn our industrial operations even more intelligent and efficient (digitalization of processes, automatization of low added value tasks, industrial productivity, supply chain performance …)
Contribute to unlocking further value and efficiency on R&D processes
Empowering transversal functions to deliver better user experiences
To accelerate this journey, a substantial additional effort is being put in place. The recent arrival of a Chief Digital & Data Officer (ExCom member) has marked the beginning of this acceleration. With a more structured and results oriented journey, CD&D officer is creating a new organisation. Data and Tech is at the heart of the transformation. A Data and Tech Factory has been created to valorise Lesaffre’s data assets, and deliver use cases, governance capacities, and innovation. Both embedded in the Business and at a Global level, digital & data talents will be crucial to this transformative journey both in the impact to business as well as the development of D&D capabilities.
In this context, Lesaffre is recruiting a Data Engineer
This position will be part of the Data & Tech Factory and will report to the Head of Data Architecture and Engineering. You will play a pivotal role in shaping our data use cases and driving our data mesh strategy forward. You will collaborate with cross-functional teams to collect, transform, and deliver high-quality data for analytics, insights, or AI driven solutions. You will be responsible for developing and maintaining our data products, ensuring data quality, and optimizing performance in a cloud-native environment.
Key Responsibilities:
Develop and maintain data products to ingest data from various sources into our cloud-based data store.
Implement data integration strategies that align with the Data Mesh architecture principles.
Transform raw data into usable formats suitable for analytics, adhering to best practices for data quality and consistency.
Implement data processing and transformation logic using state-of-the-art technologies.
Implement data quality checks and data validation processes to ensure the integrity of the data.
Optimize data pipelines and processes for performance and scalability in a cloud-based environment.
Monitor and troubleshoot data pipeline issues, ensuring minimal downtime.
Utilize cloud services (e.g., AWS, Azure, GCP) for data storage, processing, and orchestration.
Stay up to date with cloud technologies and leverage them to enhance data engineering capabilities.
Work closely with data scientists, analysts, and other stakeholders to understand their data requirements and provide timely data products solutions.
When required, participate and collaborate to enforce data governance policies and standards.
Voir moins","Profil recherché
There is no such thing as a ‘perfect’ candidate. Lesaffre is a place where you can grow and in which whatever background you come with will be a plus. If you feel excited about the position, we strongly encourage you to apply even if you meet only two third the requirements.
Proven experience as a Data Engineer, with a focus on cloud-based solutions.
Solid programming skills in one or more programming languages, including at least Python
Experience with data orchestration and workflow management tools (e.g., Apache Airflow).
Understanding of data modeling and database design principles.
Experience working with both relational and non-relational databases (Postgresql, Cassandra, MongoDB, RDS, DynamoDB)
Ability to work effectively in a cross-functional and collaborative team environment.
Experience working with container management tools such as Docker.
Knowledge of cloud data storage technologies (Snowflake, NoSQL, S3)
Voir plus",2024-02-23,https://www.welcometothejungle.com/fr/companies/lesaffre/jobs/data-engineer_marcq-en-baroeul?q=ef902e83f94cc3417877b26437a07dbc&o=3d6113d9-e31a-4965-bce9-13143bd0d18a,wttj
Data Engineer - Transport,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spécifié,Télétravail fréquent,05 février 2024,,,"Descriptif du poste
L’environnement data vous anime, vous êtes sensibles par les enjeux de transitions énergétiques et environnementaux.
MP DATA recrute un(e) Data Engineer - Data visualisation (H/F) afin de travailler pour des projets auprès d’un acteur majeur du Transport.
Conception et développement de solutions permettant la collecte, l’organisation, le stockage et la modélisation des données. Ceux-ci doivent être suffisamment sécurisés et lisibles pour les Data Analysts et Data Scientists,
Mise à jour permanente sur les technologies et les langages utilisés dans le but de partager ses connaissances et aider à l’avancement des projets,
Contribution, sous la responsabilité opérationnelle de notre Architecte, aux meilleures pratiques, normes, politiques, méthodes, outils et procédures sur le Cluster Big Data,
Assurer l’accès aux différentes sources de données, et veiller à la qualité des données,
Donner un accès facilité aux Data Analysts et Data Scientists afin exploiter les données dans des conditions optimales,
Accompagné par les équipes internes MP DATA, vous monterez en compétences sur le management des flux de données pour l’ingénierie (pré processing, feature engineering…), la modélisation et enfin l’industrialisation de vos modèles.
Voir moins","Profil recherché
Ingénieur d’une grande école (Centrale, Mines, Supaero, Supelec, …), vous avez des connaissances en modélisation et machine learning (deep learning, random forest, svm…) acquises lors de votre scolarité ou de vos expériences passées (stage ou césure) vous avez de bonnes connaissances en Python pour coder ces algorithmes. Suite à votre cursus ingénieur ou vos expériences professionnelles, vous disposez de appétences métiers dans les domaines de l’aéronautique, énergie, transport, etc…
Vous êtes intéressés pour vous dépasser en data science & data engineering et vous avez des premières expériences dans ce domaine, comme par exemple :
Spark / PySpark
Kafka
Cloud : AWS / GCP / Azure
Technologies de stockage : Snowflake / S3 / GCS / Azure Blob
Git Lab
SQL : Postgres / MongoDB
CI/CD.
Voir plus",2024-02-23,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-transport_boulogne-billancourt?q=ef902e83f94cc3417877b26437a07dbc&o=9132eb47-99ff-44f2-809b-f0819ee9671d,wttj
Data Engineer Spark Scala H/F,"{'name': 'SKIILS', 'sector': 'Intelligence artificielle / Machine Learning, Transformation, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2020', 'turnover': '11M€', 'mean_age': '34 ans'}",CDI,,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
🪄Tu as le pouvoir de créer des pipelines capables de transformer des données en véritables trésors exploitables, alors tu es peut-être notre Super Data Engineer !
🎯Tu es prêt à affronter des défis titanesques, à gérer des montagnes de données, à défendre la résilience des systèmes, et à affronter des flux de données massifs, l’équipe DATA Factorii t’ouvre ses portes comme un véritable repaire de super-héros !
🚀En tant que Super Data Engineer - Spark Scala H/F, tes missions seront de :
·         Définir et déployer le socle technologique d’un Datalake
·         Conseiller et concevoir une architecture de données
·         Implémenter l’intégration des données au sein du Datalake
·         Identifier, étudier et prototyper des cas d’usage stratégiques
·         Industrialiser les projets Big Data en environnement cloud
·         Implémenter les méthodologies Devops pour optimiser les processus de développement
·         Participer à l’estimation des besoins utilisateurs.
·         Concevoir du code et le documenter.
·         Collaborer étroitement au sein de l’équipe SCRUM, comprenant le Product Owner, les développeurs, Quality Analyst, et le support, pour assurer le succès des projets.
🎁 Ce que nous t’offrons ?
·         Un salaire qui évolue comme une rock star sur scène !
·         Une carrière à la “James Bond” : à moyen et long terme, c’est toi le héros !
·         Ta mutuelle et ton titre de transport pris en charge à 100% (bye-bye les frais) !
·         Télétravail partiel : l’équilibre parfait entre pyjama et costume !
Et surtout, la chance de t’investir dans des projets ultra cool qui te propulseront techniquement vers l’infini et au-delà ! 🚀
Voir moins","Profil recherché
En 1er, un savoir être qui correspond à l’ADN de skiils !
·         Les processus agiles, c’est ton super-pouvoir ! Le Manifeste Agile, c’est ton livre de chevet, toujours prêt à l’action.
·         Comprendre l’environnement fonctionnel du client est ta mission principale, car tu sais que c’est là que se trouvent les indices cruciaux pour tes analyses héroïques.
·         Doté(e) d’une autonomie inébranlable, d’un dynamisme surpuissant et d’un sens des relations humaines extraordinaire, tu es une véritable icône.
En 2nd, un bagage technique qui tient la route :
·         Connaissance approfondie des concepts de Kafka, notamment Kafka-Stream.
·         Expérience sur les outils Scala ou Java.
·         Compétence en CI/CD et outils de déploiement (Jenkins, GitLab, Kubernetes, Docker, Ansible).
·         Maîtrise de l’écosystème Big Data (Hadoop, Spark, Apache Kafka, Avro).
·         Expérience avec les bases de données NoSQL (Cassandra, BigTable).
·         Connaissance des moteurs de recherche (Elasticsearch).
Voir plus",2024-02-23,https://www.welcometothejungle.com/fr/companies/skiils/jobs/data-engineer-spark-scala-h-f_SKIIL_Y01ea9P?q=ef902e83f94cc3417877b26437a07dbc&o=ce2f17c5-e599-4cd8-a38f-d12a84b93ddb,wttj
"Data Engineer Nearshore | Spark, Scala, Kafka H/F","{'name': 'SKIILS', 'sector': 'Intelligence artificielle / Machine Learning, Transformation, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2020', 'turnover': '11M€', 'mean_age': '34 ans'}",Freelance,,200 à 300 € par jour,Télétravail total,23 février 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
Tu as le pouvoir de créer des pipelines capables de transformer des données en véritables trésors exploitables, alors tu es peut-être notre Super Data Engineer !
Tu es prêt à affronter des défis titanesques, à gérer des montagnes de données, à défendre la résilience des systèmes, et à affronter des flux de données massifs, l’équipe DATA Factorii t’ouvre ses portes comme un véritable repaire de super-héros !
En tant que Super Data Engineer - Spark Scala H/F, tes missions seront de :
 Définir et déployer le socle technologique d’un Datalake
 Conseiller et concevoir une architecture de données
 Implémenter l’intégration des données au sein du Datalake
 Identifier, étudier et prototyper des cas d’usage stratégiques
 Industrialiser les projets Big Data en environnement cloud
Implémenter les méthodologies Devops pour optimiser les processus de développement
 Participer à l’estimation des besoins utilisateurs.       
 Concevoir du code et le documenter.
 Collaborer étroitement au sein de l’équipe SCRUM, comprenant le Product Owner, les développeurs, Quality Analyst, et le support, pour assurer le succès des projets.
Ce que nous t’offrons ?
Un salaire qui évolue comme une rock star sur scène !
 Une carrière à la “James Bond” : à moyen et long terme, c’est toi le héros !
Ta mutuelle et ton titre de transport pris en charge à 100% (bye-bye les frais) !
 Télétravail partiel : l’équilibre parfait entre pyjama et costume !
Et surtout, la chance de t’investir dans des projets ultra cool qui te propulseront techniquement vers l’infini et au-delà !
Voir moins","Profil recherché
Profil recherché
En 1er, un savoir être qui correspond à l’ADN de skiils !
         Les processus agiles, c’est ton super-pouvoir ! Le Manifeste Agile, c’est ton livre de chevet, toujours prêt à l’action.
         Comprendre l’environnement fonctionnel du client est ta mission principale, car tu sais que c’est là que se trouvent les indices cruciaux pour tes analyses héroïques.
         Doté(e) d’une autonomie inébranlable, d’un dynamisme surpuissant et d’un sens des relations humaines extraordinaire, tu es une véritable icône.
En 2nd, un bagage technique qui tient la route :
         Connaissance approfondie des concepts de Kafka, notamment Kafka-Stream.
         Expérience sur les outils Scala ou Java.
         Compétence en CI/CD et outils de déploiement (Jenkins, GitLab, Kubernetes, Docker, Ansible).
         Maîtrise de l’écosystème Big Data (Hadoop, Spark, Apache Kafka, Avro).
Voir plus",2024-02-23,https://www.welcometothejungle.com/fr/companies/skiils/jobs/data-engineer-nearshore-spark-scala-kafka-h-f?q=ef902e83f94cc3417877b26437a07dbc&o=98b6f489-1fb0-49d2-9efb-6562f8a62b72,wttj
Data Engineer H/F/X,"{'name': 'ELEVEN LABS', 'sector': 'Logiciels, IT / Digital, Audit', 'employees': '100 collaborateurs', 'creation_year': '2011', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 2 ans,,"Descriptif du poste
Seras-tu notre furtur.e Data Engineer !
Un peu de contexte
☝️ De plus en plus de nos consultants s’intéressent de près au sujet de la Data, ce qui nous a poussé à explorer ces problématiques chez nos clients et de constater un besoin fort d’accompagnement de leur part.
Nous recherchons donc la personne qui ouvrira la voie à cette expertise chez Eleven Labs et qui accompagnera la création de l’escouade Data !","Profil recherché
Nos attentes
🧠 Nous recherchons quelqu’un d’expérimenté/e dans la mise en place de pipeline ETL/ELT et data lake / data hub, capable de répondre au mieux aux problématiques qui lui seront soumises, pour qui les requêtes SQL, NoSQL sur BDD n’ont aucun secret, et qui maîtrise déjà une ou plusieurs solutions de Data Warehouse (de type BigQuery ou SnowFlake).
🍒 Cerise sur le gâteau : on cherche aussi un profil maîtrisant les langages type Python, Java ou Scala pour customiser les steps, avec bien entendu des connaissances solides sur des outils comme Spark, Jupyter ou encore Cloud Run comme outils de calcul distribué. Des connaissances dans l’utilisation d’outils ML et d’environnement Cloud en général sont un vrai plus.
🎭 Côté personnalité, et outre cet aspect expérimenté et “ouvreur de voie”, on cherche quelqu’un de moteur, avec un réel enthousiasme à transmettre ses connaissances, former et échanger.
Les missions
Voir plus",2024-02-23,https://www.welcometothejungle.com/fr/companies/eleven-labs/jobs/data-engineer-h-f-x_paris_EL_Rw5Pw5d?q=ef902e83f94cc3417877b26437a07dbc&o=01b26959-1e31-4a9c-9147-a2256df22aa8,wttj
Data Engineer,"{'name': 'SANCARE', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, Santé', 'employees': '47 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': None}",CDI,Paris,45K à 55K €,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
- Qui sont-ils ?
Les hôpitaux recueillent de multiples données de santé lors de l’hospitalisation d’un patient : comptes rendus médicaux, observations du personnel soignant, résultats d’examens, etc.
À l’échelle de l’hôpital, cela représente une quantité massive de données, qui sont largement sous-exploitées. Sancare propose des outils prédictifs utilisant les dernières avancées en intelligence artificielle pour mettre ces données au service des hôpitaux et de la santé.
Notre premier produit est déjà utilisé par une quarantaine de groupement hospitalier. Il permet la détection automatique de diagnostics à partir de documents en texte libre et autres données contenus dans les dossiers patients, visualisables dans une interface web intuitive et ergonomique, et fait gagner du temps aux médecins et à leurs assistants administratifs. Nous développons en parallèle un nouvel outil facilitant la conduite d’études en vie réelle pour évaluer des médicaments et dispositifs médicaux. Vu le fort impact potentiel de ce projet sur la recherche clinique, l’attente de la part de différents acteurs de la santé (notamment, hôpitaux et laboratoires pharmaceutiques) est considérable.

L'équipe de Sancare est composée de presque 50 collaborateurs spécialisées dans le développement informatique, le machine learning et la santé. Nous avons de plus la chance d’être accompagnés par des chercheurs reconnus dans le domaine du machine learning, ainsi que par des médecins et experts du monde de la santé.  

Nous recherchons un(e) Data Engineer avec de solides compétences opérationnelles et souhaitant rejoindre une équipe dynamique, expérimentée et motivée, afin d’accélérer l'arrivée de nos solutions en rupture dans le monde de la santé.

  - Descriptif du poste
La gestion et le traitement de la donnée sont au coeur des problématiques de Sancare. Comme chaque hôpital dispose de son propre système d’information, des connecteurs doivent être implémentés pour chacun, afin de nourrir les algorithmes de machine learning. Les moyens d’accès et le format des données contenues dans les dossiers patients sont très variés et diffèrent d’un établissement à un autre.
De plus, de nombreuses mesures sont à respecter afin de garantir la sécurité et la confidentialité des données.

Missions :
Développement de connecteurs permettant la transmission des données hospitalières entre les SI hospitaliers et les logiciels de Sancare
Développement d’outils de standardisation et de traitement des données hospitalières en vue de leur utilisation par les algorithmes de machine learning
Amélioration et maintenance des fonctionnalités existantes de traitement de données
Gestion opérationnelle des différents services de traitement de données, etc.
    - Les avantages  Sancare :
Des superbes locaux en plein centre de Paris (Châtelet)
Une organisation du travail flexible (109 jours de télétravail par année civile pour les salariés en forfait jour: soit deux jours de télétravail possibles par semaine et ce forfait pourra être porté à 131 jours de télétravail si les salariés au forfait jour justifient d’un temps de déplacement domicile-bureau supérieur à 3h par jour: soit trois à quatre jours de télétravail possibles par semaines pour les personnes à plus d’1h30 du bureau)
Tickets restaurant
Éligibilité BSPCE
Mutuelle Alan
Hello CSE, etc.
 Chez Sancare on n’est jamais à l’abri d’un apéro ou d’un cours de street-art ! Des retours d’expérience réguliers dans des formats variés (afterworks, séminaires, …) pour valoriser le partage d’idées et la connaissance commune.
    - Profil recherché
Expérience significative dans le développement en Python orienté objet (3ans à 5ans)
Expérience de développement sous Linux
Expérience dans la manipulation de données avec le langage SQL
Pratique avancée des outils d’intégration continue avec Git et tests unitaires
Des qualités d’autonomie, de flexibilité et de responsabilité
L’esprit d’équipe et la volonté de prendre part à une aventure collective
Un intérêt pour le monde de la santé
Sont un plus :
Familiarité avec Docker et RabbitMq
Expérience avec les données de santé dans le secteur hospitalier
N’hésitez pas à partager vos projets personnels de développement (sur GitHub ou ailleurs).

  - Déroulement des entretiens
Entretien RH
Test Technique puis Entretien Technique de pair programing avec l'équipe 
Entretien avec notre CEO
Voir moins",,2024-02-23,https://www.welcometothejungle.com/fr/companies/sancare/jobs/data-engineer_paris_SANCA_zDMr9a2?q=ef902e83f94cc3417877b26437a07dbc&o=26b85488-a2f6-41bb-ad25-70e4baed5d9e,wttj
,,,,,,,,,,,,https://www.welcometothejungle.com/fr/companies/cenova/jobs/luxe-cloud-data-engineer-experimente-h-f-paris_neuilly-sur-seine?q=ef902e83f94cc3417877b26437a07dbc&o=d3e04b61-1f10-4b76-bc67-0aef3a1a2fa1,wttj
Data Engineer,"{'name': 'THE PRODUCT CREW', 'sector': 'Recrutement', 'employees': '10 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Nous travaillons avec +400 startups et scale ups de la scène tech française et européenne, à la recherche de Data Engineers expérimentés de Confirmés à C-Level:
Heetch, Scaleway, Skello, Blablacar, Sendinblue, Mirakl, Partoo, Frichti, Swan, Jellysmack, MangoPay, Coinhouse… mais aussi les startups d’eFounders comme Collective Work, Numeral, ou Folk… et bien d’autres. Nous développons une communauté de hauts talents avec pour vocation d’apporter du soutien à leur carrière tout au long de leur vie professionnelle. Événements, ressources, sessions de recrutement…","Profil recherché
🤜 Décroche ton prochain rôle de Data Engineers avec l’aide de la communauté The Product Crew 🤛
Comme chaque 1er du mois, nous lançons une nouvelle session de recrutement. Les inscriptions sont ouvertes pour quelques jours seulement :
Tu as la possibilité de rendre ton profil visible auprès de nos startups partenaires,
Celles qui sont intéressées rentrent directement en contact avec toi,
Nous t’accompagnons tout au long du process.
On sera ravis de t’accompagner ton prochain objectif 🚀
L’inscription prend 5min. Pas besoin de CV, et c’est 100% gratuit 😊 Voici le lien pour t’inscrire 👉 https://app.theproductcrew.io/subscribe",2024-02-23,https://www.welcometothejungle.com/fr/companies/the-product-crew/jobs/data-engineer_paris_TPC_KbxzMk8?q=ef902e83f94cc3417877b26437a07dbc&o=d590aeae-ef41-47f3-8eda-93cb6475db33,wttj
Alternance (Bac +5) - Data Engineer (F/H/X),"{'name': 'IADVIZE', 'sector': 'IT / Digital, Économie collaborative, E-commerce', 'employees': '220 collaborateurs', 'creation_year': '2010', 'turnover': None, 'mean_age': '33 ans'}",Alternance,Nantes,Non spécifié,Télétravail fréquent,,> 6 mois,,"Descriptif du poste
Vous rejoindrez l'équipe Data (4 personnes) au sein du département Product & Engineering. Vous serez sous la responsabilité du Senior Data Engineer et l'aiderez à concevoir, construire, améliorer et maintenir la stack Data.
Vous aurez l'opportunité de participer à une gamme étendue de tâches, allant de la surveillance de l'infrastructure de données à la mise en œuvre de changements critiques, ainsi que de la collecte de données pour répondre aux défis business.
Votre travail implique des actions à plus long terme ainsi que des interventions opérationnelles quotidiennes, vous offrant ainsi une expérience réaliste du rôle de Data Engineer.
Vous collaborez avec des Data Scientists et des Analystes, ainsi qu'avec l'équipe Engineering Platform et éventuellement avec des parties prenantes commerciales.
Vous acquerrez de l'expérience dans un environnement technique riche, notamment sur Google Big Query, Apache Airflow, Amazon Athena, Elasticsearch, Tableau…
Vos missions :
Surveiller l'exécution des pipelines de données.
Participer à la migration des processus ETL.
Implémenter des évolutions dans la stack d'ingénierie des données (par exemple, automatisations, systèmes d'alerte, traçabilité, documentation).
Contribuer à la mise à jour ou à la configuration de nouveaux pipelines de collecte.
Effectuer des extractions ad hoc et/ou des corrections BI pour répondre aux besoins urgents de l'entreprise.
Voir moins","Profil recherché
Profil recherché
En dernière année d'études (Bac +5), vous recherchez pour 2024/2025 un terrain propice pour vous forger une expérience valorisante.
Vous disposez d’au moins une première expérience en programmation, de compétences en manipulation de données ainsi que de connaissances de base des environnements cloud. Enfin, vous êtes à l'aise avec la gestion de plusieurs tâches et des délais.
 Compétences techniques
Bonne connaissance de Python (usage général, avec un accent sur la manipulation de structures de données).
Bonne connaissance de SQL.
Familiarité avec les environnements Linux et la ligne de commande (CLI).
Compréhension des processus et de l'orchestration ELT/ETL.
Bonus 1 : Expérience avec au moins un fournisseur de Cloud majeur (AWS, GCP, Azure, …).
Voir plus",2024-02-23,https://www.welcometothejungle.com/fr/companies/iadvize/jobs/alternance-bac-5-data-engineer-f-h-x_nantes_IADVI_lxRMdJ2?q=ef902e83f94cc3417877b26437a07dbc&o=09271f99-2afb-4d4d-8c97-5c60a552dff0,wttj
Data Engineer H/F,"{'name': 'KALI GROUP', 'sector': 'Ingénieries Spécialisées, Stratégie, Recrutement', 'employees': '100 collaborateurs', 'creation_year': '2021', 'turnover': '6 millions', 'mean_age': '31 ans'}",CDI,Chassieu,Non spécifié,Télétravail non autorisé,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Rejoignez le bureau d'études d'un industriel en plein développement de la région lyonnaise !
Dans le cadre du développement de nos activités nous recherchons un Data Engineer (H/F).
Vous aurez pour objectifs et responsabilités le traitement et l'analyse de données industrielles.
A ce titre vous, vous êtes en charge de :
Élaborer la stratégie sur les données ;
Superviser la création et la modification du data lake ;
Documenter les flux de données, les règles de gestion, et évaluer la criticité des données techniques ;
Identifier les besoins métiers, suivre l'évolution des données et mettre en place des alertes de surveillance ;
Établir des standards de documentation des procédures et soutenir la rédaction de documents ;
Élaborer des indicateurs, rapports et tableaux de bord et les actualiser ;
Accompagner l'équipe Données Industrielles dans son développement de compétences.
Superviser les projets d'amélioration de l'outil industriel en respectant les objectifs de coûts, qualité et délais.
Voir moins","Profil recherché
Apportez vos compétences :
Issu d'une formation Ingénieur généraliste ou master en gestion de données industrielles, vous justifiez d'une expérience similaire réussie de minimum 3 ans.
Vous possédez de bonnes connaissances en ERP et vous maîtrisez les outils d'extraction et de traitement de base de données. Vous avez déjà eu une expérience en gestion de projet. Vous êtes pédagogue et un bon communicant.
Rencontrons-nous :
Vous êtes disponible immédiatement ? Si vous vous reconnaissez dans les missions et le profil, n'hésitez plus et postulez.
Nous pourrons échanger à propos de votre projet et dessiner ensemble votre avenir professionnel !",2024-02-22,https://www.welcometothejungle.com/fr/companies/kali-group/jobs/data-engineer-h-f_chassieu?q=ef902e83f94cc3417877b26437a07dbc&o=62e14097-d76f-49b7-83e6-5bd2a4e1643f,wttj
Data Engineer,"{'name': 'AIVE', 'sector': 'Intelligence artificielle / Machine Learning, SaaS / Cloud Services', 'employees': '21 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '32 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail fréquent,,> 3 ans,,"Descriptif du poste
En temps que Data Engineer chez Aive, vos missions seront de :
Participer à la conception et l’implémentation de nouvelles fonctionnalités reposant sur l’analyse ou le traitement vidéo, audio ou textuel.
Concevoir ou appliquer des modèles, algorithmes et méthodes pour mettre un oeuvres ces fonctionnalités
Maintenir une veille technologique sur les sujets pertinents pour le produit
Collaborer avec les autres spécialités de l’équipe pour industrialiser le produit (qualité, performance, maintenance)
L’offre est ouverte pour toute la France, avec une préférence pour les candidats en région Parisienne ayant la possibilité de venir régulièrement dans les locaux.","Profil recherché
Une bonne connaissance des sujets et technologies suivants est appréciée (exemples tirés de nos projets récents ou à venir):
Languages: Python, Golang
Frameworks de machine learning: Torch, ONNX
Opération: Github CI, Docker, Kubernetes
Computer Vision (object/logo/face detection, shot/scene detection, feature extraction)
Signal Processing (automatic speech recognition, diarization)
Natural Language Processing (topic segmentation, summarization)
Les compétences et expériences suivantes seront fortement appréciées :
3 ans d’expérience préalable
Vous aimez travailler en équipe, partager vos connaissances et les approfondir au contact des autres
Recherchez l’efficacité dans la création d’algorithme à grande échelle et évolutifs
Si jamais vous ne remplissez pas tous ces critères, n’hésitez pas à nous contacter quand même, nous étudierons tous les profils intéressants !
Voir plus",2024-02-22,https://www.welcometothejungle.com/fr/companies/aive/jobs/data-engineer_paris?q=ef902e83f94cc3417877b26437a07dbc&o=04beb790-8547-44f8-b590-d9ca04d1a433,wttj
Data Engineer (H/F),"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Toulouse,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
MP DATA recrute un(e) Data Engineer (H/F).
Dans le cadre de la transformation digitale industriel, l’équipe de data engineering en charge de l’exploitation du Cluster Big Data cherche à se développer.
En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des données, en veillant à ce qu’elles soient prêtes pour l’analyse. Votre expertise dans la conception de pipelines ETL et la sécurisation des données sera essentielle pour soutenir les activités d’analyse et de prise de décision de l’entreprise. Votre rôle contribuera à créer une base de données solide et sécurisée pour des insights pertinents et en temps réel.","Profil recherché
Diplômé(e) d’une école d’ingénieur, vous avez des connaissances en modélisation et machine learning (deep learning, random forest, svm…) acquises lors de votre scolarité ou de vos expériences passées (stage ou césure).
Vous avez de bonnes connaissances en Python pour coder ces algorithmes. Suite à votre cursus ingénieur ou vos expériences professionnelles, vous disposez d’une appétence métier dans les domaines de l’aéronautique, énergie, transport, etc…
Vous êtes reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacité à être force de proposition.
Vous êtes intéressés pour vous dépasser en data science & data engineering et vous avez des premières expériences dans ce domaine, comme par exemple :
C/C++ / Java / Rust / Python
Spark
Kafka
Cloud : AWS / GCP / Azure
Technologies de stockage : Snowflake / S3 / GCS / Azure Blob
Voir plus",2024-02-22,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-h-f_toulouse_MD_XNW0jaK?q=ef902e83f94cc3417877b26437a07dbc&o=f3138855-9b28-4822-9a05-938616f32c92,wttj
Data Engineer (F/H) - Life Sciences,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spécifié,Télétravail fréquent,,< 6 mois,Bac +5 / Master,"Descriptif du poste
·      Concevoir et développer des solutions Data pour la collecte, l’organisation, le stockage et la modélisation des données,
·      Assurer l’accès fiable, efficace et sécurisé aux différentes sources de données métier et processus, tout en mettant en place des outils et méthodes de contrôle et de validation de la qualité des données,
·      Optimiser les processus de collecte, transfert et stockage des données (ETL), en assurant l’adéquation avec les contraintes techniques et opérationnelles,
·      Maintenir les outils, technologies et processus à jour, en assurant une veille technique assidue et une supervision permanente de l’environnement.","Profil recherché
Diplômé(e) ingénieur(e) d’une grande école (Centrale, Mines, Supaero, Supelec, …),
Appétences métiers dans les domaines de l’industrie et êtes intéressé(e) par l’industrie 4.0,
Notions d’automatisme dans l’automobile et connaissez les systèmes de contrôle type Scada,
Compétences en développement (C/C++, Java, Rust) et en technologies de stockage (Snowflake, S3, GCS, Azure Blob),
Connaissances en CI/CD, en bases de données SQL (Postgres, MongoDB) et en Cloud (AWS, GCP, Azure).",2024-02-22,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-f-h-life-sciences_boulogne-billancourt?q=ef902e83f94cc3417877b26437a07dbc&o=eba17938-311c-4108-b0d8-0b7fcf07e9f6,wttj
Data Engineer,"{'name': 'INDY', 'sector': 'FinTech / InsurTech', 'employees': '266 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '29 ans'}",CDI,Lyon,42K à 52K €,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
En raison de notre forte croissance, nous avons la volonté de mettre en place une stack robuste, performante et scalable.
Nous avons besoin de mieux utiliser les données en présence, et c’est une super opportunité pour toi : cela te permettra de créer de la valeur pour l’entreprise !
Aujourd’hui, l’équipe Data est composée de 4 personnes, dans une équipe Tech globale de 45 personnes.
Tu rejoindras :
Benoit, Lead Data Engineer
Eloïse, Data Engineer
Maud, Data Engineer
Maxime, Data Scientist
Les missions de l’équipe:
Fournir des données up-to-date, utiles et fiables aux équipes Business de Indy pour leur permettre d’analyser et piloter leur activité.
Améliorer notre système de catégorisation automatique des transactions bancaires.
L’un de nos challenges du moment est que la BI soit la source de vérité et alimente directement les outils des équipes Customer Support, Sales et Marketing.
Avec la croissance de notre base utilisateur, notre volume de données augmente. Nous en avons plus à récupérer, à traiter, à stocker… Tu vas pouvoir intervenir sur les pipelines de données pour améliorer leur robustesse et la vitesse de traitement. De plus, tu participeras à l’évolution de notre stack technique pour relever ces challenges. En d’autres termes, la scalabilité de nos outils et de notre stack data!
Notre stack actuelle se compose de: PostgreSQL, Airbyte, DBT, Metabase, Dagster, Census, Python, Heroku, AWS ECS, DataDog
Plus concrètement, tes missions seront:
Développer, puis passer à l’échelle et monitorer notre plateforme de traitement et de visualisation de données.
Être garant du cycle de vie des données.
Définir, développer, documenter et maintenir les pipelines de données pour la B.I.
Faire le lien entre les équipes de consommation de la donnée et l’équipe de R&D applicative.
Participer aux définitions d’architecture système des équipes de développement.
Former les équipes techniques aux bonnes pratiques de gestion de la donnée.
Assurer la sécurité des données.
Voir moins","Profil recherché
Le candidat idéal pour rejoindre notre équipe Data
Tu as une expérience confirmée en tant que Data Engineer (4~8 ans) et tu cherches à avoir plus d’impact à travers tes contributions
Tu as déjà travaillé sur différents types de bases de données, et également sur des sujets de volumétrie et modélisation.
Tu maitrises la programmation Python et SQL
Tu es orienté résultats et tu as une bonne compréhension des enjeux business
Tu as envie de résoudre des problèmes, en toute autonomie, en prenant des initiatives et en sachant prendre des décisions
Tu es un bon communicant, tu sais interagir avec différents interlocuteurs, y compris non techniques
Nous portons une attention particulière à la diversité dans notre processus de recrutement. Nous savons que certaines personnes n’osent parfois pas répondre sans cocher toutes les cases : Venez nous en parler.
Dans le cadre de nos valeurs d’inclusions, nous accordons chez Indy une attention particulière aux personnes en situation de handicap.
Voir plus",2024-02-22,https://www.welcometothejungle.com/fr/companies/indy/jobs/data-engineer_lyon_INDY_V73g69J?q=ef902e83f94cc3417877b26437a07dbc&o=15a24119-76a9-4eb3-9c03-2168a231c0bb,wttj
Data Engineer - Energie - Ile-de-France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Courbevoie,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Description de l’entreprise
Sopra Steria, l’un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d’édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d’activité et des technologies innovantes à une approche résolument collaborative.
Sopra Steria place l’humain au centre de son action et s’engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 50 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d’affaires de 5,1 milliards d’euros en 2022.
The world is how we shape it
Description du poste
Votre futur environnement de travail :
La division « Energie » accompagne les grands acteurs du secteur en France dans les domaines de la production et de la distribution thermique, hydraulique et nucléaire. Dans un contexte agile, nos équipes d’experts participent à des projets autour de la transformation numérique pour conduire nos clients vers une transition écologique.
Le défi que nous vous proposons de relever ? Mettre l’énergie au service des Smart Grid & Cities !
Sous la responsabilité d’un directeur de la Business Unit Energie, vous participez aux principaux grands projets de transformation numérique de ses secteurs.
Acteur majeur de l’avant-vente jusqu’à la livraison du produit final, vous intervenez sur un périmètre large, au sein d’un environnement technique innovant
Votre rôle et missions :
Au sein d’une équipe Agile, accompagné par un chef de projet, en tant que Data Engineer et dans le cadre de nos projets de data management dans le secteur de l’énergie, vous intervenez dans le cadre de développement de projet BI (incluant la réalisation de datamarts, cubes ou rapports) complexes et à forte valeur ajoutée (Pilotage des trains, reporting financier, gestion des conducteurs). Votre rôle est donc prépondérant dans la réussite du projet.
Vous intervenez sur toute la chaîne de valeur du cycle projet :
- Vous rédigez des spécifications fonctionnelles générales ou détaillées sur la base d’expression de besoins
- Vous participez à la conception et au développement des applications Big Data, les tester, les faites évoluer et assurer leur maintenance.
- Vous assurez l’intégrité et la qualité de la donnée sur tout le processus d’ETL
- Vous industrialisez et optimisez la gestion des flux de données
- Vous participez à la conception de l’architecture et l’infrastructure de nos systèmes de collecte et de traitement des données.
- Vous pilotez et accompagnez les utilisateurs durant les phases de recette
- Vous accompagnez des key users et des utilisateurs finaux dans l’usage des nouveaux rapports (formations, support…)
- Vous contribuez à l’amélioration du reporting et du pilotage de la performance.
Grâce à votre excellent esprit collectif vous avez à cœur de partager votre savoir et contribuer à la progression des membres de l’équipe.
Environnement technologique riche : Talend, Power BI, Cloud computing, Java, Python, PostgreSQL, Cloudera, Spark…
Qualifications
Diplômé(e) d’une école d’Ingénieurs ou équivalent, vous justifiez d’une expérience technique de 3 ans minimum et souhaitez évoluer rapidement dans un contexte motivant.
Vous avez au moins l’une de ces compétences requises :
· Maîtrise des technologies de bases de données Relationnelles et NoSQL
· Maîtrise des technologies de traitement distribué de données (spark, Hadoop)
· Maîtrise d’au moins un framework de streaming de données (Kafka, RabbitMQ, etc.)
· Maîtrise de chaines CI/CD et de des bonnes pratiques de DataOps
· Maîtrise de solution de Virutualisation de données (Denodo, Dremio, etc.)
· Maîtrise d’au moins un environnement cloud public ou privé (Azure, AWS, Outscale, etc.)
Vous êtes attiré(e) par le monde du numérique, le Cloud et des technologies innovantes.
Vous avez un bon esprit d’analyse, êtes curieux(se) et passionné(e) et vous avez le sens du travail en équipe.
Informations supplémentaires
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.
Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord
d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s’engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L’opportunité de rejoindre le collectif Tech’Me UP (formations, conférences, veille, et bien plus encore…).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
Voir moins",,2024-02-22,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-energie-ile-de-france_courbevoie_SS_6Dgg0ow?q=ef902e83f94cc3417877b26437a07dbc&o=f8a2849e-9094-46d6-af2d-fcce878e3ff4,wttj
Data Engineer Databricks,"{'name': 'VISIAN', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Stratégie', 'employees': '80 collaborateurs', 'creation_year': '2017', 'turnover': ""14 Millions d'euros"", 'mean_age': '28 ans'}",CDI,Courbevoie,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
La Direction des Systèmes d’Information de notre client grand compte dans l’énergie recherche un profil Data Engineer Databricks pour concevoir, développer et maintenir les architectures Data nécessaires à l’exploitation de ses données par les analystes métiers et data scientists. 
Le data engineer intègre une équipe en charge du lakehouse (AWS + Databricks) pour la B2C.
Missions :
Contribue à la conception de outils de traitement BigData (Ingestion / Traitement / Analyse)
Cadrage technique des besoins émis par les consommateurs de la plateforme Data
Garantir la mise en production des traitements au sein de la plateforme
Optimisation du code et de la capacité des VMs mise en œuvre pour chaque traitement
Garantir la disponibilité et l’outillage pour les équipes métier, ainsi qu’aux utilisateurs de la plateforme (data scientists / data analystes / data engineer)
Etre en relation avec les équipes infrastructure afin d’assurer le cadrage et le déploiement des solutions valides
Support aux équipes consommatrices
Analyse d’anomalies et proposition solution court / moyen terme
Développement sous Databrick (Python / SQL / Spark / Airflow)
Etre force de propositions techniques
Voir moins","Profil recherché
Formation ingénieure ou universitaire de niveau Bac+5 à dominante informatique et mathématiques
Expérience de 3 à 5 ans minimum sur un poste similaire
Code source (composants applicatifs et tests unitaires)
Maîtrise de Databricks + Python + SQL + Spark + Airflow
Avoir une première expérience sur de la MCO et Support
Compétences en langage SQL et en programmation (Python et PowerShell)
Aisance dans l’utilisation des API (REST, SOA)
Maîtrise de l’anglais
Rigueur, capacité d’analyse et d’adaptation
Autonome, vous savez travailler en équipe et avez l’esprit d’initiative",2024-02-22,https://www.welcometothejungle.com/fr/companies/visian/jobs/data-engineer-databricks_courbevoie?q=ef902e83f94cc3417877b26437a07dbc&o=7662f7de-55b7-460f-ab48-29d0ab2fe9f7,wttj
Data Engineer Azure,"{'name': 'VISIAN', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Stratégie', 'employees': '80 collaborateurs', 'creation_year': '2017', 'turnover': ""14 Millions d'euros"", 'mean_age': '28 ans'}",CDI,Courbevoie,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
La Direction des Systèmes d’Information de notre client grand compte recherche un profil Data Engineer Azure pour concevoir, développer et maintenir les architectures Data nécessaires à l’exploitation de ses données par les analystes métiers et data scientists. 
A ce titre, vos principales missions consisteront à :
Mener les projets d’intégration (temps réel) et data (big data & insights),
Comprendre, analyser et proposer des solutions techniques répondant aux besoins des divers acteurs de la donnée (spécialistes métier, domain managers, architecte, data analystes et scientists),
Apporter un éclairage technique sur les architectures Cloud, dialoguer avec les fournisseurs de solutions et les consultants techniques,
Dans une logique de mise en production, créer et déployer des pipelines de données robustes pour les data scientists et data analysts (collecte, stockage, transformation et exploitation),
Assurer une bonne qualité des données pour les projets Machine Learning (préparation, complétude, épuration, enrichissement) dans le but d’optimiser les performances des modèles,
Améliorer les processus internes : localisation et traçabilité de la donnée, standardisation des flux et des scripts de traitement des données, documentation,
Collaborer avec les équipes basées aux Pays-Bas pour faciliter le Data-Sharing, échanger sur les best-practices et les moyens d’optimiser les architectures,
Contribuer à l’amélioration de la gouvernance sur la protection et la confidentialité des données.
Voir moins","Profil recherché
Formation ingénieure ou universitaire de niveau Bac+5 à dominante informatique et mathématiques
Expérience de 3 à 5 ans minimum sur un poste similaire
Maîtrise des services Azure, en particulier Data Factory, Azure Functions, Event Grid et Azure SQL
Connaissance d’Azure DevOps pour le déploiement (YAML, Bicep), la documentation et la gestion de projets
Compétences en langage SQL et en programmation (Python et PowerShell)
Aisance dans l’utilisation des API (REST, SOA)
Maîtrise de l’anglais impérative (niveau C1)
Rigueur, capacité d’analyse et d’adaptation
Autonome, vous savez travailler en équipe et avez l’esprit d’initiative",2024-02-22,https://www.welcometothejungle.com/fr/companies/visian/jobs/data-engineer-azure_courbevoie_VISIA_lYDkON?q=ef902e83f94cc3417877b26437a07dbc&o=c18ead56-b3f4-4dde-b747-37e3abd65251,wttj
Data Engineer H/F,"{'name': 'NEXTON', 'sector': 'Design, IT / Digital, Digital', 'employees': '450 collaborateurs', 'creation_year': '2011', 'turnover': '31 millions', 'mean_age': None}",CDI,Valbonne,Non spécifié,Télétravail non autorisé,,> 5 ans,Bac +5 / Master,"Descriptif du poste
NEXTON recrute un DATA ENGINEER H/F, en CDI, à Biot !

Qui sommes-nous ?

NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…).

Nous sommes experts du digital aussi bien sur de l'accompagnement stratégique qu'opérationnel.

Fort du succès, NEXTON connaît aujourd'hui un développement significatif, autour de ses valeurs piliers : cohésion, confiance et performance.

Et pour toi ? Notre politique de développement des compétences dynamique saura te séduire avec un programme de suivi de carrière sur-mesure.

Le contexte :

En tant que Data Engineer, tu maîtrises les concepts de Business Intelligence, de Datawarehouse, de reporting ou les bases de données. Tu as une appétence particulière pour les domaines de l'intégration, de la transformation et du stockage et tu interviens sur la récolte, l'exploitation et la mise à disposition de données.

Les missions :

Tu es le leader de la brique Datalakehouse pour en assurer :
Le respect des bonnes pratiques de développements (les définir / mettre en place)
Son évolution fonctionnelle et technique
Sa disponibilité et sa résilience
Tu développes les scripts de transformations de données et les pipelines d'alimentation
Tu proposes des évolutions architecturales ou de fonctionnalités pour améliorer notre socle technique
Tu es le back-up du leader technique sur la partie reporting (Power BI)
Tu transmets tes compétences
Tu as une forte orientation satisfaction client et résultat mais également sensibilité au « comment »
Tu conçois et documentes des projets pris en charge avant d'effectuer leur mise en œuvre
Tu participes à l'innovation et proposes de nouvelles pratiques pour améliorer l'environnement et les conditions de travail des équipes


Voir moins","Profil recherché
Issu de formation supérieure, tu as une expérience d'environ 5 ans sur une fonction similaire.

Tu as de nombreuses compétences techniques, notamment les suivantes :
Microsoft Azure
Microsoft Azure Synapse Analytics (Spark / Python / Pipeline / Serverless)
Fichiers parquet / delta
Microsoft Power BI
Microsoft SQL Server
Langage SQL
Datawarehousing / Modélisation de données
Reporting a vocation business
Analyses et export de données
Tu as également connaissance de l'ensemble du processus depuis la collecte jusqu'à la mise à disposition des données en ayant comme point fort la maitrise de sa transformation et mise en forme.

Tu aimes travailler en équipe afin de créer une solution data moderne, pleinement intégrée et répondant à l'ensemble des besoins du client.

Tu connais bien les méthodes Agiles.

Enfin, tu as un bon niveau d'anglais (lu, parlé, écrit).

NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'année :

- Des communautés : 2 Meet Up par mois pour partager et échanger avec des experts

- De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'année

- Des moments privilégiés avec ton manager

Prêt à nous rejoindre ?
Voir plus",2024-02-22,https://www.welcometothejungle.com/fr/companies/nexton-consulting/jobs/data-engineer-h-f_valbonne_NEXTO_7R0jwmd?q=ef902e83f94cc3417877b26437a07dbc&o=3995665c-eee7-4f71-aa84-c0c8df3b0a32,wttj
Data Engineer (F/H),"{'name': 'THALES', 'sector': 'Logiciels, Cybersécurité, Aéronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mds€', 'mean_age': None}",CDI,Vélizy-Villacoublay,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Au sein du site de Vélizy, nos équipes hautement qualifiées conçoivent et produisent des amplificateurs de puissance (tubes à ondes progressives, klystrons, gyrotrons, sous-systèmes pour les Grandes Infrastructures de Recherche, etc.) à destination des marchés Défense, Sécurité, Spatial et Scientifique. Chaque jour nos cadres, ingénieurs, techniciens et opérateurs mettent en commun leurs savoir-faire unique au service de l’innovation.Description de l'emploi
QUI SOMMES-NOUS ?
 Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs présents sur tous les continents. Le Groupe investit dans les innovations du numérique et de la « deep tech » – big data, intelligence artificielle, connectivité, cybersécurité et quantique – pour construire un avenir de confiance, essentiel au développement de nos sociétés, en plaçant l’humain au cœur des décisions.
Thales propose des solutions, services et produits qui aident ses clients – entreprises, organisations, Etats – dans cinq grands marchés vitaux pour le fonctionnement de nos sociétés : identité et sécurité numériques, défense, aéronautique, espace, et transport.
 QUI ETES-VOUS ?
 Diplômé d’un Bac+5 en école d’ingénieur ou équivalent universitaire avec une spécialisation en informatique, vous avez au moins 3 ans d'expérience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
 En tant que Data Engineer, vous jouerez un rôle clé dans la conception, le développement et la maintenance de notre infrastructure de données, ainsi que dans la transformation et la gestion des flux de données.
 VOS MISSIONS :
 • Concevoir, développer et déployer des solutions Big Data en utilisant les technologies Hadoop.
 • Mettre en place des pipelines de données performants pour l'ingestion, le traitement et le stockage des données massives.
 • Collaborer étroitement avec les équipes métier pour comprendre leurs besoins en matière d'analyse de données et proposer des solutions adaptées.
 • Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des données.
 • Assurer la qualité et la fiabilité des données traitées, en mettant en place des processus de validation et de nettoyage.
 • Identifier et résoudre les problèmes liés à l'infrastructure Big Data et proposer des améliorations.
 • Travailler en étroite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents à partir des données.
  Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Voir moins",,2024-02-22,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-f-h_velizy-villacoublay_THALE_382jGdb?q=ef902e83f94cc3417877b26437a07dbc&o=09b86e79-1761-4a07-a40c-334aebf09621,wttj
Ingénieur Data Engineer (F/H),"{'name': 'THALES', 'sector': 'Logiciels, Cybersécurité, Aéronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mds€', 'mean_age': None}",CDI,Vélizy-Villacoublay,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Au sein du site de Vélizy, nos équipes hautement qualifiées conçoivent et produisent des amplificateurs de puissance (tubes à ondes progressives, klystrons, gyrotrons, sous-systèmes pour les Grandes Infrastructures de Recherche, etc.) à destination des marchés Défense, Sécurité, Spatial et Scientifique. Chaque jour nos cadres, ingénieurs, techniciens et opérateurs mettent en commun leurs savoir-faire unique au service de l’innovation.
QUI SOMMES-NOUS ?
 Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs présents sur tous les continents. Le Groupe investit dans les innovations du numérique et de la « deep tech » – big data, intelligence artificielle, connectivité, cybersécurité et quantique – pour construire un avenir de confiance, essentiel au développement de nos sociétés, en plaçant l’humain au cœur des décisions.
Thales propose des solutions, services et produits qui aident ses clients – entreprises, organisations, Etats – dans cinq grands marchés vitaux pour le fonctionnement de nos sociétés : identité et sécurité numériques, défense, aéronautique, espace, et transport.
 QUI ETES-VOUS ?
 Diplômé d’un Bac+5 en école d’ingénieur ou équivalent universitaire avec une spécialisation en informatique, vous avez au moins 3 ans d'expérience dans les technologies Big Data.
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
 En tant que Data Engineer, vous jouerez un rôle clé dans la conception, le développement et la maintenance de notre infrastructure de données, ainsi que dans la transformation et la gestion des flux de données.
 VOS MISSIONS :
 • Concevoir, développer et déployer des solutions Big Data en utilisant les technologies Hadoop.
 • Mettre en place des pipelines de données performants pour l'ingestion, le traitement et le stockage des données massives.
 • Collaborer étroitement avec les équipes métier pour comprendre leurs besoins en matière d'analyse de données et proposer des solutions adaptées.
 • Optimiser les performances des clusters Hadoop pour garantir une exploitation efficace des données.
 • Assurer la qualité et la fiabilité des données traitées, en mettant en place des processus de validation et de nettoyage.
 • Identifier et résoudre les problèmes liés à l'infrastructure Big Data et proposer des améliorations.
 • Travailler en étroite collaboration avec les Data Scientists et les Data Analysts pour fournir des insights pertinents à partir des données.
  Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Voir moins",,2024-02-22,https://www.welcometothejungle.com/fr/companies/thales/jobs/ingenieur-data-engineer-f-h_velizy-villacoublay?q=ef902e83f94cc3417877b26437a07dbc&o=e234d444-edc5-47b4-84d3-a1703ec76b89,wttj
Data Engineer Cloud Data F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Big Data, Data Science, Data analyse, Data architecture, … Ça n’a pas de secret pour vous ?
Que vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l’une de ces disciplines, intégrer notre communauté Data, c’est l’assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.

Rejoignez notre centre d’excellence en innovation à Montpellier et rendez unique l’expérience digitale de nos clients en travaillant sur des sujets tels que le marketing digital, User eXperience, CRM, RPA, data, développement web et mobile, API management ou encore cybersécurité.


Fonctions et responsabilités
- Vous êtes passionné(e) par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …
- Vous disposez de solides connaissances sur les architectures de données et le cloud (AWS, GCP ou Azure).

Vos missions sont :
- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place
- Travailler en collaboration avec les ingénieurs techniques et autres experts afin de rechercher et fournir des réponses aux problématiques techniques
- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)
- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)
- Participer à l'élaboration et la révision de normes / documentation technique
- Animer des formations internes.
- Accompagner la montée en compétences des équipes
- Assurer un support technique aux équipes Data et aux clients au quotidien

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
- Passionné(e) d’informatique et de données, vous aimez le travail en équipe, apprendre et partager.
- Vous êtes également doté(e) d'un esprit audacieux et ambitieux.
- Vous faites preuve d’initiative et travaillez sur le long terme.
- Vous avez un minimum de 2 années d’expérience sur des projets Cloud (AWS, GCP ou Azure).
- Vous maitrisez un ou plusieurs services : Snowflake, Synapse, Databricks, Azure DevOps, Terraform, BigQuery, EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB etc.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-02-22,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-cloud-data-azure-f-h_paris?q=ef902e83f94cc3417877b26437a07dbc&o=97086452-201e-441e-ac1e-234cfc819afb,wttj
R&D Data Engineer,"{'name': 'EXOTEC', 'sector': 'Logistique, Objets connectés, Robotique', 'employees': '600 collaborateurs', 'creation_year': '2015', 'turnover': '126 M€', 'mean_age': '31 ans'}",CDI,Lyon,Non spécifié,Télétravail non autorisé,,,Bac +5 / Master,"Descriptif du poste
Exotec is at the forefront of technological excellence, redefining the relationship between humans and robots. Our solutions are contributing to the success of some of the largest brands in retail and e-Commerce by revolutionizing the way they fulfill their orders to the end consumers, all while mitigating labor constraints and increasing workplace safety.
Through the unification of artificial intelligence and high-performance hardware, our robotic solutions are now deployed across the globe and our exponential growth has led us to become the first industrial unicorn in France.
Working at Exotec is an exciting opportunity to give purpose to your skills. Learn and grow with over 600 ExoPeople around the world to help turn your ideas into a reality.
The robotics revolution is just the beginning at Exotec. Will you be part of it?
 We are seeking a talented and experienced Data Engineer to join our team in the Product Department.
As a Data Engineer at Exotec, you will play a key role in designing, developing and maintaining our data infrastructure.
 Responsibilities
Collaborate with cross-functional teams to understand data requirements and design scalable data solutions.
Collect data coming from our different client sites
Design and implement an event driven data lake
Provide the data to applications and end user
Requirements
IT/Software Engineer or related field.
Proven experience as a Data Engineer or similar role
Strong proficiency in Python
Hands-on experience with Terraform for Infrastructure as Code
Knowledge of containerization and orchestration tools like Docker and Kubernetes
Familiarity with AWS
Strong problem-solving and analytical skills
Excellent communication and collaboration skills
Nice to have:
Familiarity with Kafka or other message queuing system
Hands-on experience with Apache Airflow or Dagster
Familiarity with machine learning frameworks and concepts
Benefits
Couverture mutuelle et prévoyance santé compétitive
Primes collectives et attribution de BSPCE
Politique famille avantageuse
Programme de mobilité interne et internationale
Nombreuses opportunités de formation et de développement
Chez Exotec, nous garantissons l’égalité des chances dans notre processus de recrutement. L’ensemble des candidatures reçues sont étudiées indépendamment de l’âge, du genre, de l’origine, de la religion, de la couleur de peau, de la nationalité, du sexe, du handicap, de l’orientation sexuelle ou de toute autre distinction protégée par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les différences. En rejoignant le Pacte Parité, Exotec s’engage pour un écosystème French Tech plus paritaire.
Voir moins",,2024-02-21,https://www.welcometothejungle.com/fr/companies/exotec/jobs/r-d-data-engineer_lyon?q=ef902e83f94cc3417877b26437a07dbc&o=39558acf-7632-422c-acb4-eb8328610ceb,wttj
Confirmed Data Engineer,"{'name': 'DOCTRINE', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Service juridique', 'employees': '120 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Notre mission ⚖️
Nous nous engageons pour un enjeu démocratique majeur : rendre le droit plus accessible et transparent aux justiciables et aux professionnels du droit.
Doctrine est la première plateforme d'intelligence juridique. Nous centralisons et organisons toute l'information juridique disponible pour permettre aux avocats et juristes de mieux conseiller et défendre leurs clients. Plus d'un million de personnes viennent tous les mois sur Doctrine se renseigner sur leurs droits, et déjà 12 000 professionnels du droit nous font confiance.
Nos valeurs 🤝
Challenge the status quo. Nous défendons les idées audacieuses et la prise de risque intelligente.
Liberty and responsibility. Nous promouvons l’autonomie, l’impact de chacun·e et l’ownership.
Knowledge is power. L'information est au cœur de la mission de Doctrine, et nous voulons toujours apprendre plus.
Release early, release often and listen to your customers. Nous croyons au pouvoir de l’itération et à l’importance d’écouter en permanence notre marché, nos client·e·s et leurs problématiques.
Le contexte
Nous sommes actuellement à la recherche d'un.e ingénieur data confirmé pour rejoindre l’une de nos squads et participer à la construction de la première plateforme d’intelligence juridique.
Tu rejoindras une équipe dédiée à l’acquisition, l’enrichissement et la mise à disposition de la donnée juridique dans notre plateforme.
Tu peux trouver des détails sur l’ensemble de la stack sur Github !
A savoir : il n’est pas nécessaire d’avoir une expérience professionnelle dans le domaine du droit, cependant l’envie de s’investir et de monter en compétence dans la compréhension des documents juridique est importante :)
Les missions 🛠
Consolider les pipelines de données du périmètre de la squad
Concevoir, développer, monitorer et maintenir de nouveaux scripts d’acquisition et de traitement des données en Python pour ajouter de nouveaux contenus dans notre plateforme
Assurer la qualité de la donnée et son monitoring
Travailler en collaboration avec nos Machine Learning Engineers et experts NLP pour les aider à intégrer leur travail dans le pipeline de données
Contribuer à l’évolution de nos outils de pipeline de données (Airflow, Kubernetes, Dask, Amazon S3, PostgreSQL, Terraform, etc...), et faire en sorte d’en tirer le meilleur profit au quotidien
Au sein du Chapter Data Engineering, participer à l'élaboration de nos pratiques de modélisation et de traitement des données.
Le profil idéal 👀
De bonnes compétences en programmation Python
Une expérience des pratiques d'acquisition et de modélisation des données
Une bonne connaissance de SQL et du stockage objet
Une expérience dans un écosystème cloud (AWS de préférence)
L’envie de partager tes connaissances pour participer à la progression de chacun.e
La maîtrise de la langue française, car tu seras amené.e à manipuler des données juridiques en français.
Ce qui t'attend si tu rejoins Doctrine 🤗
- Contribuer à un projet ambitieux, avec un impact réel et positif sur la société : rendre le droit plus accessible et plus ouvert.
- Un accompagnement sur mesure dès ton arrivée sur l'écosystème juridique pour t'aider à naviguer très vite dans cet environnement stimulant.
- Une aventure dans laquelle tu apprendras sans cesse et partageras tes connaissances à l’ensemble de tes collègues (talks internes/externes, meetups, Tech & Sales Monthly, blog Medium, etc.)
- Travailler au sein d’une équipe en ébullition qui cherche sans cesse à se renouveler : de la place pour innover et mener des projets en autonomie ou en équipe.
Nos avantages pour faire la différence ☀️
🏡 Une politique de télétravail flexible, avec 2 jours de présence au bureau par semaine (mardi et jeudi)
🌱 De nombreuses options pour ta carrière, et des mobilités internes ouvertes à toutes et tous chez Doctrine
🌴 Des vacances flexibles et illimitées
📚 Un vrai accent sur la formation individuelle et collective, avec un budget annuel de 750€ en usage libre et des formations en équipe et pour toute l'entreprise régulièrement
🏄‍♂️ Des évènements collectifs réguliers
👩‍⚕️ Une bonne assurance santé avec Alan
🚲 Un forfait mobilité durable à hauteur de 66 euros par mois
🏋️‍♀️ Un abonnement Gymlib pour les activités sportives et bien-être
🍱 Une carte Swile pour tes tickets restaurants
🧘 Un accès gratuit à la plateforme d'accompagnement à la santé mentale Moka.care
💡 Des centaines de réductions et avantages négociés grâce à notre CSE
🍏 Un équipement de travail neuf chez Apple
Notre processus de recrutement 🚀
- Un premier échange de 30 min avec l’un.e de nos Talent Acquisition Manager pour bien comprendre ton projet professionnel et te présenter ce qu'on construit chez Doctrine
- Une rencontre d’1h avec ton/ta futur.e manager, pour détailler le poste et le scope de l’équipe, mais aussi répondre à toutes tes questions.
- Un ou deux tests techniques pour évaluer concrètement tes compétences
- Un déjeuner avec 3 personnes de différents départements chez Doctrine, pour te donner un aperçu de tes futur.e.s collègues
- Un échange sur les valeurs de l’entreprise pour te partager notre vision
- Une rencontre avec Guillaume, notre CEO.
(si nécessaire le processus pourra être adapté pour répondre à tes contraintes personnelles et professionnelles)
Mesdames, autorisez-vous à candidater !
Certaines études scientifiques montrent qu'en particulier les femmes ont moins tendance à postuler à une offre d'emploi quand elles n'ont pas toutes les qualifications. Si cela peut vous rassurer, sachez que cette fiche de poste est indicative donc prenez la comme telle : c'est un guide, ni plus ni moins.
Si Doctrine vous intéresse, sachez que nous aurons plaisir à recevoir votre candidature !
Voir moins",,2024-02-21,https://www.welcometothejungle.com/fr/companies/doctrine/jobs/confirmed-data-engineer_paris?q=ef902e83f94cc3417877b26437a07dbc&o=fed13f0c-e3c6-40d6-90b2-76b82c249b2f,wttj
Data Engineer Senior,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",CDI,Nanterre,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Environnement
Le Data Engineer Senior va intégrer l’équipe Data & RPA du Département Guilde Data, qui regroupe l’ensemble des expertises technologiques liées à l’ingénierie de la donnée, de l’automatisation et à l’exploitation des modèles de Machine Learning. 
Cette Guilde est dédiée au service d’AXA France et de ses équipes (Data office, Tribus, Business, Transformation Office etc.), afin de fournir, en collaboration avec le Data Office, les plateformes (RPA, BI, Data, …) et les données nécessaires aux équipes chargées de délivrer les cas d’usages, puis les déployer et les maintenir en conditions opérationnelles.
Vous serez directement rattaché(e) au Responsable de l’équipe Data & RPA au sein de la Direction Technologies.
Vous allez contribuer directement aux projets des directions métier (ex : Fraude santé, DSN, Pricing IARD, Optimisation du lead management, Fragilité Auto, …) d’AXA France.
La Direction Transformation Digital Tech et Data d'AXA France en quelques mots :
- Une organisation agile en feature teams : tribus, guildes, squads
- Des projets sur des applications innovantes à fort trafic (web, mobile…)
- Des méthodologies craft (TDD, BDD, clean code, code review…) et DevOps
- Une communauté de partage de bonnes pratiques (BBL, dojo, meetup, conf…)
 Votre rôle et vos missions :
Vous aurez pour missions principales de développer les projets Big Data demandés par le métier, et notamment :
- D’accompagner les développeurs plus juniors de l’équipe (coaching, code review, pair programming, …)
- Passer de la donnée brute à de la donnée exploitable, exposée sous forme de tables requêtables dans le Datalake
- Consolider ces données au fur et à mesure de leur alimentation récurrente dans le Datalake
- Les exploiter pour atteindre la finalité business (exposition de Business View, réintégration des résultats dans le SI, service de scoring, …)
- De travailler à la création du socle technique Big Data et industrialiser le cycle de développement de l'équipe
- De mettre en place et de garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de DEV (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc.)
Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :
D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;
D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine, des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;
D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;
De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;
Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longue 
Voir moins","Profil recherché
Votre profil :
D'une formation supérieure en informatique ou scientifique (Master ou Diplôme d'ingénieur), vous justifiez de plusieurs expériences significatives en tant que Senior / Expert Technique en développement Big Data
Compétences techniques :
Connaissances avancées en développement en SPARK et idéalement PySpark (Spark en Python)Une expérience sur un cloud provider public comme Azure (idéalement), AWS, ou GCPConnaissances avancées d'outils de BI comme PowerBI (idéalement) ou Spotfire
Compétences transverses :
Capacité à interagir avec des parties prenantes diverses : Business analyst, Architectes, MétierExpérience en mode de Delivery Agile (Scrum, Kanban, etc.…)
Et Idéalement :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRAMaitrise des Traitements Big Data en mode StreamingMaitrise des Bases de données relationnelles et NoSQLUne expérience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Voir plus",2024-02-21,https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-senior_nanterre_AXA_JM54W7b?q=ef902e83f94cc3417877b26437a07dbc&o=7bdadbda-887d-4cc4-b286-039895074485,wttj
Lead Data Engineer,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",CDI,Créteil,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Environnement :
Le Lead Data Engineer va intégrer l’équipe Data & RPA du Département Guilde Data, qui regroupe l’ensemble des expertises technologiques liées à l’ingénierie de la donnée, de l’automatisation et à l’exploitation des modèles de Machine Learning. 
Cette Guilde est dédiée au service d’AXA France et de ses équipes (Data office, Tribus, Business, Transformation Office etc.), afin de fournir, en collaboration avec le Data Office, les plateformes (RPA, BI, Data, …) et les données nécessaires aux équipes chargées de délivrer les cas d’usages, puis les déployer et les maintenir en conditions opérationnelles.
Vous serez directement rattaché(e) au Responsable de l’équipe Data & RPA au sein de la Direction Technologies.
Vous allez contribuer directement aux projets des directions métier (ex : Fraude santé, DSN, Pricing IARD, Optimisation du lead management, Fragilité Auto, …) d’AXA France.
La Direction Transformation Digital Tech et Data d'AXA France en quelques mots :
- Une organisation agile en feature teams : tribus, guildes, squads
- Des projets sur des applications innovantes à fort trafic (web, mobile…)
- Des méthodologies craft (TDD, BDD, clean code, code review…) et DevOps
- Une communauté de partage de bonnes pratiques (BBL, dojo, meetup, conf…)
Votre rôle et vos missions :
Vous aurez pour missions principales de développer les projets Big Data demandés par le métier, et notamment :
D’accompagner les développeurs plus juniors de l’équipe (coaching, code review, pair programming, …)
Passer de la donnée brute à de la donnée exploitable, exposée sous forme de tables requêtables dans le Datalake
Consolider ces données au fur et à mesure de leur alimentation récurrente dans le Datalake
Les exploiter pour atteindre la finalité business (exposition de Business View, réintégration des résultats dans le SI, service de scoring, …)
De travailler à la création du socle technique Big Data et industrialiser le cycle de développement de l'équipe
De mettre en place et de garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de DEV (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc.)
Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :
D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;
D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine, des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;
D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;
De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;
Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longue 
Voir moins","Profil recherché
Votre profil :
D'une formation supérieure en informatique ou scientifique (Master ou Diplôme d'ingénieur), vous justifiez de plusieurs expériences significatives en tant que Lead / Expert Technique / Tech Lead en développement Big Data
Compétences techniques :
Connaissances avancées en développement en SPARK et idéalement PySpark (Spark en Python)Une expérience sur un cloud provider public comme Azure (idéalement), AWS, ou GCPConnaissances avancées d'outils de BI comme PowerBI (idéalement) ou Spotfire
Compétences transverses :
Capacité à interagir avec des parties prenantes diverses : Business analyst, Architectes, MétierExpérience en mode de Delivery Agile (Scrum, Kanban, etc.…)
Et Idéalement :
Des Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRAMaitrise des Traitements Big Data en mode StreamingMaitrise des Bases de données relationnelles et NoSQLUne expérience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory
Voir plus",2024-02-21,https://www.welcometothejungle.com/fr/companies/axa/jobs/lead-data-engineer_nanterre?q=ef902e83f94cc3417877b26437a07dbc&o=234ad906-0036-4db0-abbc-b6c710b2a906,wttj
Tech Lead Data Engineer,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",CDI,Wasquehal,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
En tant que Lead Data Engineer F/H, vous allez contribuer directement aux projets des directions métier (ex : fraude santé, multi-équipements, pricing IARD, optimisation du lead management, fragilité auto, …) d’AXA France et à la construction du socle technique Big Data. Vous allez intégrer une équipe d'une dizaine de personne composée de Data Engineer et des Tech Lead travaillant en feature team au sein des tribus métier de la Direction Transformation Digital Tech et Data (DT2).  La Direction Transformation Digital Tech et Data d'AXA France en quelques mots : - Une organisation agile en feature teams : tribus, guildes, squads - Des projets sur des applications innovantes à fort trafic (web, mobile…) - Des méthodologies craft (TDD, BDD, clean code, code review…) et DevOps - Une communauté de partage de bonnes pratiques (BBL, dojo, meetup, conf…)  Votre rôle et vos missions Vous aurez pour missions principales de développer les projets Big Data demandés par le métier, et notamment : - D’accompagner les développeurs de l’équipe (coaching, code review, pair programming, etc.) - Passer de la donnée brute à de la donnée exploitable, exposée sous forme de tables requêtables dans le datalake - Consolider ces données au fur et à mesure de leur alimentation récurrente dans le data lake - Les exploiter pour atteindre la finalité business (exposition de business view, réintégration des résultats dans le SI, service de scoring, etc.) - De travailler à la création du socle technique Big Data et industrialiser le cycle de développement de l'équipe - De mettre en place et de garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de DEV (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc.) 
Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :
D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;
D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine, des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;
D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;
De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;
Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longue 
Voir moins","Profil recherché
D'une formation supérieure en informatique ou scientifique (Master ou Diplôme d'ingénieur), vous justifiez de plusieurs expériences significatives en tant que lead sur du développement Big Data.
Compétences techniques : - Connaissances avancées en développement en SPARK et idéalement PySpark (Spark en Python) - Maitrise de l'environnement Microsoft Azure - Connaissances avancées d'outils de BI comme PowerBI  Compétences transverses : - Capacité à interagir avec des parties prenantes diverses : Business analyst, Architectes, Métier - Expérience en mode de delivery Agile (Scrum, Kanban, etc.)  Et Idéalement : - Avoir une expérience en tant que Lead - Des Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRA - Maitrise des Traitements Big Data en mode Streaming - Maitrise des Bases de données relationnelles et NoSQL - Une expérience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data Factory ",2024-02-21,https://www.welcometothejungle.com/fr/companies/axa/jobs/tech-lead-data-engineer_wasquehal?q=ef902e83f94cc3417877b26437a07dbc&o=4e0698a1-094f-49c0-b32c-7a5ddcb7e522,wttj
Data Engineer - Big Data - Data Factory - Services Financiers - Ile de France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Notre Data Factory
Vous êtes passionné(e) par la valorisation de la donnée, rejoignez notre Data Factory localisée à Paris ! Vous y rencontrerez des experts de la mise en œuvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée.
Vous êtes accompagné(e) au développement de vos connaissances aux travers de différents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnée, la modélisation et mise à disposition.
Rejoindre notre Data Factory Sopra Steria, c'est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.
Votre rôle et mission :
Dans le cadre de la mise en place du centre Data pour un grand acteur financier de l’état et selon votre appétence, vous participerez à plusieurs étapes de la chaîne :
- La compréhension des besoins métiers et la traduction solution de data ingénierie
- La mise en œuvre de solution d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;
- La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;
- Le traitement de la donnée jusqu'à l'exposition au métier ;
- La mise en place de la chaine CI/CD et de sa supervision ;
- La veille technologie avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients.
 Additional Information
 Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.
Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire « vendredi ».
L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore).
 Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
> 
Voir moins","Profil recherché
Diplômé(e) d'une Ecole d'ingénieur ou formation équivalente, vous avez déjà participé à un projet Data (Big Data, BI) et vous avez une expérience de minimum 3 ans.
Vous maitrisez un langage de programmation appliqué à l’analyse de données (SQL, Scala, R, Python, Java), le traitement distribué de données (Spark, Pyspark , Hadoop) et un Framework de streaming de données (Kafka, RabbitMQ, etc.)
Vous êtes attiré(e) par le monde du numérique, le Cloud et des technologies innovantes.
Vous avez un bon esprit d'analyse, êtes curieux(se) et passionné(e) et vous avez le sens du travail en équipe dans une organisation Agile type Srcum ou SAFE
Vous accordez une importance particulière au développement de vos compétences sur plusieurs technologies. Vous souhaitez une évolution réelle de carrière à travers l'expérience projet. Vous êtes soucieux de l'apport de valeur pour vos clients. Et vous voulez transmettre votre savoir auprès de collaborateurs moins expérimentés. Alors, n'attendez-plus, ce poste est fait pour vous !
 ",2024-02-21,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-big-data-data-factory-services-financiers-ile-de-france_paris_SS_9Mo8108?q=ef902e83f94cc3417877b26437a07dbc&o=da031cbd-5f8e-46d9-88d5-a5b198b245c5,wttj
Data Engineer - Services Financiers - Ile de France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail :
Au sein de notre Data Factory, vous êtes pleinement impliqué(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi à leur succès. Vous avez l'occasion de développer vos compétences techniques et fonctionnelles de manière approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.
Votre rôle et vos missions :
Vous avez pour rôle la mise en place de pipelines de données fiables, sécurisés et à l’échelle pour soutenir la mise à disposition des données aux cas d’usage métier qui en ont besoin.
Vos activités principales sont les suivantes :
Vous travaillez avec le client pour évaluer, concevoir, déployer, améliorer et maintenir les pipelines de données ;
Vous vous assurez que les pipelines de données créés sont résilients, sécurisés et accessibles ;
Vous définissez le modèle opérationnel pour monitorer et supporter les pipelines de données
Vous fournissez une expertise à nos clients sur leurs données pour assurer leur optimisation et leur sécurité par rapport à leurs besoins ;
Vous apportez un savoir en gestion de la qualité et la gouvernance de la donnée pour assurer le suivi de la conformité à la gouvernance de la donnée
Vous faites de la veille technologique dans le domaine afin d’enrichir les roadmaps technologiques et fournir des solutions modernes à nos clients.
 Informations supplémentaires
Ce que nous vous proposons :
Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.
Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.
.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherché
Votre profil :
De formation Master 2 Ecole d'Ingénieurs ou Informatique, ou équivalent, vous justifiez d'une expérience technique de 3 ans minimum et souhaitez évoluer rapidement dans un contexte motivant. 
Vous avez au moins l'une de ces compétences requises :
Maîtrise des technologies de bases de données Relationnelles et NoSQL
Maîtrise d’au moins un outil d’ETL/ELT (Informatica, datastage, etc.)
Maîtrise des technologies de traitement distribué de données (spark, Hadoop)
Maîtrise d’au moins un framework de streaming de données (Kafka, RabbitMQ, etc.)
Maîtrise de chaines CI/CD et de des bonnes pratiques de DataOps
Maîtrise de solution de Virutualisation de données (Denodo, Dremio, etc.)
Maîtrise d’au moins un environnement cloud public ou privé (Azure, AWS, Outscale, etc.)
Vous êtes attiré(e) par le monde du numérique, le Cloud et des technologies innovantes.
Vous avez un bon esprit d'analyse, êtes curieux(se) et passionné(e) et vous avez le sens du travail en équipe. 
Voir plus",2024-02-21,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-services-financiers-ile-de-france_paris_SS_XN767Ya?q=ef902e83f94cc3417877b26437a07dbc&o=041499b1-8e11-4f02-9b4c-87352dd00e52,wttj
Data Engineer,"{'name': 'LUCKY CART', 'sector': 'Intelligence artificielle / Machine Learning, Grande distribution, SaaS / Cloud Services', 'employees': '58 collaborateurs', 'creation_year': '2011', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,01 mars 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
La forte croissance que nous enregistrons et les projets de développement à l’international nous amènent à renforcer notre équipe data en recrutant un Data Engineer (H/F). 
Rattaché(e) au Lead Dataflow, vos travaux d’innovation et de recherche en data engineering permettront de faire évoluer les produits de Lucky Cart, d’évaluer au mieux leur performance et d’élargir la palette de services connexes.
Vos recherches pourront faire l’objet de publications, de présentation dans des séminaires ou des meetups et de dépôts de brevet.
Votre leadership, votre ambition et votre engagement feront de vous une partie intégrante de la forte expansion de Lucky Cart en France et en Europe.
Au cœur de la société, vous collaborerez au quotidien avec toutes les équipes impliquées (marketing, R&D, data et juridique) pour mener à bien vos missions.
MISSIONS
Sous la responsabilité du Lead Dataflow, vous aurez pour missions :
Définir, développer et mettre en place et maintenir les outils et infrastructures adéquats à la conception d’algorithmes de data science et de recherche opérationnelle, intégrant les contraintes liées à des volumes de données très importants, à des modèles de grande dimension, au temps réel, ainsi qu’à la sécurité, la disponibilité et la performance,
Déployer des pipelines de données et les modèles ci-dessus en production notamment  en concevant et en développant une architecture en micro-services,
Assurer la fiabilité des pipelines de données, des processus ETL et de la transformation des données en réalisant et en mettant en œuvre des tests manuels et automatisés,
Être force de proposition sur tous les sujets d’architecture et de modélisation,
Participer à l’amélioration des étapes du workflow scientifique de Lucky Cart: phase de recherche sur des environnements de calculs distribués, développement d’outils, mise en production, et tests, data lineage,
Être force de proposition et prendre le lead sur des dispositifs innovants,
Travailler en parfaite collaboration avec les autres fonctions au sein de la société (marketing, R&D, Sales, Produit),
Assurer un reporting régulier de l’activité.
Voir moins","Profil recherché
COMPÉTENCES
Maîtriser un ou plusieurs langages structurés (Python, Javascript, Java, C/C++, Scala…),
Maîtriser différents systèmes de base de données (SQL et NoSQL)
Avoir une appétence pour les technologies utilisées dans le Big Data (Hadoop, Map Reduce, Spark, Kafka…),
Avoir une expérience sur une plateforme Cloud (GCP, Azure, AWS,..)
Être familier avec les concepts et algorithmes de statistiques, de data science, de deep learning et d’optimisation en général (recherche opérationnelle notamment),
Avoir une bonne connaissance/expérience de méthodologies d’ingénierie informatique: contrôle des sources, tests unitaires, revue de code,
Être curieux et avoir une forte capacité d’adaptation dans un environnement en mutation constante,
Chercher constamment à élargir et approfondir ses connaissances notamment dans des domaines connexes à la data science, le e-commerce et la distribution,
Voir plus",2024-02-21,https://www.welcometothejungle.com/fr/companies/lucky-cart/jobs/data-engineer_paris?q=ef902e83f94cc3417877b26437a07dbc&o=2868738f-b442-4353-862a-cbedb4d089a0,wttj
Data Engineer (H/F),"{'name': 'TREEZOR', 'sector': 'FinTech / InsurTech', 'employees': '230 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Pour accompagner sa croissance, Treezor recherche un(e) Data Engineer (H/F).
L’équipe Data a pour mission de démocratiser l’usage de la Data à tous les niveaux de l'entreprise.
L’un des principaux axes pour atteindre cet objectif est l’automatisation des processus de transformation de la data au travers de pipelines data.

Toutes les tâches annexes comme la mise en place de dashboards et d’exports ponctuels restent elles aussi importantes.

Le Data Engineer (H/F) joue un rôle clé pour permettre une large adoption de la Data sous ses différents aspects au sein de Treezor.
Vous aurez pour principales missions :
Extraire divers indicateurs de notre Data Lake
Construire des Dashboards
Construire des pipelines Data en Python ou d’autres langages dans l’environnement AWS
Exploiter des sources de données variées (APIs, fichiers CSV, Google docs, etc.) pour enrichir les données du Data Lake
Voici les prérequis pour ce poste : 
Bac+5 dans les domaines suivants : Ingénieur informatique avec une spécialisation ou bien une forte appétence Data
Maîtrise du langage SQL, idéalement sur plusieurs types de bases de données
Compréhension de la modélisation de données dans des bases de données relationnelles
Maîtrise du langage Python dans un contexte Data
Connaissance de l’environnement AWS
Capacité à comprendre rapidement les environnements techniques complexes
Autonomie
Rejoindre l’aventure TREEZOR c’est aussi :
💥 Un environnement agile, dynamique et en pleine croissance et des bureaux en plein cœur de Paris (près de l’Arc de Triomphe) et de Rennes (près de la gare)
📖 Des opportunités d'apprentissage constantes
🤝 Une culture collaborative où la créativité est encouragée
💰 Une rémunération compétitive
🏠 Organisation de travail hybride avec une participation financière pour vous équiper à la maison
🚀 Des avantages pour les salariés (des subventions, des cartes cadeaux etc.) et des événements créés par le CSE (loterie, sorties de groupe dans des parcs d'attractions, grands événements mondiaux comme Roland Garros et Rolex Paris Master, etc.)

Au travers de ses recrutements, Treezor cultive une politique en faveur de la diversité, de l’égalité professionnelle et de l’emploi des travailleurs handicapés.

Voir moins",,2024-02-21,https://www.welcometothejungle.com/fr/companies/treezor/jobs/data-engineer-h-f_paris_TREEZ_AJ98e5L?q=ef902e83f94cc3417877b26437a07dbc&o=eb353393-ac66-42b3-a73e-91fe0ee23619,wttj
Data Engineer F/H,"{'name': 'ONEY', 'sector': 'Banque, FinTech / InsurTech', 'employees': '2300 collaborateurs', 'creation_year': '1983', 'turnover': None, 'mean_age': '41 ans'}",CDI,Croix,Non spécifié,Télétravail occasionnel,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Être Data Engineer F/H chez Oney, pourquoi c'est mieux ?
Plus qu'un poste... une mission pour vous ! Et quelle mission !
Leader indispensable sur les technologies du Big Data, votre challenge est d'assurer la maîtrise de la donnée et d'être garant de la qualité de son utilisation (référencement, normalisation et qualification) afin d'en faciliter l'exploitation par les équipes.
Voici ce que nous vous proposons :
Créer et gérer l'infrastructure et les outils Big Data d'Oney France en relation avec nos prestataires de services, en surveiller les performances et conseiller les modifications d'infrastructure nécessaires.

Travailler sur la collecte, le stockage, le traitement et l'analyse de volumes importants de données. Proposer des solutions optimales (en accord avec les normes / réglementations), les maintenir et les intégrer à l'architecture implémentée par Oney.

Travailler en étroite collaboration avec l'équipe de Data Scientist (consolider / optimiser leurs algorithmes).

Gérer le backlog (projets, évolution, maintenance) de la plate-forme et être un acteur majeur dans la définition et la mise en œuvre de la roadmap.

Réaliser la veille, la promotion et la formation permettant la montée en compétence des équipes IT et métier.
Voir moins","Profil recherché
Ce qui nous plaira le plus chez vous, c'est vous-même ! Alors bien évidemment on vous préférera ouvert, force de proposition, capable de challenger vos interlocuteurs et doté d'une vraie capacité d'analyse et de synthèse, car c'est ce qui vous permettra de mener au mieux votre mission.
Dans votre bagage, on aimerait trouver :
Une expérience dans l'intégration de données provenant de plusieurs sources de données (Connaissance de diverses techniques et frameworks ETL ou ELT) et dans la création de systèmes de traitement de flux en utilisant des solutions telles que Storm ou Spark-Streaming.

Une bonne compréhension des principes de l'informatique distribuée.

Une bonne connaissance des outils Big Data (type Python, Apache Spark) et de gestion du cluster du type Snowflake (ou autres bases de données NoSQL).

Voir plus",2024-02-21,https://www.welcometothejungle.com/fr/companies/oney/jobs/data-engineer-f-h_croix_ONEY_P6J16kP?q=bec13a0c38c548b2046a3d2db01d956a&o=b16b024f-d4d0-4849-b3ff-535afb959b72,wttj
SENIOR DATA ENGINEER (F/H),"{'name': 'COFFREO', 'sector': ""Bureau d'études et d'ingénierie, IT / Digital, SaaS / Cloud Services"", 'employees': '42 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '37 ans'}",CDI,,60K à 65K €,Télétravail total,04 mars 2024,> 5 ans,,"Descriptif du poste
Tous les mois, des centaines de milliers d’utilisateurs (employeurs, salariés, entreprises clientes) font confiance à Coffreo pour fluidifier et sécuriser leurs échanges d’information et de documents RH. Dans le cadre de son développement, Coffreo recherche un Senior Data Engineer.
Vous intégrez l’équipe Solutions qui regroupe l’ensemble des collaborateurs en charge de la plateforme Saas de Coffreo (Produit, Design, Data, Développement, Sécurité, Infrastructure et Exploitation). Vous prenez en charge la structuration et la mise en place des bonnes pratiques et des outils pour exploiter la richesse des données et permettre à Coffreo d’offrir de nouvelles expériences à forte valeur ajoutée à ses utilisateurs.
En tant que Senior Data Engineer, vous aurez 3 missions principales : 
Identification, collecte, traitement et restitution des données
Identifier et rassembler l’ensemble des sources de données structurées ou non structurées pertinentes pour l’entreprise.
Concevoir, construire et gérer des entrepôts de données fiables pour la collecte, le stockage, le traitement et la manipulation des données.
Développer des flux de traitements efficaces pour l’extraction, le nettoyage, la transformation et le chargement des données provenant de différentes sources.
Maintenir à jour le hub des données.
Analyse des marchés et valorisation des données
Identifier les besoins business et métier de l’entreprise en se concentrant sur les opportunités offrant le plus de valeur pour les utilisateurs et les clients.
Proposer de nouveaux indicateurs pour faciliter la visualisation et l’interprétation des données.
Architecture, conseils et contrôles
Effectuer une veille sur les nouvelles technos, les outils et les bonnes pratiques dans l’univers data et une veille métier autour des données de l’entreprise.
Proposer et valider les choix d’outils et les modèles de données de l’entreprise.
Documenter les choix données et s’aligner avec les parties prenantes de l’entreprise.
Mettre en sécurité et contrôler l’usage des données, en accord avec les besoins de l’entreprise et les contraintes réglementaires.
Garantir la qualité et la fiabilité des données de l’entreprise.
Fournir des conseils en développement pertinent pour optimiser les performances de l’exploitation des données.
Voir moins","Profil recherché
Expériences et diplômes
Formation Bac+5 ou équivalent
5 ans d’expérience minimum
Manipulation de gros volumes de données hétérogènes
Compétences techniques
Base de données : MongoDB, MariaDB, PostgreSQL
Langages : Python, PHP - Symfony
Outils : Airflow, Metabase, Datahub
Environnement Saas : Kubernetes, Docker
Qualités humaines
Capacité à la prise d’initiative et à être force de proposition.
Autonome et curieux pour apprendre. 
S’inscrire dans un collectif en s’appuyant sur les 3 piliers de la culture de Coffreo que sont l’ouverture, l’énergie constructive et le courage.
Partager avec, former et faire grandir l’équipe Data.",2024-02-21,https://www.welcometothejungle.com/fr/companies/coffreo/jobs/senior-data-engineer-f-h?q=bec13a0c38c548b2046a3d2db01d956a&o=b94af44d-875c-45d9-94e1-9f88c4f00002,wttj
Data Engineer - BORDEAUX H/F,"{'name': 'CAPGEMINI', 'sector': 'IT / Digital, Organisation / Management, Stratégie, Transformation', 'employees': '360000 collaborateurs', 'creation_year': '1967', 'turnover': '18 Mds €', 'mean_age': '37 ans'}",CDI,Bordeaux,Non spécifié,Télétravail non autorisé,,> 2 ans,Bac +5 / Master,"Descriptif du poste
VOTRE RÔLE
  Vous êtes passionné.e par le domaine de la DATA et vous souhaitez prendre part à un projet d’envergure dans le secteur Telecom ? Rejoignez notre équipe Hybrid Intelligence au sein de Capgemini Engineering en tant que DATA Engineer.
  Vous avez acquis une expérience solide dans le développement de pipelines de données et de solutions pour le traitement d'un grand volume de données. Vous êtes capable de créer des solutions qui répondent aux besoins de différentes parties prenantes telles que les spécialistes de la visualisation de données, les scientifiques de données et les analystes de données.
  En qualité de DATA Engineer, vos missions seront les suivantes :
▪ Concevoir et développer des solutions Data/IA à des fins analytics & dashboarding
▪ Accompagner les Métier dans la compréhension des Analytics et mise en œuvre de solution ""data driven""
▪ Collaborer avec les data scientiste et data ops dans la construction d'une culture axée sur les données
▪ Gérer un écosystème de partenaires data science et assurer un haut niveau d'expertise
▪ Assurer un rôle de veille technologique sur tous les outils autours de la data, IA et BI.


Voir moins","Profil recherché
Profile description:

VOTRE PROFIL
 Vous êtes issu.e d’une formation Ingénieur ou équivalent Bac + 5 Informatique spécialisé en DATA et vous justifiez d’une expérience réussie dans le domaine du développement de pipelines de données et de solution Data (5 ans min).
 Vous maîtrisez les technologies informatiques pour manipuler des bases de données de type : Oracle, Postgre, NoSQL,.. et framework : Hadoop, Spark, Hive, Oozie, Nifi, Jupyter, Kafka , … Votre maîtrise des langages : SQL, SCALA, Pyhton, JAVA, Shell…vous permettent d’être autonome sur la manipulation de données. Enfin, vous avez acquis une expérience dans les outils BI, data visualisation : Kibana, Qliksense, Power Bi… La maitrise de l’Anglais est nécessaire pour ce poste.




Voir plus",2024-02-21,https://www.welcometothejungle.com/fr/companies/capgemini/jobs/data-engineer-bordeaux-h-f_bordeaux_CAPGE_dYV7Vwr?q=bec13a0c38c548b2046a3d2db01d956a&o=f3a013ba-c5bf-4a54-931e-16d4ff860632,wttj
Data Engineer - Apprentice,"{'name': 'WELCOME TO THE JUNGLE', 'sector': 'Média, Recrutement', 'employees': '350 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '32 ans'}","Alternance
(12 mois)",Paris,Non spécifié,Télétravail occasionnel,08 juillet 2024,,,"Descriptif du poste
- Cette offre d’alternance est à pourvoir à partir de juillet ou septembre 2024 pour une période de 12 mois -
On recherche un(e) alternant.e Data Engineer pour rejoindre l’équipe Data de WTTJ et ainsi développer une puissante infrastructure de données capable de supporter les données issues de nos produits (Welcome to the Jungle, Welcome Kit) et de les activer à travers des features à construire !
Ces trois dernières années nous ont permis de structurer de nombreux sujets côté Data, notamment :
La mise en place d’une plateforme data pour réconcilier et activer les données de différentes sources (DBs métier / Analytics / CRMs / Mobile Apps / divers outils et APIs externes) en utilisant Airflow et AWS
La mise en place de dashboards et d’indicateurs de suivi pour toutes nos équipes en utilisant des outils type Metabase ou Looker
Les premières briques de notre moteur de recommandations
Notre stack Data actuelle :
AWS
Airflow
Snowflake
Redshift
Fivetran
dbt
Looker
C’est une belle base, mais il nous reste beaucoup de chemin à parcourir afin de répondre aux besoins internes toujours croissants et tenter de proposer la meilleure expérience à nos utilisateurs.
En 2023, les projets data ont été nombreux et ambitieux : restructuration de certaines briques de la stack, développement de projets data science, définition d’une gouvernance data, … avec des attentes élevées en termes de performance et de qualité.
A noter que l’équipe Data (14 personnes) fait partie intégrante de l’équipe Product et travaille avec tous les corps de métiers (Tech, Produit, Business, Account Management, Marketing, Media, etc.).
Sous la responsabilité de Katia, notre Senior Data Engineer, voici quelques missions sur lesquelles tu seras peut-être amené(e) à travailler :
Prise en main et optimisation des pipelines Airflow actuelles
Aide à la mise en place des dernières briques de notre nouvelle data stack
Amélioration de l’observabilité et de l’alerting de notre solution d’orchestration Airflow
Mais aussi :
Collaborer avec les data analysts et les analytics engineer afin de traduire leurs besoins en solutions techniques
Notre accompagnement pour ta réussite :
Nous aidons les étudiants à se professionnaliser grâce à notre support évolutif :
des missions enrichissantes pour développer ton potentiel
un management bienveillant et à l’écoute
un suivi personnalisé par notre équipe RH
Pour toutes ces raisons, nous avons été récompensés par le label HappyIndex®Trainees | France 2023.
Pourquoi nous rejoindre ?
Reconnue par le label Happy Trainees, comme l’une des meilleures entreprises en France pour faire un stage ou une alternance
Un projet ambitieux dans le secteur du recrutement et de la marque employeur… et des idées à la pelle pour le faire grandir !
Une équipe + de 300 personnes soudées, enthousiastes et passionnées pour faire évoluer notre projet : Rendre le travail réellement passionnant, afin qu’il est une place plus durable dans nos vies
Des compétences extrêmement variées (production vidéo, tech, content,… ) et donc un environnement de travail riche et stimulant
De nombreux événements internes : Jungle Party, Jungle Morning, All hands, Off-site… pour développer la cohésion dans les équipes
Ce que nous te proposons comme avantages :
🏡 Télétravail (à hauteur de 50% de temps)
🍽️ Carte Swile - tickets restaurant digitalisée de 9€ financés à 50% par Welcome
Ⓜ️ Remboursement à hauteur de 75% des titres de transports (abonnements)
⛱ 1 jour de congés offert par mois
Voir moins","Profil recherché
Il n’y a pas de profil type chez Welcome to the Jungle, nous venons tous d’horizons différents et c’est ce qui fait notre force !
Nous t’invitons à postuler si tu es motivé(e) et intéressé(e) par les médias et par le domaine de l’emploi de manière générale et si :
Tu maîtrises Python et SQL (et tu sais vérifier/valider ton code)
Tu as des connaissances en environnement Cloud (AWS, GCP…)
Tu as un profil très technique et tu es capable de travailler avec des profils techniques (DevOps, lead full stack, …).
Tu sais communiquer sur l’avancement de ton travail et évangéliser ton métier auprès d’une audience non technique.
Tu es curieux, débrouillard et tu as une démarche proactive.
Les diplômes nous importent peu, on recherche un(e) passionné(e), un(e) acharné(e) de veille et surtout quelqu’un qui peut nous présenter des projets dont il est fier !
Aussi, l’équipe étant encore relativement petite, on reste très ouverts aux initiatives ! (choix des technos / outils / etc.) C’est le bon moment pour nous rejoindre et apprendre un maximum de choses !
Voir plus",2024-02-21,https://www.welcometothejungle.com/fr/companies/wttj/jobs/stage-data-engineer-x-f-m_paris?q=bec13a0c38c548b2046a3d2db01d956a&o=29ca9d37-8944-420a-af20-c29695b58460,wttj
Data Engineer (H/F),"{'name': 'MELTONE ADVISORY', 'sector': 'Logiciels, IT / Digital, Transformation', 'employees': '150 collaborateurs', 'creation_year': '2014', 'turnover': '17M€', 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,Bac +5 / Master,"Descriptif du poste
Chez MeltOne Advisory, il n’y a pas les fonctions métiers d’un côté et la technologie de l’autre. Tous les consultants sont polyvalents et ont un parcours qui leur confère une expertise indéniable à la fois sur vos problématiques métiers mais aussi sur la dimension IT.
Tu interviendras en collaboration étroite avec nos managers et sur différents types de projet :
Transformations digitales,
Optimisation des processus,
Amélioration de la qualité de l’information,
Mise en oeuvre et évolution de systèmes d’information,
Assistance à la gestion de projet
Tes missions seront :
Concevoir des solutions pertinentes et innovantes en tenant compte de tous les enjeux du contexte client
Implémenter et optimiser ces solutions dans les règles de l’art
Conseiller les clients dans leurs choix
Transmettre ton savoir-faire et participer à la capitalisation de connaissance des utilisateurs
Notre structure à taille humaine est un cadre parfait pour te permettre d’évoluer rapidement en t’offrant l’opportunité d’intervenir à la fois sur les différentes phases d’un projet : cadrage / conception et mise en oeuvre / conduite de projet et encadrement d’équipe, mais également sur des activités à dominante commerciale : conception d’offres / rédaction de proposition / soutenance en clientèle.
Voir moins","Profil recherché
Tu as une expérience projets avec Snowflake
Tu maitrises le domaine fonctionnel de la finance ou de la logistique
Tu souhaites intervenir sur des projets à forte valeur ajoutée
Tu as un goût prononcé pour les nouvelles technologies
Tu as un fort esprit d’équipe, et aime partager des moments conviviaux avec tes collègues
Tu es doté(e) d’un bon relationnel et tu maîtrises l’anglais
Tu recherches une entreprise à taille humaine avec un management de proximité pour accompagner ton développement de carrière, et un environnement où l’autonomie et l’esprit d’initiative sont mis en avant.
Si en lisant cela, tu te dis que c’est tout toi (ou presque), c’est que tu as l’étoffe d’un futur MeltOner et que tu dois postuler à cette offre.",2024-02-21,https://www.welcometothejungle.com/fr/companies/meltone-advisory/jobs/consultant-d-a-snowflake-h-f_paris?q=bec13a0c38c548b2046a3d2db01d956a&o=536f2e06-5584-45d6-8d30-8aa7ac203615,wttj
Margo Analytics - Data Engineer - H/F,"{'name': 'MARGO', 'sector': 'Logiciels, IT / Digital', 'employees': '400 collaborateurs', 'creation_year': '2005', 'turnover': '43M', 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,Bac +5 / Master,"Descriptif du poste
Margo Analytics est l'entité experte de Margo Group des problématiques Data, Cloud et DevOps créée en 2020 par leurs fondateurs Raphaël et Mounir. Aujourd’hui 60 consultants ont intégré l'entité et nous avons commencé à travailler avec 18 nouveaux clients (Banque, Industrie, Assurance, Énergie, E commerce, Santé). A leurs côtés, vous pourrez évoluer rapidement et développer de nouvelles compétences. 
Deux ADN fondateurs forts et spécifiques à Margo Analytics à l’origine de l’entité :
- Toujours se positionner sur les plus beaux sujets et sur les missions à fortes valeurs ajoutées
- Recruter des consultants passionnés et curieux qui cherchent à être challengés
Aujourd’hui, Margo Analytics possède 4 communautés de compétences : 
- Data engineer 
- Data Science/ IA 
- Galaxy OPS (devOps, dataOps, cloudOps)
- Architecte Big Data 
Ainsi en rejoignant Margo Analytics vous aurez le choix des missions (#consultantfirst) sur lesquelles vous souhaitez travailler. Vous serez accompagné par les deux fondateurs ainsi que par le leader de votre communauté, dont les rôles sont de rechercher le projet qui correspondra le plus à vos attentes et de vous accompagner dans votre carrière.
🎯Les missions Margo Analytics : 
Au sein de la communauté Data Engineer vos missions seront : 
- Développer en mode agile les cas d’usages métier 
- Mettre en place des processus de collecte, d’organisation, de stockage et de modélisation des données 
- Développer des traitements de transformation et de production de données
- Assurer la mise en production des modèles de prédiction créés par les Data Scientists
- Participer à l’amélioration continue et au refactoring de code
Besoin de projection ? Voici un exemple de mission : 
Camille accompagne un grand compte dans le domaine de l’industrie sur son projet de mise en place d’un nouveau datalake en Azure databricks. L’objectif de cette mission est d’assurer la distribution de la donnée de manière optimisée pour créer une couche de distribution et permettre aux Data Scientists d’implémenter les use cases. Camille apporte son expertise sur les technologies suivantes : Spark, Scala, Azure, Databricks.
Nos stack Technique : 
- Langage : Python/Scala/Java
- Framework : Spark/Hadoop
- Cloud: Azure/ AWS/ GCP 
🙌 Les avantages : 
- Tickets restaurants Swile
- Mutuelle Alan prise en charge à 100%
- Pass Navigo pris en charge à 100%
- Télétravail
- Formations illimitées
- Locaux en plein coeur de Paris
- Places en crèches
🤝Notre processus de recrutement : 
Notre processus de recrutement se fait en 3 étapes, réparties sur 7 à 15 jours maximum :
- Première rencontre ! Vous échangez avec un RH et un dirigeant sur votre parcours, vos aspirations professionnelles ainsi que sur Margo Analytics et les opportunités que nous proposons
- Challengez-vous dans le cadre d’un entretien technique avec l’un de nos experts. C’est également l’occasion pour vous d’avoir son retour d’expérience
- Dernier entretien de motivation : pour finir, vous rencontrez un membre du board de Margo Analytics pour un entretien final
🔍 Vous êtes un(e) futur(e) Margo Analytics si : 
Must-Have
Vous êtes issu(e) d’une école d’ingénieur ou d’un cursus universitaire équivalent niveau Bac + 5 / Master
Vous aimez coder et vous êtes passionné(e) d’informatique et de Data
Vous êtes curieux(se) et vous vous intéressez aux dernières technologies du marché
Vous justifiez d’une première expérience en tant que Data Engineer
Nice to Have
Vous êtes ambitieux(se) et n’avez pas peur de travailler sur des projets challengeants dans des environnements à fortes contraintes techniques . Vous parlez et comprenez l’anglais. 
Voir moins",,2024-02-21,https://www.welcometothejungle.com/fr/companies/margo/jobs/margo-analytics-data-engineer-h-f_paris?q=bec13a0c38c548b2046a3d2db01d956a&o=b2b0255c-af91-4826-9b60-f23ea56ca5b0,wttj
SENIOR DATA ENGINEER (H/F),"{'name': 'SNCF CONNECT & TECH', 'sector': 'Mobilité, Application mobile, Logiciels, Intelligence artificielle / Machine Learning, Big Data, E-commerce', 'employees': '1178 collaborateurs', 'creation_year': '2000', 'turnover': None, 'mean_age': '36 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
SNCF Connect & Tech, filiale privée de SNCF Voyageurs, est le leader du e-commerce français et implémente les solutions digitales clients dans le secteur des mobilités. En s’appuyant sur l’expertise de plus de 1200 collaborateurs basés à Lille, Nantes et Paris, SNCF Connect & Tech accompagne le groupe SNCF dans les projets de digitalisation.
Son ambition : innover pour rendre les mobilités durables accessibles à tous.
Au sein de l’équipe Business&Client, les Data Engineers répondent aux besoins de reporting de l’activité commerciale de notre plateforme e-commerce : SNCF Connect, application de réservation de billets de train en ligne.
En lien direct avec les équipes Marketing et la Direction Générale, vous collectez et transformez la donnée. Dans un contexte de migration sur le Cloud AWS en 2021, vous participez également à l’implémentation de l’architecture dans le but de migrer d’un dataware house vers un datalake house.
Vous serez entouré.e d’une équipe composée actuellement de 6 Data Engineers, un Product Owner, un Project Manager, un Scrum master dédié et de 2 Quality Assurance Engineers.
Activités :
Collecter, nettoyer et transformer la donnée de manière hebdomadaire,
Participation aux développements sur le socle Data,
Assurer la mise en production et son support,
Accompagner les équipes Client Interne à analyser la donnée afin qu’ils puissent prendre des décisions stratégiques pour le groupe,
Participer au cadrage de l’implémentation de l’architecture,
Documenter l’architecture,
Garantir les bonnes pratiques de développement et de mise en production.
Environnement technique :
SQL
AWS
Spark
Scala
Airflow
Python
Connaissances BI
Profil recherché :
Vous avez au minimum 6 ans d'expérience dans la DATA et une première expérience BI,
Vous êtes proactif.ve, vous ne laissez jamais une problématique sans solution,
Savoir échanger sur l’avancée de ses projets et partager à l’équipe sont indispensables,
Vous êtes capable de prendre du recul pour analyser vos pratiques et proposer des solutions dans un esprit d’amélioration continue,
Vous souhaitez vous impliquer dans une équipe aux projets stratégiques,
Des connaissances en JAVA/KOTLIN serait un plus.
Rejoindre SNCF Connect & Tech :
C’est intégrer la plus grande communauté d’experts des transformations numériques, en France, dans le secteur des mobilités et devenir un #DigitalMobilityChanger.
C’est innover pour rendre les mobilités durables accessibles à tous"", en incarnant les valeurs de l'entreprise : Citoyenneté, Audace, Performance, Ouverture, Confiance.
C'est continuer à apprendre et grandir grâce à un programme de formation adaptée aux envies de chacun
C'est bénéficier d'un package financier compétitif et équitable fondé sur un principe de méritocratie collective et individuelle
C'est évoluer au sein d’une entreprise humaine, inclusive qui favorise un bon équilibre de vie pro/perso (jusqu’à 3 jours de télétravail par semaine), certifiée Great Place to Work pour la 4è année consécutive
C'est s’engager au service d’une société durable et solidaire, en favorisant des comportements, des mobilités et des usages responsables
Voir moins",,2024-02-20,https://www.welcometothejungle.com/fr/companies/sncf-connect-tech/jobs/data-engineer_paris_SCT_RpP8yyw?q=bec13a0c38c548b2046a3d2db01d956a&o=4acb313e-4250-4e57-9d88-603b9d5edb24,wttj
Data Engineer (H/F),"{'name': 'EXTIA', 'sector': 'Ingénieries Spécialisées, IT / Digital, Stratégie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Tours,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Ensuite quoi !
Vous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse…
Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer à la définition des besoins et à la rédaction des User Stories,
Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,
Concevoir et construire des architectures de données,
Intégrer des sources de données,
Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,
Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux.
Profil recherché
Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple,
Vous maitrisez les bases de l’analyse statistique,
Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
Vous êtes familiarisé avec l’environnement Linux,
Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts.
#LI-FIC
Voir moins","Profil recherché
D'abord qui ?
Ingénieux(se), votre imagination débordante vient à bout de chaque problématique,
Attentif(ve) aux détails, vous avez un œil de Lynx pour repérer les incohérences,
Efficace, vous ne remettez pas à demain ce qui peut être fait dès aujourd’hui.",2024-02-20,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_tours?q=bec13a0c38c548b2046a3d2db01d956a&o=ae827471-671d-49f1-b70a-48b3b060842e,wttj
Alternance - ingénieur de données (data engineer) - 1/2 ans - Grenoble - H/F,"{'name': 'SCHNEIDER ELECTRIC', 'sector': 'Ingénieries Spécialisées, Objets connectés, Energie', 'employees': '128000 collaborateurs', 'creation_year': '1836', 'turnover': ""34 milliards d'euros CA (22)"", 'mean_age': '39 ans'}",Alternance,Grenoble,Non spécifié,Télétravail non autorisé,,> 1 an,Bac +4,"Descriptif du poste
Vous êtes étudiant spécialisé en DATA et avez une forte appétence pour le domaine de la Data Science alors rejoignez l'équipe PLM process and Governance basée à Grenoble.Environnement de travail Dans le cadre de la Gouvernance des données, nous sommes responsables, pour les données Produits de Schneider Electric, de la modélisation des données, de la gestion de leurs metadata et de nous assurer que les moyens de contrôle de la qualité des données sont en place. Sont inclues dans le périmètre l'ensemble de données Produits de Schneider Electric sur l'ensemble des systèmes d'information techniques. La mission de l'équipe PLM process and Governance est de s'assurer, pour Schneider Electric, que les données décrivant nos Produits dans nos systèmes sont fiables, et ce, pour une meilleure expérience client et une meilleure capacité à prendre des décisions stratégiques.Vos missions En tant que Data analyst, vous aurez 3 activités à réaliser dans le cadre de cette alternance :
Data modelling : Gérer la définition (dictionnaire de données), documenter le type de relation reliant différents ensembles de données, finaliser et optimiser la modélisation des données Produit et maintenir les metadata. Application utilisée : Collibra
Data analysis : Faire des analyses permettant d'identifier et d'investiguer les problèmes qualité de données. Applications utilisées : Excel , Tableau, Base SQL
Data Quality : participer aux tests des nouveaux tableaux de bord de mesure de la qualité des données . Applications utilisées : Excel , Tableau, Base SQL
Vous contribuerz également à :
Data Architecture: Participer à l'application des règles d'or de la gouvernance des données. Maintien des documentations techniques, suivre l'évolution de l'architecture, Intégration et de la sécurité. Applications utilisées : MS Visio, Confluence
Profil recherché
Bac +4 - Bac +5 - Ingénieur / université.
Spécialité : Modélisation des données, Analyse des données, Gouvernance des données, Master Data management, Gestion de l'information, Génie Industriel
Pré-requis :
Bachelor en Computer Science ou Master en Data Science ou Ingénieur généraliste passionné de données
Expérience dans la Data ou les systèmes d'information est un plus.
Intérêt pour travailler dans l'architecture de données et de solutions
Capacité à apprendre rapidement de nouvelles technologies, systèmes et sujets
Capacité à travailler de manière autonome sur les tâches assignées et à accepter des directives sur les affectations données.
Compréhension et documentation des diagrammes de flux de données et du schéma de base de données.
Capacité à comprendre des structures de données complexes, des modèles de données avec leur relation / lien
Capacité à travailler dans une équipe multiculturelle
Langues : Anglais (B2)
Logiciels : Excel, Tableau, MS Visio
Compétences exceptionnelles en matière de documentation.
Connaissance des langages R ou Python est plus
Détails techniques et logistiques
Durée de l'alternance : 1 à 2 ans (2 ans serait souhaitable)
Date de démarrage souhaitée : Septembre 2024
Localisation du poste : Grenoble (38)
Pourquoi nous? Schneider Electric est la référence en matière de transformation numérique de la gestion de l'énergie et de l'automatisation. Nos technologies permettent au monde d'utiliser l'énergie de manière søre, efficace et durable. Nous nous efforçons de promouvoir une économie mondiale à la fois viable sur le plan écologique et hautement productive.34 milliards d'euros de chiffre d'affaires global 128 000+ employés dans plus de 100 pays 45 % du chiffre d'affaires de l'IoT 5 % du chiffre d'affaires consacré à la R&DVous devez soumettre une demande en ligne pour que votre profil soit pris en considération pour un poste chez nous. Ce poste sera visible jusqu'à ce qu'il soit pourvu.Schneider Electric a pour politique de fournir des possibilités d'emploi et d'avancement égales dans les domaines du recrutement, de l'embauche, de la formation, du transfert et de la promotion de toutes les personnes qualifiées, quelle que soit leur race, religion, couleur, sexe, handicap, origine nationale, ascendance, âge, statut militaire, orientation sexuelle, état matrimonial ou toute autre caractéristique ou conduite légalement protégée. Agences concernées : Schneider Electric n'accepte pas de curriculum vitæ soumis de façon spontanée et ne sera pas responsable des frais occasionnés par de tels envois.
Voir moins",,2024-02-20,https://www.welcometothejungle.com/fr/companies/schneider-electric/jobs/alternance-ingenieur-de-donnees-data-engineer-1-2-ans-grenoble-h-f_grenoble?q=bec13a0c38c548b2046a3d2db01d956a&o=017c9210-d600-456e-b0ad-d73d8a010ae4,wttj
Data Engineer Confirmé(e) H/F - Lyon,"{'name': 'EVOTEO', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '35 collaborateurs', 'creation_year': '2017', 'turnover': '3M€', 'mean_age': '30 ans'}",CDI,Lyon,42K à 55K €,Télétravail fréquent,19 février 2023,> 3 ans,Bac +5 / Master,"Descriptif du poste
Dans le cadre de notre expansion ambitieuse mais contrôlée, et pour satisfaire aux besoins changeants de tous nos clients, nous recherchons une/un Data Engineer pour renforcer nos équipes.
Dans le cadre du projet de migration de notre client, de leur ancien système BI vers leur nouvel écosystème Lakehouse (Discover) sur Databricks / AWS, nous sommes à la recherche d’une personne qui peut gérer :
La récupération (et surtout la refonte) de leur modèle de données pour qu’il soit la base de leurs futurs cas d’utilisation des données (refonte des procédures SQL Server de Side vers des travaux Databricks en Python / SQL / Spark)
La migration des tableaux de bord PowerBI ainsi que la refonte de leur modèle pour les simplifier, en les source sur le Lakehouse au lieu de Sid
La refonte des rapports SSRS vers des tableaux de bord Databricks pour les rapports opérationnels
La récupération des exports (principalement des fichiers CSV) gérés par Side aujourd’hui.
La durée de ce projet devrait s’étaler sur 2023-2024.
Voir moins","Profil recherché
Nous recherchons avant tout des personnalités : curieuses, habiles, sociales, adaptables et passionnées.
De formation BAC+5 (Master 2,DESS,DEA), formation ingénieure ou informatique, tu as une expérience d’au moins 3 ans en engineering des environnements Big #DATA
Les technos:
Développement : Spark (scala), Python
Intégration continue : GIT, Maven, Jenkins, Ansible, Docker
Technologies Big #DATA (Hadoop, Yarn, Pig, Hive, Sqoop, Flume, Impala, Spark, ElasticSearch)
Cloud AWS : S3, Glue, ECS
Cloud Azure
Nous insistons sur les compétences Spark.
Ce poste en CDI est à pourvoir dès que possible sur la région lyonnaise.
Tu êtes un futur collaborateur acteur, en quête de perspectives d’évolution, capable de rigueur et d’esprit d’analyse ? Rejoins-nous !",2024-02-20,https://www.welcometothejungle.com/fr/companies/evoteo/jobs/data-engineer-h-f-lyon_lyon_EVOTE_bomOVgb?q=bec13a0c38c548b2046a3d2db01d956a&o=7e03ee66-2a91-4428-a37c-1aa1fe51f9d8,wttj
,,,,,,,,,,,,https://www.welcometothejungle.com/fr/companies/groover/jobs/data-engineer_paris_GROOV_b1JpdRw?q=bec13a0c38c548b2046a3d2db01d956a&o=577516c9-b0e5-4929-8e22-330ce5983070,wttj
Data Engineer (H/F) - Bordeaux,"{'name': 'GROUPE BPCE', 'sector': 'Banque, FinTech / InsurTech, Finance', 'employees': '100000 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': None}",CDI,Bordeaux,Non spécifié,Télétravail non autorisé,08 mai 2023,< 6 mois,Bac +5 / Master,"Descriptif du poste
Poste et missions
Au sein de la « Plateforme Assurances » vous intégrez l'équipe Data Management Office sous la responsabilité du manager de l'équipe.
L'équipe DMO est en charge de mettre en place les nouveaux projets liés à la feuille de route Data des métiers de l'assurance non vie et de maintennir les solutions décisionnelles.
Vous interviendrez sur le périmètre indemnisation :
Sur le périmètre RUN, vous assurez la gestion, l'analyse et le suivi de résolution des incidents et des évolutions remontées par les utilisateurs.
Sur le périmètre projet, vous assurez le cadrage fonctionnel du projet avec les métiers, le suivi des développements et les tests.
Votre rôle sera de :
Collaborer avec les référents métier pour recuillir leurs besoin ;
Rédiger des spécifications techniques et fonctionnelles ;
Collaborer avec les référents applicatifs pour établir les mapping liés aux besoins métier ;
Collaborer avec les intervenants IT (Infrasctructure, DBA) ;
Participer aux phases de modélisation (modélisation relationnelle / BI) ;
Assurer la conception et le développement des flux d'intégration du DWH et des Datamart métier ;
Mise en place des stratégies de tests unitaires et fonctionnelles ;
La mise en place des normes de développements et les bonnes pratiques (modèles de traitements, …) ;
Mise en place des documents de référence ;
Pilotage des développeurs intervenant sur le périmètre indemnisation.
Voir moins","Profil recherché
Vous avez déjà participé à un ou plusieurs projets BI, sur des problématiques de Data Integration (mise en place des bonnes pratiques pour des flux otpimisés) ou plus généralement dans la mise en place de Datawarehouses/Datamarts.
Vous attachez une importance particulière à la qualité de vos développements (respect de l'architecture, normes de codage, tests unitaires,…).
Vous avez une très bonne maîtrise des outils suivants :
Idéalement ETL Stambia: Talend
SGBD : SQL Server, Oracle
Reporting : Microstrategy, PowerBI",2024-02-20,https://www.welcometothejungle.com/fr/companies/groupe-bpce/jobs/data-engineer-h-f-bordeaux_bordeaux_GB_5rJjZea?q=bec13a0c38c548b2046a3d2db01d956a&o=98e8eb16-847c-450d-89a2-22510e3baa4e,wttj
Cell Performance Data Engineer (F/H),"{'name': 'ACC - AUTOMOTIVE CELLS COMPANY', 'sector': 'Ingénieries Spécialisées, Energie, Automobile', 'employees': '1200 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '38 ans'}",CDI,Bruges,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
The main focus of this position is on the cell performance requirements verification and the analysis and treatment of battery data.

- The cell performance team drives the battery design process on cell level. The design of lithium-ion-batteries allows for many parameters to be set. Each parameter shall be chosen to fulfil the customer requirements to the final product in the best and most cost-efficient way. The connection between design parameters and final product performance is not trivial for lithium-ion-batteries. Many design decisions require a large number of tests, generating large amounts of data. Data which needs to be analysed carefully. This data analysis requires skilful data handling, a thorough working method and an in-depth understanding of batteries.   
- The main work consists in performing data analysis autonomously. The work includes data collection from different sources, data verification and validation, automatic or semi-automatic data treatment, data presentation and interpretation of the results. The main outputs of the work are concise data analysis reports and presentations. An important secondary outputs are software tools which allow for automation of the data treatment and the analysis process, starting with data cleaning routines up to simple machine-learning models for parameter prediction.
Voir moins","Profil recherché
Knowledge:
Data science and programming (preferably Python), statistics and machine learning, measurement technics.
Experience:
Data driven scientific research, data work in a manufacturing industry (chemical, automotive, aerospace, …)  (> 2 years)
Qualifications:
Master, non-IT engineering background required
Field of study: Physics, Chemistry, Mechanical Engineering, Electrical Engineering or Chemical Process Engineering.
Some extra skills which make the difference:
Software development skills, electro-chemical and battery knowledge, chemical laboratory experience

Nos avantages : Locaux neufs, places de parking réservées aux covoitureurs, possibilité de recharger votre voiture électrique sur des emplacements réservés de notre parking. Restaurant d'entreprise et service de livraison de repas et de paniers fruits & légumes. Télétravail, retraite complémentaire, conciergerie.

Vous bénéficierez aussi de nos conférences, ateliers bien-être, séances d'ostéopathie, de notre association Sports & Culture, ainsi que des subventions vacances, sport, et culture.


Voir plus",2024-02-20,https://www.welcometothejungle.com/fr/companies/acc-automotive-cells-company/jobs/cell-performance-data-engineer-f-h_bruges?q=bec13a0c38c548b2046a3d2db01d956a&o=6493f770-03fd-4dc3-bc26-e0059eb06b61,wttj
DATA ENGINEER - H/F,"{'name': 'BANQUE DE FRANCE', 'sector': 'Banque, Assurance', 'employees': '8959 collaborateurs', 'creation_year': '1800', 'turnover': None, 'mean_age': None}",Stage,Paris,Non spécifié,Télétravail non autorisé,,> 6 mois,,"Descriptif du poste
Dans le cadre de son plan de travail sur l'Intelligence Artificielle, le Lab propose un stage afin de développer et de concrétiser les sujets suivants :
Maintenance de scraping de sites avec l’IA (évaluer si à partir de scraping existant, l’IA pourrait corriger les erreurs liées aux évolutions des sites scrapés.)
Évaluation du produit Giskard (framework pour tester les modèles LLM)
Gestion des CRA (Comptes Rendus d’Activités) des prestataires (traitement à base de OCR les CRA transmis par les prestataires, contrôle sur les consommations, voir la possibilité de faire des traitements IA)","Profil recherché
Formation recherchée : 
Master (1 ou 2) Data Engineer, Data Scientist
Master (1 ou 2) Ingénierie des systèmes numériques
Compétences : 
Technologie: IA, IA Générative
outils de gestion/analyse de la data: PowerBI ou autres
Langages de programmation: Python, ReactJS, Java
Environnements: Cloud, Docker, Git
Qualités : 
Capable de travailler à la fois en autonomie et en équipe.
Force de proposition dans son domaine d'expertise
Une très bonne communication autant à l'écrit qu'à l'oral
  Contactez nos ambassadeurs 
Voir plus",2024-02-20,https://www.welcometothejungle.com/fr/companies/banque-de-france/jobs/data-engineer-h-f_paris-ii_BDF_wR2RLD?q=bec13a0c38c548b2046a3d2db01d956a&o=31da430d-84a3-4851-8eff-4bbf0d48d43f,wttj
Data Engineer PySpark,"{'name': 'THALES', 'sector': 'Logiciels, Cybersécurité, Aéronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mds€', 'mean_age': None}",CDI,Toulouse,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces.
Le Centre de Compétence Augmented Data recherche un Data Engineer PySpark confirmé - H/F en CDI à Toulouse (Site de Labège – 31). 
Nous recherchons actuellement un Data Engineer expérimenté dans les solutions basées sur PySpark, adossées à des stockages de types HDFS ou Parquet, pour participer à l’un de nos projets mettant en œuvre plusieurs composants software et impliquant plusieurs collaborateurs sur des missions de Data Engineering similaires. 
Vous intégrez le Centre de Compétence Augmented Data, dont le cœur de métier est la conception et la mise en œuvre de solutions techniques innovantes et performantes autour de la gestion et du traitement massif de données dans un contexte mêlant Big Data et développements d’applicatifs exploitant ces données, le tout correspondant aux exigences de nos clients dans les domaines du spatial, de l’aéronautique, de l’énergie, du secteur public ou encore de l’e-santé. 
QUI ETES-VOUS ?
Issu d’une formation universitaire ou ingénieur en informatique, vous justifiez d’une expérience solide dans le domaine de la donnée (Data Science, Data Engineering, Stockage), en ingénierie logicielle globalement.
Une connaissance cloud serait un réel atout, qu’il soit public (AWS, GCP, AZURE) ou privé. 
Vous avez de bonnes expériences en développement logiciel et/ou scripting (principalement Scala & Java).  
Vous êtes à l’aise en anglais.  
Vous êtes curieux et rigoureux.  
Vous aimez travailler en équipe au quotidien. 
Pour vous le succès n’est que collectif. 
CE QUE NOUS POUVONS FAIRE ENSEMBLE :
En nous rejoignant, vous vous verrez confier les missions suivantes : 
La conception et architecture de solutions logicielles dans des contextes cloud ou assimilés, pouvant inclure des composants de calculs utilisant PySpark, 
La rédaction de dossiers d’architecture technique répondant au besoin client, 
La participation aux développements et à la maintenance opérationnelle des composants logiciels mis en œuvre, 
L’estimation des charges techniques liées aux activités de conception, de développement, d’intégration et de validation, 
La participation aux réponses à appel d'offre émises par nos clients et qui impliquerait l’utilisation de technologies de calculs distribuées, 
La veille technologique dans votre domaine d'expertise et réalisation en avance de phase de prototypes innovants. 
Techniquement vous serez donc amené à réaliser les activités suivantes :
Mise en place de pipelines de traitement de données  
Utilisation de l’état de l’art des technologies actuelles dédiées à ces activités : Spark / Spark Streaming / Flink / Storm / Kafka  
Développement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie)  
Utilisation de tous les types de stockage actuels :  
SQL : Oracle, SQLServer, PostgreSQL  
NoSQL : Cassandra / MongoDB / HBase  
Objet : S3 / MinIO 
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Voir moins",,2024-02-20,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-pyspark_toulouse_THALE_xyLQR81?q=bec13a0c38c548b2046a3d2db01d956a&o=61564b0b-c596-47c9-a984-c88d2597b43b,wttj
Data Engineer (F/H),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 M€', 'mean_age': '34 ans'}",CDI,Montpellier,32K à 43K €,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
SII Montpellier accompagne ses clients dans l’intégration des nouvelles technologies, procédés et méthodes de management de l’innovation pour contribuer au développement de leurs futurs produits ou services et faire évoluer leurs systèmes d’information. Nous conjuguons de manière durable et vertueuse la satisfaction de nos clients avec le bien-être et l’épanouissement de nos collaborateurs tout en délivrant un haut niveau de performance.
Au travers de notre entité composée d’une quarantaine de consultants et de leurs expertises liées au développement applicatif, à la gestion de projets et d’infrastructures, au test et aux enjeux autour de la data et cyber sécurité. Nous intervenons aujourd’hui sur des projets à forte valeur ajoutée, ambitieux et à l’international autour des secteurs du numérique, du télécom, de la banque/assurance, de l’industrie et des services en assistance technique et/ou en engagement (centre de services, centre de compétences, ...). Nous accompagnons de nombreux acteurs locaux (Montpellier et agglomération) vous permettant de trouver plusieurs opportunités proches de chez vous ou depuis chez vous (flexibilité / mode de fonctionnement hybride).
Vous rejoindrez une équipe soudée, talentueuse et engagée qui priorise le bien-être au travail, l’humilité et le partage. Vos compétences techniques et votre savoir-être seront mis en valeur au sein de missions sur des sujets variés allant de la conception et développement d’applications web, mobile, IHM à la gestion d’infrastructure traditionnelle et Cloud en passant par la gestion de projets agiles.
Rencontrons-nous et valorisons ensemble nos savoir-faire.
Dans le but de répondre aux demandes de nos partenaires, nous ouvrons un poste en qualité de Data Engineer (F/H), sur Montpellier (34).  
Vos missions :

- Collecter et stocker les données

- Comprendre les besoins des utilisateurs

- Déterminer la cohérence des données

- Implémenter des outils de pointe pour faciliter l’usage des données dans l’entreprise et améliorer l’efficacité opérationnelle.
Diplômé(e) d'un Master en Informatique, d'une école d'Ingénieur ou équivalent, vous disposez d'une expérience de minimum 5 ans sur des compétences similaires en DATA. Vos compétences techniques sur SSAS, SSIS, SSRS seront un vrai plus !
 La rigueur, la patience et la curiosité sont vos points forts. Vous disposez d'un important esprit d’équipe et faites preuve de bienveillance au quotidien.
Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN).
Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés.
En 2023, pour la 6e année consécutive, SII France a obtenu le label Great Place To Work®.
Nous avons été reconnus 3e entreprise de « + de 2500 salariés » où il fait bon vivre.
Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés !
Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières.
En fonction de la mission, il est possible de réaliser jusqu'à 50 % de télétravail grâce à notre accord dédié. Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.
Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins","Profil recherché
Compétences requises : Big data, SQL.
Qualités désirées : Capacités d'analyse, Bon relationnel, Satisfaction client.
Avantages : Aide à la mobilité, Tickets restaurant, Télétravail.",2024-02-20,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer-f-h_montpellier?q=bec13a0c38c548b2046a3d2db01d956a&o=dee6ef25-41e8-4519-9c7c-959e08153c0a,wttj
Senior Data Engineer (F/M/D) - Lisbon,"{'name': 'VESTIAIRE COLLECTIVE', 'sector': 'Luxe, Mode, E-commerce', 'employees': '800 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': '34 ans'}",Autres,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Vestiaire Collective is the leading global online marketplace for desirable pre-loved fashion. Our mission is to transform the fashion industry for a more sustainable future by empowering our community to promote the circular fashion movement. Vestiaire was founded in 2009 and is headquartered in Paris with offices in London, Berlin, New York, Singapore and Hong Kong and warehouses in Tourcoing (France), Crawley (UK), Hong Kong and New York.
We currently have a diverse global team of 700 employees representing over 50 nationalities. Our values are community, activism, transparency, dedication and greatness. We are proud to be a BCorp.
Senior Data Engineer (F/M/D)
Full-time, Permanent role based in Lisbon
About the role
Vestiaire Collective is hiring a Senior Data Engineer on our data platform team, to play a crucial role in developing and enhancing our data infrastructure, driving Vestiaire Collective's mission towards a sustainable fashion industry.
What you'll do
Real-Time Data Processing
Create real-time data processing applications, leveraging Kafka for timely data availability.
Ensure high throughput and low latency in data processing/service.
Data Platform Architecture:
Design and evolve our data platform's architecture for scalable, efficient data processing and analytics.
Participate in strategic planning for long-term alignment with business goals
Data Integration and Modeling
Implement robust, scalable data integration strategies.
Optimize data models for efficient storage, retrieval, and analytics.
Building ML Platform Ecosystem
Collaboratively develop a scalable, reliable ML platform, focusing on model serving, training, and essential MLOps features.
Prioritize efficiency, automation, and best practices in MLOps.
Workflow Automation
Develop automated solutions to enhance data operations.
Utilize Apache Airflow for effective data workflow management.
Continuous Learning and Improvement
Stay abreast of the latest data engineering trends and technologies.
Foster a culture of continuous learning and knowledge sharing.
Who you are
Concrete knowledge on Real-Time data processing (Apache Spark/Flink, Apache Beam)
Required Skills
Python
Expert in clean, efficient Python coding; proficient with data libraries and web frameworks
Skilled in asynchronous programming.
SQL: Strong in SQL syntax and query optimization.
Kafka:Proficient in Kafka architecture and stream processing.
ML Deployment / Optimization: Experienced in ML model deployment and MLOps principles.
Required Toolings
Spark/Flink (or any other framework): Experienced in distributed data processing
Apache Airflow: Expertise in workflow management.
FastAPI/Robyn: Skilled in FastAPI/Robyn development and features.
Git:Advanced knowledge in version control and CI/CD integration.
Cloud Services: AWS or similar cloud experience.
Data Visualization Tools: Proficient in tools like Streamlit.
Monitoring and Logging Tools: Experienced with tools like DataDog, Prometheus, and Grafana.
Nice to have skills
Terraform/Ansible: Skills in infrastructure automation.
Golang: Experience in Go programming and its ecosystem.
DBT: Proficient in DBT for data warehousing.
What we offer
A meaningful job with an impact on the way people consume fashion and promote sustainability
Flexible work possibilities
The opportunity to do career-defining work in a fast-growing French-born scale up
The possibility to work as part of a globally diverse team with more than 50 nationalities
Two days to help Project - reinforcing your activist journey and volunteer for an association
Significant investment in your learning and growth
Competitive compensation and benefits package
As full member of our entrepreneurial project, you will be eligible to free shares
Vestiaire Collective is an equal opportunities employer
Voir moins",,2024-02-20,https://www.welcometothejungle.com/fr/companies/vestiaire-collective/jobs/senior-data-engineer-f-m-d-lisbon_paris?q=bec13a0c38c548b2046a3d2db01d956a&o=bf7eab47-ff5b-46e2-baa7-ac32d2a058f4,wttj
Data Engineer (F/H),"{'name': 'ASI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '500 collaborateurs', 'creation_year': '1993', 'turnover': '42,5 M€', 'mean_age': '34 ans'}",CDI,Nantes,Non spécifié,Télétravail non autorisé,,> 3 ans,,"Descriptif du poste
Dans un souci d’accessibilité et de clarté, les termes employés au masculin se réfèrent aussi bien au genre féminin que masculin.  
Simon, Responsable de l’équipe Data Nantaise, est à la recherche d’un Data Engineer pour mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud et On Premise pour nos projets clients.
Au sein d’une équipe dédiée et principalement en contexte agile : 
Vous participez à la rédaction de spécifications techniques et fonctionnelles
Vous maitrisez les formats de données structurés et non structurés et savez les manipuler
Vous connectez une solution ETL / ELT à une source de données
Vous concevez et réalisez un pipeline de transformation et de valorisation des données, et ordonnancez son fonctionnement
Vous prenez en charge les développements de médiations 
Vous veillez à la sécurisation des pipelines de données
Vous concevez et réalisez des API utilisant les données valorisées
Vous concevez et implémentez des solutions BI
Vous participez à la rédaction des spécifications fonctionnelles et techniques des flux
Vous définissez des plans de tests et d’intégration
Vous prenez en charge la maintenance évolutive et corrective
Vous traitez les problématiques de qualité de données
En fonction de vos compétences et appétences, vous intervenez sur l’une ou plusieurs des technologies suivantes :
L’écosystème data notamment Microsoft Azure
Les langages : SQL, Java
Les bases de données SQL et NoSQL
Stockage cloud: S3, Azure Blob Storage…
Les ETL/ESB et autres outils : Talend, Spark, Kafka NIFI, Matillion, Airflow, Datafactory, Glue...
En rejoignant ASI,
Vous évoluerez au sein d’une entreprise aux modes de fonctionnement internes flexibles garantis par une politique RH attentive (accord télétravail 3J/semaine, accord congé parenthèse…) 
Vous pourrez participer (ou animer si le cœur vous en dit) à nos nombreux rituels, nos événements internes (midi geek, dej’tech) et externes (DevFest, Camping des Speakers…)  
Vous évoluerez dans une entreprise bientôt reconnue Société à mission, Team GreenCaring et non GreenWashing porteuse d’une démarche RSE incarnée et animée, depuis plus de 10 ans. (Equipe RSE dédiée, accord forfaits mobilités durables…) 
Voir moins","Profil recherché
Vous êtes issu d’une formation supérieure en informatique, mathématiques ou spécialisé en Big Data, et avez une expérience minimale de 3 ans en ingénierie des données et d'une expérience opérationnelle réussie dans la construction de pipelines de données structurées et non structurées.
Attaché à la qualité de ce que vous réalisez, vous faites preuve de rigueur et d'organisation dans la réalisation de vos activités.
Doté d'une bonne culture technologique, vous faites régulièrement de la veille pour actualiser vos connaissances.
Un bon niveau d’anglais, tant à l’écrit qu’à l’oral est recommandé.
Désireux d’intégrer une entreprise à votre image, vous vous retrouvez dans nos valeurs de confiance, d’écoute, de plaisir et d’engagement. 
Le salaire proposé pour ce poste est compris entre 36 000 et 40 000 €, selon l'expérience et les compétences, tout en respectant l'équité salariale au sein de l'équipe. 
 A compétences égales, ce poste est ouvert aux personnes en situation de handicap. ",2024-02-19,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-f-h_nantes_ASI_w17yGm1?q=bec13a0c38c548b2046a3d2db01d956a&o=86704c33-9111-40ce-a36e-dcb401dde06c,wttj
Cloud Data Engineer (F/H),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Villeurbanne,Non spécifié,Télétravail non autorisé,,> 4 ans,,"Descriptif du poste
En résumé :
Poste : Cloud Data Engineer F/H
Secteur de l'entreprise : experts conseil dans les secteurs de la banque-assurance, le luxe-retail et l’Industrie
Localité : Lyon
Type de contrat : CDI
Niveau d’expérience : au moins 3 ans
Vous êtes passionné(e)s par ladata ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data driven et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?
Vous souhaitezrejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez répondu « Oui » à chacune de cesquestions alors devenez Cloud Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/services.
Alors, prêt à rejoindrel’aventure Micropole ? N’attendez plus !
Vous rejoignez notreentité Data Analytics basée à Lyon, où vous interviendrez sur l’intégralité deplusieurs projets avec une vision « Data 360° », mêlant Conseil,Architecture, Intégration et Data Science. En tant que Cloud Data Engineer, vousaccompagnerez les directions métiers dans l'évaluation de l'efficacité de leurprocessus et dans leur stratégie pour optimiser leur performance. Vous serezrattaché(e) à l’équipe Data Analytics, composée de 50 #InnovativePeople.
 Dans vos missionsquotidiennes, vous serez amené(e)à : 
Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data/Cloud
Modéliser et analyser des données dans le Cloud ;
Garantir la sécurité et la compliance des données ; 
Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. 
Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; 
Réaliser une veille technologique pour être à la pointe sur les solutions Cloud & Data ; 
Participer au développement de notre centre d’excellence GCP
Voir moins","Profil recherché
Profil
Vos compétences techniques : 
Vous avez un minimum de 3 années d’expérience en tant que Cloud Data Engineer dont au moins une première sur des projets  Azure et GCP ou AWS ;
Vous êtes idéalement certifié(e) ou à défaut avez l’ambition de le devenir ;
Vous êtes à l'aise avec un langage de programmation (Spark, Scala, Python, Java ou R) ; 
Vous maitrisez les théories et outils de modélisation de données ;
Des connaissances en industrialisation, CI/CD et/ou gestion de version seront particulièrement appréciées 
Vos  atouts: 
Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; 
Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients ;
Vous souhaitez vous impliquer dans le développement de communautés techniques autour du Cloud GCP et des solutions Data. 
Voir plus",2024-02-19,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/cloud-data-engineer-f-h_villeurbanne?q=bec13a0c38c548b2046a3d2db01d956a&o=403d3bb2-cab5-4908-adf8-5f1057c2d023,wttj
Senior Data Engineer / Azure (H/F),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Villeurbanne,Non spécifié,Télétravail non autorisé,,> 7 ans,,"Descriptif du poste
En résumé :
Poste : Senior Data Engineer / Azure F/H
Secteur de l'entreprise : experts conseil dans les secteurs de la banque-assurance, le luxe-retail et l’Industrie
Localité : Lyon
Type de contrat : CDI
Niveau d’expérience : au moins 3 ans
Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data driven et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez répondu « Oui » à chacune de ces questions alors devenez Senior Data Engineer / Azure pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/ services.
Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !
Dans vos missionsquotidiennes, vous serez amené(e) à : 
Apporter votre expertise à nos clients pour garantir une valeur ajoutée rigoureuse et innovante
Participer activement à la réalisation technique des projets de nos clients
Accompagner et conseiller les clients sur les meilleures pratiques, les technologies et outils les plus adaptés au contexte.
Réaliser des présentations, démonstrations, POC ou Pilotes pour mettre en lumière les recommandations technologiques.
Être constamment en veille technologique
Transférer des compétences spécifiques aux équipes techniques de nos clients
Voir moins","Profil recherché
Profil
Vous avez un minimum de 5 années d’expérience sur des projets Data et sur des projets Cloud Microsoft Azure ou à défaut une certification Azure avec l’ambition de vous préparer à d’autres. 
Vous maîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R) ; 
Vous avez une maitrise des théories et outils de modélisation de données, 
Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, 
Solide Expérience Technique DansLes Domaines Suivants
Azure Data Factory
Azure Synapse Pipeline
Spark/Scala
pyspark
Python
Voir plus",2024-02-19,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/senior-data-engineer-azure-h-f_villeurbanne?q=bec13a0c38c548b2046a3d2db01d956a&o=69a0033e-ae60-40d9-a751-d691b061e8e3,wttj
Expert Python-Data Engineer H/F,"{'name': 'OPEN', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '4000 collaborateurs', 'creation_year': '1989', 'turnover': '420M', 'mean_age': '40 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
💡 Qui sommes-nous ? 
 Rejoindre la BU Cloud & DevOps, c’est rejoindre la communauté d'experts techniques qui accompagne des sujets stratégiques et transverses pour Open France. 
 Afin d'accompagner nos clients dans la mise en œuvre de leur transformation digitale, et dans le cadre de leurs projets à forte valeur ajoutée, nous recrutons un.e Expert Python-Data Engineer   H/F !  📌 Vos missions détaillées  
Etablir ou challenger le cahier des charges,  
Rédiger les spécifications techniques,  
Définir l’architecture de la librairie,  
Développer, documenter, tester et maintenir ces librairies en s’appuyant sur des pratiques de développement à l’état de l’art,  
Optimiser le traitement de jeux de données de grande taille (plusieurs téraoctets) pour minimiser les coûts et délais de traitement,  Adapter les librairies pour permettre le traitement de données diverses   (comptes-rendus médicaux, images d’IRM, bases hospitalières, bases nationales),   Mentorer des profils développeurs moins expérimentés,   Collaborer avec les équipes Produit, de la Direction Technique et de la Direction des   données en suivant la méthodologie agile (scrum ou kanban) (gestion d'un backlog, rituels, etc.),  
 ⚙ Votre environnement Technique 
 python3, R, designs patterns, pytest, NumPy, Pandas, (Py)Spark Airflow, Dask, AWS S3, Azure Blob Storage...  
🌟 Vous êtes 
 Passionné.e de technique et justifiez de 3 à 6 ans d’expérience en développement Back end python, permettant d’avoir une connaissance approfondie du langage, y compris ses fonctionnalités avancées, ses bibliothèques standard et ses meilleures pratiques
Maîtrisez bien dans un environnement cloud de l’utilisation du stockage objet (eg.AWS S3 ou Azure Blob Storage),
 Nous recherchons de la technique mais aussi de la passion et du dynamisme ! 
 🤝 Vous êtes mettre de votre carrière : Comment ?  
 Intégrer des projets transverses et stratégiques : outils internes, meetups, summits, formations, avant-ventes, chiffrage, veille, audit SI …  
Evoluer vers un rôle de leader Technique grâce à un accompagnement personnalisé et un parcours de formation et certifications adaptées.  
 💬 Notre Process De Recrutement 
📞 Bref échange téléphonique 
🗨 Rencontre RH pour parler de vous, de vos aspirations professionnelles et vous présenter Open, 
💭 Echange avec l’un des experts 
🆗 Temps de partage avec votre futur manager. 
✅Après vous avoir souhaité la bienvenue vous bénéficiez d’un parcours d’intégration sur-mesure. 
  CODE REC : ACH23516  
   Qu’attendez-vous pour être Open ?
Voir moins",,2024-02-19,https://www.welcometothejungle.com/fr/companies/open/jobs/data-engineer-python-h-f_levallois-perret?q=bec13a0c38c548b2046a3d2db01d956a&o=852366ff-c7d0-401f-9360-8b25d8086de1,wttj
Senior Data Engineer (H/F),"{'name': 'PUBLICIS FRANCE', 'sector': 'Marketing / Communication, Publicité, Digital, Relations publiques, AdTech / MarTech, Evénementiel, Design', 'employees': '5000 collaborateurs', 'creation_year': '1926', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 3 ans,,"Descriptif du poste
Capability
L'équipe Data est composée d'une quinzaine de collaborateurs regroupant Data Scientists, Data Engineers, Data Analysts et Data Strategists, travaillant sur la co-construction d'outils générant de la valeur à partir de la donnée de nos clients.
Si vous aussi, vous partagez cette vision et souhaitez profiter et contribuer à notre communauté internationale sur le sujet, rejoignez-nous !
Vous interviendrez chez nos clients et serez en charge des missions suivantes : 
Travailler étroitement avec les parties prenantes à la compréhension fonctionnelle de leurs projets au travers d’ateliers de spécification et de modélisation 
Construire des pipelines d’ingestion, de transformation et de valorisation de leurs données au service de la réalisation de produits décisionnels (BI), de data science/machine learning ou d’analytique opérationnelle 
S’assurer de la qualité du code réalisé en adéquation avec les normes et standards du projet et mettre en place les tests de validation  
Documenter ces projets jusqu’à leur industrialisation opérationnelle et le support nécessaire à la vie du produit. 
Vous contribuerez également à la veille collective et à l’émulation commune lors de nos journées de partage au sein de la craft Data engineer, à la rédaction d’articles ou à la participation de projets internes.
Voir moins","Profil recherché
Vous disposez de plus de 3 ans d’expérience dans la réalisation de pipelines de données, dans des contextes de construction de la plateforme data à l’échelle, dont notamment dans l’usage des technologies suivantes : 
Python 3 : programmation de traitement de la donnée sous la forme de Notebook, utilisant des librairies orientées data et analytique tels que PySpark et/ou Panda, en mode batch ou streaming 
SQL pour manipuler les données stockées et réaliser des traitements de transformation avancées et à l’échelle 
Collecte et publication utilisant les protocoles de brokers de messages en streaming tels que Kafka, API REST, GRPC, fichiers avec SFTP ou Objet (S3, GCS, ADLS) 
Formatage de la donnée JSON, Avro ou Parquet et SQL Apache Iceberg, Delta Lake 
Cloud native platform AWS (S3, Glue, Athena, RDS, Kinesis, ...), GCP (Cloud Storage, Big Query, Pub/Sub, Data Flow), Azure (ADLS, Synapse, Stream Analytics) 
Principes d’automatisation et de gestion de release, usage d’outillage de gestion de configuration et de pipeline de CI/CD. 
Voir plus",2024-02-19,https://www.welcometothejungle.com/fr/companies/publicis-france-1/jobs/senior-data-engineer-h-f_paris_PF_KRaDyW2?q=bec13a0c38c548b2046a3d2db01d956a&o=54830772-dd45-446a-8ae0-7f3b77bfcf66,wttj
Cloud Ops Data Engineer - W/M,"{'name': 'LESAFFRE', 'sector': 'Pharmaceutique / Biotechnologique, Agroalimentaire / Nutrition animale', 'employees': '11000 collaborateurs', 'creation_year': '1853', 'turnover': '2.7 milliards', 'mean_age': '41 ans'}",CDI,Marcq-en-Baroeul,Non spécifié,Télétravail occasionnel,,> 5 ans,,"Descriptif du poste
Lesaffre Digital & Data ambitions 
Lesaffre’s Digital & Data journey started some years’ ago with a strong push to encourage and cross-fertilize initiatives across the organization. Business impact of some of these first actions (Sales efficiency tools, My Lesaffre App for Bakers, digitalization of key operations etc…) have confirmed the importance of accelerating this journey.
Digital & Data are to become a fundamental transformative force for Lesaffre growth. On one hand, as a lever to increase customer centricity and user experience. On the other, to bring operational excellence across the company.
More concretely, some of these opportunities are: 
Further empower salesforce & leverage digital marketing to capture, convert and keep our future and current clients and consumers  
Leverage omnichannel strategies to sell, serve and delight our customers
Turn our industrial operations even more intelligent and efficient (digitalization of processes, automatization of low added value tasks, industrial productivity, supply chain performance …)
Contribute to unlocking further value and efficiency on R&D processes
Empowering transversal functions to deliver better user experiences
To accelerate this journey, a substantial additional effort is being put in place. The recent arrival of a Chief Digital & Data Officer (ExCom member) has marked the beginning of this acceleration. With a more structured and results oriented journey, CD&D officer is creating a new organisation. Data and Tech is at the heart of the transformation. A Data and Tech Factory has been created to valorise Lesaffre’s data assets, and deliver use cases, governance capacities, and innovation. Both embedded in the Business and at a Global level, digital & data talents will be crucial to this transformative journey both in the impact to business as well as the development of D&D capabilities.
In this context, Lesaffre is recruiting a Cloud Ops Data Engineer
Job Description
The Cloud Ops Data Engineer will help build and maintain a data services platform based on a data mesh approach. This position will be part of the Data & Tech Factory and will report to the Head of Data Architecture and Engineering. She/he will be responsible for designing, architecting, developing, and maintaining our data services platform with a strong focus on automation, infrastructure as code, and DevOps practices.
Responsibilities:
Design, develop, and maintain data services platform that supports a data mesh approach using infrastructure as code principles
Collaborate with data development teams to integrate digital and data services into the platform
Design and implement automation solutions for platform configuration, provisioning, and monitoring using DevOps tools and practices such as Ansible, Terraform, and GitOps
Implement continuous integration and continuous deployment (CI/CD) pipelines for data services
Identify and resolve platform performance issues using automated monitoring and alerting
Establish processes to monitor the state of the platform and notify support teams in case of malfunction
Collaborate with IT security teams to ensure the platform meets security standards and implement security as code principles
Create and maintain documentation and runbooks to ensure platform resiliency and recovery in case of failure
Voir moins","Profil recherché
There is no such thing as a ‘perfect’ candidate. Lesaffre is a place where you can grow and in which whatever background you come with will be a plus. If you feel excited about the position, we strongly encourage you to apply even if you meet only two third the requirements.
In-depth knowledge of distributed data architectures
Strong experience in designing and developing large-scale distributed data solutions using infrastructure as code and DevOps principles
In-depth knowledge of cloud-based data technologies (AWS is a plus)
Experience working with container management tools such as Kubernetes and Docker (EKS, ECS)
Knowledge of data storage technologies (Snowflake, NoSQL, S3)
 Solid programming skills in one or more programming languages, including at least Python
Experience working with both relational and non-relational databases (Postgresql, Cassandra, MongoDB, RDS, DynamoDB)
Voir plus",2024-02-19,https://www.welcometothejungle.com/fr/companies/lesaffre/jobs/cloud-ops-data-engineer-w-m_marcq-en-baroeul?q=bec13a0c38c548b2046a3d2db01d956a&o=89f1d71b-1f0f-4f9b-9252-a88928954979,wttj
"Data Engineer (Spark, Scala)","{'name': 'SHAPE IT', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '103 collaborateurs', 'creation_year': '2020', 'turnover': '7.650.000', 'mean_age': '29 ans'}",CDI,Lyon,40K à 48K €,Télétravail fréquent,01 avril 2024,> 4 ans,Bac +5 / Master,"Descriptif du poste
Rejoindre une équipe de shapers qui partagent des valeurs et des convictions écologiques, humaines et sociales et intégrer un projet client challengeant, ça te dit ?
Ce poste est en CDI !
Localisation : Lyon. Mode hybride avec possibilité de travailler depuis ton chez toi.
Le salaire est compris entre 40 et 48k€ en fonction du niveau requis pour le projet !
Ce que l’on te propose en détail :
Nous recherchons un Data Engineer confirmé qui aura pour missions de prendre en charge des tâches de développement sur des projets de build et d’intervenir sur le maintien en condition opérationnelle du Datalake.
Tes missions pourraient être les suivantes :
Accompagner les clients sur leur transformation digitale
Développer sur des langages Big Data
Réaliser la phase de tests
Rédiger des documentations techniques
Rechercher et conseiller sur de nouvelles technologies","Profil recherché
Ce projet est pour toi, si :
tu as des compétences solides Spark (Scala) (job, scripting, déploiement). Python est un plus, Kafka également.
tu as une bonne connaissance des services Data Azure batch et streaming (Data Factory, HDInsight, Synapse, Stream Analytics …).
tu as des connaissances des outils Azure DevOps et de déploiements automatisés
tu maîtrises l’anglais, car l’environnement de travail est international",2024-02-19,https://www.welcometothejungle.com/fr/companies/shape-it/jobs/data-engineer-spark-scala_lyon_SI_NoNN4oD?q=bec13a0c38c548b2046a3d2db01d956a&o=a17f05c5-3d5c-4a4a-a926-aa7187eec8af,wttj
Data Engineer Snowflake,"{'name': 'SHAPE IT', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '103 collaborateurs', 'creation_year': '2020', 'turnover': '7.650.000', 'mean_age': '29 ans'}",CDI,Lyon,42K à 50K €,Télétravail fréquent,25 mars 2024,> 5 ans,Bac +5 / Master,"Descriptif du poste
Rejoindre une équipe de shapers qui partagent des valeurs et des convictions écologiques, humaines et sociales et intégrer un projet client challengeant, ça te dit ?
Ce poste est en CDI !
Localisation : Lyon. Mode hybride avec possibilité de travailler depuis ton chez toi.
Le salaire est compris entre 42 et 50k€ en fonction du niveau requis pour le projet !
Chez l’un de nos clients dans le secteur de l’assurance, entouré.e d’une équipe de passionné.es, comme toi, tu auras la responsabilité de :
Créer et structurer un datawarehouse
Exposer le DW avec des applications de dataviz
Créer des dashboards à destination des équipes métier
Développer, tester et déployer les flux d’ingestion de données
Automatiser les flux d’extraction et de traitement des données
Identifier les besoins métier et proposer des solutions pertinentes","Profil recherché
Ce projet est pour toi, si :
la donnée est ton dada
tu as envie de t’investir dans un beau projet from scratch
tu aimes relever des challenges
tu es autonome
tu as des compétences en : ETL : Talend / Librairie : Snowflake / outils de dataviz (PowerBI, Qlik…) / BDD : SQL - MongoDB / outils de gestion de projet Agile : Jira - Confluence",2024-02-19,https://www.welcometothejungle.com/fr/companies/shape-it/jobs/data-engineer-snowflake_lyon_SI_xYdeX6m?q=bec13a0c38c548b2046a3d2db01d956a&o=2894fc04-b8e1-4fea-bd16-07f44bcfd153,wttj
Data Engineer Snowflake,"{'name': 'SHAPE IT', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '103 collaborateurs', 'creation_year': '2020', 'turnover': '7.650.000', 'mean_age': '29 ans'}",CDI,Lille,42K à 50K €,Télétravail fréquent,25 mars 2024,> 5 ans,Bac +5 / Master,"Descriptif du poste
Rejoindre une équipe de shapers qui partagent des valeurs et des convictions écologiques, humaines et sociales et intégrer un projet client challengeant, ça te dit ?
Ce poste est en CDI !
Localisation : Lille. Mode hybride avec possibilité de travailler depuis ton chez toi.
Le salaire est compris entre 42 et 50k€ en fonction du niveau requis pour le projet !
Chez l’un de nos clients dans le secteur de l’assurance, entouré.e d’une équipe de passionné.es, comme toi, tu auras la responsabilité de :
Créer et structurer un datawarehouse
Exposer le DW avec des applications de dataviz
Créer des dashboards à destination des équipes métier
Développer, tester et déployer les flux d’ingestion de données
Automatiser les flux d’extraction et de traitement des données
Identifier les besoins métier et proposer des solutions pertinentes","Profil recherché
Ce projet est pour toi, si :
la donnée est ton dada
tu as envie de t’investir dans un beau projet from scratch
tu aimes relever des challenges
tu es autonome
tu as des compétences en : ETL : Talend / Librairie : Snowflake / outils de dataviz (PowerBI, Qlik…) / BDD : SQL - MongoDB / outils de gestion de projet Agile : Jira - Confluence",2024-02-19,https://www.welcometothejungle.com/fr/companies/shape-it/jobs/data-engineer-snowflake_lille?q=bec13a0c38c548b2046a3d2db01d956a&o=4b162e43-941e-4033-8652-4380b37d4a98,wttj
"Data Engineer (Spark, Scala)","{'name': 'SHAPE IT', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '103 collaborateurs', 'creation_year': '2020', 'turnover': '7.650.000', 'mean_age': '29 ans'}",CDI,Lille,40K à 48K €,Télétravail fréquent,01 avril 2024,> 4 ans,Bac +5 / Master,"Descriptif du poste
Rejoindre une équipe de shapers qui partagent des valeurs et des convictions écologiques, humaines et sociales et intégrer un projet client challengeant, ça te dit ?
Ce poste est en CDI !
Localisation : Lille. Mode hybride avec possibilité de travailler depuis ton chez toi.
Le salaire est compris entre 40 et 48k€ en fonction du niveau requis pour le projet !
Ce que l’on te propose en détail :
Nous recherchons un Data Engineer confirmé qui aura pour missions de prendre en charge des tâches de développement sur des projets de build et d’intervenir sur le maintien en condition opérationnelle du Datalake.
Tes missions pourraient être les suivantes :
Accompagner les clients sur leur transformation digitale
Développer sur des langages Big Data
Réaliser la phase de tests
Rédiger des documentations techniques
Rechercher et conseiller sur de nouvelles technologies","Profil recherché
Ce projet est pour toi, si :
tu as des compétences solides Spark (Scala) (job, scripting, déploiement). Python est un plus, Kafka également.
tu as une bonne connaissance des services Data Azure batch et streaming (Data Factory, HDInsight, Synapse, Stream Analytics …).
tu as des connaissances des outils Azure DevOps et de déploiements automatisés
tu maîtrises l’anglais, car l’environnement de travail est international",2024-02-19,https://www.welcometothejungle.com/fr/companies/shape-it/jobs/data-engineer-spark-scala_lille?q=bec13a0c38c548b2046a3d2db01d956a&o=c1e5a34e-5ceb-4be1-9211-093408d6ec3b,wttj
Senior Data Engineer,"{'name': 'YUBO', 'sector': 'Application mobile', 'employees': '70 collaborateurs', 'creation_year': '2015', 'turnover': '25 millions €', 'mean_age': '28 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Challenges:
As a Senior Data Engineer, you:
- Propose solutions with a product approach to the business (consider different use cases)
- Design data models for new features
- Participate in the evolution of existing products
- Help the more junior members of the team to reach their full potential
- Working in an environment with major constraints on relationship graphs
- Work on a high-volume product/database (peak 10k ops/second)
- Make sure you have the right database for the right problem (business, tech…)
- Address issues of testability (non-production data sets) and observability","Profil recherché
Technical & Mindset Prerequisites
>Professional background:
> 8-10 years 
Start-up / Scale-up
>Specific knowledge:
English B2-C1
Must have: Mastery of microservices architecture
Must have: Mastery of high-availability topics
Must have: Mastery of event sourcing architecture
Must have: Mastery Kafka or NATS
Must have: couchbase, MongoDB, Trino, redis, Postgres, elasticsearch
Take a 360° view of data architecture (not just respond to each need 1 by 1)
Notions of data sciences needs in term of datas
>Soft skills:
Inventiveness
Voir plus",2024-02-19,https://www.welcometothejungle.com/fr/companies/yubo/jobs/senior-data-engineer_paris_YUBO_j0aJb0J?q=bec13a0c38c548b2046a3d2db01d956a&o=a6a9f31d-c48b-4a63-9a9a-a045cc620634,wttj
Data Engineer,"{'name': 'PICTARINE', 'sector': 'Application mobile, Logiciels, E-commerce', 'employees': '50 collaborateurs', 'creation_year': '2009', 'turnover': '14M$', 'mean_age': '32 ans'}",CDI,Toulouse,Non spécifié,Télétravail occasionnel,,> 3 ans,,"Descriptif du poste
Mission and challenges 🎯
Si tu es enthousiaste à embarquer dans la nouvelle équipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c’est l’aventure qu’il te faut! 🏔️
Avec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les équipes de Pictarine ne sont jamais à court d’idées pour explorer de nouveaux horizons. 🚀
En tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toute ta créativité pour garantir la qualité de la data, accompagner et challenger les besoins data.
Tu évolueras au sein de l’équipe Engineering, composée des pôles dev & data. Tu rejoindras une équipe data déjà composée d’une data analyste, Romane, et de la data manager, Marie !
Ton rôle comprendra les aspects suivants 👇🏻
Tu es garant de la qualité de la data !
En simplifiant la structure de la data et réduisant le nombre de tables
En transformant les données pour les rendre facilement utilisables
En orchestrant le flux des données de manière continue et automatique
Tu accompagnes et challenges les équipes de Pictarine !
En co-construisant des solutions data appropriées
En élevant le niveau de jeu des méthodes data existantes
En faisant rayonner la data autour de bonnes pratiques et d’outillages adéquates
Voir moins","Profil recherché
About you 💎
Tu as au moins 3 ans d’expérience sur un poste similaire
Tu as de bonnes connaissances dans la transformation des données (ETL), la conception de modèles de données et les stratégies d’optimisation des requêtes
Tu as des compétences en DevOps pour le déploiement et la gestion efficace des pipelines de données
Tu as une bonne maîtrise de Python, SQL & Github
Tu maîtrises l’un des data warehouse suivants : BigQuery, Refshift, Snowflake, Synapse Analytics
Tu as une passion pour résoudre des problèmes business avec la programmation
Tu es curieux de tester des nouvelles technologies
Tu es organisé, rigoureux et portes une grande attention aux détails
Tu es doté d’excellentes qualités relationnelles, de communication et de vulgarisation
Tu es un team player et toujours à l’affût de nouvelles idées
Voir plus",2024-02-19,https://www.welcometothejungle.com/fr/companies/pictarine/jobs/data-engineer_toulouse?q=bec13a0c38c548b2046a3d2db01d956a&o=d3ac419e-7b64-4657-8668-d53814635f08,wttj
Data Engineer Senior (H/F),"{'name': 'BUSINESS AT WORK', 'sector': 'IT / Digital, Organisation / Management, Transformation', 'employees': '350 collaborateurs', 'creation_year': '2000', 'turnover': '37 millions', 'mean_age': '35 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Au sein de notre Practice Analytics, le produit c’est l’équipe ! C’est pourquoi nous cherchons constamment à la développer et à l’enrichir.
En tant que Data Engineer, vous aurez pour mission de concevoir et développer l’environnement technique de gestion des données de nos clients. Vous comprendrez leurs enjeux métiers et proposerez des solutions innovantes pour garantir un accès facile et sécurisé aux données tout en réduisant les coûts.
Vos missions :
·         Evaluer l’architecture de gestion de données actuelle et proposer de nouvelles approches innovantes.
·         Préconiser des solutions techniques de stockage et de gestion de Big Data.
·         Implémenter des outils de pointe pour faciliter l’usage des données dans l’entreprise et améliorer l’efficacité opérationnelle.
·         Assurer la conformité des solutions proposées avec la réglementation RGPD pour garantir la confidentialité et la protection des données de nos clients.
·         Analyser l’impact de la gestion des données sur la performance globale de l’entreprise et fournir des insights précieux à nos clients pour les aider dans leurs prises de décisions.
·         Effectuer une veille technologique constante et participer à des conférences et colloques sur les sujets Cloud et du Big Data pour rester à la pointe de votre domaine d’expertise.
Nous rejoindre, c’est aussi :
·         Participer au plan de développement de notre Practice Analytics !
·         Vivre une expérience entrepreneuriale !
·         Participer à des missions variées, et sur des technologies innovantes (Analytics, Cloud, MDM, Datascience…)
Voir moins","Profil recherché
Les incontournables pour un(e) Data Architect chez Business At Work :
·         La Gestion de la donnée n’a aucun secret pour vous ? (Une certification est un + !)
·         Vous avez utilisé lors de vos derniers projets des technologies data de type : Python, SQL, Databricks, Azure, GCP, AWS, Talend, data virtualisation (Power BI, Tableau…), les solutions MDM etc.… et ce sont désormais des solutions incontournables pour vous ?
·         Vous avez l’habitude de participer à la conception des architectures modernes de données ou des Data hub ?
·         Vous maitrisez le décisionnel et la modélisation des données.
·         Les enjeux de la donnée pour les directions métier vous parlent ? Vous pourriez passer des heures à discuter de l’impact des données sur la performance d’une entreprise
·         Vous êtes capable d’animer des ateliers avec des collaborateurs de fonctions supports ou production",2024-02-19,https://www.welcometothejungle.com/fr/companies/baw-business-at-work/jobs/data-engineer-h-f_paris?q=bec13a0c38c548b2046a3d2db01d956a&o=e8605ebc-031c-4253-a8d7-d954477436d7,wttj
Senior Data Engineer,"{'name': 'VOODOO', 'sector': 'Jeux vidéo, AdTech / MarTech', 'employees': '750 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Voodoo is a tech company that creates mobile games and apps. With 7 billion downloads and over 150 million monthly active users, Voodoo is the #3 mobile publisher worldwide in terms of downloads after Google and Meta.
The company is one of the most impressive examples of hypergrowth in the ecosystem, having raised over $1B and backed by Goldman Sachs, Tencent, and GBL.
Voodoo is now a team of over 750 employees worldwide, we’re looking for talented individuals from across the globe to come and entertain the world with us.
Team
The Engineering & Data team builds innovative tech products and platforms to support the impressive growth of their gaming and consumer apps which allow Voodoo to stay at the forefront of the mobile industry. The Engineering & Data team plays a key role in Voodoo’s long-term strategy. It enables Voodoo to both accelerate product diversification and provide a state of the art growth-engine to distribute and scale our games. They create innovative solutions that drive growth with a pragmatic approach, ranging from simple searching to complex machine learning systems.
This position is hybrid and requires 2/3 days per week in the office based in Paris. 
Construct and manage robust data pipelines to align with ever-evolving business needs, ensuring optimal architecture support.
Contribute to the codebase, push and maintain your changes in production, and be an evangelist of good coding and data engineering practices
Take ownership of projects from initial discussions to release, including feature estimation & scoping, architecture design, benchmarking of new technologies, product feedback...
Work in a very agile environment with a fast decision process
Collaborate directly with people working on back-end development, data science, mobile games, broad audience mobile apps, product & marketing
Our Stack
Amazon Web Services ⧫ Python ⧫ Spark ⧫ Scala ⧫ Terraform ⧫ SQL ⧫ DBT ⧫ Airflow ⧫ Kubernetes
Profile
Extensive experience as a Data Engineer or another similar role.
A proven track record of building and optimizing data pipelines for massive amounts of data (at scale).
Strong experience in scalability, reliability, and security topics.
Strong analytical skills and ability to work with unstructured datasets.
Experience with Amazon Web Services.
Result-oriented and focused on the value created by your developments
Curious about business needs and keen to create innovative, agile solutions to help grow the business through data.
Excellent communication skills (you can speak & write English).
Understanding of ML concepts is a plus.
Working experience in a Gaming, Advertising, or successful company is a plus.
Familiarity with Voodoo's ecosystem: gaming, apps, advertising, analytics, etc
Voir moins",,2024-02-19,https://www.welcometothejungle.com/fr/companies/voodoo/jobs/senior-data-engineer_paris_VOODO_3eZPkym?q=cc56186ce2f784003cb5323d3989988c&o=4915ad83-eacd-44cc-ba37-9d28e91c5230,wttj
Data Engineer - Databricks,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Paris,50K à 60K €,Télétravail occasionnel,26 février 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
MP DATA recrute un(e) Data Engineer (H/F) ayant une forte appétence databricks.
Dans le cadre de la transformation digitale industrielle de notre client, votre rôle est d’accompagner l’équipe de data engineering en charge de l’exploitation du Cluster Big Data.
En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des données, en veillant à ce qu’elles soient prêtes pour l’analyse.
Votre expertise dans la conception de pipelines ETL et la sécurisation des données sera essentielle pour soutenir les activités d’analyse et de prise de décision de l’entreprise. Votre rôle contribuera à créer une base de données solide et sécurisée pour des insights pertinents et en temps réel.
Création et développement de flux et pipeline sous databricks !
Le vrai plus du poste, une vision end to end du cycle de la donnée, recueil, traitement et visualisation.
Nous recherchons un(e) collaborateur(trice) dynamique, bon communicant disposant d’une bonne qualité de synthèse.
Vous travaillerez dans un environnement international auprès d’un acteur central de l’énergie !
Voir moins","Profil recherché
Nous recrutons un(e) Data Engineer (H/F) afin de travailler pour un client secteur de l’énergie, Vous interviendrez au sein du département en charge du pilotage des différentes business unit.
Diplômé(e) d’une école d’ingénieur, vous disposez d’une première expériences réussie autour de la création de pipelines sous DataBricks.
Vous êtes reconnu(e) pour votre autonomie, votre excellent relationnel et votre capacité à être force de proposition, vous êtes à l’aise dans un environnement challengeant.
Vous êtes intéressé(e)s pour vous dépasser en data science & data engineering et vous avez des premières expériences dans ce domaine, comme par exemple :
Spark, PySpark
Cloud : Azure / AWS
SQL : Postgres / MongoDB /
Power BI
DATABRICKS
Palantir Foundry
Voir plus",2024-02-18,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-databricks_paris?q=cc56186ce2f784003cb5323d3989988c&o=f7c17767-a52d-40dd-8cdc-02e9455de55b,wttj
"Data Engineer - Scientific Engine (Airflow, DVC) - CDI","{'name': 'DESCARTES UNDERWRITING', 'sector': 'Intelligence artificielle / Machine Learning, Assurance, FinTech / InsurTech', 'employees': '160 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
ABOUT DESCARTES UNDERWRITING
Descartes was born out of the conviction that climate change calls for a revolutionary approach in insurance to better protect corporations, governments, and vulnerable communities. We offer a new generation of parametric insurance that builds resilience against the full spectrum of climate and emerging risks. Utilizing Machine Learning and real-time monitoring from satellite imagery & IoT, our state-of-the-art climate tech provides innovative coverage for all trade sectors in all regions of the world. After a successful Series B raise of $120M USD, Descartes Underwriting is proud to be recognized among the French Tech Next40 and launched Descartes Insurance, a ‘full stack’ insurer licensed to underwrite risk by the French Regulator (ACPR). With a growing corporate client base (350+ and counting) - our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. 

ABOUT YOUR ROLE
Due to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenario to make a climate risk assessment. You will have to take initiative and assess the viability of proof of concept projects.
You will have to work with data scientists and software engineers to run and develop our models. You will be working along DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events.
🔔 KEY MISSIONS 🔔
Setup, automate, maintain and update:
Connections to external and internal APIs
Data preparation process
Model training and inference process
Data storage process
Associated CI/CD pipelines
Associated package versioning and releasing pipeline
Modularization of code base
Notification tools to inform the team of the status of the operations
Setup data storage, data processing and data visualizing tools, by :
Assessing the pains and needs of the teams
Benchmarking the open source and private solutions
Assessing the security, price and reliability of data architecture
Following the development the evolution of technologies on the topic
Forecasting the usage of the tools
Tracking the cost of the tools
Participate in:
Tech stack selection
Discussions with tech partners
Training of software and underwriting teams
Support and debug of internal users
TECH STACK 🖥️
Cloud provider: GCP
Code versioning tool: Git + Gitlab
OS: Linux
Container: Docker
Container orchestrator: Kubernetes
Website architecture: LAMP
Code base: Python
Notification tool: Slack
DATA STACK 🗄️
Types: images, timeseries,
Storage: GCP bucket
Version: DVC (roll out in progress)
Pipeline: Airflow (PoC stage)
Data base: to be setup depending on the use cases
In our project, data is collected by sensors (satellite, weather station, IoT). We don’t work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation …).
EQUIPMENT 🖱️
Laptop: Dell Latitude 7530
OS: you decide

ABOUT YOU 
EXPERIENCE & QUALIFICATIONS 👩‍💻👨‍💻
[Hard skills]
Knowledge of the tech stack or equivalent tools
Experience converting python code to efficient data engineering tools (eg: spark)
Experience with Docker
Experience with a cloud provider (GCP, AWS or azure)
Experience automating a CI/CD pipeline
Good knowledge in English and fluency in French
[Soft skills]
Desire to train junior developers and explain CI/CD and cloud tools
Desire to suggest improvements to the architecture
[Nice-to-have]
Experience working data science project or scientific code
Experience with Kubernetes
Experience in HPC
Contribution to an open source project
MINDSET 💥
Strong interest with climate issue (it’s not a hoax, many people suffer from it)
Being comfortable to work alongside corporate insurers (some still wear suits 👔)
You enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline)
Strong team spirit and ability to work (you’ll have to review code and have your code reviewed)
Rigorous, creative and meticulous mind (we handle large insurance, we take our time)
Strong desire to learn (there’s no limitation to the tech used, we’re happy to test and learn new tools)
Eagerness to work in a multi-cultural environment (policies and teams are from all around the world 🗺️)

WHY JOIN DESCARTES UNDERWRITING?
Join a company with a true purpose – help us help our clients be more resilient towards climate risks;
A competitive salary, bonus and benefits (Premium Alan health insurance, Swile restaurant vouchers, Navigo reimbursement etc.);
The opportunity to grow in your role, as the company does;
Commitment from Descartes to it’s staff of continued learning and development (think annual seminars, training etc.);
Be part of a collaborative, diverse team where your ideas are heard;
A paid referral scheme for successfully referring peers;
Frequent team events.

OUR COMMUNITY
At Descartes Underwriting, we are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences.
With equal skills, all our positions are open to people with disabilities.

HOW TO APPLY?
If you want to develop your skills and work in a friendly start-up atmosphere, don't hesitate and send us your application!
https://www.descartesunderwriting.com/careers/
If you don’t check all the requirements in the description, don’t worry. We can try to make some room for you within the company if you’re motivated to work on climate risk.

RECRUITMENT PROCESS
Step 1: Call and HR Interview with our Talent Recruiter
Step 2: Technical project submitted via GitHub
Step 3: Technical interview
Step 4: Manager interview
Step 5: Final round interview with the team
(Candidates can opt to have the manager interview before the technical project and interview)
Voir moins",,2024-02-17,https://www.welcometothejungle.com/fr/companies/descartesunderwriting/jobs/data-engineer-scientific-engine-airflow-dvc_paris?q=cc56186ce2f784003cb5323d3989988c&o=622d22c5-b888-41cc-bc20-64b85f4fccfd,wttj
Accelerator - Digital Data Engineer - All Gender,"{'name': 'SANOFI', 'sector': 'Pharmaceutique / Biotechnologique', 'employees': 'Créée en 1973', 'creation_year': ""Chiffre d'affaires : 1,7 Milliard d'€"", 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Our Team:
We are a global biopharmaceutical company focused on human health. Our purpose is to find treatment to fight pain and ease suffering. We combine breakthrough science and advanced technology to develop life-changing medicines and vaccines.
Digital & Data is at the heart of Sanofi: our ambition is to be the leading digital healthcare platform to develop & deliver medicine faster, enable healthcare professionals to improve treatments and help patients improve their health. Our scale, strong connections within health ecosystems across leveraging the world, and ability to leverage Sanofi’s capabilities make us the best place to push the boundaries of medicine through technology.
We are building Digital R&D products developing outstanding capabilities that will participate in new drug discovery together with scientists, in trial efficiency and cycle time reduction, leveraging Data Analytics and Artificial Intelligence.
Remote working : 2 days remote working, 3 days on site
Main responsibilities:
Work with business teams to understand requirements, and translate them into technical needs  
Gather/organize large & complex data assets, and perform relevant analysis  
Ensure the quality of the data in coordination with Data Analysts and Data Scientists (peer validation) 
Propose and implement relevant data models for each business case 
Create data models and optimize queries performance  
Communicate results and findings in a structured way 
Partner with Product Owner and Data Analysts to prioritize the pipeline implementation plan 
Partner with Data Analysts and Data scientists to design pipelines relevant for business requirements 
Leverage existing or create new “standard data pipelines” within Sanofi to bring value through business use cases 
Ensure best practices in data manipulation are enforced end-to-end 
Actively contribute to Data governance community 
Remains up to date on company’s standards, industry practices and emerging technologies 
You are a dynamic Data Engineer interested in challenging the status quo to ensure the seamless creation and operation of the data pipelines that are needed for the enterprise data and analytics initiatives following industry standard practices and tools for the betterment of our global patients and customers.
You are a valued influencer and leader who has contributed to making key datasets available to data scientists, analysts, and consumers throughout the enterprise to meet vital business use needs. You have a keen eye for improvement opportunities while continuing to fully comply with all data quality, security, and governance standards.
Experience:
Strong experience in automation tools and methodologies
Experience working with data models and query tuning
Experience on working within compliance (e.g.: quality, regulatory - data privacy, GxP, SOX) and cybersecurity requirements is a plus
Experience in the healthcare industry is a strong plus
Soft skills:
Excellent written and verbal communication skills
Experience working with multiple teams to drive alignment and results
Service-oriented, flexible, positive team player
Self-motivated, takes initiative
Problem solving & critical thinking
Technical skills:
Experience with AWS cloud services (Azure & GCP a plus)
Good knowledge of SQL and relational databases technologies/concepts
Experience in Data warehousing solutions (Snowflake a plus)
Experience in Integration Services (IICS, Tibco a plus) 
Working knowledge of scripting languages (Python, R a plus)
Familiarity with Source Code Management Tools (GitHub a plus)
Familiarity with Visualization Tools (PowerBI, Tableau a plus)
Familiarity with Project Management Tools (JIRA, Confluence a plus)
Familiarity with Service Management Tools (Service Now a plus)
Relevant cloud certifications (AWS, Azure, Snowflake, IICS) are a plus
Experience with backup system like Netbackup & CommVault
Good knowledge of ServiceNow and monitoring tool such as Datadog, Splunk, BPPM
Experience with Real World Data (e,g, EHR, Claims) and standard data models (e,g, OMOP, FHIR)
Experience using frameworks to create pipelines (e.g. Apache Airflow, Kedro)
Education:
Bachelor’s Degree or equivalent in Computer Science, Engineering, or relevant field
Languages : English
We provide a highly collaborative environment, with an opportunity to work with a world class team. You will be able to :
Learn what it takes to make a service with a truly global reach.
Be part of an organization that values diversity, inclusion, and the richness of different backgrounds and experiences. 
Engage in meaningful work that combines the challenges of the medical, pharma, and technical fields, offering abundant opportunities for professional growth and impact. 
Contribute to a company that is not only a leader in healthcare but also a pioneer in digital transformation, shaping the future of global health. 
Better is out there. Better medications, better outcomes, better science. But progress doesn’t happen without people – people from different backgrounds, in different locations, doing different roles, all united by one thing: a desire to make miracles happen. So, let’s be those people.
At Sanofi, we provide equal opportunities to all regardless of race, colour, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, or gender identity.
Watch our ALL IN video and check out our Diversity Equity and Inclusion actions at sanofi.com!
#Accelerator
At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.
As part of its diversity commitment, Sanofi is welcoming and integrating people with disabilities.
Voir moins",,2024-02-17,https://www.welcometothejungle.com/fr/companies/sanofi/jobs/accelerator-digital-data-engineer-all-gender_paris?q=cc56186ce2f784003cb5323d3989988c&o=1e854084-f0b3-4584-8f66-3411ffd13c44,wttj
Stage de fin d'étude - Data Engineer F/H,"{'name': 'CS', 'sector': 'Ingénieries Spécialisées, Aéronautique / Spatiale, Energie', 'employees': '2700 collaborateurs', 'creation_year': '1968', 'turnover': '300 000 000€', 'mean_age': '40 ans'}",Stage,Le Plessis-Robinson,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Rattaché(e) au pôle Recherche et Développement de l’entreprise et au sein d’une équipe expérimentée et complémentaire, le stagiaire sera amené à intervenir sur le développement d’un use case de data science dans un contexte de cybersécurité.
Détails des missions :
Acquisition et traitement de données :
Développement des connecteurs d’acquisition de la donnée des menaces cyber (CTI)
Mise en place d’une chaîne de traitement des données
Installation serveurs CTI : MISP, OpenCTI, etc …
Monitoring de la chaîne de traitement
Mise en place du stockage des données (entrée et sortie des modèles)
Déploiement :
Containerisation des modèles de machine learning
Développement des APIs nécessaires
Voir moins","Profil recherché
Compétences techniques requises :
Connaissance de Linux, python et Git.
Notion de data science : librairies de ML, de
Connaissances de base de données SQL et NoSQL
Connaissances d’une technologie de streaming Kafka
Des connaissances en containerisation et orchestration sont appréciables.
De formation ingénieur, vous recherchez un stage de fin d'étude (M2) en Data Engineering.",2024-02-17,https://www.welcometothejungle.com/fr/companies/cs-group/jobs/stage-de-fin-d-etude-data-engineer-f-h_le-plessis-robinson_CS_1z8JpbP?q=cc56186ce2f784003cb5323d3989988c&o=87553ff8-236b-4320-a0b4-15609c5b7e85,wttj
Data Engineer Junior H/F,"{'name': 'MEILLEURTAUX', 'sector': 'FinTech / InsurTech, Immobilier commercial, Immobilier particulier', 'employees': '2000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Vous souhaitez rejoindre la fintech leader en crédit et en assurance, en forte croissance, innovante, dynamique et débordante de projets ? Ce qui suit va vous intéresser !
Nous sommes engagés dans le développement de la plateforme Data du Groupe incluant notamment des problématiques métiers clefs telles que la Customer Data Platform.  
Cette plateforme de données est au cœur de la stratégie de croissance de l’entreprise et va nous permettre de : 
- Augmenter la Customer Lifetime Value (CLTV) de nos clients, 
- D'intégrer dans tous nos produits des composants IA innovants,  
- Réduire nos coûts d’acquisition, 
- Faciliter le pilotage du business à travers une optimisation de nos outils de BI. 
Au sein de l’équipe Data, vous vous épanouirez dans notre environnement en évolution rapide, où l'adaptabilité est essentielle. Au-delà de la résolution de défis techniques, nous souhaitons que vous contribuiez activement à la construction de la culture d'ingénierie de Meilleurtaux, à l'amélioration des pratiques et à la promotion d'un environnement collaboratif et innovant. L’équipe est en pleine construction donc nous n’attendons plus que vous pour participer à cette belle aventure. 
Vos missions 📝
Créer et maintenir une infrastructure de données de pointe en permettant aux utilisateurs finaux d'accéder à de la donnée précise et de qualité ; 
Développer de nouveaux modèles de données et des pipelines ; 
Ils auront pour objectif de prendre en charge une grande variété de cas d'utilisation (de l'analyse et du reporting à l'apprentissage automatique et à l'innovation de produits) ; 
Explorer en permanence de nouvelles technologies de données ; 
Tester les solutions les plus innovantes et prometteuses du marché en vue de pouvoir améliorer nos capacités en matière de données.
Notre stack technique  
Développement : Python, java, Salesforce.
CI-CD :  Git, Docker.
Infrastructure cloud : GCP et Azure. 
Bases de données : Google BigQuery, SQL Server.
BI : Qlik Sense. 
Ce poste nécessite d'interagir avec de nombreuses équipes au sein de Meilleurtaux que ce soit sur le plan technique (équipes IT, Data Scientist et BI) et/ou fonctionnel (Product Managers). 
Ceci n’est qu’un avant-goût de la superbe aventure que vous vous apprêtez à rejoindre, le poste étant évidemment amené à évoluer en fonction de vous et vos propositions.
Voir moins","Profil recherché
Pourquoi êtes-vous notre TOP candidat ? 🧐
Une première expérience réussie sur des sujets Data, idéalement de 2 ans.  
Vous savez modéliser la donnée et monitorer sa qualité. 
Bien entendu, il est important que vous ayez de très bonnes bases dans les compétences techniques nécessaires pour une plateforme data, que ce soit en Python, SQL ou les technologies du Cloud. 
Vous avez déjà utilisé des plateformes data. 
Vous vous tenez au fait des dernières actualités et suivez les communautés data. 
Le must : vous avez déjà des connaissances sur l'industrie Fintech / Assurtech ou secteur équivalent.  
Les soft-skills attendus pour réussir chez Meilleurtaux ? 
De la curiosité et de l'apprentissage continu : dans un domaine en constante évolution, nous recherchons une personne connectée aux nouvelles technologies et aux dernières innovations. 
L’esprit d’équipe : travailler chez Meilleurtaux c’est pratiquer un sport d’équipe, chacun collabore avec ses collègues pour aller jusqu’à une victoire collective. 
Voir plus",2024-02-17,https://www.welcometothejungle.com/fr/companies/meilleurtaux-com/jobs/data-engineer-junior-h-f_paris_MEILL_JzKgGw6?q=cc56186ce2f784003cb5323d3989988c&o=5f7af6d2-6727-40e9-b8a1-0d25c1b90d88,wttj
Lead Data Engineer / Architect H/F,"{'name': 'MEILLEURTAUX', 'sector': 'FinTech / InsurTech, Immobilier commercial, Immobilier particulier', 'employees': '2000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Vous souhaitez rejoindre la fintech leader en crédit et en assurance, en forte croissance, innovante, dynamique et débordante de projets ? Ce qui suit va vous intéresser !
Contexte de ce recrutement 🚀
Nous sommes engagés dans le développement d’une Customer Data Platform. 
Cette plateforme de données est au cœur de la stratégie de croissance de l’entreprise va nous permettre de :
- Augmenter la Customer Lifetime Value (CLTV) de nos clients,
- D'intégrer dans tous nos produits des composants IA innovants, 
- Réduire nos coûts d’acquisition,
- Faciliter le pilotage du business à travers une optimisation de nos outils de BI.
Vous vous épanouirez dans notre environnement en évolution rapide, où l'adaptabilité est essentielle. Au-delà de la résolution de défis techniques, nous souhaitons que vous contribuiez activement à la construction de la culture d'ingénierie de Meilleurtaux, à l'amélioration des pratiques et à la promotion d'un environnement collaboratif et innovant.
Vos missions 📝
Créer et maintenir une infrastructure de données de pointe en permettant aux utilisateurs finaux d'accéder à de la donnée précise et de qualité ;
Développer de nouveaux modèles de données et des pipelines.
Ils ont auront pour objectif de prendre en charge une grande variété de cas d'utilisation (de l'analyse et du reporting à l'apprentissage automatique et à l'innovation de produits) ;
Explorer en permanence de nouvelles technologies de données ;
Tester les solutions les plus innovantes et prometteuses du marché en vue de pouvoir améliorer nos capacités en matière de données ;
Recruter, encadrer et accompagner votre équipe de Data Engineers au quotidien ;
Partager et défendre vos meilleures pratiques d'ingénierie de données au sein des principaux organes de décision de l'entreprise.
Notre stack technique 🛠 
Développement : Python, React, java, Salesforce
CI-CD :  Git, Docker
Infrastructure cloud : GCP et Azure
Bases de données : Google BigQuery et Databricks
BI : Qliqsense
Ce poste nécessite d'interagir avec de nombreuses équipes au sein de Meilleurtaux que ce soit sur le plan technique (équipes IT, Data Scientist et BI) et/ou fonctionnel (Product Managers).
Ceci n’est qu’un avant-goût de la superbe aventure que vous vous apprêtez à rejoindre, le poste étant évidemment amené à évoluer en fonction de vous et vos propositions.
Voir moins","Profil recherché
Pourquoi êtes-vous notre TOP candidat ? 🧐
Avec une expérience d'au moins 5 ans dans la Data, vous avez idéalement déjà managé une petite équipe (entre 1 à 3 personnes) de Data Engineers.
Vous savez créer des architectures de données efficaces, évolutives et robustes.
Vous concevez des systèmes adaptés au présent mais également à l'avenir et qui résistent à l'épreuve du temps.
Bien entendu, il est important que vous ayez de très bonnes compétences techniques que ce soit en Python ; SQL et les autres outils pouvant exister en ingénierie de données.
La Big Data n'a plus de secret pour vous. Spark & Hadoop sont vos plateformes de référence sur ce domaine.
Vous avez déjà participé au déploiement d'infrastructure en Big Data.
Idéalement, vous faîtes partie d'une communauté de professionnels de la Data vous permettant d'être toujours au fait des dernières actualités.
Le must : cette expertise a été acquise au sein de l'industrie Fintech / Assurtech ou secteur équivalent. 
Voir plus",2024-02-17,https://www.welcometothejungle.com/fr/companies/meilleurtaux-com/jobs/lead-data-engineer-architect-h-f_paris_MEILL_AOrWeW7?q=cc56186ce2f784003cb5323d3989988c&o=b4440e2c-2d5c-4e45-9326-692954d88cd6,wttj
NAT CAT Data Engineer/Analyst (Intern) - (M/F) March 2024,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",Stage,Puteaux,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Context
AXA Group Risk Management Property & Casualty (GRM P&C) deals with the most sophisticated P&C technical and actuarial challenges of a leading international insurance company, among which the management of natural catastrophe risks (CAT). Natural variability of climate and seismic activity have demonstrated their devastating potential, climate change bringing additional uncertainty for the future. AXA’s rapid expansion over the last years – both in terms of geographical footprint and P&C insurance offer – widely exposes AXA to natural perils, being in charge of the financial protection of its clients. In this context, AXA must maintain state-of-the-art CAT risk management techniques through permanent innovations.
Group Risk Management
AXA GRM brings together high level and multidisciplinary staff with engineers, PhDs, actuaries, data scientists and financials split between Paris, Hong Kong, Zürich and Madrid. Its main missions are focused on the following key areas
develop and maintain models and tools in an efficient and strong IT ecosystem to industrialize deliverables. 
analyze, model and aggregate the P&C Group’s risks (economic capital);
define and implement the process enabling to secure the undertaken risks (risk appetite, assets accumulation, reserve, premium, natural catastrophe and man-made risks...);
optimize the Group protections (reinsurance, securitization, hedging, etc.) to meet the desired strategy.
Job background
Position belongs to the Group P&C Risk Management Natural Catastrophe and Reinsurance team (21 FTE) which is organized several excellence centers NAT CAT R&D Modeling, Data Analytics, Accumulation Management and Reinsurance. As part of AXA’s Internal Model under the Solvency II framework, the NAT CAT and Reinsurance team are primarily in charge of delivering the annual NAT CAT modeling process, consisting of
Collecting Property exposure data (geographical, physical and financial information) on a per-entity (AXA France, AXA Mexico, AXA Philippines…) and per-location basis (houses, factories, vehicles etc.);
Assessing the risk on a per-entity per-peril basis (cyclones, earthquakes, floods, hailstorms...) which feeds the whole downstream chain locally (underwriting, pricing, strat plan, reinsurance decisions, economic capital modeling)
Estimating the efficiency of the Group Property Reinsurance covers
Developing in-house internal NAT CAT models, methodologies and applications to support the NAT CAT risk monitoring.
The NAT CAT modelling process has strong strategic and operational impacts since it feeds AXA Economic Capital internal model, the Economic Combined Ratio and NAT CAT budget and strategic plan calculations which drives the earnings and the solvency position of AXA Group. It and determines adequate levels of reinsurance needs, which may boost or hinder profitability. It is also a technical challenge with the data collection of 25+ millions of complex and worldwide policies covering 50+ millions risks, the parallel use of multiple modeling solutions including both physics and machine learning techniques, and finally the assessment of 190 country x peril levels of risk.
Mission
The NAT CAT DATA & Analytics team widely interacts with R&D Modelling team (in charge of developing internal CAT models), Reinsurance teams (in charge of ceded reinsurance modelling), Underwriting team (in charge of developing actuarial frameworks for technical pricings) and benefits from the IT expertise of two additional FTEs. The Internal Data Engineer/Analyst will have to develop and integrate innovative data products to enhance the NAT CAT risk assessment, be proactive and innovative in the continuous development of new functionalities.
The intern will actively contribute to this effort by:
Developing innovative tools and technics for collecting processing, cleaning and modelling data
Group Property Exposure data base: cleaning, integrating, and implementing missing information from entities
Global Exposure Database: Contribute to a global exposure database build (searching, collecting,)
Collecting claims related to Nat Cat risk across major P&C entities
Exploit data science techniques to analyze meteorological data
Produce technical documentation
Developing and improving our internal reports (Power BI) to assess the risks associated with NAT CAT risks and climate change
Implement data analytics best-practices to assess the data accuracy and reliability
Support the P&C risk assessment related to NAT CAT risks (Live Event Analysis)
Vous rejoignez une entreprise :
-    Responsable, vis-à-vis des personnes, y compris ses employés et ses clients, et de la planète. -    Aux valeurs fortes-    Qui encourage la mobilité interne, et la formation de ses employés-    Qui vous offre de nombreux avantages (en savoir plus ici : Reward & Benefits - french | AXA Group)-    Flexible, qui permet le travail hybride, au bureau et à la maison.
Les informations fournies par les candidat(e)s seront traitées de manière strictement confidentielle et utilisées uniquement à des fins de recrutement.
Voir moins","Profil recherché
Education
Engineering or master’s degree in relevant field (engineering, natural hazards, actuarial science, applied maths)
Technical & Professional Skills
Robust Data and programming skills collection, transformation and mining (R/Python, SQL, Power BI)
Strong problem-solving skills and keen attention to detail;
French and Business English – fluent (spoken and written)
Experience with writing documentation, version control (e.g., Git) is a plus
Interpersonal skills
Analytical skills / Ability to evolve in a diverse technical and operational environment
Strong communication skills
Autonomous and with a strong sense of team spirit
Organized and rigorous
Motivated by an international and dynamic environment
Voir plus",2024-02-17,https://www.welcometothejungle.com/fr/companies/axa/jobs/nat-cat-data-engineer-analyst-intern-m-f-march-2024_puteaux?q=cc56186ce2f784003cb5323d3989988c&o=0e621b36-6b1e-493f-8e49-d9b86af073a2,wttj
Data Engineer / Databrick F/H,"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Villeurbanne,Non spécifié,Télétravail non autorisé,,> 4 ans,,"Descriptif du poste
Enrésumé :
Poste: Data Engineer / Databricks F/H
Secteur de l'entreprise :experts conseil dans les secteurs de la banque-assurance, le luxe-retail etl’Industrie
Localité : Lyon
Type de contrat : CDI
Niveau d’expérience :au moins 3 ans
Vous êtes passionné(e)s par la data ? Vous êtesconvaincus que l’optimisation du patrimoine data des entreprises est laclé de leur performance ? Vous voulez rendre les entreprises data drivenet les aider à se transformer pour préparer dès à présent leur futur? Vous êtes au fait des dernières tendances et prêt à explorer de nouveauxterritoires ?
Vous souhaitez rejoindre un groupe pionnier des grandesinnovations data et digitale ?
Si vous avez répondu « Oui » à chacune de cesquestions alors devenez Data Engineer pour nos clients grands-comptesdans les secteurs de le luxe/retail, la banque/assurance et l’industrie/services.
Alors,prêt à rejoindre l’aventure Micropole ? N’attendez plus !
EN TANT QUE DATA ENGINEER :
Vous rejoignez notre entité Data Analytics basée à Lyon, oùvous interviendrez sur l’intégralité de plusieurs projets avec une vision« Data 360° », mêlant Conseil, Architecture, Intégration et DataScience. En tant que Data Engineer / Databricks, vous accompagnerezles directions métiers dans l'évaluation de l'efficacité de leur processus etdans leur stratégie pour optimiser leur performance. Vous serez rattaché(e) à l’équipe Data Analytics,composée de 50 #InnovativePeople.
Dans vos missions quotidiennes, vous serezamenés :
Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Databricks. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; 
Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; 
Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; 
Participer au développement de notre centre d’excellence. 
Voir moins","Profil recherché
Vos compétences techniques :
Vous avez un minimum de 3 années d’expérience sur des projets Data dont au moins une sur des projets Databricks (sur AWS et/ou Azure), ou à défaut une certification Databricks avec l’ambition de vous préparer à d’autres. 
Vous maîtrisez au minimum un langage de programmation (Spark, Scala ou SQL) ; 
Vous avez une maitrise des théories et outils de modélisation de données, 
Vous maîtrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, 
Vos  atouts :
Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; 
Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; 
Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. 
Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud et des solutions Data. 
Voir plus",2024-02-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-databrick-f-h_villeurbanne?q=cc56186ce2f784003cb5323d3989988c&o=28bfd527-9a17-45aa-aafe-4a71805a1e19,wttj
Data Engineer (H/F),"{'name': 'MOONCARD', 'sector': 'Banque, IT / Digital, Big Data', 'employees': '125 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '28 ans'}",CDI,Paris,50 à 65 €,Télétravail non autorisé,12 mars 2024,,,"Descriptif du poste
Fintech fondée en mars 2016, Mooncard est un leader français de l’automatisation des dépenses en entreprise, proposant une solution intégrée avec une carte entièrement sécurisée et paramétrable, une application de gestion et un moteur comptable. Mooncard est une solution SaaS et a déjà séduit plus de 6000 entreprises.
Libérer les collaborateurs de la gestion chronophage des notes de frais, c’est gagner en productivité sur des tâches à plus forte valeur ajoutée.
Portée par une équipe jeune et passionnée, Mooncard est une scale-up en forte croissance, offrant de rapides perspectives d’évolution.
Vous allez rencontrer des équipes soudées, enthousiastes et passionnées qui ont un but commun : faire grandir notre projet.

Nos valeurs :
L’empathie
La curiosité
L’ambition
La collaboration
 Nous recherchons notre futur(e) Data Engineer, qui sera plongé.e au coeur de la stratégie commerciale et opérationnelle de Mooncard.
 Votre rôle au sein de l'équipe :
En tant que société technologique et financière, Mooncard dispose d’un patrimoine de données particulièrement riche et dont l’exploitation est clé pour l’excellence opérationnelle de l’entreprise.
Au sein de l'équipe Data & Business Operations (6 collaborateurs), vous serez en charge de construire, maintenir et documenter les flux de données entre les systèmes de Mooncard et de fournir des datamarts pertinents pour les équipes business.

Vos missions au quotidien :
Intégration de Données
Établir des pipelines de données robustes pour fusionner des bases de données multiples, notamment l'application de production, nos outils Salesforce, Stripe..
Data Lake / Data Warehouse
Développer et maintenir notre Data lake / Data warehouse centralisé pour les équipes BI, Produit, et machine learning.
Automatisation et Monitoring
Automatiser les processus récurrents et mettre en place des alertes pour surveiller la santé des pipelines de données.
Optimisation de Coûts AWS
Analyser et ajuster l'utilisation des ressources AWS pour optimiser les coûts tout en maintenant la qualité de service.
Support aux Équipes Data ""Front""
Fournir des jeux de données exploitables et des outils aux data analysts/scientists et autres Data champions de Mooncard.
Documentation et Best Practices
Documenter les architectures de données, les configurations, et les best practices pour assurer une maintenance aisée et la formation des nouveaux membres de l'équipe.
Collaboration Inter-Équipes
- Travailler en étroite collaboration avec les équipes BI, ML, Produit et DevOps pour assurer que les besoins en données sont bien compris et satisfaits.
- Faire l’intermédiaire entre les développeurs et les analystes pour trouver des quick wins qui faciliteront le travail des équipes BI et la scalabilité de l’infrastructure. Développer et prendre l’ownership d’une logique de Data Contracts.
Gestion des Données Sensibles
Mettre en œuvre des mesures de sécurité pour protéger les données sensibles et garantir la conformité aux régulations (GDPR, etc.).
Est-ce que ça vous ressemble ?
Expérience professionnelle avérée en tant que Data Engineer (3 ans d'expérience)
Forte capacité à analyser et à manipuler des données
Connaissance avancée du langage SQL et expérience en Python
Connaissance de Databricks
Maîtrise d’un ou plusieurs ETL du marché
Connaissance d’outils BI tels que Tableau.
Nice to have : Connaissance du modèle de données Salesforce
Anglais courant : lu, écrit, parlé

Ce que nous vous offrons :
Contrat CDI : CP + RTT
Team buildings et séminaires d'équipe réguliers
We Work situé dans le 9ème arrondissement à Paris
Mutuelle Generalli (50%)
Tickets restaurant Up (9€/jour)
Télétravail jusqu'a 3 jours par semaine
Voir moins",,2024-02-16,https://www.welcometothejungle.com/fr/companies/mooncard/jobs/data-engineer-h-f_paris_MOONC_rGy7r10?q=cc56186ce2f784003cb5323d3989988c&o=f9b0083f-5b10-4db6-b1b9-bddb359fa640,wttj
Consultant Senior Data Engineer H/F - CDI,"{'name': 'CONVERTEO', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Stratégie', 'employees': '400 collaborateurs', 'creation_year': '2007', 'turnover': '43M €', 'mean_age': '27 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
Description de l'entreprise

Converteo est un cabinet de conseil pure player de la data, au service du progrès et de la performance des entreprises. Qu’il s’agisse de définir la stratégie ou de déployer les projets, Converteo accompagne ses clients sur l’ensemble de la chaîne de valeur de la donnée : collecte, modélisation, mesure, activation, gouvernance, conformité.
Avec plus de 420 consultants et plus de 200 clients dans tous les secteurs de l’économie, de la grande distribution au luxe en passant par l’industrie, Converteo connaît une très forte croissance et voit ses besoins marketing croître d’année en année.

Description du poste
A la croisée des sujets data engineering, data science, IA et développement, la Practice Data Technologies est à l’initiative de la construction et l’évolution des offres Data et Technologiques au sein de Converteo. La Practice couvre un champ d’expertises très large et intervient notamment sur :
- les stratégies move to cloud (cadrage et implémentation) avec GCP, SF, AWS, Azure ;
- la conception de produits data : plateformes d'activation et de reporting in-house (Advanced Analytics / BI / Insights Sharing / Forecast / Activation Locale / CDP) ;
- la mise en place de squads data chez nos clients ;
- le cadrage et déploiement de stratégies de gouvernance de la donnée ;
- le déploiement de stratégies IA chez nos clients ;
- l’implémentation d'outils partenaires sur nos sujets stratégiques (CDP SaaS, PriceFX)
Nos consultants savent à la fois développer, conseiller leurs clients sur la marche à suivre et gérer leur activité en autonomie (force de proposition, initiative). Ils sont à même de gérer un projet ou un produit, du cadrage jusqu'à l'implémentation et l'optimisation. 
Nous recrutons un(e) **Consultant Senior Data Engineer** :

Après formation interne à notre méthodologie et notre offre client, vous assurez, en autonomie, les missions suivantes en interne ou auprès de grands comptes :
- Collecte du besoin, cadrage des attentes et des tâches, capacité à traduire un besoin fonctionnel en action technique et chiffrer les implémentations ;
- Cartographie des données et des flux de données ;
- Collecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes) sur différentes architectures (Medallion...) et modèles (Data Vault, OBT...) ; 
- Développer et automatiser (orchestration, infrastructure -IaC- et FinOps) les flux de données de bout en bout suivant divers paradigmes (ELT, ETL, streaming...) ; 
- S'assurer de la scalabilité, l'observabilité, la sécurité, la stabilité et la disponibilité des données de la plateforme ;
- Mettre en place l'orchestration et la supervision des flux précitées en gérant les cas limites.
Profil recherché 

De formation supérieure en école d’ingénieur/université (niveau Bac+5 ou plus), vous justifiez d'au moins 3 ans d'expérience professionnelle en tant que Data Engineer, idéalement dans un programme data en lien avec les métiers marketing. 
Notre stack :
- GCP / AWS / Azure 
- Big Query, Snowflake, RedShift, Athena, MongoDB
- Python, SQL, NoSQL, Spark
- Terraform, CloudFormation
- dbt
- CI/CD, Docker, GIT (GitHub, GitLab)
- Tout type de certification est appréciée, notamment SnowPro Core ou SnowPro Advanced.
Vous disposez des qualités suivantes : 
- Excellente qualité relationnelle et rédactionnelle 
- Autonomie / Sens de l’initiative 
- Ethique et rigueur 
- Vous avez l’esprit d’équipe et êtes impliqué(e) dans votre travail au quotidien 
- Vous avez hâte de proposer des améliorations, les partager et les prioriser avec vos collègues 
- Vous avez un niveau courant en Anglais 
Notre process de recrutement
Un entretien avec notre recruteur et un Senior Manager (45min)
Un entretien technique avec deux Manager Data Engineering (1h)
Un entretien Final avec nos deux Practice Leaders (30min)
Bienvenue chez nous 🤗

Conditions du poste 
Locaux situés à Paris intramuros : 117 Quai de Valmy - 75010 Paris
Contrat en CDI, statut Cadre
Poste à pourvoir dès que possible

Notre petit + ? 

Et parce que le bien-être de l’équipe est au cœur de notre modèle, quelques infos sur le cadre de travail :
4,66 / 5 à l'enquête Happy at Work - 96% de taux de recommandation à des proches
N°1 au classement HappyIndex®AtWork 2021, 2022 & 2023 des entreprises du secteur Conseil, n°1 au classement HappyWomenAtWork 2023
Equilibre vie pro / vie perso (temps de travail maîtrisé, mesures pour accompagner la parentalité)
Une politique de télétravail flexible, sans limitation de jours
Des bureaux spacieux tout confort au pied du Canal Saint-Martin
Équipement pour travailler en remote + participation aux frais du télétravail (allocation mensuelle)
Des séminaires d'équipe et des teambuilding pour se retrouver
Une multitude d'activités sportives : via GymLib ou en rejoignant les équipes sportives de l'équipe (yoga, foot, basket, cross training, etc)
Valorisation des mobilités douces (forfait mobilité durable pour les adeptes du vélo ou de la trottinette)
Une School interne pour se former et se certifier sur des outils continuellement

Nos collaborateurs témoignent sur Glassdoor

Découvrez l'aventure Converteo en vidéo


🌟 En 2021, 2022 et en 2023, Converteo occupe la 1ère place du classement HappyIndex®AtWork des entreprises du secteur Conseil, rejoignez-nous !
👩 En 2023, Converteo occupe la 1ère place du classement HappyWomenAtWork, classement des entreprises dans lesquelles les femmes sont les plus engagées et motivées 🤗
Voir moins","Profil recherché
.",2024-02-16,https://www.welcometothejungle.com/fr/companies/converteo/jobs/consultant-senior-data-engineer-h-f-cdi_paris?q=cc56186ce2f784003cb5323d3989988c&o=e352cb69-cc49-40d4-80b4-623ec56417d5,wttj
Data Engineer - H/F,"{'name': 'GS1 FRANCE', 'sector': 'Association', 'employees': '110 collaborateurs', 'creation_year': '1972', 'turnover': '20 220 825 €', 'mean_age': '40 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,Bac +5 / Master,"Descriptif du poste
La Direction Marketing & Communication recrute un(e) Data Engineer.
Contexte 
GS1 France a initié fin 2023 sa transformation Data.  Une feuille de route est définie et vise à déployer sur les prochains mois des cas d’usage apportant de la valeur aux métiers (marketing & commercial). Une équipe Data est créée et le poste est localisé au sein de ce pôle. 
GS1 France est désormais à la recherche d’un Data Engineer pour accompagner cette transformation en développant et valorisant l’utilisation de la data au sein de l’entreprise. 
 Rôle 
Contribuer au sein de la squad Data à construire les produits Data (avec le product owner et le data analyst) 
Concevoir, maintenir et faire évoluer les flux de données (pipelines Azure Data Factory) 
Intégrer des nouvelles sources de données (internes ou externes) à la plateforme Data  
Développer les transformations de données (python) 
Comprendre la finalité métier des produits, et surtout la complexité fonctionnelle des données manipulées afin de concevoir des pipelines adaptés, robustes et évolutifs 
Assurer la conformité et la maintenabilité du code et de la plateforme (documentation, clean code, tests automatisés) 
Veiller à l’amélioration continue de la conception, de la qualité et de la performance  
Contribuer à sensibiliser les interlocuteurs aux enjeux et bénéfices de la Data
Voir moins","Profil recherché
Qui êtes-vous ?
Diplômé d’une école d’ingénieur ou d’informatique 
2 / 3 ans d’expérience  
Compétences techniques 
Environnement Azure (ADF, Azure Fonctions)
Python
Git 
CI/CD Azure 
Compétences métiers :
Curiosité 
Travail en équipe 
Autonomie et proactivité 
Connaissance et mise en œuvre des méthodologies Agiles (Scrum, Kanban…) 
 Pourquoi rejoindre GS1 France ?  
Voir plus",2024-02-16,https://www.welcometothejungle.com/fr/companies/gs1-france/jobs/data-engineer-h-f_paris-9e-arrondissement?q=cc56186ce2f784003cb5323d3989988c&o=fabe43df-a8c5-4b3e-b649-6421698fa159,wttj
Data Engineer (F/H),"{'name': 'RENAULT DIGITAL', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '267 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '38 ans'}",CDI,Boulogne-Billancourt,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Contexte :
Fort de partenariats stratégiques signés avec Google Cloud (stack data full GCP), Renault Digital est à la recherche d’un(e) Data Engineer au sein du Pôle Architecture et Data pour mettre en place les fondations de la plateforme IA répondant à de nouveaux besoins métiers.
Vous collaborerez au jour le jour avec les équipes métiers ainsi qu’avec les autres fonctions du Pôle Architecture & Data (Data Analysts et Scientists, architectes, …), exploitant des téraoctets de données (événements en mode streaming, traitements en batch et temps réels et les appels aux APIs) afin entre autres d’alimenter des modèles de machine learning (segmentation clients, détection automatique des pannes des véhicules, …).
Responsabilités principales :
Vous participez aux phases de framing, MVP et release des produits, services et APIs orientés IA ;
Vous argumentez les choix d’architecture des projets et de la plateforme IA sur GCP ;
Vous contribuez à la valeur métier des produits orientés IA s’appuyant sur le Datalake, en mettant en place des chaînes bout en bout de traitement de la data, de l’ingestion à l’exposition d’APIs et à la visualisation des données et des solutions IA/ML ;
Vous êtes garant(e) de la qualité des données transformées dans le Datalake, du bon fonctionnement des chaînes de traitement et de l’optimisation de l’utilisation des ressources cloud ;
Vous définissez et développez les composants nécessaires pour orchestrer un système de machine learning en production suivant les best practice MLOPS (validation de données, preprocessing, apprentissage, analyse de modèle, déploiement, monitoring, etc.)
Vous proposez des standards d’architecture et de développement ;
Vous êtes force de proposition, innovant(e) et bienveillant(e).
 
Environnement Technique :
Google Cloud Platform (BigQuery, PubSub, Dataflow, Vertex AI), Airflow, Terraform, Spark, Scala, Python, Looker, Dataiku, Kubernetes, SQL, Git
Voir moins","Profil recherché
Vous êtes diplômé(e) en informatique, ingénierie informatique ou autre diplôme d’ingénieur pertinent ;
Vous disposez de minimum 5 ans d’expérience dans le déploiement de services/ plateformes data ;
Vous disposez d’une solide expérience en développement Spark, Scala, Python et framework ML (Vertex, Tensorflow, Scikit, PyTorch, …) ;
Vous avez une appétence pour la data : validation, transformation, analyse, valorisation ;
Vous possédez une expérience de développement et orchestration de chaines ETL complexes via Airflow ou équivalent ;
Vous pratiquez la méthodologie agile (Agile Scrum et/ou Kanban) ;
Vous savez utiliser des services cloud (préférablement GCP) ;
Vous êtes capable d’échanger en anglais technique écrit et oral
Informations complémentaires :
Votre poste sera basé à Boulogne-Billancourt (France) en CDI (temps plein)
Voir plus",2024-02-16,https://www.welcometothejungle.com/fr/companies/renault-digital/jobs/data-engineer-f-h_boulogne-billancourt?q=cc56186ce2f784003cb5323d3989988c&o=91880681-7347-4a42-9674-91e6c527179e,wttj
Data Engineer - Industries et Services - Metz,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Metz,Non spécifié,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail :
Vous intervenez en régie directement chez notre client sur ses problématiques en lien avec la data.
Vos missions :
Vous participez aux sujets techniques data (engineering, Big Data) en lien avec la collecte et la mise à disposition des données.
Vous participez à l'industrialisation et à la mise en production des traitements sur les données
Vous effectuez la rédaction de spécification techniques et fonctionnelles, cette action nécessitant de travailler en anglais
Vous participez aux réunions projet
Environnement technologique/fonctionnel : Big Data : Cloudera, Hive, Spark,…, ETL : Talend, Bases données : SQL Server, Reporting : Power BI
Ce que nous vous proposons :
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.
Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor. Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ». - L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore).
Informations supplémentaires
Ce que nous vous proposons :
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.
Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor. Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ». - L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherché
Votre profil :
Vous avez développé de solides compétences en matière d'autonomie, d'adaptabilité et de communication.
Des compétences et/ou de solides connaissances en Talend sont fortement souhaitées.
Des compétences en Data Visualisation / data Viz peuvent être un plus sans être obligatoires
Vous avez un bon niveau d'anglais
Diplômé(e) d'une formation supérieur en informatique type Bac + 5 (école ingénieur, université ou équivalent), vous avez déjà acquis une expérience significative en data, de minimum 3 ans, principalement sur des sujets traitant de la data engineer et du big data.",2024-02-15,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-industries-et-services-metz_metz_SS_w2Vm2p8?q=cc56186ce2f784003cb5323d3989988c&o=05676759-0fd1-4559-abe6-c50ae82604dd,wttj
Data Engineer Confirmé.e,"{'name': 'JAKALA', 'sector': 'Digital Marketing / Data Marketing, Big Data, E-commerce', 'employees': '150 collaborateurs', 'creation_year': '2023', 'turnover': '15M€', 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Au sein de notre DataLab, vous travaillez conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et vous êtes impliqué.e dans la prise de décisions liée à notre solution Data et à son évolution. 
A cet effet, vous êtes en charge de :
Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clients 
Comprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internes,
Définir l’architecture logiciel ETL / ELT en collaboration avec vos pairs
Travailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage),
Rédiger de la documentation technique (diagrammes UML, documentation d’API, …), 
Partager votre savoir-faire entre les différents membres de l’équipe,
Concevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateforme,
Concevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big Data,
Assurer une veille technologique et savoir mener à bien un projet de R&D.
Vous assurez en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :
Cartographier des données et des flux de données
Implémenter des algorithmes d’analyse de données pour l’industrialisation
Collecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)
Développer et automatiser des flux de données et leurs visualisations en dashboards, reporting
S’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateforme
Analyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big Data
Mettre en place du séquencement et de la supervision des flux précitées en gérant les cas limites
Compétences attendues : 
Bon niveau en développement: : 
De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)
De script ETL : DBT (ex. Snowflake, PostgreSQL)
Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQL
LakeHouse : Delta LakeConnaissance message broker, RabbitMQ, Kafka
Compétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)
Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managés
Cartographie des données
Voir moins","Profil recherché
Diplômé·e d’études supérieures dans le système d’information, computer sciences, big data (école d’ingénieurs, école spécialisée ou équivalent universitaire), vous justifiez d’au moins 3 ans en Data engineering.
Vous avez une expérience significative sur la mise en place de pipelines complets de valorisation de données massives, de la collecte à la mise à disposition d’applications en passant par le traitement.
La maîtrise de l’anglais est appréciée.
Certification·s appréciée·s : GCP Professionnal Data Engineer OU Azure Data Engineer Associate OU AWS Solution Architect.
Vous êtes passionné·e par votre métier, aimez le faire partager.",2024-02-15,https://www.welcometothejungle.com/fr/companies/soyhuce/jobs/data-engineer-confirme-cdi-paris_paris?q=cc56186ce2f784003cb5323d3989988c&o=5289e6f3-19c2-40cc-b99a-d2671d6eff50,wttj
Azure Data Engineer (H/F),"{'name': 'DECILIA', 'sector': 'IT / Digital', 'employees': '40 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",CDI,Boulogne-Billancourt,Non spécifié,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Dans le cadre de la croissance de nos activités, nous recrutons un(e) Azure Data Engineer.
En tant que Azure Data Engineer, vous serez amené(e) pour le compte de nos clients à :
🔹 Développer et optimiser des pipelines de données (ETL, ELT) : DataFactory, Datalake/Databricks, Synapse Analytics, Azure Blob Storage / Azure BUS Service, Azure Functions,
🔹 Assurer le recueil du besoin client
🔹 Participer à la conception de Datalake,
🔹 Travailler en étroite collaboration avec l’équipe architectes,
🔹 Industrialiser des modèles de Machine Learning issus de notre entité Décilia Science
🔹 Utiliser au quotidien la méthodologie SCRUM et DEVOPS
🎯 Pourquoi nous rejoindre ? 🎯
Décilia favorise la consolidation des connaissances de ses consultants par la formation et la m rtifications ;
Devenez référent d’une brique technologique, et à terme, animez une de nos squads !
Vous serez accompagné personnellement par un coach et boosterez vos compétences relationnelles ;
Un grand nombre de vos missions seront en télétravail ;
Bénéficiez d’un cadre de travail stimulant et bienveillant :
🔹2 agences idéalement situées à Boulogne-Billancourt (Les Passages) et à Rouen (Théâtre des arts)
🔹Plusieurs événements internes organisés : séminaires, tech lunch, afterworks, team building,…
Et intégrez une entreprise certifiée « Happy at Work » depuis 4 ans !
Voir moins","Profil recherché
Environnement technique :
🔹Cloud : Microsoft Azure (ADF, Azure Datalake Store, Azure Storage Queue, SQL DB Azure, Synapse Analytics, Azure Machine Learning)
🔹Langages: Python, Scala, SQL, C#
🔹Big Data : Spark, Databricks
Si vous aimez les challenges, l’esprit d’équipe, la bonne humeur, rejoignez une société à taille humaine en postulant dès maintenant !! 🚀",2024-02-15,https://www.welcometothejungle.com/fr/companies/decilia/jobs/azure-data-engineer-h-f_boulogne-billancourt_DECIL_roV16KG?q=cc56186ce2f784003cb5323d3989988c&o=a96630a9-d12f-405d-b04c-d489b01ad8d2,wttj
Azure Data Engineer (H/F),"{'name': 'DECILIA', 'sector': 'IT / Digital', 'employees': '40 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",CDI,Rouen,Non spécifié,Télétravail occasionnel,01 août 2023,> 3 ans,Bac +5 / Master,"Descriptif du poste
Poste : Azure Data Engineer (H/F) Type de contrat : CDI à plein temps Lieu : Normandie Niveau d’expérience : confirmé (Minimum 3 ans) Salaire : selon profil
Décilia est une ESN Gold Partner Microsoft. Spécialiste de la data depuis 14 ans, nous accompagnons nos clients dans la réalisation de projets complexes et innovants. Dans le cadre de la croissance de nos activités, nous recrutons 2 Azure Data Engineer.
En tant que Azure Data Engineer, vous serez amené(e) pour le compte de nos clients à :
Développer et optimiser des pipelines de données (ETL, ELT) : DataFactory, Datalake/Databricks, Synapse Analytics, Azure Blob Storage / Azure BUS Service, Azure Functions,
Assurer le recueil du besoin client
Participer à la conception de Datalake,
Travailler en étroite collaboration avec l’équipe architectes,
Industrialiser des modèles de Machine Learning issus de notre entité Décilia Science
Utiliser au quotidien la méthodologie SCRUM et DEVOPS
Pourquoi nous rejoindre ?
Décilia favorise la consolidation des connaissances de ses consultants par la formation et la multiplication des certifications ;
Devenez référent d’une brique technologique, et à terme, animez une de nos squads !
Vous serez accompagné personnellement par un coach et boosterez vos compétences relationnelles ;
Un grand nombre de vos missions seront en télétravail ;
Bénéficiez d’un cadre de travail stimulant et bienveillant :
2 agences idéalement situées à Boulogne-Billancourt (Les Passages) et à Rouen Centre (Palais de Justice)
Plusieurs événements internes organisés : séminaires, tech lunch, afterworks, team building,…
Et intégrez une entreprise certifiée « Happy at Work » depuis 4 ans !
Environnement technique :
Cloud : Microsoft Azure (ADF, Azure Datalake Store, Azure Storage Queue, SQL DB Azure, Synapse Analytics, Azure Machine Learning)
Langages: Python, Scala, SQL, C#
Big Data : Spark, Databricks
Voir moins","Profil recherché
Niveau d’expérience : confirmé (3ans d’expérience minimum)",2024-02-15,https://www.welcometothejungle.com/fr/companies/decilia/jobs/azure-data-engineer-h-f_boulogne-billancourt?q=cc56186ce2f784003cb5323d3989988c&o=183b8a81-bb0f-4261-99a1-a0f9ff276a12,wttj
Data Engineer confirmé H/F - CDI @ CybeleTech,"{'name': 'OSS VENTURES', 'sector': 'SaaS / Cloud Services', 'employees': '19 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,15 février 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
Qui sommes nous ?
CybeleTech est une jeune entreprise qui développe des outils logiciels au service de l’agriculture d’aujourd’hui et de demain : stratégies de production à la fois productives et respectueuses de l’environnement, amélioration de la qualité nutritionnelle et gustative des aliments, réduction des pesticides, pérennité des cultures vis-à-vis des aléas climatiques…
Ces outils reposent sur des algorithmes innovants combinant Data Science et Modélisation, rendus accessibles à nos clients grâce à des logiciels SaaS.
Initialement spin-off du laboratoire de mathématiques appliquées de Centrale Paris, nous sommes aujourd’hui une équipe pluridisciplinaire de 15 personnes, œuvrant aussi bien dans le champ des mathématiques, de l’informatique, de la biologie et de l’agronomie.
Nous sommes implantés à Orléans et au cœur de Montrouge (M4 parisien).
Afin d’accompagner la croissance de notre activité, nous recherchons un(e) Data Engineer. Le poste est à pourvoir en CDI à temps plein.
Vous intégrerez au quotidien l’équipe Datascience de Cybeletech. Vos missions en lien avec les Datascientists, Modélisateurs, Agronomes de l’équipe mais aussi en lien avec notre équipe DevOps :
Développement et industrialisation de pipelines d’ingestion et transformation de données, exploitant notamment de l’imagerie satellite : développement, requêtes performantes, distribution des calculs des modèles…
Optimisation de l’exécution distribuée des modèles.
Maintenance et évolution de la codebase scientifique (gestion des environnements et version, organisation des librairies, configuration de la CI…).
Participer aux reviews et à la mise en place de bonnes pratiques de développement (gestion des exceptions…), rédaction de référentiels.
Design des bases et des modèles de données (architecture des tables et schémas, gestion des droits…)
Skills techniques / Stack
Python, pandas/geopandas, jupyter
postgresQL, S3, mongodb
Aws et azure cloud services, docker, kubernetes, rabbitMQ, azureML
La connaissance des éléments suivants est un plus : Systèmes SIG, data visualisation, C/C++, images satellites
Voir moins","Profil recherché
Vous êtes titulaire d’une formation d’ingénieur(e) développeur(se).
Vous possédez déjà 3 ans d’expérience minimum en temps que titulaire sur un poste de développement autour de la Data mettant en œuvre SQL et Python.
Vous aimez échanger avec des profils complémentaires (modélisateurs, DevOps…), et partager vos savoirs faire.",2024-02-15,https://www.welcometothejungle.com/fr/companies/oss-ventures/jobs/cdi-data-engineer-h-f_paris?q=cc56186ce2f784003cb5323d3989988c&o=6f531538-f8bb-44fa-980f-3bf442554752,wttj
Data Engineer confirmé(e) - Services Financiers - Lille,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Villeneuve-d'Ascq,Non spécifié,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail :
Au sein d’une Data Factory, vous êtes pleinement impliqué(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi à leur succès.
Vous avez l'occasion de développer vos compétences techniques et fonctionnelles de manière approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.
C'est tentant non ? Alors embarquez pour une nouvelle aventure professionnelle !
 Vos missions :
Rattaché(e) à la division  « Banque », vous évoluez dans un environnement challengeant et convivial, entouré(e) de passionnés dotés d'expertises dans leurs domaines.
En tant que Data Engineer, vous évoluez sur des projets IT à forte valeur ajoutée et avez pour rôle la mise en place de pipelines de données fiables, sécurisés et à l’échelle pour soutenir la mise à disposition des données aux cas d’usage métier qui en ont besoin.
Vos activités principales sont les suivantes :
Vous travaillez avec le client pour évaluer, concevoir, déployer, améliorer et maintenir les pipelines de données 
Vous vous assurez que les pipelines de données créés sont résilients, sécurisés et accessibles 
Vous définissez le modèle opérationnel pour monitorer et supporter les pipelines de données 
Vous fournissez une expertise à nos clients sur leurs données pour assurer leur optimisation et leur sécurité par rapport à leurs besoins 
Vous apportez un savoir en gestion de la qualité et la gouvernance de la donnée pour assurer le suivi de la conformité à la gouvernance de la donnée 
Vous faites de la veille technologique dans le domaine afin d’enrichir les roadmaps technologiques et fournir des solutions modernes à nos clients.
     Informations supplémentaires
Les avantages à nous rejoindre :
Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.
Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor que vous choisissez.
Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble. Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire «Vendredi »
L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
> 
Voir moins","Profil recherché
Votre profil :
Diplômé(e) d'une formation supérieur en informatique type Bac + 5 (école ingénieur, université ou équivalent), vous avez déjà acquis une expérience significative en data engineer.
Vous avez au moins l'une de ces compétences requises :
Maîtrise des technologies de bases de données Relationnelles et NoSQL
Maîtrise d’au moins un outil d’ETL/ELT (Semarchy, Informatica, Datastage, etc.)
Maîtrise des technologies de traitement distribué de données (Spark, Hadoop)
Maîtrise d’au moins un framework de streaming de données (Kafka, RabbitMQ, etc.)
Maîtrise de chaines CI/CD et de des bonnes pratiques de DataOps
Maîtrise de solution de Virutualisation de données (Denodo, Dremio, etc.)
Maîtrise d’au moins un environnement cloud public ou privé (Azure, AWS, Outscale, etc.)
 Vous avez développé de solides compétences en matière d'autonomie, d'adaptabilité et de communication.
Voir plus",2024-02-14,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-confirme-services-financiers-lille_villeneuve-d-ascq?q=cc56186ce2f784003cb5323d3989988c&o=f97746ab-893b-4f98-b818-6f5e2e4ab7c9,wttj
Stage long pré-alternance - Data Engineer - LILLE,"{'name': 'WAYKONECT', 'sector': 'Logiciels, Automobile', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '32 ans'}","Stage
(2 à 6 mois)",Lille,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
WayKonect renforce la place de la data au sein de sa stratégie.
Cela se concrétise par la mise en place d’une logique data centrique et d’une platform technologique adaptée à la centralisation, validation et valorisation des données de mobilité (transactions, bornes de recharge, véhicules connectés…), i.e. le data lake de l’entreprise. 
Vous intègrerez l’équipe Data organisée en méthode agile autour de 4 autres data engineers, un tech lead, un architecte, un devops, un scrum master, un PO, un QA et un data manager.
L’équipe Data a la charge de construire le data lake. Celui-ci est bâti selon une architecture en médaillon (bronze, silver, gold), où les données progressent et sont valorisées de couches en couches. Chaque couche représente un niveau de qualité croissante, du bronze au gold. En cas de problèmes de qualité de données, celles-ci sont identifiées et rejetées au stade approprié. La donnée ainsi rejetée est mise de côté, non promue, préservant l’intégrité et la fiabilité des données de qualité supérieure dans le data lake.
Dans ce cadre, WayKonect renforce son équipe data et recherche un.e stagiaire data engineer [ingénieur.e des données].
Voir moins","Profil recherché
Vos missions :  
·       Vous mettrez en place un mécanisme d’alerting sur la qualité des données, permettant d’identifier quelles données ont été rejetées, à quelle étape du processus, et pour quelles raisons, assurant ainsi une surveillance proactive de la qualité des données.
·       Vous construirez le monitoring adéquat en développant des dashboards dédiés aux données rejetées, fournissant des visualisations claires des volumes de données rejetées, des étapes du processus affectées, ainsi que des motifs spécifiques de rejet, facilitant ainsi l’analyse et la compréhension des problèmes potentiels.
·       Vous mettrez en place un cycle de retraitement pour les données rejetées, assurant une gestion efficace des corrections nécessaires.
·       Vous explorerez la possibilité de mettre en place des interactions avec Dynatrace, l’outil de monitoring de la production, afin d’optimiser la corrélation entre les alertes liées à la qualité des données et les indicateurs de performance de l’environnement global.
·       Vous formaliserez, documenterez et communiquerez sur l’ensemble de vos travaux réalisés
Voir plus",2024-02-14,https://www.welcometothejungle.com/fr/companies/waykonect-1/jobs/stage-long-pre-alternance-data-engineer-lille_lille?q=cc56186ce2f784003cb5323d3989988c&o=dd76bed4-c674-4b06-b6fa-bf31191d658a,wttj
Data engineer H/F,"{'name': 'MEERO', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning', 'employees': '250 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,14 février 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
Position Overview
Are you looking to build high-impact data pipelines that fuel intelligent decision-making across an entire organization? Do you thrive in a collaborative environment where your code crafts the foundation for business success? Then this Data Engineer role is for you! 
Join our transversal Data Team and become a key player in our ambitious journey to empower everyone at Meero with the power of data. You’ll build and maintain our self-service oriented Data Platform, ensuring seamless access to insights that drive growth and innovation.
Key Responsibilities
As a Data Engineer, you will report to the Lead Data and will:
Design and implement robust ETL pipelines, bringing valuable data from diverse sources into our BigQuery data warehouse.
Empower Data Analysts with intuitive tools and infrastructure, streamlining their workflow and maximizing their impact.
Collaborate closely with cross-functional teams to translate business needs into actionable data solutions.
Be the guardian of data integrity, ensuring accuracy and consistency across the platform.
Continuously optimize and innovate, staying ahead of the curve in data engineering best practices
Tech Stack
Cloud provider: Google Cloud Platform
Data Warehouse: Bigquery
Ingestion: Python script & Segment CDP
Orchestration: Airflow
Transformation: DBT core
BI Tool: Looker Studio
Coding: Python & SQL
Voir moins","Profil recherché
3+ years of experience as a Data Engineer or similar role.
Bachelor’s or Master’s degree in Computer Science, Engineering (or equivalent).
Python master, fluent in data manipulation libraries.
SQL ability, crafting complex queries and transformations.
Airflow expertise, orchestrating workflows with ease.
Familiarity with data viz tools like Tableau or Looker is a plus.
Excellent communication skills in English, both written and verbal.
Passionate learner, eager to explore, experiment, and push boundaries.
Hiring Process
A first call with a member of our Talent Acquisition Team
Video call with the hiring manager to get to know each other and to explain you more about the role
Technical Assessment to know your knowledge 
Final interview with the team and with the CEO
Welcome aboard!",2024-02-14,https://www.welcometothejungle.com/fr/companies/meero/jobs/data-engineer-h-f_paris?q=cc56186ce2f784003cb5323d3989988c&o=545d0086-d15d-4a7b-8d42-5e084dc465a6,wttj
Cloud Data Engineer (Lille),"{'name': 'CENOVA', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Transformation', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '32 ans'}",CDI,Marcq-en-Baroeul,Non spécifié,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Vous travaillerez chez l’un de nos clients, spécialiste du #Retail, au sein de l’équipe Data sur le développement de solutions Data Analytics. Vos missions, si vous les acceptez, seront les suivantes : 
·       Participer aux rituels agiles de l’équipe,
·       Analyser les besoins des utilisateurs et proposer des solutions innovantes et en phase avec les drivers de l’entreprise,
·       Être garant de l’accès qualitatif aux sources de données,
·       S’assurer de la maîtrise de la donnée et être garant de la qualité de son utilisation (référencement, normalisation, et qualification) afin d’en faciliter l’exploitation par les équipes (Data Analysts et Data Scientists),
·       Contribuer à la définition de la politique de la donnée et à la structuration de son cycle de vie dans le respect des réglementations en vigueur,
·       Être capable d’intervenir sur les systèmes applicatifs autour de la gestion de la donnée et du traitement, et sur les plateformes Big Data,
·       Assurer la supervision et l’intégration des données de diverse nature qui proviennent de ces sources multiples et vérifier la qualité des données qui entrent dans le Data Lake.
Environnement technique :
SQL, Python, ETL
Power BI, Data Studio, Looker, Tableau, Business Object
CI/CD, Github, Terraform, Kafka, Airflow, Databricks
GCP (BigQuery), AWS, Azure
Voir moins","Profil recherché
Vous avez une expérience minimale de 2 ans sur des missions de Data Engineering et vous disposez d’une grande appétence technique.
Vous appréciez comprendre le cycle de vie de la donnée et vous êtes à l’aise avec les concepts de data lineage, data gouvernance, data privacy. Vous êtes amateur.e de datavisualisation, idéalement avec PowerBI.
Travailler en mode agile ? Vous adorez !
Vous avez par ailleurs, le contact facile et vous comprenez les enjeux business et adaptez vos analyses en ce sens.
Vous êtes proactif(ve), autonome, bon(ne) communiquant(e) et vous êtes à l’aise en anglais.
Votre personnalité et votre savoir-faire feront le reste.",2024-02-14,https://www.welcometothejungle.com/fr/companies/cenova/jobs/cloud-data-engineer-lille_marcq-en-baroeul?q=cc56186ce2f784003cb5323d3989988c&o=e7c49082-2c86-495e-82f0-8e3feaf42e23,wttj
Stage - 6 mois - Market Risk IT Data Engineer F/H,"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards € de PNB', 'mean_age': None}","Stage
(6 mois)",Paris,Non spécifié,Télétravail non autorisé,,< 6 mois,Bac +5 / Master,"Descriptif du poste
Votre MISSION & bien plus encore…
Vous rejoignez notre équipe ""Risk DPM Sensitivities"" de Natixis , qui recherche un Développeur Hadoop Scala, pour un stage de 6 mois dès maintenant.
Cela se traduit par des calculs et intégrations de sensibilités de marchés quotidiens, des problématiques de stockage, et de distribution des données.
En collaboration avec votre tuteur vos missions principales seront :
Comprendre le positionnement de l'application dans le système d'information de Natixis et ses fonctionnalités ;
Etudier les besoins de monitoring des différentes équipes (Département des risques, équipe support à Lisbonne, Equipes projets à Paris) ;
Etudier les outils similaires déjà utilisés chez Natixis ;
Etudier la faisabilité de certaines solutions de visualisation des données afin de choisir la plus appropriée ;
Designer les écrans de monitoring qui devront être mis en œuvre ;
#FinanceTransformative
En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours.
Vous évoluez dans un environnement de travail inclusif et favorisant le collaboratif qui vous donnera toutes les chances de réussir cette nouvelle mission.
Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise.
Vous bénéficiez d'une indemnité de stage en fonction de votre formation et de votre niveau d'études, également d'un remboursement de votre titre de transport à hauteur de 60 %, d'un jour d'absence autorisé payé pour chaque mois travaillé et de l'accès au restaurant de l'entreprise.




Voir moins","Profil recherché
Étudiant de niveau BAC+5, vous préparez un diplôme d'école d'ingénieur en informatique ou un master 2 universitaire.
Vous êtes curieux et proactif et vous vous challengez constamment et cherchez à toujours développer de nouvelles compétences.
And last but not least, you are perfectly fluent in English.
Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier. Un moment d'échange idéal pour mettre en avant votre personnalité ainsi que votre projet.",2024-02-14,https://www.welcometothejungle.com/fr/companies/natixis/jobs/stage-6-mois-market-risk-it-data-engineer-f-h_paris_NATIX_V02j83Q?q=cc56186ce2f784003cb5323d3989988c&o=4edcf974-5581-486d-ac1a-5bcaf79004cf,wttj
Stage - 6 mois - Market Risk IT Data Engineer F/H,"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards € de PNB', 'mean_age': None}","Stage
(6 mois)",Paris,Non spécifié,Télétravail non autorisé,,< 6 mois,Bac +5 / Master,"Descriptif du poste
Votre MISSION & bien plus encore…
Vous rejoignez notre équipe ""Risk DPM Sensitivities"" de Natixis , qui recherche un Développeur Hadoop Scala, pour un stage de 6 mois dès maintenant.
Cela se traduit par des calculs et intégrations de sensibilités de marchés quotidiens, des problématiques de stockage, et de distribution des données.
En collaboration avec votre tuteur vos missions principales seront :
Comprendre le positionnement de l'application dans le système d'information de Natixis et ses fonctionnalités ;
Etudier les besoins de monitoring des différentes équipes (Département des risques, équipe support à Lisbonne, Equipes projets à Paris) ;
Etudier les outils similaires déjà utilisés chez Natixis ;
Etudier la faisabilité de certaines solutions de visualisation des données afin de choisir la plus appropriée ;
Designer les écrans de monitoring qui devront être mis en œuvre ;
#FinanceTransformative
En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours.
Vous évoluez dans un environnement de travail inclusif et favorisant le collaboratif qui vous donnera toutes les chances de réussir cette nouvelle mission.
Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise.
Vous bénéficiez d'une indemnité de stage en fonction de votre formation et de votre niveau d'études, également d'un remboursement de votre titre de transport à hauteur de 60 %, d'un jour d'absence autorisé payé pour chaque mois travaillé et de l'accès au restaurant de l'entreprise.




Voir moins","Profil recherché
Étudiant de niveau BAC+5, vous préparez un diplôme d'école d'ingénieur en informatique ou un master 2 universitaire.
Vous êtes curieux et proactif et vous vous challengez constamment et cherchez à toujours développer de nouvelles compétences.
And last but not least, you are perfectly fluent in English.
Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier. Un moment d'échange idéal pour mettre en avant votre personnalité ainsi que votre projet.",2024-02-14,https://www.welcometothejungle.com/fr/companies/natixis/jobs/stage-6-mois-market-risk-it-data-engineer-f-h_paris_NATIX_Vz37oxW?q=cc56186ce2f784003cb5323d3989988c&o=708e4de3-60a0-4b47-8884-f03bb9face41,wttj
Data Engineer H/F,"{'name': 'INNOVELA', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '15 collaborateurs', 'creation_year': '2016', 'turnover': '1.7M€', 'mean_age': '30 ans'}",CDI,Paris,45K à 65K €,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Le poste
Au sein de l’équipe de développement d’Innovela, vous participerez à la conception et au développement de pipeline de données en utilisant les solutions de la plateforme Google principalement.
Vous travaillerez en mode agile au sein d’une équipe passionnée et dynamique, et sur des technologies toujours plus innovantes.
Les projets sont effectués soit chez nos clients, soit directement dans les locaux d’Innovela situés dans le 11ème arrondissement de Paris.
Enfin, vous participerez également aux événements organisés par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.
Les responsabilités
Identifier et conseiller les solutions appropriées pour répondre aux besoins des clients.
Participer aux différentes phases d’un projet (analyse, prototypage, conception, développement, déploiement, maintenance).
Veiller à la gouvernance des données et mise en place de process MDM : Rapprochement de données de différentes sources non homogènes, Dédoublonnage, Normalisation, Historisation, Calcul d’indicateurs et d’agrégats.
Construire et monitorer des pipeline de données sur GCP.
Effectuer de la veille technologique sur les technologies web, cloud et Google.
Voir moins","Profil recherché
Master/Ingénieur en informatique ou dans un domaine technique associé.
3 ans d’experiences min (hors stages ou alternances).
Compétences en programmation Python (minimum 2 ans de pratique en entreprise).
Bonne connaissance des bases de données (relationnelles et non-relationnelles).
Bonne connaissance de la partie data et de la gouvernance sur GCP (Dataflow, Composer, Storage, Bigquery …).
Expérience significative avec des technologies Big Data telles que Hadoop, Spark, Snowflake, Bigquery, Airflow sont fortement appréciées.
Autonome, curieux(-se), passionné(e) et motivé(e).",2024-02-13,https://www.welcometothejungle.com/fr/companies/innovela/jobs/data-engineer-h-f_paris_INNOV_W6OajrA?q=cc56186ce2f784003cb5323d3989988c&o=74a9aa2e-f8ea-4ca3-9d83-a46498bbd2e2,wttj
Data Engineer Senior H/F,"{'name': 'INNOVELA', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '15 collaborateurs', 'creation_year': '2016', 'turnover': '1.7M€', 'mean_age': '30 ans'}",CDI,Paris,55K à 80K €,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Le poste Au sein de l’équipe de développement d’Innovela, vous participerez à la conception et au développement de pipeline de données en utilisant les solutions de la plateforme Google principalement.
Vous travaillerez en mode agile au sein d’une équipe passionnée et dynamique, et sur des technologies toujours plus innovantes.
Les projets sont effectués soit chez nos clients, soit directement dans les locaux d’Innovela situés à Paris.
Enfin, vous participerez également aux événements organisés par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.
Les responsabilités
Identifier et conseiller les solutions appropriées pour répondre aux besoins des clients.
Participer aux différentes phases d’un projet (analyse, prototypage, conception, développement, déploiement, maintenance).
Veiller à la gouvernance des données et mise en place de process MDM : Rapprochement de données de différentes sources non homogènes, Dédoublonnage, Normalisation, Historisation, Calcul d’indicateurs et d’agrégats.
Construire et monitorer des pipeline de données sur GCP.
Effectuer de la veille technologique sur les technologies web, cloud et Google.
Voir moins","Profil recherché
Master/Ingénieur en informatique ou dans un domaine technique associé.
5 ans d’experiences min (hors stages ou alternances).
Compétences en programmation Python.
Bonne connaissance des bases de données (relationnelles et non-relationnelles).
Bonne connaissance de la partie data et de la gouvernance sur GCP (Dataflow, Composer, Storage, Bigquery …).
Expérience significative avec des technologies Big Data telles que Hadoop, Spark, Snowflake, Bigquery, Airflow sont fortement appréciées.
Autonome, curieux(-se), passionné(e) et motivé(e).",2024-02-13,https://www.welcometothejungle.com/fr/companies/innovela/jobs/data-engineer-senior-h-f_paris?q=cc56186ce2f784003cb5323d3989988c&o=36ad7506-380a-4236-8336-4264dbd35021,wttj
[VO2 Data] - Data Engineer GCP,"{'name': 'VO2 GROUP', 'sector': 'IT / Digital, Transformation', 'employees': '700 collaborateurs', 'creation_year': '2011', 'turnover': '80M€', 'mean_age': '32 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 3 ans,,"Descriptif du poste
Collecte de données : Extraction de données à partir de diverses sources, qu’il s’agisse de bases de données, de fichiers, de flux de données en temps réel.

Nettoyage et transformation des données : Nettoyage, filtrage, enrichissement et transformation des données pour les préparer à l’analyse. Cela peut inclure le traitement des données manquantes, la normalisation, la conversion de formats, etc.

Conception de pipelines de données : Création de pipelines de données pour automatiser le flux de données, y compris la gestion des dépendances entre les différentes étapes du pipeline.

Stockage des données : Choix de la solution de stockage adaptée aux besoins, que ce soit Google Cloud Storage, Bigtable, BigQuery ou d’autres services GCP.

Intégration de données : Intégration de données dans les entrepôts de données, les entrepôts de données en colonnes, les bases de données NoSQL ou les data lakes.

Gestion de la qualité des données : Mise en place de contrôles de qualité des données pour garantir l’intégrité et la qualité des données.

Sécurité des données : Mise en place de mesures de sécurité pour protéger les données sensibles, notamment l’accès aux données, la gestion des identités et des accès, le chiffrement, etc.

Optimisation des performances : Surveillance et optimisation des performances des pipelines de données pour assurer une réponse rapide aux requêtes et une utilisation efficace des ressources.

Documentation : Documentation des pipelines de données, des schémas de données et des processus pour faciliter la compréhension et la collaboration.

Automatisation : Automatisation des processus d’ETL (Extract, Transform, Load) pour minimiser l’intervention manuelle.

Collaboration : Collaboration avec les data scientists, les analystes et d’autres membres de l’équipe pour comprendre leurs besoins et garantir que les données sont prêtes pour l’analyse.

Surveillance : Surveillance constante des pipelines de données pour détecter et résoudre les problèmes potentiels.

Évolutivité : Conception de pipelines de données évolutifs capables de gérer une croissance des volumes de données.


Cette liste de missions n’est pas exhaustive et est susceptible d’évoluer.
Voir moins","Profil recherché
Maîtrise de GCP : Une connaissance approfondie des services et des outils de GCP est essentielle pour concevoir et implémenter des solutions d’ingénierie des données.

Traitement des données en temps réel : Capacité à concevoir et mettre en œuvre des pipelines de données en temps réel, en utilisant des services tels que Dataflow ou Pub/Sub.

Traitement des données en batch : Compétence dans la création de flux de traitement de données par lots avec des outils comme Dataprep, Dataprep, et BigQuery.

Langages de programmation : Maîtrise de langages de programmation tels que Python, Java, ou Go pour le développement de scripts et d’applications.

Bases de données : Connaissance des bases de données NoSQL (Cloud Bigtable, Firestore) et SQL (BigQuery, Cloud SQL) pour le stockage et la récupération de données.

Compréhension des meilleures pratiques de sécurité des données, y compris la gestion des autorisations, le chiffrement et la conformité.

Capacité à utiliser des outils d’orchestration tels que Cloud Composer ou Cloud Dataflow pour gérer les pipelines de données.

Aptitude à résoudre des problèmes complexes liés à la collecte, au traitement et au stockage de données, ainsi qu’à optimiser les performances des pipelines de données.
Voir plus",2024-02-13,https://www.welcometothejungle.com/fr/companies/vo2-group/jobs/data-engineer-gcp-h-f_paris?q=cc56186ce2f784003cb5323d3989988c&o=34f006c1-ae5c-4cdb-9174-04bf56901f24,wttj
Lead Data Engineer - Scala (F/H/X),"{'name': 'SELOGER & MEILLEURS AGENTS', 'sector': 'Application mobile, IT / Digital, Média, Immobilier particulier', 'employees': '800 collaborateurs', 'creation_year': '1992', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
Rejoignez l’équipe Marketplace Design AVIV
La marketplace AVIV est le lieu de rencontre privilégié de tous les acteurs de l’annonce immobilière: potentiels acquéreurs ou locataires, propriétaires ou agents, … Afin de garder notre position, nous devons fournir la meilleure qualité de service possible en termes de sécurité,  de confiance, d’efficacité et de pertinence des échanges entre ces acteurs. Plusieurs facteurs entrent en ligne de compte: qualité et sérieux des prospects et des agents  ainsi que la qualité des informations affichées.
Le rôle de l’équipe Marketplace design est de concevoir et exécuter toutes les actions nécessaires pour assurer la satisfaction de nos utilisateurs : qualité et correction des données, scoring, matching, gamification, et amélioration continue. Ces actions requièrent un usage important des données, l’équipe Data Operations est responsable de la gouvernance, la modélisation et  la qualité des données ainsi que de fournir les data-sets clés et maintenir une data platform robuste et efficace pour tout le groupe AVIV.
Vos responsabilités :
En tant que Lead Data Engineer au sein de l’équipe Data Operations, vous travaillez en étroite collaboration avec un Product Manager et votre Engineering Manager. Vos développements respectent les bonnes pratiques en place et sont alignés avec l’architecture d’entreprise AVIV. Vous apportez votre expertise technique à votre équipe, vous créez, adaptez et améliorez la qualité des data-sets et des outils largement utilisés chez AVIV.
L’équipe Data Operations
L’équipe est constituée d’environ 40 personnes, avec notamment:
Coach Agile
Data Engineers
Data Quality Engineers
Data Analysts & Modelers
Devops Engineers
Enterprise & Solution Architects
Product Managers
Les projets
Décentraliser la data et Mettre en place le Data Mesh au sein du groupe Aviv
Fournir les insights sur les usages des différents sites et apps mobiles européens  
Notre Stack Technique data
AWS (CloudFormation, EMR, S3, Glue, Athena, Redshift, SNS/SQS)
Spark
Git, CircleCI, Datadog
Scala, Java
Vous avez idéalement des connaissances complémentaires telles que :
Python 
Apache Airflow, Kubernetes
Jenkins, Argo CD, Grafana, VictoriaMetrics
Voir moins","Profil recherché
Nous recherchons une personne capable de:
Créer et maintenir des datasets complexes et à gros volumes selon des spécifications fonctionnelles précises.
Participer à la création d’une infrastructure solide et optimale pour l’extraction, la transformation et le chargement (ETL) de données à partir de nombreuses sources. Utilisation de SQL et de technologies big data cloud.
Identifier, concevoir et implémenter les processus internes d’amélioration: automatisation, optimisation du delivery, scalabilité, etc…
Travailler avec des experts data et données analytiques au développement de nouvelles fonctionnalités 
Maitriser la méthodologie Agile: communication directe, adaptation, fail fast, amélioration continue et Software Craftsman
Maîtriser le produit et le business, impactant l’amélioration du service aux clients, du produit et de l’architecture
Rigueur, curiosité, autonomie et état d’esprit positif 
Voir plus",2024-02-13,https://www.welcometothejungle.com/fr/companies/groupe-seloger-meilleurs-agents/jobs/lead-data-engineer-scala-f-h-x_paris?q=cc56186ce2f784003cb5323d3989988c&o=7e5b4880-c952-4029-a312-c7f23fd8166c,wttj
Data Engineer - Banque Data Factory - Nantes,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Nantes,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Votre environnement de travail :
La division « Services Financiers » s’est développée autour des métiers de la banque de détail, de la banque privée et des services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compétences dans les domaines fonctionnels des Crédits, des Risques/Conformité et des Moyens de Paiement.
Si vous êtes passionné(e) par la valorisation de la donnée, rejoignez notre Data Factory localisée à Nantes et les quelques 100 Data Ingénieurs qui la composent. Vous y rencontrerez des experts de la mise en œuvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée.
Vous êtes accompagné(e) au développement de vos connaissances aux travers de différents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnée, la modélisation et mise à disposition.
Rejoindre la Data Factory Sopra Steria, c'est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.
Votre rôle et vos missions :
Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expérience et votre appétence pour l'un de nos chapitres Data ci-dessous, vous participez à :
La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analysis ;
La mise en œuvre de solution d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;
La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;
Le traitement de la donnée jusqu'à l'exposition au métier ;
La mise en place de la chaine CI/CD et de sa supervision ;
La veille technologie avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients.
Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, R
Informations supplémentaires
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. 
Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
> 
Voir moins","Profil recherché
Votre profil :
Diplômé(e) d'une Ecole d'ingénieur ou formation équivalente, vous avez déjà participé à un projet Data (Big Data, BI) et vous avez une expérience de minimum 2 ans.
Vous accordez une importance particulière au développement de vos compétences sur plusieurs technologies. Vous souhaitez une évolution réelle de carrière à travers l'expérience projet. Vous êtes soucieux de l'apport de valeur pour vos clients. Et vous voulez transmettre votre savoir auprès de collaborateurs moins expérimentés. Alors, n'attendez-plus, ce poste est fait pour vous !",2024-02-12,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-banque-data-factory-nantes_nantes_SS_JWJzdG?q=cc56186ce2f784003cb5323d3989988c&o=3bf80dc5-5b4e-45f9-a129-282693f98ec5,wttj
Data Engineer Talend F/H,"{'name': 'ORANGE', 'sector': 'Objets connectés, Big Data, Electronique / Télécommunications', 'employees': '136000 collaborateurs', 'creation_year': '1994', 'turnover': '43,5 milliards €', 'mean_age': '44 ans'}",CDI,Villeneuve-d'Ascq,Non spécifié,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Afin de développer notre équipe lilloise, nous recherchons aujourd’hui, un Ingénieur DATA à même d’accompagner nos clients dans la structuration de leurs SI autour de la donnée.

Vos principales missions seront les suivantes :

- Concevoir des solutions de traitement et collecter des volumes importants de données.
- Participer à des études de cadrage pour collecter le besoin métier et concevoir les solutions qui répondent au besoin du client.
- Apporter son expertise sur des problématiques précises rencontrées chez les clients.
- Participer à la veille techno
- Rester informer et former sur les nouvelles solutions DATA
- Contribuer aux phases d’avant-vente et au développement business.
- Participer à la conception, l’évolution et la présentation de nos offres DATA.","Profil recherché
Vous :
- Êtes issu(e) de formation bac+5
- Vous justifiez d’au moins 4 ans d’expériences en qualité d’Ingénieur DATA sur la solution TALEND Enterprise (Data Integration) et avez idéalement une connaissance des solutions Cloud d’AWS et d’AZURE
- Vous êtes intervenus sur des projets intégrant des pratiques DevOps et AGILE
Alors postulez, ce poste est fait pour vous !
 
Vos compétences clés :
- Expertise sur l’outil ETL TALEND Enterprise (administration et développement)
- Fortes connaissances des solutions de bases de données (SQL, NoSQL…)
- Connaissances en langages objets ou scripts (notamment Java mais aussi Javascript, Scala, Python…)
- Divers systèmes d’exploitation : UNIX, Windows
 
Autonomie, rigueur, curiosité, dynamisme et sens du service sont des qualités nécessaires pour ce poste.
 
Les compétences complémentaires qui seraient appréciées :

- Connaissances d’autres modules Talend (MDM, ESB, Data Quality, Cloud…)
- Maîtrise des technologies du Big Data (Hadoop, Spark, Kafka…)
- Expertise sur d’autres outils ETL (Informatica, SSIS, DataStage…)
- Notions en architecture des Systèmes d’Information
- Maîtrise de l’anglais (oral et écrit)
Voir plus",2024-02-12,https://www.welcometothejungle.com/fr/companies/orange-1/jobs/data-engineer-talend-f-h_villeneuve-d-ascq?q=cc56186ce2f784003cb5323d3989988c&o=67bef5fb-5b83-4516-8d25-c929c82a47dd,wttj
Data Engineer,"{'name': 'ADVANCED SCHEMA', 'sector': 'IT / Digital, SaaS / Cloud Services, Big Data', 'employees': '220 collaborateurs', 'creation_year': '2001', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,Bac +3,"Descriptif du poste
En tant que Data Engineer, vous aurez les missions suivantes :
Concevoir des modélisations physiques
Construire des mappings techniques et rédaction de spécifications d’alimentation.
Développer des flux des données
Contribuer au pilotage de projets, de proof of concepts
Participer à des missions d’expertise
N’hésitez pas à postuler même si vous ne répondez pas à toutes les exigences. Nous accordons autant d’importance à la capacité d’apprendre qu’à la maîtrise d’une technologie.
Ce poste est à pourvoir en stage et CDI","Profil recherché
Compétences professionnelles & niveau d’études requis :
Vous êtes titulaire d’un diplôme Bac +3 minimum dans le domaine de la data
Vous possédez minimum 1 an d’expérience dans le métier
Être enthousiaste à l’idée d’apprendre de nouvelles technologies
Expérience de la méthodologie Agile / Scrum
Capacité à planifier et à prioriser les tâches et les activités confiées en autonomie
Maîtrise de l’anglais oral et technique obligatoire
Expérience avérée dans l’écriture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQL",2024-02-12,https://www.welcometothejungle.com/fr/companies/advanced-schema/jobs/data-engineer_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=b0dc3ac9-a4e3-47a6-bb6e-73eaafe8c5cf,wttj
Data Engineer - Madonne Core (H/F),"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards € de PNB', 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous rejoignez l'équipe Core en charge de la maintenance évolutive des applications Madonne (Récolte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiée au coeur de l'IT Risque).

Au quotidien vous avez pour missions de :

Participer à l'adaptation de nos applications en adéquation avec les besoins métiers (nouveaux produits, nouvelles règlementations, nouveaux SI Front) ;
Participer activement à la modernisation de nos outils, modernisation de notre chaîne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;
Monter en compétences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous développerez une compréhension globale des chaînes de traitements ;
Participer à tous les travaux de modernisation de notre SI, et être donc engagé dans la migration de nombreux process vers le DataLake Risk.





#TransformativeFinance
Ce poste est basé à Paris avec la possibilité de télétravailler.
En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours.
Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.
Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise.
A propos du processus de recrutement
Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier).
Voir moins","Profil recherché
Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : Vous souhaitez bénéficier d'une première expérience significative en développement Spark et Scala. Vous maitrisez : * Les méthodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appétence pour la manipulation de la data. Vous êtes : * Reconnu par votre esprit d'équipe ; * Capable de communiquer avec des publics différents, notamment avec le métier ; * Autonome et ntéressé par l'environnement finance de marché. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous êtes intéressé en répondant à cette annonce.",2024-02-12,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-madonne-core-h-f_paris_NATIX_j0K8rw6?q=c645b17b4f1bd30795adde03b500c6a9&o=cb523ffd-fdaf-49bc-9f79-cdbbd0fe593c,wttj
"Senior Data Engineer - Paris, Toulouse, Montpellier - F/H/N","{'name': 'SWILE', 'sector': 'Application mobile, Restauration, FoodTech', 'employees': '1000 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '35 ans'}",CDI,,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Notre équipe Analytics s’agrandit et nous recherchons un.e Data Engineer Senior pour développer notre plateforme d’Analytics globale.
😎 Tes futures missions :
Développer et maintenir une Data Platform robuste qui permet l’ingestion et la mise à disposition d’une grande variété de données
Gérer nos outils SaaS (Stitch, Snowflake, …) et contribuer sur notre infrastructure K8S auto-hebergée (Airflow, Kafka, …)
Modéliser les données pour les traitements Analytics
Définir avec l’équipe les bonnes pratiques afin d’industrialiser nos modèles d’Analytics
Assurer la chaîne de traitement des données
Appliquer les bonnes pratiques de code pour permettre une croissance de la base de code sans augmenter notre dette technique (version control, testing, refactoring, …)
Participer aux choix techniques
Documenter le code et les process pour le partage de connaissance au sein de l’équipe Innovation
Voir moins","Profil recherché
✨Ce sera un match parfait si tu as …
Au moins 3 ans d’expérience sur un poste en Data Engineering avec un background en Software Engineering
Bon niveau de maitrise sur notre stack technique Analytics : Stitch/Airflow, AWS S3/ Snowflake, DBT, Github, Docker/Terraform
Bon niveau de maitrise en SQL
Excellente communication et capacité à présenter des sujets complexes de manière simple
Bonne capacité d’ownership et de priorisation
Anglais courant",2024-02-12,https://www.welcometothejungle.com/fr/companies/swile/jobs/senior-data-egineer-f-h-n_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=c8db5e7c-2bcc-4c7b-b739-ebc1a3489796,wttj
Cloud Data Engineer H/F,"{'name': 'HARDIS GROUP', 'sector': 'IT / Digital, Supply Chain, SaaS / Cloud Services', 'employees': '1500 collaborateurs', 'creation_year': '1984', 'turnover': ""156 millions d'euros en 2022"", 'mean_age': '38 ans'}",CDI,Saint-Herblain,Non spécifié,Télétravail fréquent,01 novembre 2021,> 3 ans,Bac +5 / Master,"Descriptif du poste
Au sein de notre entité Business Applications nantaise et intégré au sein d’une équipe projet, vous contribuez à l’élaboration et l’évolution des couches métiers des applications que nous réalisons pour nos clients.
En tant que Cloud Data Engineer, vous participez à des projets innovants à forte valeur ajoutée pour nos clients, à la fois technologique et métier. Entouré de développeurs, lead développeur, architecte et Scrummaster, vous travaillez en méthode agile (Scrum). Notre vision du Cloud Data Engineer :
Vous êtes capable d’appréhender un contexte client et d’implémenter une plateforme pour valoriser sa donnée
Vous avez déjà une expérience sur GCP ou AWS
Vous êtes à l’aise sur l’un des langages suivants (Python, Java, JavaScript)
Vous avez déjà utilisé un framework de calculs distribué (Spark, Beam, …)
Vous connaissez et utilisez les différentes solutions de stockage (SQL, NoSQL, Search Engine…)
Vous maitrisez les principes du développement Cloud
Vous avez des connaissances en machine learning
Voir moins","Profil recherché
De formation Bac + 5, issu d’une école d’ingénieur ou équivalent, vous justifiez d’au moins 3 ans d’expérience professionnelle réussie dans les domaines de la Data et du Cloud en contexte agile.
Vous êtes à l’aise avec un ou plusieurs des sujets suivants : Python, Java, JavaScript, GCP, AWS, Spark, Beam, Kafka, Airflow, ELK.
Vous êtes à la fois autonome et force de proposition.
Vous aimez partager vos connaissances et souhaitez évoluer au sein d’une équipe technophile et riche en expertises. Vous êtes organisé, méthodique et avez une excellente capacité d’analyse. La curiosité, l’esprit d’équipe et la bonne humeur sont indispensables pour intégrer l’équipe Business Applications Nantes.
Nous pouvons accompagner votre mobilité grâce à une offre globale (de la recherche de logement à l’accompagnement administratif, en passant par l’intégration de l’ensemble de la famille dans le nouvel environnement de vie) - sous condition d’éligibilité",2024-02-12,https://www.welcometothejungle.com/fr/companies/hardis-group/jobs/cloud-data-engineer_saint-herblain?q=c645b17b4f1bd30795adde03b500c6a9&o=3c25f853-5f7c-4653-8351-e589606a2957,wttj
Data Engineer,"{'name': 'SOCIÉTÉ GÉNÉRALE', 'sector': 'Banque, FinTech / InsurTech, Finance', 'employees': '117000 collaborateurs', 'creation_year': '1864', 'turnover': None, 'mean_age': None}",CDI,Fontenay-sous-Bois,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Au sein de la Direction des Systèmes d'Information de la Banque de Détail France de Société Générale, vous :

Bénéficierez d'un cadre de travail agréable facilitant l'équilibre vie pro/vie perso notamment en permettant jusqu'à 3 jours de télétravail par semaine.

Evoluerez dans un environnement stimulant : intégrez nos équipes afin de relever les défis innovants qui nous animent au quotidien autour des pratiques de développement green, du cloud, de la data ou encore de la Cybersécurité.

Baignerez dans une culture bienveillante : notre proximité avec le métier, l'entraide et l'écoute entre management et la communauté des experts font notre force. Un collectif plébiscité par 85% de nos collaborateurs.

Les missions seront les suivantes :
Suivre et dépanner la production pour son maintien en conditions opérationnelles
Concevoir des solutions pour collecter, transformer et exploiter de gros volumes de données
Analyser les données provenant de multiples sources (exemple : croisement simple de données jusqu'à l'analyse prédictive)
Industrialiser des traitements et participer à leur amélioration continue pour qu'ils soient fiables, robustes, performants et résilients afin de répondre aux exigences des partenaires métiers
Travailler en étroite collaboration avec les Data Architectes et Data Scientists pour industrialiser le procédé et produire des analyses opérationnelles => ajouter les autres transverses + PO métier
Tester de nouvelles fonctionnalités, nouveaux outils et participer à des conférences internationales (Flink Forward, Spark Summit)
Documenter ses travaux
Contribuer à l'acculturation et à la vulgarisation des sujets Big Data auprès de ses principaux interlocuteurs


Et si c’était vous ?


Vous possédez les compétences suivantes :
Connaissances des outils liés au Big Data : Spark, Hive, Hadoop, NiFi, Kafka, Elastic, Kibana
Développement informatique : Scala, Python, Java, Devops, Big Data, outils CI/CD, microservice, API
Modélisation des données Modèles de données : modèle en étoile, modèle Data Vault
Connaissances en architecture technique Big Data
Relationnel et esprit d'équipe sens du service, capacité à collaborer, à communiquer et à s'adapter à ses interlocuteurs
Autonomie
Savoir s'adapter aux différentes méthodologies (prédictives, agiles, hybrides)
Forte transversalité (interactions avec des équipes variées) : Admin plate-forme, équipe DevOps, support, Expert IT : Architecte Big Data, IT Data Designer, Experts Data : Data Scientist, Data Quality Manager, Business Data Designer, Métiers, Chef de Projet

Plus qu'un poste, un tremplin


Notre vision est de jouer un rôle moteur dans les transformations positives du monde et de contribuer à un avenir plus écologique, respectueux de la planète !

Choisir Société Générale, c'est intégrer un Groupe où la culture d'entreprise est tournée vers l'inclusion, la diversité et l'esprit d'équipe !

C'est construire une carrière dynamique avec la possibilité de changer de poste en moyenne tous les 4 ans, en France et à l'international tout en bénéficiant de formations régulières !

Au regard de vos compétences, une rémunération attractive revue annuellement, composée d'un salaire fixe, d'une part variable individuelle et d'une prime d'intéressement et de participation vous sera proposée.

Vous bénéficiez également de tarifs préférentiels sur vos services bancaires, d'un compte épargne temps monétisable et d'un Plan d'Epargne Entreprise abondé.

Attentif à votre qualité de vie et conditions de travail, vous bénéficiez de nombreux avantages complémentaires :
À minima 2 jours de télétravail par semaine
26 à 28 jours de congés payés par an et 14 à 18 jours de RTT (suivant les années), des congés liés aux événements de la vie
Un Comité d'Entreprise (billetterie événements sportifs & culturels, primes et subventions vacances, garde d'enfants, chèque cadeaux à Noel)
Une offre variée de restaurants d'entreprise et de cafétérias à tarifs compétitifs ainsi que des titres restaurants dématérialisés quand vous êtes en télétravail

Pourquoi nous choisir ?


Chez Société Générale, nous sommes convaincus que vous êtes le moteur du changement et que le monde de demain sera fait de toutes vos initiatives, des plus petites aux plus ambitieuses. Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques années ou toute votre carrière, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. Créer, oser, innover, entreprendre font partie de notre ADN.

Si vous aussi vous souhaitez être dans l'action, évoluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et développer ou renforcer votre expertise, nous sommes faits pour nous rencontrer !

Vous hésitez encore ?

Sachez que nos collaborateurs peuvent s'engager quelques jours par an pour des actions de solidarité sur leur temps de travail : parrainer des personnes en difficulté dans leur orientation ou leur insertion professionnelle, participer à l'éducation financière de jeunes en apprentissage ou encore partager leurs compétences avec une association. Les formats d'engagement sont multiples.

Nous sommes un employeur garantissant l'égalité des chances et nous sommes fiers de faire de la diversité une force pour notre entreprise. Le groupe s'engage à reconnaître et à promouvoir tous les talents, quels que soient leurs croyances, âge, handicap, parentalité, origine ethnique, nationalité, identité de genre, orientation sexuelle, appartenance à une organisation politique, religieuse, syndicale ou à une minorité, ou toute autre caractéristique qui pourrait faire l'objet d'une discrimination.

Référence: 240003CI
Entité: Banque de détail France
Date de début: 01/04/2024

Date de publication: 08/02/2024
Voir moins",,2024-02-12,https://www.welcometothejungle.com/fr/companies/societe-generale/jobs/data-engineer_fontenay-sous-bois_SG_Jel07g?q=c645b17b4f1bd30795adde03b500c6a9&o=76ce65c9-2a5a-4cd9-b40f-e5cf12591a4c,wttj
Data Engineer - Equipements Biomédicaux connectés,"{'name': 'APHP DSI', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, Santé', 'employees': '495 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '46 ans'}","CDD / Temporaire
(12 à 36 mois)",Paris,Non spécifié,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
La mission de votre équipe
Afin de permettre le développement de projets de recherche innovants, en particulier dans le domaine de l’intelligence artificielle, l’AP–HP a mis en place une plateforme Big Data, infrastructure informatique propre, intégrant des capacités de stockage et de calcul pour l’exploitation sécurisée et performante des données de santé dont elle est dépositaire. Cette plateforme héberge notamment l’entrepôt de données de santé (EDS) de l’AP-HP.

L’Entrepôt de Données de Santé (EDS) de l’AP-HP intègre des données administratives et médicales de plus de 8 millions de patients hospitalisés ou venus en consultation au sein des 39 établissements de l’AP-HP (20 millions de dossiers médicaux, plus de 10 millions de diagnostics, 181 millions de résultats de laboratoires…). Cet entrepôt permet d’améliorer le pilotage de l’activité hospitalière et de faire avancer la recherche scientifique dans le domaine de la santé en favorisant la réalisation d’études sur données, la mise en place d’essais cliniques et le développement d’algorithmes d’aide à la décision.

La Plateforme Big Data de l’AP-HP compte actuellement +30 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d’espace disque), de machines GPU (48 Nvidia P40 / V100), de 20 machines dédiées aux environnements Jupyter pour l’analyse de données, et de nombreuses autres machines applicatives.

Votre équipe, le domaine « Plateforme Big Data », a pour mission l’intégration des données de santé massives et complexes (données structurés, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation à grande échelle, de manière performante, ergonomique et sécurisée dans le respect des principes et règles de gouvernance des données définis par l’AP-HP. Les données issues des équipements biomédicaux connectés proviennent globalement de l’ensemble des services de l’APHP et en particulier dans les services de soins intensifs. Selon le contexte, la fréquence d’acquisition et la durée d’enregistrement des signaux varient dans des proportoins importantes (de quelques secondes à plusieurs jours et de 0.02Hz à 3kHz).
Vos missions
Au sein de l’équipe en charge de la Plateforme Big Data de l’APHP, vous prenez en charge le développement des outils ou composants répondant aux attentes des médecins et chercheurs pour le stockage et l’exploitation des données de type signaux physiologiques (ECG, EEG, EMG, courbes respiratoires, …) collectées dans le cadre de leurs projets de recherche.
La plateforme big data cherche a se doter d’une solution technique spécifique pour le stockage, le traitement et l’exploitation de ces données sous forme de séries temporelles. Vous serez amené à analyser, à proposer et à mettre en oeuvre une architecture et des solutions adaptées aux différents besoins des projets de recherche et vous participerez également à la mise en place d’un certain nombre d’outils de base (visualisation, annotation, etc.) pour faciliter l’exploitation et l’enrichissement des données physiologiques par les utilisateurs de la plateforme.
En tant que data engineer spécialisé en traitement du signal et idéalement en systèmes biomédicaux, vous :
Réaliserez la définition des besoins et l’accompagnement des médecins pour la réalisation d’un projet de recherche
Analyserez les différents équipements biomédicaux, signaux et protocoles de communication
Développerez, industrialiserez et maintiendrez les flux d’intégration des signaux physiologiques pour permettre leur collecte au sein de la plateforme big data
Contribuerez à l’utilisation de ces nouvelles typologies de données (extraction, sélection, collecte et intégration) via des connecteurs spécifiques développés en java, python ou d’autres langages
Industrialiserez le code de génération du flux de données et assurer sa performance globale
Aiderez à l’implémentation de standards et normes de mise à disposition des données
Mettrez en place des outils permettant l’enrichissement des données (analyse, annotation, etc)
Travaillerez en collaboration avec des partenaires industriels dans le cadre des différents projets de recherche
Voir moins","Profil recherché
Idéalement, vous..
Avez un diplôme d’ingénieur ou équivalent (bac+4/5, master2) en informatique ou sciences avec formation complémentaire en informatique
Avez une expérience de développement sous Linux, des langagage Java et/ou Python et des outils EAI (Mirth, …) et ETL (Talend ou autre)
Avez une expérience dans la manipulation de données avec le langage SQL
Connaissez les standards en informatique de santé (HL7 v2, DICOM, HL7-FHIR, OMOP, …)
Avez le goût de l’intégration de systèmes informatiques hétérogènes
Avez des connaissances des bonnes pratiques de sécurité informatique et de la réglementation informatique et libertés
Adhérez aux valeurs du service public et vous avez un intérêt prononcé pour le domaine de la santé
Avez un niveau d’anglais courant
Vous avez un savoir faire dans un de ces domaines :
Voir plus",2024-02-12,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-equipements-biomedicaux-connectes_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=c65d22e3-c3cb-424c-bea1-fcd8d36f5d0d,wttj
Data Engineer,"{'name': 'NIELSENIQ GROUP INCL DATA IMPACT AND GFK', 'sector': 'Big Data, E-commerce', 'employees': '40000 collaborateurs', 'creation_year': '1923', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
We’re looking for an experienced Data Engineer to join our growing Machine Learning team.Your work will entail the following :
Creating data flows
Working on data versioning
Launching flows in orchestration tools
Improve CI/CD pipelines
Dependencies management (poetry)
Deploying scripts/models created by data scientists on Notebooks
Contrat : CDI
Localisation : Paris 10e
#LI-DAIM
About NIQ
NIQ is the world’s leading consumer intelligence company, delivering the most complete understanding of consumer buying behavior and revealing new pathways to growth. In 2023, NIQ combined with GfK, bringing together the two industry leaders with unparalleled global reach. With a holistic retail read and the most comprehensive consumer insights—delivered with advanced analytics through state-of-the-art platforms—NIQ delivers the Full View™.
NIQ, is an Advent International portfolio company with operations in 100+ markets, covering more than 90% of the world’s population. For more information, visit NIQ.com.
Want to keep up with our latest updates?
Follow us on: LinkedIn | Instagram | Twitter | Facebook
  Our commitment to Diversity, Equity, and Inclusion
NIQ is committed to reflecting the diversity of the clients, communities, and markets we measure within our own workforce. We exist to count everyone and are on a mission to systematically embed inclusion and diversity into all aspects of our workforce, measurement, and products. We enthusiastically invite candidates who share that mission to join us.
We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class. Our global non-discrimination policy covers these protected classes in every market in which we do business worldwide.
Learn more about how we are driving diversity and inclusion in everything we do by visiting the NielsenIQ News Center: https://nielseniq.com/global/en/news-center/diversity-inclusion/
NIQ or any of our subsidiaries will never ask you for money at any point of the recruitment or onboarding process.
Voir moins","Profil recherché
1-2 years of experience
Proficiency with Python
Experience with distributed systems to manipulate big data (Dask, Spark)
Experience with ML datasets is a plus
Experience creating ETL pipelines
Experience working with GCP (Google Cloud Platform) on main data services (cloud storage, bigquery, cloud build, GKE..)
Experience using orchestrators (airflow, dagster...)
Work environment (Linux, Jupyter, Python, Git, Docker, SQL, NoSQL, ...)
Significant experience with Pandas, SQL technologies and writing Dockerfiles
Professional level of French and English",2024-02-10,https://www.welcometothejungle.com/fr/companies/data-impact/jobs/data-engineer_paris_NGIDIAG_23O9D95?q=c645b17b4f1bd30795adde03b500c6a9&o=43982201-5a7b-4308-a2d8-3d104951a7f6,wttj
Senior Data Engineer (H/F),"{'name': 'STUDI - DIGITAL EDUCATION FOR LIFE', 'sector': 'Education, EdTech, Formation', 'employees': '1000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,Pérols,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Avec plus de 1000 collaborateurs, Studi est LA grande école en ligne française, acteur incontournable de l’edtech et leader sur son marché de la formation en ligne et l’alternance.
Filiale Edtech de Galileo Global Education - N°1 groupe mondial de l’enseignement supérieur privé - Studi propose plus de 200 formations reconnues par l’État du niveau CAP au BAC+5 et forme plus de 70 000 apprenants chaque jour. 
Pour y parvenir, Studi accélère son développement en France et à l’international 🌍, et souhaite renforcer ses effectifs.
Nous recrutons continuellement de nouveaux talents passionnés qui souhaitent grandir et prendre part à une belle aventure.
Join us ! 😎
 Vos missions
Sous la responsabilité du Head of Data, le Senior Data Engineer est chargé de collecter, transformer et activer la data afin d’accompagner la prise de décision. Il est chargé de la conception de solutions robustes, permettant le traitement de volumes importants de pipelines données. Par ailleurs, les solutions choisies doivent être suffisamment sécurisées et lisibles pour les Data Analysts et Data Scientists qui seront les premiers consommateurs de ces données stockées, nécessaires aux besoins opérationnels et décisionnels de l’entreprise.
Vous concevez, développez et maintenez des pipelines de données robustes, évolutifs et fiables pour le recueil, le traitement et la distribution des données. 
Vous assurez la qualité des données en mettant en place des processus de nettoyage, de transformation et de validation et mettez en œuvre des solutions de stockage adaptées et performantes. 
Vous optimisez les performances des requêtes et des processus liés aux données pour garantir une réponse rapide aux besoins des Data Analysts. 
Vous participez à la documentation des architectures, des processus et des flux de données et collaborez avec les équipes de sécurité afin d'en garantir la confidentialité et leur conformité. 
Vous disposez d'une expérience significative en ingénierie des données et une solide connaissance des technologies ETL (Extract, Transform, Load).
Vous maitrisez les langages de programmation tels que Python ou autre. 
Vous avez des compétences avancées en SQL et une connaissance approfondie des concepts de modélisation de données et de normalisation. 
Vous avez une expérience en dans la conception et la mise en œuvre d'architectures de données distribuées. 
Vous êtes force de proposition, rigoureux et disposez d'un esprit analytique et de synthèse. 
Vous aves l'esprit d'équipe et un excellent relationnel. 
Vous avez le sens de l'organisation et de la qualité. 
AUDACE : Try it! Shake it! Chez Studi nous sommes curieux, nous proposons de nouvelles solutions et sortons de notre zone de confort.
ENERGIE: Go for it! Do It! Nous donnons le meilleur de nous-même pour avancer.
SOLIDARITE: Share it! Nous favorisons la collaboration, l'entraide et la bienveillance.
RESPONSABILITE: Own it! Nous assumons une mission qui a du sens : moderniser et démocratiser l’éducation. 
Vous vous reconnaissez ?
Nous sommes impatient(e)s de vous rencontrer !
 Et puis Studi c'est aussi...
De superbes nouveaux locaux de 10 000m2
Une carte tickets restaurant SWILE
Une prime d’intéressement et participation
Des jours de congé conventionnels
Un CE
Une charte de 2 jours de Télétravail par semaine
Une mutuelle et une prévoyance d’entreprise
Petit plus, vous pouvez bénéficier au cours de votre carrière de contenus de formation Studi!
 Adressez-nous votre candidature !
 Type de contrat : CDI
Lieu : Montpellier (34 000)
Cette opportunité est ouverte aux personnes en situation de handicap.
STUDI_SJ+
Voir moins",,2024-02-09,https://www.welcometothejungle.com/fr/companies/studi-digital-education/jobs/data-engineer-h-f_perols?q=c645b17b4f1bd30795adde03b500c6a9&o=bbca4d94-cd5c-49f4-a829-816c87664608,wttj
Alternance - Cloud Data Engineer (H/F),"{'name': 'EPSILON FRANCE', 'sector': 'Digital Marketing / Data Marketing, Big Data, AdTech / MarTech', 'employees': '600 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '38 ans'}",Alternance,Wasquehal,Non spécifié,Télétravail non autorisé,,> 6 mois,,"Descriptif du poste
L’ambition du Pôle Data Management est d'offrir la meilleure expérience à nos clients grâce à des solutions data-driven et cloud.
Nous les accompagnons sur des projets innovants et la création de modèles s'appuyant sur les nouvelles technologies.
 En tant que Cloud Data Engineer Azure et/ou Google voici vos missions : 
Contribuer à la réalisation de projets Data Client, Data Lake, Data services dans un contexte de plus en plus DevOps et Agile,
Assurer la veille technologique sur les composants d’une plateforme Data,  Datalake, Cloud,
Rédiger des documents projets (design, réalisation, déploiement, …),
Gérer l’évolution des solutions proposées, et possiblement en assurer la TMA,
Participer aux initiatives projets et à l’évolution de nos assets data internes.
C'est un travail passionnant et enrichissant pour nos collaborateurs qui sont amenés à collaborer avec le marketing, le digital et la création.","Profil recherché
Vous avez une première expérience sur des projets data en environnement cloud (GCP, Azure), ou une connaissance des DWH (sur technologie traditionnelle et/ou cloud), voire du DataOps.
Vous souhaitez évoluer sur les technologies Big Data Hadoop/HDFS, Hive, Python et le requêtage de données (Impala, Hive, ...).
Votre expérience dans le traitement de la data, sa valorisation et sa production est un atout considérable. 
Une connaissance d’un ETL (Stambia, Talend…) est un plus.
 Localisation : Campus 5.9 (Wasquehal)
Rémunération : Nous savons que le salaire est un élément essentiel pour vous ! C’est pourquoi nous en parlerons sans tabou dès les premiers échanges.
Les + EPSILON France :
Accès au Restaurant d'entreprise 
Travail Hybride grâce à notre Accord Télétravail qui autorise jusqu’à 2 jours par semaine
Voir plus",2024-02-09,https://www.welcometothejungle.com/fr/companies/epsilon/jobs/alternance-cloud-data-engineer-h-f_wasquehal?q=c645b17b4f1bd30795adde03b500c6a9&o=0abafb37-642b-42ea-875d-00f1debb4dde,wttj
Stagiaire / Intern Data Engineer,"{'name': 'QUANTCUBE TECHNOLOGY', 'sector': 'Intelligence artificielle / Machine Learning, FinTech / InsurTech, Big Data', 'employees': '55 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '29 ans'}","Stage
(6 mois)",Paris,Non spécifié,Télétravail fréquent,,< 6 mois,Bac +5 / Master,"Descriptif du poste
At the forefront of AI innovation and investment strategies, we’re a leading company on the lookout for a passionate Junior Data Engineer to join our dynamic and rapidly expanding quantitative team. Our mission revolves around setting up cutting-edge technology, fortified infrastructure, and ingenious quantitative methodologies to drive our business and sustain a competitive advantage in the market.
Your primary responsibility will manage the freshly installed infrastructure and systems that lie at the heart of our quant desk. Picture yourself in charge of architecting ingenious trading systems, managing our databases, and maintaining seamless communication with our full-stack developers to continuously enhance and elevate our existing dashboards.
Missions:
You will be a pivotal and essential member of our team. Your assignments will immerse you in the heart of our current projects, providing you with unparalleled opportunities for growth and impact. Your daily tasks will include:
Pioneering the development, rigorous testing, and deployment of quantitative trading systems, databases, and other mission-critical software.
Playing a pivotal role in the architectural decision-making process, architecting scalable solutions to the most intricate challenges that come our way.
Coordinating role between the Quant team and the IT team (full-stack developers and DevOps engineers), ensuring the meticulous management and real-time monitoring of our trading desk dashboard.
Maintaining the pulse of our database, meticulously safeguarding its performance, availability, scalability, and security to ensure it runs like clockwork.
What we offer
At the heart of these assignments lies the opportunity to drive innovation forward in the world of AI and finance. You will have the opportunity to take part to challenging and valuable projects, to communicate directly with our IT, Product and Data Science teams, at the forefront of AI for economics and finance.
You’ll also be joining a multicultural, warm and close-knit team that loves to organise events and activities after work.
A la pointe de l’innovation en matière d’IA et de stratégies d’investissement, nous sommes une entreprise de premier plan à la recherche d’un ingénieur de données passionné pour rejoindre notre équipe dynamique d’analyst quantitatifs et en pleine expansion. Notre mission consiste à mettre en place une technologie de pointe, une infrastructure fortifiée et des méthodologies quantitatives ingénieuses pour stimuler notre activité et maintenir un avantage concurrentiel sur le marché.
Votre principale responsabilité sera de gérer l’infrastructure nouvellement mise en place et les systèmes qui sont au cœur de notre desk quantitatif. Vous vous imaginez en charge de l’architecture de systèmes de trading ingénieux, de la gestion de nos bases de données et du maintien d’une communication transparente avec nos développeurs full-stack afin d’améliorer et de rehausser continuellement nos tableaux de bord existants.
Missions :
Vous serez un membre essentiel de notre équipe. Vos missions vous plongeront au cœur de nos projets actuels, vous offrant des opportunités de croissance et d’impact inégalées. Vos tâches quotidiennes consisteront notamment à
Être pionnier dans le développement, les tests rigoureux et le déploiement de systèmes de négociation quantitative, de bases de données et d’autres logiciels critiques.
Jouer un rôle central dans le processus de prise de décision en matière d’architecture, en élaborant des solutions évolutives pour relever les défis les plus complexes qui se présentent à nous.
Rôle de coordination entre l’équipe Quant et l’équipe IT (développeurs Full-Stack et ingénieurs DevOps), assurant la gestion méticuleuse et le suivi en temps réel du tableau de bord de notre trading desk.
Prendre le pouls de notre base de données, en protégeant méticuleusement ses performances, sa disponibilité, son évolutivité et sa sécurité afin de s’assurer qu’elle fonctionne comme une horloge.
Ce que nous proposons
Au cœur de ces missions se trouve l’opportunité de faire avancer l’innovation dans le monde de l’IA et de la finance. Vous aurez l’occasion de participer à des projets stimulants et utiles, de communiquer directement avec nos équipes IT, Produit et Data Science, à la pointe de l’IA pour l’économie et la finance.
Vous rejoindrez également une équipe multiculturelle, chaleureuse et soudée qui aime organiser des événements et des activités après le travail.
Voir moins","Profil recherché
Degree in Computer Science, Engineering, Mathematics, or a related quantitative discipline
Knowledge of python packages (requests, beautiful soup, selenium) and SQL database management systems
Strong knowledge of data structures, algorithms, and object-oriented programming
Proficiency in UNIX commands and Linux development
Good development practices: version control, testing
What is a plus :
First experience in Quantitative trading environment
Interest in Finance, trading systems and relevant technology
Strong problem-solving abilities, with an analytical mind and a keen attention to detail
Excellent written and verbal communication skills
QuantCube recruits and recognises all talents.
Diplôme en informatique, ingénierie, mathématiques ou dans une discipline quantitative similaire
Voir plus",2024-02-09,https://www.welcometothejungle.com/fr/companies/quantcube-technology/jobs/stagiaire-intern-data-engineer_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=9adf712f-9790-4d87-8078-bcb6a4437d3a,wttj
Senior Data Engineer H/F,"{'name': 'QANTEV', 'sector': 'Intelligence artificielle / Machine Learning, FinTech / InsurTech, SaaS / Cloud Services', 'employees': '46 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '29 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
What you will be doing
As a member of the data science and engineering team, alongside our technical experts, you will be able to:
Improve our OCR pipeline deployed on insurance claims data.
Work on our NLP pipelines for medical coding inference and sentiment analysis on hospital reviews.
Enhance our fraud detection machine learning models.
Scale our proprietary patient journey optimizer based on state-of-the-art optimal transport.
Implement and optimize the associated algorithms.
Integrate your contribution in our python/postgresql/elasticsearch stack.
Develop test framework for the models.
Think about the best ways to deploy our machine learning models at scale.
Continuously provide ideas to improve the solution.","Profil recherché
Preferred Experience
What you need to succeed
3+ years of experience in the field of data engineering and machine learning.
Advanced technical skills in Applied Mathematics, preferably in machine learning,
probabilistic modeling, computer sciences, statistics and/or operations research
Strong analysis and synthesis abilities, not afraid to deal with details.
Proficient knowledge of Python and Deep Learning Frameworks.
Ability to read, understand and implement research papers.
Able to write quality production code and provide coding review to improve the skills of the team.
Fluent in English.
Bonus skills
Working on production-grade projects with good software engineering insights.
Previous experience working within an agile framework.
Previous startup or health insurance experience.
Voir plus",2024-02-09,https://www.welcometothejungle.com/fr/companies/qantev/jobs/senior-machine-learning-engineer_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=a01acad0-34ef-48f3-8082-baee305ccf62,wttj
Data Engineer GCP Senior (F/H),"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, Cybersécurité', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232M€', 'mean_age': None}",CDI,La Défense,Non spécifié,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
💥 Découvrez la Vie Apsidienne 📹 et vous aussi, devenez Apsidien
On aurait pu demander à Chat GPT de vous démontrer en quoi Apside est l’ESN qu’il vous faut, mais on préfère que vous le découvriez vous-mêmes 👇😏
🔥 Découvrez votre future mission
👉 Contexte
Rejoignez notre Practise Cloud/Data, afin d’intervenir sur des sujets à haute valeur ajoutée !
Secteur  : Télécom
Méthode de travail : Agile Safe
Notre client a besoin d’un accompagnement sur leurs projets métiers Data/IA accostant sur un cloud public et à la construction d'outils pour accélérer et faciliter cet accostage.
Cela sera réalisé dans un environnement GCP et en grande majorité sur des technologies innovantes pour des services Data & IA. La mission sera partagé entre le ""build"" des cas d'usage et outils, et le ""run"" de ces derniers.
😎 Mission
Etude et définition des architectures GCP, ainsi que leur implémentation
Mise en application des exigences opérationnelles (sécurité, exploitabilité et industrialisation)
Aiguillage sur nos outils transverse et préconisations à l'usage du cloud public
Construction d'outillages facilitant l'accostage de ces des projets métiers DATA-IA
…
Environnement technique :
GCP
Git
Gitlab
Bash
Docker
Kubernetes
GitlabCI
💰 Le package salarial que nous vous proposons
Contrat : CDI
Avantages groupe : carte ticket restaurant Swile, prime de mobilité, RTT, accord télétravail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle à 100% etc…
Avantages agence : intégration de la Practise Cloud/Data, afterworks, communauté techlead...
Formation : certifications techniques, cours particuliers d’anglais en interne, accès à un catalogue de formations grâce à notre plateforme e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherché
🔮 Ô vous futur Apsidien, qui êtes-vous ?
Au moins 5 ans d'expérience en tant que Data Engineer
Maitrise de l’environnement cloud GCP
Force de proposition, bon relationnel et autonome
😏 Apside a suscité votre curiosité ?
Dans un environnement marqué par une accélération des évolutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients à créer de la valeur et à adresser leurs enjeux stratégiques en leur mettant à disposition des expertises technologiques (Data / IA, Cloud, Cyber) et une expérience sectorielle (Industrie, Banque, Assurance, Service, Secteur Public). Pour un accompagnement global, le groupe propose des offres transverses autour du Handicap (Apsid’EA), du Digital Learning, et du Conseil.
🤔 Et votre place dans tout ça ?
👉 Notre volonté est de vous accompagner dans la construction et l’épanouissement de votre carrière en nous appuyant notamment sur 3 piliers :
Voir plus",2024-02-08,https://www.welcometothejungle.com/fr/companies/apside/jobs/data-engineer-gcp-senior-f-h_la-defense?q=c645b17b4f1bd30795adde03b500c6a9&o=a803a30f-8d0f-42a4-aab8-ff2d0c62d5ce,wttj
Data Engineer AWS Senior (F/H),"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, Cybersécurité', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232M€', 'mean_age': None}",CDI,La Défense,Non spécifié,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
💥 Découvrez la Vie Apsidienne 📹 et vous aussi, devenez Apsidien
On aurait pu demander à Chat GPT de vous démontrer en quoi Apside est l’ESN qu’il vous faut, mais on préfère que vous le découvriez vous-mêmes 👇😏
🔥 Découvrez votre future mission
👉 Contexte
Rejoignez notre Practise Cloud/Data, afin d’intervenir sur des sujets à haute valeur ajoutée !
Dans le cadre du renforcement de leur équipe data, notre client recherche un data ingénieur qui sera amené à travailler sur la mise en oeuvre de plusieurs produits data visant à l'exposition et la mise en qualité des données de références.
L'environnement de travail est sur le cloud AWS avec terraform en infra as code
Secteur  : culture/média
Méthode de travail : Agile / Scrum
😎 Mission
Ingestion et traitement des sources de données
Préparation des données (transformation fonctionnelle et technique)
Elaboration de système avancé de gestion de qualité de données
Elaboration d'API/workflow
Exposition des données (Elasticsearch, RDS) via des API pour les applications front
Préparation des package de livraison en Infra as code
Gestion du cycle de livraison en production
MCO
Rédaction des documentations techniques
…
Environnement technique :
AWS (lambda, EMR, APIGateway, cognito ...)
Python
TerraForm
Git CI/CD
Elasticsearch
PySpark
JSON
SQL (PostgreSQL)
📍 Localisation
     La Défense
💰 Le package salarial que nous vous proposons
Contrat : CDI
Avantages groupe : carte ticket restaurant Swile, prime de mobilité, RTT, accord télétravail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle à 100% etc…
Avantages agence : intégration de la Practise Cloud/Data, afterworks, communauté techlead...
Formation : certifications techniques, cours particuliers d’anglais en interne, accès à un catalogue de formations grâce à notre plateforme e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherché
🔮 Ô vous futur Apsidien, qui êtes-vous ?
Au moins 5 ans d'expérience en tant que Data Engineer
Maitrise de l’environnement cloud AWS
Force de proposition, bon relationnel et autonome
😏 Apside a suscité votre curiosité ?
Dans un environnement marqué par une accélération des évolutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients à créer de la valeur et à adresser leurs enjeux stratégiques en leur mettant à disposition des expertises technologiques (Data / IA, Cloud, Cyber) et une expérience sectorielle (Industrie, Banque, Assurance, Service, Secteur Public). Pour un accompagnement global, le groupe propose des offres transverses autour du Handicap (Apsid’EA), du Digital Learning, et du Conseil.
🤔 Et votre place dans tout ça ?
👉 Notre volonté est de vous accompagner dans la construction et l’épanouissement de votre carrière en nous appuyant notamment sur 3 piliers :
Voir plus",2024-02-08,https://www.welcometothejungle.com/fr/companies/apside/jobs/data-engineer-aws-senior-f-h_la-defense?q=c645b17b4f1bd30795adde03b500c6a9&o=d4c6c8a2-f9a5-4e1f-bd9a-d420de37ff4b,wttj
Senior Data Engineer M/F,"{'name': 'SPLIO', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Marketing / Communication', 'employees': '250 collaborateurs', 'creation_year': '2001', 'turnover': '26M€', 'mean_age': '33 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
About Splio
Splio is a scale-up in the Martech industry with around 30 million ARR. It is headquartered in Paris and employs 220 people (with 90 within the Product and Tech department and across 4 offices (France, Spain, Italy, Tunisia).
In 2023, Splio acquired Tinyclues to integrate their predictive marketing into Splio's CRM and become the European leader in intelligent CRM, allowing brands to easily orchestrate highly personalized marketing at scale through AI.
We are proud to include Longchamp, 3 Suisses, Cojean, Micromania, FNAC, SNCF Connect, Orange, and Samsung among a portfolio of 500 client companies from SME to larger companies across various industries (retail, catering, telecoms, etc.).
To support our growth, we are looking for a Senior Data Engineer to join our R&D team.
Your missions
Build, manage & improve several hundred data pipelines
You are a SQL guru : you are able to find the most cost-effective way to create an asset in our data layer
You are a practitioner of orchestration technologies (Airflow, Kubeflow)
Focus on :
Multi Tenancy : every client has its own data schema, ability to build flexible and configurable KPIs
Scalability : Client’s data can be big but the computation and scoring we process for our clients are even bigger
Cost efficiency : linked to the amount of data to process for each client, we maintain the cost low to make profit
Stack :
Languages : SQL, Python
Framework/Lib : dbt
Dev Env : GCP, Airflow 
Your responsibilities
Tech (80%)
Contribute to the overall engineering at Splio
Contribute to the development with your team
Proactively ensure that security, reliability, performance and cost-efficiency are included in technical and architectural discussions
Keep up to date with the latest relevant technologies, continually evaluating their use for Splio
Leadership (20%)
As a Senior Data Engineer, you provide guidance, allow teams to discover and learn independently.
You can handle high level of complexity and bring clarity on those complex problems
Actively question decisions and provide guidance and own experience to ensure no stone is left unturned and risks are identified and highlighted
Collaborate with other teams when necessary for the product you’re building
Your Profile
🏛 Good technical architectural skills, you are Python fluent with a knowledge of Google Cloud Platform and an experience of BigQuery
📣Excellent communication skills to build relationships, trust, and respect
⚙️ A solid background in technology allowing you to handle new technologies & to challenge technical choices
✅ A strong interest for engineering practices
🧑🏻‍🏫 Able to lead by example, hands-on and ownership
🔁 Comfortable in dealing with change and uncertainty during the software development lifecycle
🤸‍♂️ Good knowledge about Agile development practices
🇬🇧 Good english skills (speaking and writing)
Perks & Benefits
🌴 12 Splio days (days off), in addition to the 25 legal days off
🛋️ Friendly remote policy (5 days on site in one of the cities where there’s a Splio office)
😋 A Swile card that you can use for lunch (10€ per worked day)
👨‍👩‍👦‍👦 Possibility to attend or participate to conferences once or twice a year
Interested in joining Splio ?
30 min video-call with François Bonicel, VP engineering to get to know you, present the job position and exchange on your qualifications & motivations to join Splio
1 hour technical case in our Paris office to evaluate your hard skills and deep dive into the role
30 min video-call with a member of the HR team to assess your interpersonal skills and give you more information about the company culture & benefits
30 min video-call with our CPTO or CTO for final validation
Voir moins",,2024-02-08,https://www.welcometothejungle.com/fr/companies/splio/jobs/senior-data-engineer-m-f_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=ef4277f0-c7a3-4302-87eb-114f303490d8,wttj
Stagiaire Data Engineer,"{'name': 'NAMR', 'sector': 'Big Data', 'employees': '48 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '31 ans'}","Stage
(6 mois)",Paris,Non spécifié,Télétravail occasionnel,04 mars 2024,< 6 mois,,"Descriptif du poste
En rejoignant notre équipe Data Engineering, tu auras les missions suivantes :
Implémenter et gérer CI/CD pipelines
Sourcer, analyser, nettoyer, intégrer et documenter les datasets du datalake
Extraire les données issues de ces datasets pour construire les données de notre base de données (attributs)
Maintenir les scripts de mise à jour des flux de données (airflow)
Développer l’outil interne de gestion et administration de nos données et métadonnées (Python, SQL)
Contribuer à l’évolution de notre infrastructure de données vers des technologies scalables (Postgresql, BigQuery, Kubernetes) intégrant plusieurs types de données (structurées, géolocalisées, imagerie, texte, etc.)
maintenance de la code base + maitrise des bonnes pratiques de code (Tests unitaires, Ci/CD etc)
Effectuer une veille systématique des technos, outils et méthodes de gestion des bases de données","Profil recherché
Ton parcours : Tu es en Master Computer Science ou en formation d’Ingénieur en Informatique et recherches un stage de fin d’études.
Ta stack technique :
Python, SQL ;
Traitement/nettoyage de donnée.
Les technologies souhaitables :
Cloud (OVH, AWS, GCS, Azur, Scaleway) ;
Docker ;
QGIS ;
Dataiku ;
Git ;
NoSQL ;
PostgreSQL, PostGIS ;
Airflow
Tes qualités humaines :
Voir plus",2024-02-08,https://www.welcometothejungle.com/fr/companies/nam-r/jobs/stagiaire-data-engineer_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=3bc4da3e-0e15-40e1-a90d-82de0bb8c974,wttj
Consultant.e Data Engineer Expérimenté.e,"{'name': 'THE INFORMATION LAB', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '38 collaborateurs', 'creation_year': '2015', 'turnover': '5M€', 'mean_age': None}",CDI,Paris,45 à 60 €,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Qui sommes-nous ?
Véritables passionnés de data, nous avons construit The Information Lab autour des solutions Tableau, Alteryx et Snowflake. Nous sommes convaincus que ce sont les meilleures technologies pour accomplir la transformation digitale de nos clients.
Notre spécialisation nous permet d’être les premiers partenaires de ces éditeurs et d’être les experts reconnus de ces solutions en France et en Europe.
En nous rejoignant vous pourrez partager votre passion avec vos pairs, travailler dans une ambiance décontractée pour remplir notre mission : ""Helping people make sense of data”.
Description du poste
Rattaché(e) au pôle Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous métiers. Vos missions ont pour objet le traitement, l’analyse, l’enrichissement des données de nos clients et l’adoption par nos clients des technologies que nous proposons. Au sein d’une équipe de 5 à 8 personnes, vous réalisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre “pod leader” (chef d’équipe).
Votre rôle consiste à :
Intervenir en avant-vente et cadrer vos missions
Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours à quelques mois
Mener des projets de bout en bout, en méthode classique ou agile, en coordination avec les équipes de nos clients, nos équipes internes et les éditeurs partenaires
Présenter les livrables de vos missions et mettre en avant leur ROI
Former nos clients à nos technologies
Mettre vos compétences au service de vos collègues au-delà des missions dont vous avez la charge et participer au développement des compétences en partageant vos retours d’expérience
Participer aux activités d’évangélisation, par exemple : rédaction de posts de blogs, participation aux communautés des éditeurs, interventions lors d’événements (salons, conférences, webinaires)
Participer aux projets internes (BI interne, méthodes & qualités)
Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires.
Voir moins","Profil recherché
Vos principales qualités :
Excellentes facultés d’écoute et de communication, orale et écrite
Aptitude à travailler sur plusieurs sujets en parallèle, à prioriser
Humilité et capacité à apprendre ainsi qu’à transmettre ses connaissances
Sens du service, un bon relationnel avec les clients et la rigueur nécessaire au succès de leurs projets
Team player
Compétences méthodologiques :
Analyse du besoin et cadrage de mission
Construction d’indicateurs métiers à partir de données brutes
Idéalement connaissance d’un ou plusieurs métiers et de leurs indicateurs clés
Préparation de données complexes à des fins d’analyse
Méthodes de gestion de projet (classique et agile)
Capacité prouvée à réaliser des démonstrations d’outils
Compétences techniques :
Voir plus",2024-02-08,https://www.welcometothejungle.com/fr/companies/the-information-lab/jobs/consultant-e-data-engineer-experimente-e_paris_TIL_z1PepgM?q=c645b17b4f1bd30795adde03b500c6a9&o=80e697a6-f81b-4056-8969-e1cc60e6edeb,wttj
Lead Data Engineer - Scala (F/H/X),"{'name': 'AVIV GROUP', 'sector': 'Immobilier commercial, Immobilier particulier', 'employees': '1800 collaborateurs', 'creation_year': '2015', 'turnover': '500M€', 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
Rejoignez l’équipe Marketplace Design AVIV
La marketplace AVIV est le lieu de rencontre privilégié de tous les acteurs de l’annonce immobilière: potentiels acquéreurs ou locataires, propriétaires ou agents, … Afin de garder notre position, nous devons fournir la meilleure qualité de service possible en termes de sécurité,  de confiance, d’efficacité et de pertinence des échanges entre ces acteurs. Plusieurs facteurs entrent en ligne de compte: qualité et sérieux des prospects et des agents  ainsi que la qualité des informations affichées.
Le rôle de l’équipe Marketplace design est de concevoir et exécuter toutes les actions nécessaires pour assurer la satisfaction de nos utilisateurs : qualité et correction des données, scoring, matching, gamification, et amélioration continue. Ces actions requièrent un usage important des données, l’équipe Data Operations est responsable de la gouvernance, la modélisation et  la qualité des données ainsi que de fournir les data-sets clés et maintenir une data platform robuste et efficace pour tout le groupe AVIV.
Vos responsabilités :
En tant que Lead Data Engineer au sein de l’équipe Data Operations, vous travaillez en étroite collaboration avec un Product Manager et votre Engineering Manager. Vos développements respectent les bonnes pratiques en place et sont alignés avec l’architecture d’entreprise AVIV. Vous apportez votre expertise technique à votre équipe, vous créez, adaptez et améliorez la qualité des data-sets et des outils largement utilisés chez AVIV.
L’équipe Data Operations
L’équipe est constituée d’environ 40 personnes, avec notamment:
Coach Agile
Data Engineers
Data Quality Engineers
Data Analysts & Modelers
Devops Engineers
Enterprise & Solution Architects
Product Managers
Les projets
Décentraliser la data et Mettre en place le Data Mesh au sein du groupe Aviv
Fournir les insights sur les usages des différents sites et apps mobiles européens  
Notre Stack Technique data
AWS (CloudFormation, EMR, S3, Glue, Athena, Redshift, SNS/SQS)
Spark
Git, CircleCI, Datadog
Scala, Java
Vous avez idéalement des connaissances complémentaires telles que :
Python 
Apache Airflow, Kubernetes
Jenkins, Argo CD, Grafana, VictoriaMetrics
Voir moins","Profil recherché
Nous recherchons une personne capable de:
Créer et maintenir des datasets complexes et à gros volumes selon des spécifications fonctionnelles précises.
Participer à la création d’une infrastructure solide et optimale pour l’extraction, la transformation et le chargement (ETL) de données à partir de nombreuses sources. Utilisation de SQL et de technologies big data cloud.
Identifier, concevoir et implémenter les processus internes d’amélioration: automatisation, optimisation du delivery, scalabilité, etc…
Travailler avec des experts data et données analytiques au développement de nouvelles fonctionnalités 
Maitriser la méthodologie Agile: communication directe, adaptation, fail fast, amélioration continue et Software Craftsman
Maîtriser le produit et le business, impactant l’amélioration du service aux clients, du produit et de l’architecture
Rigueur, curiosité, autonomie et état d’esprit positif 
Voir plus",2024-02-08,https://www.welcometothejungle.com/fr/companies/aviv-group/jobs/lead-data-engineer-scala-f-h-x_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=ad8082da-634e-4c4a-8235-676bac993891,wttj
Data Engineer H/F,"{'name': 'CAPGEMINI', 'sector': 'IT / Digital, Organisation / Management, Stratégie, Transformation', 'employees': '360000 collaborateurs', 'creation_year': '1967', 'turnover': '18 Mds €', 'mean_age': '37 ans'}",CDI,Bordeaux,Non spécifié,Télétravail non autorisé,,> 3 ans,Bac +5 / Master,"Descriptif du poste
  Vous êtes passionné par le domaine de la Data, vous souhaitez prendre part à des projets d'envergure, concevoir des solutions, les implémenter et les faire évoluer?
Alors rejoignez notre équipe Data Engineering Services au sein de Capgemini Cloud Infrastructure Services en tant que Data Engineer.
Vous avez acquis une expérience solide dans le développement, la mise en œuvre et l’optimisation de solutions pour le traitement d'un grand volume de données, vous êtes capable de créer des solutions qui répondent aux besoins métiers et IT, alors rejoignez notre équipe d’experts.
  En qualité de Data engineer, vos missions sont les suivantes :
▪ Concevoir et développer des solutions Data/IA.
▪ Accompagner les Métier dans la compréhension et la mise en œuvre de solution orientées données.
▪ Collaborer avec les Dev, les Ops, les experts infrastructures dans la construction de solutions et d’infrastructures axées sur les données.
▪ Gérer un écosystème de partenaires data et assurer un haut niveau d'expertise
▪ Assurer un rôle de veille technologique sur tous les outils autours de la data, de l’IA et de la BI.
    Avec nous, votre futur ressemblera à :
Des projets d’envergure, variés et passionnants
Des clients grands comptes de tous secteurs
Des évolutions avec une offre de formation solide
Des échanges avec une communauté d’experts très actives
Un accompagnement de proximité.
 Voir moins","Profil recherché
Description du profil :

Vous êtes issu d’une formation ingénieur ou équivalent bac+5 informatique spécialisée en DATA et vous justifiez d’une expérience d’au moins 5 ans dans un rôle similaire. Expert dans une technologie de base de données relationnelle (PostgreSQL, Oracle…)
Expert dans une technologie de base NoSQL (MongoDB, Cassandra…)
Vous maitrisez un framework de manipulation de données (Hadoop, Spark, Kafka…)
Vous maitrisez les concepts DevOps et avez de bonnes notions en scripting et développement
Vous avez une expérience des outils BI et de data visualisation (Kibana, PowerBI…)
La maitrise de l’anglais est nécessaire. 


Nous proposons :

Et pour (finir de) vous convaincre, on vous en dit un peu plus sur nous :
Les avantages aussi nombreux que variés :
Voir plus",2024-02-07,https://www.welcometothejungle.com/fr/companies/capgemini/jobs/data-engineer-h-f_bordeaux_CAPGE_3NXA38e?q=c645b17b4f1bd30795adde03b500c6a9&o=40db8230-1ec2-4c0e-ad0b-c93546abd1dd,wttj
Data Engineer Senior,"{'name': 'JAKALA', 'sector': 'Digital Marketing / Data Marketing, Big Data, E-commerce', 'employees': '150 collaborateurs', 'creation_year': '2023', 'turnover': '15M€', 'mean_age': '31 ans'}",CDI,,Non spécifié,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Au sein de notre Data Lab, vous travaillerez conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et vous serez impliqué.e dans la prise de décisions liée à notre solution Data et à son évolution.
A cet effet, vous êtes en charge de :
Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clients
Comprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internes,
Définir l’architecture logiciel ETL / ELT en collaboration avec vos pairs
Travailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage),
Rédiger de la documentation technique (diagrammes UML, documentation d’API, …),
Partager votre savoir-faire entre les différents membres de l’équipe,
Concevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateforme,
Concevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big Data,
Assurer une veille technologique et savoir mener à bien un projet de R&D.
Vous assurez en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :
Cartographier des données et des flux de données
Implémenter des algorithmes d’analyse de données pour l’industrialisation
Collecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)
Développer et automatiser des flux de données et leurs visualisations en dashboards, reporting
S’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateforme
Analyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big Data
Mettre en place du séquencement et de la supervision des flux précitées en gérant les cas limites
Compétences attendues :
Bon niveau en développement :
De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)
De script ELT : DBT (ex. Snowflake, PostgreSQL)
Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQL
LakeHouse: Delta LakeConnaissance message broker : RabbitMQ, Kafka
Compétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)
Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managés
Cartographie des données
Voir moins","Profil recherché
Diplômé·e d’études supérieures dans le système d’information, computer sciences, big data (école d’ingénieurs, école spécialisée ou équivalent universitaire), vous justifiez d’au moins 5 ans en Data engineering.
Vous avez une expertise reconnue sur la mise en place de pipelines complets de valorisation de données massives, de la collecte à la mise à disposition d’applications en passant par le traitement.
La maîtrise de l’anglais est appréciée.
Certification·s indispensable·s : GCP Professionnal Data Engineer OU Azure Data Engineer Associate OU AWS Solution Architect.
Vous êtes passionné·e par votre métier, aimez le faire partager.",2024-02-07,https://www.welcometothejungle.com/fr/companies/soyhuce/jobs/data-engineer-senior-cdi-paris-ou-caen?q=c645b17b4f1bd30795adde03b500c6a9&o=6696f7e0-63be-4373-8470-85bff272293b,wttj
Data Architect / Data Engineer Confirmé.e,"{'name': 'JAKALA', 'sector': 'Digital Marketing / Data Marketing, Big Data, E-commerce', 'employees': '150 collaborateurs', 'creation_year': '2023', 'turnover': '15M€', 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
SOYHUCE est à la recherche d’un·e Data architect / Data Engineer afin d’accompagner techniquement et opérationnellement le Data Lab (Data Scientist, Data Engineer, Data Analystes, MLOps …) et travailler étroitement avec les équipes IT pour le développement des projets.
Vous contribuez ainsi aux grands programmes innovants et stratégique du groupe.
Vos missions au quotidien :
Gérer l’environnement Big Data (GCP) et d’en assurer la stabilité et  l’optimisation dans le cadre des projets DATA inscrits dans la Roadmap
Implémenter des flux de collecte, de transformation et de stockage des données multi- sources
Automatiser le processus de structuration de la DATA en amont de l’intervention d’un Data Scientist (création et maintenance du code)
Concevoir et automatiser le processus de structuration de la DATA et des outils nécessaires permettant aux experts de l’équipe un accès facile aux données pour développer les cas d’usage métier (Data science/IA, Reporting, Analytics, Activation média, …)
Être l’interlocuteur privilégié  de l’équipe Architecture IT pour assurer un avancement conjoint sur les sujets Data prioritaires
Assurer avec l’IT le processus de qualité et la fiabilité des flux de données (scalabilité, sécurité, performance, recovery) en conformité avec les standards définis par la sécurité du groupe
Assurer la rédaction et la maintenance  d’une documentation claire sur les différents projets développés
Assurer la mise en production des projets DATA
Évaluer l’architecture et l’environnement DATA actuels et prévoir des mises à jour nécessaires selon les besoins de l’équipe. (ex. intégration nouveaux outils de Data Prep)
Développer les APIs/ connecteurs nécessaires pour intégrer notre DATA dans les plateformes AdTech 3rd (ex DSP/SSP Média)
Compétences techniques :
Maîtrise des solutions Cloud GCP (BigQuery, DataProc…) et AWS (RDS, EMR…)
Langages SQL, NoSQL, Python, R…
Modélisation, traitement et transformation des données complexes et multi-sources
Conception et déploiement d’une architecture distribuée pour le traitement de données
Maitrise des aspects d’authentification, de sécurité, de containerisation et d’orchestration
Maitrise des technologies: Spark, Kafka, Couchbase, Cassandra, Solr, Suite ELK, Redis, SQL Server, PostgreSQL, Docker, Kubernetes
Outils : Tableau et PowerBI
Voir moins","Profil recherché
Diplôme Bac + 5, ingénieur ou équivalent universitaire ou ayant démontré ses compétences dans l’architecture DATA.
Passionné·e de la data avec au moins 5 ans d’expérience dans des rôles Data Architect, Architecture ou similaire, vous possédez les qualités suivantes :
Esprit d’équipe et sens de l’écoute
Autonomie et proactivité
Curiosité et créativité
Sens relationnel et capacité d’adaptation
Rigueur
Esprit d’analyse",2024-02-07,https://www.welcometothejungle.com/fr/companies/soyhuce/jobs/data-architect-data-engineer-cdi-paris_paris_JAKAL_kMQdDJl?q=c645b17b4f1bd30795adde03b500c6a9&o=cd8b4043-af93-474a-9a96-c3fe3dd70fb1,wttj
Data Engineer GCP (H/F),"{'name': 'THALES', 'sector': 'Logiciels, Cybersécurité, Aéronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mds€', 'mean_age': None}",CDI,Bordeaux,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces.
THALES Bordeaux recherche un Ingénieur Data / GCP (H/F) :
CDI (pas de full-remote ni freelance)
2 jours de télétravail par semaine
Site : Mérignac (33700)
QUI ETES-VOUS ?
De formation supérieure en Informatique/Data (Bac+5 ou supérieur), vous disposez d'une expérience professionnelle d’au moins 3 ans dans l’utilisation de technologies cloud, et notamment GCP. Vous avez géré des projets industrialisés en data engineering et/ou IA, et souhaitez continuer à évoluer dans ces deux domaines.
Vous maîtrisez les outils de cloud, Data Analytics et les techniques de traitement de données. Vous avez une expérience du travail DevOps, de l'automatisation et la surveillance continues tout au long du cycle de vie des applications (approche CI/CD).
Vous connaissez au moins le langage de programmation PYTHON ainsi que les bases de données (postgreSQL) et leur langage associé (SQL...). Vous savez vous adapter à diverses technologies et outils, et tirer parti de la meilleure solution pour répondre aux exigences du client.
Votre rigueur, votre esprit d'équipe et vos qualités relationnelles sont autant d'atouts qui vous permettront de réussir dans vos missions.
CE QUE NOUS POUVONS FAIRE ENSEMBLE :
Au sein de projets Agile, vous aurez pour mission de :
Concevoir et développer des pipelines de traitements de la donnée
Collaborer avec l’équipe pour le respect des délais de livraisons dans une organisation en mode Agile
Utiliser des outils comme Google Cloud Platform (GCP) pour réaliser des traitements IA et Data
Réfléchir à la sécurisation des données confidentielles
Contribuer au développement des cas d’usage métier, apporter de la valeur et de l’innovation en utilisant les outils à disposition
Participer aux projets d’évolutions en apportant votre analyse technique et fonctionnelle
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Voir moins",,2024-02-07,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-gcp-h-f_bordeaux?q=c645b17b4f1bd30795adde03b500c6a9&o=99ef78b1-a820-43b8-a9f8-ed6356beb7a6,wttj
STAGE - Data Engineer,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",Stage,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
La mission d’AXA est de « donner à chacun les moyens de vivre une vie meilleure ». Nous souhaitons alors passer du rôle de payeur à celui de partenaire. La mission de notre division, AXA Group Operations (GO), est de soutenir et responsabiliser l’ensemble des équipes d’AXA afin de concrétiser cette ambition commune.
L’innovation et l’exécution sont nos principaux leviers pour atteindre cet objectif. Ils guident l’ensemble des équipes de GO au quotidien : Innovation : créer et fournir les bases et opportunités aux équipes d’AXA qui développeront des solutions innovantes afin de répondre aux besoins de nos clients actuels et futurs ;
Exécution : créer l’environnement qui permettra à nos équipes à travers le monde, de donner vie à leurs idées et de tenir les promesses faites à nos clients.
Nos objectifs concrets sont de :- Renforcer la création de valeur pour l’ensemble du groupe AXA ;- Soutenir et encourager l'innovation au sein d'AXA, en collaboration avec la division Group Business Innovation ;- Automatiser et intégrer la simplicité dans notre travail quotidien, en nous assurant de contribuer efficacement à la mission et stratégie d’AXA.
Les équipes de Group Operations sont alors composées de :
Group IT : définit la stratégie IT globale d’AXA ; favorise la convergence de l’IT au sein des entités et leur fournit des services partagés ;
Group Security : protège les salariés, nos parties prenantes et la marque AXA en sécurisant les informations et gérant les cyber sécurité, la sécurité physique ainsi que la résilience des opérations ;
REV: définit les ambitions concernant la maturité des données du Groupe ; construit et gère la communauté ; conduit la recherche et l’expertise ; assiste les entités les moins matures en termes de données ;
Technology Innovation : identifie les technologies de pointe et en développe des disruptives pour les entités ; crée des cas d’usage sur des technologies spécifiques avec les entités ;
Group Procurement : définit la stratégie d’achats d’AXA, ses lignes directrices et les normes du Groupe ; gère les relations avec nos fournisseurs stratégiques et accélère les achats métiers ;
Group Strategic Program Management : s’assure de la cohérence des projets globaux avec la stratégie du Groupe ; veille à la mise en œuvre et performance des projets stratégiques ;
AXA Business Services : offre des services partagés alignés aux priorités commerciales d’AXA ;
Group Operations Transformation : accélère la transformation agile au sein de Group Operations ; établit et met en œuvre une communication et stratégie RH commune à notre division.
Dans ce contexte, vous intégrerez le département  Data, BI and Analytics pour rejoindre une équipe projets en charge du développement de solutions data pour les entités. Le département Data, BI & Analytics propose des produits aux entités du Groupe AXA pour stocker la donnée (datalake), la transformer, l’agréger et la visualiser. Notre catalogue de services s’appuie sur 3 piliers :
Le CoE (Center of Excellence) qui joue un rôle d’expertise et de conseil vis-à-vis des entités (formation, R&D, expertise fonctionnelle et technique, UX…)
Le Delivery - projet et BAU – qui implémente et maintient les produits (IT Services, qualité de service, support, évolutions…)
La Factory qui implémente et maintient les couches techniques des applications (CI/CD, monitoring de plateforme, capacity management…).
Dans ce contexte, le département Data, BI & Analytics prend en charge le cycle complet des produits et services : avant-vente, delivery du projet, exploitation et maintenance des solutions.
VOS MISSIONS : 
Construire et maintenir des composents Microsoft BigData & BI
Développer des rapports BI
Interagir avec une équipe et le tech lead
Ecrire et maintenir la document technique autour d’une application
Mener de courtes missions en autonomie autour des besoins d’une application (résoudre les incidents techniques)
Nous célébrons l'expertise, la diversité culturelle et la créativité de plus de 8 000 employés de par le monde.  Nous nous engageons à assurer l'égalité des chances en matière d'emploi (parité hommes-femmes, communauté LGBT+, personnes handicapées ou personnes d'origines diverses) et à promouvoir la diversité et l'inclusion en créant un environnement de travail où tous les employés sont traités avec dignité et respect, et où les différences individuelles sont valorisées.
Voir moins","Profil recherché
PROFIL : Etudiant en école d'ingénierie à la recherche d'un stage de 4-6 mois.
Vous développerez vos compétences sur :
Le travail dans un contexte internationnal (anglais)
Vos connaissances en traitement de données et les bonnes pratiques
Vos capacités à travailler en équipe
Vos capacités à résoudre les problèmes et incidents techniques 
Compétences techniques / Hard skills:
Python
SQL Server
DAX (serait un plus)
Langues : Français (bilingue), anglais(opérationnel)
Outils informatiques :
Office 365 (EXCEL)
PowerBI
Plateforme Cloud Azure",2024-02-07,https://www.welcometothejungle.com/fr/companies/axa/jobs/stage-data-engineer_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=014fcfba-471e-4511-9159-f6c9e8d09583,wttj
Data Engineer,"{'name': 'WEWYSE', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Transformation', 'employees': '60 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 1 an,Bac +5 / Master,"Descriptif du poste
Être Data Engineer chez Wewyse c’est :
intégrer une communauté d’experts Data passionnés,
recevoir et partager de la connaissance et des savoirs-faire lors de nombreux évènements,
intervenir chez des clients pour y porter l’expertise Wewyse dans des contextes et des secteurs variés,
participer à des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires académiques et des start up,
viser l’excellence des développement en s’appuyant sur le Software craftsmanship,
concevoir des architectures logicielles modernes,
penser DevOps pour l’automatisation des déploiements et la continuité des services.
être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles,
faire partie de la famille Wemanity avec ses évènements et ses multiples opportunités de carrière.","Profil recherché
Ce que nous aimons chez Wewyse :
les personnalités ouvertes, curieuses, ambitieuses
les langages Scala, Python et Java
le cloud : AWS, GCP, Azure
les écosystèmes : Hadoop et Spark
la conteneurisation : Docker et Kubernetes
les méthodes Agiles
le SQL et le NoSQL
l’approche DevOps : Jenkins, Ansible et Terraform
le versionning : Git
l’anglais",2024-02-06,https://www.welcometothejungle.com/fr/companies/wewyse/jobs/data-engineer_paris_WEWYS_Orerk8M?q=c645b17b4f1bd30795adde03b500c6a9&o=d2b6ef9b-0fbb-4f36-8da0-6d4990c0f72d,wttj
Senior Data Engineer,"{'name': 'ECHO ANALYTICS', 'sector': 'Intelligence artificielle / Machine Learning, Big Data', 'employees': '85 collaborateurs', 'creation_year': '2021', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,19 février 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
🚀 Founded in 2021, Echo's narrative is one of relentless growth, ambition, and promise. A cutting-edge startup at the forefront of Geospatial Data and Gen AI technologies, we have skyrocketed from 0 to 50+ employees in just two years!
Specialists in the location intelligence industry, we empower innovation by helping companies better understand the world around them.
In a world inundated with data, quality is crucial. We use data science, machine learning, and human feedback to build Europe's most comprehensive, high-quality datasets, enriched with differentiating attributes that outmaneuver the competition.
We aren’t just about reliable data (read: unmatched quality) though.
Life at Echo is about individual growth, collective ambition, and a culture that values and celebrates diversity; With a ""people first"" philosophy guiding everything we do.
You'll be at the heart of innovation, tackling projects that shape our future, with the best people possible!
Your Role at Echo
As a Senior Data Engineer on our R&D team, you'll be a key player in shaping data flows within our Google Cloud Platform (GCP) environment. Your role involves designing and managing intricate data processes using technologies like BigQuery, Pub/Sub, Data flow, Airflow, Terraform, and GCP. Beyond design, you'll actively contribute to data modeling, overseeing data flows from concept to production support. Join us in a unique opportunity to be part of a successful startup, leading its market from the early stages.
As such, your main responsibilities will be
Be the driving force behind the development and maintenance of the team's products. This can take many forms, here are a few examples:
Ensure data is reliable, consistent, and available.
Expose the data through APIs, flat files, etc., for internal and external use.
Design geographical datasets for external consumers for speed, consistency, cost, and efficiency.
Be the technical mentor for a team of 2 to 5 Data/Software Engineers:
Provide best practices and guidance for individual contributors.
Report to the R&D management team on progress and difficulties.
Be proactive in investigating and testing new tools, processes, and technologies on an ongoing basis.
Continuing learning new skills thanks to the Echo Analytics knowledge plan.
Proposing architecture and design changes based on internal audit.

What we’re looking for
Fluent in English (French is a plus).
Minimum 5 years of data industry experience.
Proficient in Python programming.
Expertise in data engineering principles, ETL processes (Apache Airflow), and data warehousing.
Hands-on experience with Google Cloud Platform (or other providers) and cloud data processing frameworks
Proven experience with Apache Spark/Apache Beam.
Design and implementation of scalable and resilient data architectures in cloud environments.
Hands-on experience with Ops tools like GitHub Actions and Terraform.
Proven ability to provide ongoing support, monitor data processes, and optimize pipelines for stability and efficiency.

Why us?
🌎 A great diverse and international team based in Paris (25+ nationalities!)
🚀 Impact and ownership mindset: at Echo we encourage everyone to take ownership of their projects
🎇 People first company: without our people we have no business, we have dedicated a People Manifesto to them
🌆 A contemporary office space in central Paris with a rooftop to admire the view
💻 Remote-friendly policy
🥘 Free coffee, snacks on top of your lunch voucher card (Swile, 10€/ working day)
🏥 Healthcare insurance
Still hesitating or feeling like you don’t check all the boxes? We encourage you to apply anyway! 🙂
Best case scenario: we start an incredible collaboration. If not, you only invest a few minutes towards your application. We promise, you won’t regret it!
We are committed to providing equal employment opportunities regardless of gender, sexual orientation, origin, disabilities, or any other traits that make you who you are.
Voir moins",,2024-02-06,https://www.welcometothejungle.com/fr/companies/echo-analytics/jobs/senior-data-engineer_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=fb34814a-dc95-4bd0-82f8-5e77dc7a8e05,wttj
Data Engineer,"{'name': 'MEWS PARTNERS', 'sector': 'Organisation / Management, Transformation, Audit', 'employees': '300 collaborateurs', 'creation_year': '1992', 'turnover': '47M€', 'mean_age': '32 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
Vous serez amené.e à travailler dans un environnement scientifique de premier plan (collaboration avec des centres de R&D en France et à l’international, mais aussi avec des laboratoires de recherche universitaires) sur des sujets de pointe en traitement statistique de données et data mining. Vous bénéficierez du support d’une équipe pluridisciplinaire et travaillerez sous l’autorité directe du Directeur technique du département.
Le poste consistera à accompagner des Data Scientists dans l’utilisation des données sur divers projets, et intègrera les tâches suivantes :
· définition de nouveaux schémas de bases de données relationnelles en fonction des besoins des Data Scientists,
· développement d’outils communs pour faciliter l’utilisation des données,
· automatisation des processus de génération de bases de données,
· développement de tests de validation de la cohérence des bases de données.","Profil recherché
Notre futur talent…
… est idéalement un.e Ingénieur.e diplômé.e d’une école d’informatique ou généraliste (ou équivalent universitaire Bac+5), et aura une première expérience dans le développement informatique ainsi que dans la gestion de bases de données.
… a une bonne connaissance des langages SQL et Python (pandas, numpy).
… a éventuellement des connaissances poussées sur l’ensemble des étapes de traitement des données (collecte, nettoyage, consolidation, formatage) et l’administration de bases de données, ainsi que de postgreSQL.
… maîtrise l’environnement Linux.
Informations complémentaires
Poste en CDI basé dans les locaux de Mews Labs (au 61 Avenue du Président Wilson, 94230 Cachan).
Si vous êtes prêt.e à relever des défis stimulants et à développer vos compétences au sein d’une équipe de passionnés, nous vous attendons avec impatience !",2024-02-06,https://www.welcometothejungle.com/fr/companies/mews-partners/jobs/data-engineer_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=e53d43f6-d2ea-40e6-ad46-bc1db968dc18,wttj
Data Engineer - F/H,"{'name': 'CS', 'sector': 'Ingénieries Spécialisées, Aéronautique / Spatiale, Energie', 'employees': '2700 collaborateurs', 'creation_year': '1968', 'turnover': '300 000 000€', 'mean_age': '40 ans'}",CDI,Fontaine,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Nous recrutons un.e Data Engineer pour rejoindre notre Business Unit INDUSTRIE au sein de la Business Line Data Intelligence.
Dans le cadre de son offre « Data Intelligence », CS GROUP accompagne ses clients sur l’ensemble des étapes de valorisation de leurs données, incluant les démarches de Data Gouvernance. Ces projets d’ampleur sont opérationnellement menés par des « Data Offices » accompagnant les experts métiers dans l’application de la stratégie Data de l’entreprise.
Votre mission :
Concevoir et développer des outils de traitements et processing de données ;
Déployer, industrialiser et tester des solutions développées ;
Monitoring et analyse de flux de données ;
Contribuer aux activités de conseil (compréhension du besoin, proposition de solutions techniques - architectures, réalisation de missions d’audit, industrialisation de modèles de données…).
Environnement technique : 
Spark, Hadoop
Environnement Cloud (AWS, GCP)
R, Python, Shiny
HTML, CSS, Javascript
DevOps
Voir moins","Profil recherché
Qui êtes-vous ?
De formation supérieur (Bac+5), vous justifiez d'une première expérience sur un projet de Data Engireening.
Vous appréciez de travailler en équipe ? Vous possédez des qualités en communication et êtes rigoureux.se ? Alors vous êtes la pépite que nous recherchons !
A compétences égales, ce poste est ouvert aux personnes en situation de handicap.",2024-02-06,https://www.welcometothejungle.com/fr/companies/cs-group/jobs/data-engineer-f-h_fontaine_CS_egWjw0m?q=c645b17b4f1bd30795adde03b500c6a9&o=f34992dd-cd84-43e2-8afe-768c3c484f1e,wttj
Data Engineer H/F- CDI,"{'name': 'ACHEEL', 'sector': 'Assurance, FinTech / InsurTech', 'employees': '75 collaborateurs', 'creation_year': '2020', 'turnover': '130 millions', 'mean_age': '33 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,17 juillet 2023,> 1 an,Bac +3,"Descriptif du poste
🚀 Venez participer à l’essor de l’équipe Data d’Acheel ! Ce nouveau pôle a pour rôle de centraliser les outils de data science et data analyse de l’entreprise, et a pour cela vocation de grandir rapidement. Son objectif est de construire une architecture de données robuste et documentée afin de proposer les meilleures solutions possibles et de fournir un outil d’aide à la prise de décisions business aux équipes. Directement rattaché au CEO, vos missions seront de :
Etudier, Formater, transformer et transférer les données ingérées dans notre Data Warehouse provenant de nos différents domaines d’activité avec Dagster, et Airbyte
Mettre en place les tests nécessaires pour vérifier leur cohérence avec DBT et BigQuery
Mettre en place les KPI, et tableaux de bord pour leur compréhension avec Metabase
Documenter les données dans DBT
Faire évoluer ces modèles de données
Nous nous efforcerons de mettre en place les meilleurs pratiques afin de toujours nous améliorer et apprendre un maximum les uns des autres :
Intégration continue
Déploiement continu
Tests
Code review
Pair-programming
Voir moins","Profil recherché
Issu d’un cursus d’école d’ingénieur
Excellente connaissance de SQL et Python
Une première expérience de 2 ans minimum dans un poste similaire
Expérience avec Git
Une expérience avec DBT, GCP et Airbyte serait fortement appréciée
Savoir lire et compléter de la documentation en Anglais
Un esprit entrepreneurial et un goût prononcé pour les challenges.
Une volonté de grandir vite et de gagner rapidement en autonomie",2024-02-05,https://www.welcometothejungle.com/fr/companies/acheel/jobs/data-engineer-cdi_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=ecf3082f-78cf-447a-b317-164ac00315bb,wttj
Medical Data Engineer H/F,"{'name': 'GLEAMER', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, Santé', 'employees': '68 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,,,> Bac +5 / Doctorat,"Descriptif du poste
Joining the Data Team means immersing yourself in an environment that fosters a profound grasp of the medical domain central to our mission.
You will have the opportunity to leverage a massive medical database of about ten million exams. It’s a formidable and rare context for creating Medical Devices that meet and exceed the performance of expert humans in the field, thus improving the care of millions of patients every month.
As a member of the Data Team, you will collaborate closely with Radiologists, Product Managers, AI Engineers and Software Developers to build and improve our medical products.
Working at Gleamer means bringing your enthusiasm for enhancing people’s health and embracing the deep conviction that kindness is the cornerstone of a great work environment.
Missions:
Build and structure medically relevant and representative datasets.
Refine NLP techniques to unveil data insights.
Establish relevant annotation guidelines and training to ensure annotation quality.
Be a stakeholder in the ongoing overseeing and refinement of AI algorithm performance.
Contribute to clinical studies to scientifically assess the impact of our Medical Devices.
Voir moins","Profil recherché
PhD in the fields, but not limited to, Data & Computer Science, Bio-Informatics, Medical Physics
Hard Skills
Strong reasoning abilities and attention to detail.
Analytical and scientific mindset
Proficiency in a programming language
Soft Skills
Good communication skills
Driven to solve medical problems
Fluent in French. Proficient English level
Nice-to-have
Knowledge of medical imaging is a plus
Machine learning understanding is a plus",2024-02-05,https://www.welcometothejungle.com/fr/companies/gleamer/jobs/data-engineer-h-f_paris?q=c645b17b4f1bd30795adde03b500c6a9&o=81b36140-45ce-4361-aaf9-1a86db4efe9b,wttj
Senior Data Engineer,"{'name': 'FABERNOVEL', 'sector': 'IT / Digital, Stratégie, Transformation, Formation', 'employees': '350 collaborateurs', 'creation_year': '2003', 'turnover': None, 'mean_age': '29 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,,> 5 ans,,"Descriptif du poste
Descriptif du poste
Tu rejoindra notre team Data ! Tu participeras à la réalisation de solutions, en collaboration étroite avec des machine learning engineer, software architect, designers, developers...
Force de proposition en interne, tu interviendras pour être garant du développement d'architecture Data, de la collecte multi-source de données, du pilotage et de la pertinence de ces dernières.
Tu viendras compléter l'offre par tes connaissances techniques
Activités principales :
Compréhension des conceptions d'architecture data et des systèmes distribués
Conception et modélisation des pipelines de données en assurant un stockage et une interrogation efficace
Développement des traitements de données et de leur exploitation
Maîtrise l'ensemble des techniques, technologies et concepts utilisés
Responsable de la qualité technique sur le périmètre confié
Contribuer à la CI/CD avec TechLead et Ops
Accompagnement des juniors dans leur montée en compétence (pair programming, présentation sur des sujets techs, management...)
Tu auras la chance d'arriver à un moment charnière pour les équipes Datas, tu pourras ainsi participer aux différents changements qui s'opérent et batir avec eux le nouveau socle Data de Fabernovel en s'appropriant des nouveaux sujets : Datawarehouse, Big Data ... Chez Fabernovel nous sommes des chimistes, nous experimentons et créons !
Profil recherché :

Nous recherchons avant tout une personne avec des compétences en développement logiciel ayant au moins 7 ans d’expérience et qui a un attrait pour les problématiques data.
  Notre futur talent est :
En plus de tes compétences techniques, nous recherchons une personne curieuse, bienveillante, qui soit autonome et force de proposition.
Tu as un bon niveau en programmation fonctionnelle (ex : Scala, Rust)
Tu as déjà collaboré en workflows Git (One flow, Trunk based)
Tu es expert en base données SQL / NoSQL
Tu maitrise les systèmes et calcul distribués
Tu as une expérience significative sur plusieurs projets de stream processing sur une ou plusieurs des technos suivantes : Akka, Kafka, Spark
Tu as déjà travaillé sur un Cloud Provider: AWS, GCP, Azure, IBM
Bonus : tu connais l'untilisation de Kubernetes, Docker ou Airflow.
Tu sais communiquer de façon claire et précise et fait preuve d’un esprit de synthèse.
  Ce que nous offrons à tous nos talents
Des projets riches et impactants, chez Fabernovel nous transformons les environnements, les situations, avec nos propres méthodes et secrets de fabrication.
Une société apprenante ou nous avons conçu notre propre Learning development factory pour un partage de connaissance et un apprentissage continue.
Un management fondé sur la bienveillance, il n’y a pas d’échec, seulement des itérations et des occasions d’apprendre.
De la liberté dans ses choix : Flex office, horaires aménageables, possibilité de remote, culture de l’intrapreunariat.
Des avantages toujours sympa, avec des locaux au coeur de Paris, des paniers fruits, du café/thé, des salles de jeux techs et low techs, ainsi que des salles de siestes.
Mais aussi…
Une Carte Swile prise en charge à 60% par Fabernovel
Accès à des offres privilèges Gymlib
Remboursement de 50% des transports
RTT
PC ou MacBook
À propos de nous :
Créé en 2003 au cœur de l’écosystème numérique français, Fabernovel naît d’une conviction : celle que la technologie a le pouvoir de construire un futur plus vertueux pour les entreprises et le monde qui les entoure.
Aujourd’hui, ce sont 350 talents, sur 3 continents, experts du conseil en transformation numérique et de la création de produits et de services numériques. Nous maîtrisons les expertises liées au design, aux technologies, au marketing et aux cultures nouvelles dans l’entreprise et accompagnons de grandes entreprises de tous secteurs d’activité dans leur projet de transformation digitale et culturelle.
Cette Talent Company rassemble Designers, Strategists, Project Analysts, Developers, Data Architects, Product Managers, Media Specialists, Finance Managers, Communication Managers, Business Developers…qui font naître l’innovation chez nos clients. Nous activons pour nos clients les meilleures combinatoires de talents individuels et de méthodologies à la pointe, avec toujours l’objectif de les rendre le plus autonome possible.
Voir moins",,2024-02-05,https://www.welcometothejungle.com/fr/companies/fabernovel/jobs/senior-data-engineer_paris_FABER_5x1b0oa?q=c645b17b4f1bd30795adde03b500c6a9&o=8406f0e4-4308-4b7b-a211-2794eca3fcec,wttj
Senior data engineer H/F,"{'name': 'INVIVO DIGITAL FACTORY', 'sector': 'IT / Digital, E-commerce', 'employees': '68 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '30 ans'}",CDI,Courbevoie,Non spécifié,Télétravail fréquent,01 mars 2024,> 5 ans,Bac +4,"Descriptif du poste
Au sein des équipes Digital Factory du Groupe InVivo, vous prenez en charge la collecte des données issues de sources et de volumétries variées (systèmes d’information traditionnel ou No SQL, systèmes de production, IoT, log, Events, …). Vous assurez la connectivité vers les différentes sources, analysez le modèle des données sources et comprenez les problématiques métier afin de définir une modélisation adéquate des DataSets.
Vous prenez en charge la transformation de ces données (nettoyage, normalisation, et préparation), pour y appliquer les traitements analytiques conçus par les Data Scientists, ou les traitements décisionnels conçus par les Data Analysts.
En tant que sénior de l’équipe Data Engineering, vous assurez la relation avec les PO et apportez, au reste de l’équipe, votre maîtrise des architectures de flux de données, votre expérience sur la qualité des flux et des données ainsi que sur la sécurité.
Vous participez activement à l’acculturation des métiers.
Les locaux de la Digital Factory sont basés à La Défense. Télétravail à hauteur de 60%.
🐱‍🏍Les missions
Recueillir les besoins en données (Data Product Owner, Data Analysts, Data Scientists) et analyser les sources de données, identifier de nouvelles sources de données pertinentes.
Coordonner la mise en place de l’architecture Data & Analytics, conçue avec le data architect et en garantir le bon fonctionnement, la disponibilité, l’évolution et la performance technique des outils
Développer les pipelines d’intégration de données et la data quality en collaboration avec les Data Product Owner, Data Analysts et Data Scientists
Garantir l’industrialisation et l’automatisation de la chaîne de valeur de la donnée, en y intégrant les algorithmes décisionnels et les modèles de prédiction des données
Effectuer une veille sur les nouvelles technologies et solutions et participer activement à l’effort R&D
Contribuer à l’évolution des pratiques dans son domaine de compétences, en étant actif dans des réseaux de veille
Voir moins","Profil recherché
👨‍🎓 De formation Bac+5 école d’ingénieur orienté développement, ou master spécialisé en data, avec une spécialisation Big Data, vous êtes passionné.e par l’innovation et les technologies liées aux domaines Data Analytics & AI. Vous avez une expérience d’au moins 5 ans sur un poste similaire.
Vous faites preuve d’une grande capacité d’adaptation et capacité à communiquer avec des interlocuteurs multiples.
Vous êtes rigoureux.se, force de proposition, vous avez un bon esprit d’analyse et de synthèse. Vous appréciez le travail en équipe. Vous disposez d’une bonne capacité d’organisation, autonomie et sens de l’initiative. Maîtrise de l’anglais indispensable.
De fortes aptitudes en développement, notamment à travers une excellente maîtrise de langages de programmation comme : Python, C#, …
Bonne connaissance de la conception, l’audit et du déploiement d’architecture logicielle et technique autour des plateformes décisionnelles et des plateformes Big Data (Spark, Hadoop…)
Une excellente maîtrise du langage SQL, des bases dans la programmation de quelques bases de données NoSQL (Neo4j, MongoDB, …)
Voir plus",2024-02-05,https://www.welcometothejungle.com/fr/companies/invivo-digital-factory/jobs/senior-data-engineer-h-f_courbevoie_IDF_KRePbVN?q=c645b17b4f1bd30795adde03b500c6a9&o=d7c7cdfc-6b73-4cbe-885a-382f94defc0f,wttj
Data Engineer,"{'name': 'CONSORTIA', 'sector': 'Big Data', 'employees': '515 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '35 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
LOCALISATION : Limay (78), 2 jours de télétravail
Accompagnement de l’équipe Data en charge du déploiement de la gouvernance Data
·  Reprise et maintien du périmètre Data d’une de nos filliales.
·  Prise en main et maintenance de l’architecture Data Sarpi en cours de conception.
·  Evolution du modèle et intégration de nouvelles sources de données.
·  Accompagnement stratégique en termes d’architecture auprès du chef de projet.
·  Prise en main de l’ETL Snaplogic pour le développement et la documentation des flux d’intégration de données.
·  Utilisation de l’outil GCP BigQuery pour la construction des vues Métier et calcul d’indicateurs.
·  Mise en place et maintien de la sécurité d’accès aux données et le support niveau 2 sur l’outil Looker Studio.","Profil recherché
Une expérience significative (minimum 3 ans) sur des projets Data en tant que Data Engineer / Data Architect
Compétences requises : 
·  Connaissance des outils de la Google Cloud Platform (BigQuery, Looker Studio) avec les langages associés
·  Usage d’ETL
Compétences comportementales :
·  Capacité d’écoute, d’analyse et de synthèse
·  Aptitude à travailler en équipe
·  Aptitude à travailler de façon autonome avec un bon sens de l’initiative.",2024-02-05,https://www.welcometothejungle.com/fr/companies/consortia/jobs/data-engineer_paris?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=9e780867-f496-4085-b5c4-284faa08888d,wttj
(Senior) Data Engineer,"{'name': 'MIRAKL', 'sector': 'SaaS / Cloud Services, E-commerce', 'employees': '750 collaborateurs', 'creation_year': '2012', 'turnover': None, 'mean_age': '33 ans'}",CDI,Bordeaux,Non spécifié,Télétravail total,,> 4 ans,,"Descriptif du poste
Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerçants à travers le monde. Cette solution gère et produit de gros volumes de données qui présentent des challenges extrêmement intéressants pour les spécialistes de la donnée (produits, commandes, clients, niveaux de stock, prix, messages, appels API, données de navigation, séries temporelles, données géolocalisées etc.).
En tant que (Senior) Data Engineer au sein de l’équipe Data Mirakl, vos principales missions seront de :
contribuer à l'enrichissement de la Data Platform (ETL)
améliorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inférence real time etc.)
Intégré(e) dans une équipe de spécialistes de la donnée (data engineers, machine learning engineers, data scientists, data analysts), vous êtes un des acteurs clés pour garantir la place de Mirakl comme solution dominante sur son marché.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer à la définition et à l’implémentation d’une architecture performante, robuste, scalable et aux coûts maîtrisés pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (évaluation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et améliorer la CI/CD de l’équipe en collaboration avec l’équipe SRE
Assurer la montée en compétence des membres de l’équipe sur les sujets de MLOps et Data Engineering
Réfléchir à la meilleure façon d'intégrer les données Google Analytics dans la data platform
Partager ses connaissances et présenter les travaux devant toutes les équipes Labs
Ce qu’on peut vous apporter :
Des projets data driven, divers et variés (traitements massifs d’images, de textes, time series etc.) pour des produits différents de Mirakl
Une culture orientée sur la veille technologique
Des projets qui ont un vrai impact business devant être déployés sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des données produit à partir des images et des descriptions
Modération automatique des produits
Mapping automatique des données produit
Identification des produits à fort potentiels
Détection de comportements frauduleux
Sentiment analysis sur les messages échangés entre clients et vendeurs et dans les évaluations
Détermination de prix optimaux
Monitoring de la qualité de service des vendeurs
Des applications d’inférence en synchrone de nos modèles de ML
Vous aimerez ce job si :
Vous êtes passionné(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous intéressez à la data science et avez des connaissances générales sur les algorithmes de Machine Learning
Vous avez un background en développement et avez évolué dans un environnement Data
Vous avez a minima 4 ans d’expérience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succès des applications Big Data faisant appel à du Machine Learning, du NLP, du traitement d’images dans des projets d'envergure, à fort volume de données
Votre maîtrisez Python, êtes un pro des frameworks data de la fondation Apache et êtes à l'aise dans un environnement AWS
Vous maîtrisez au moins un outil d’orchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous présentez vos travaux de manière simple et accessible
Vous faîtes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et français
Les plus pour le poste :
Vous avez une expérience significative dans le domaine du e-commerce
Vous avez déjà mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez déployé des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de données avec une approche CDC à l'aide de Debezium ou autre
Vous maîtrisez Java/Scala
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Voir moins",,2024-02-05,https://www.welcometothejungle.com/fr/companies/mirakl/jobs/senior-data-engineer_bordeaux?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=d4e0b922-2d61-4846-bace-4678b8560113,wttj
(Senior) Data Engineer,"{'name': 'MIRAKL', 'sector': 'SaaS / Cloud Services, E-commerce', 'employees': '750 collaborateurs', 'creation_year': '2012', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 4 ans,,"Descriptif du poste
Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerçants à travers le monde. Cette solution gère et produit de gros volumes de données qui présentent des challenges extrêmement intéressants pour les spécialistes de la donnée (produits, commandes, clients, niveaux de stock, prix, messages, appels API, données de navigation, séries temporelles, données géolocalisées etc.).
En tant que (Senior) Data Engineer au sein de l’équipe Data Mirakl, vos principales missions seront de :
contribuer à l'enrichissement de la Data Platform (ETL)
améliorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inférence real time etc.)
Intégré(e) dans une équipe de spécialistes de la donnée (data engineers, machine learning engineers, data scientists, data analysts), vous êtes un des acteurs clés pour garantir la place de Mirakl comme solution dominante sur son marché.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer à la définition et à l’implémentation d’une architecture performante, robuste, scalable et aux coûts maîtrisés pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (évaluation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et améliorer la CI/CD de l’équipe en collaboration avec l’équipe SRE
Assurer la montée en compétence des membres de l’équipe sur les sujets de MLOps et Data Engineering
Réfléchir à la meilleure façon d'intégrer les données Google Analytics dans la data platform
Partager ses connaissances et présenter les travaux devant toutes les équipes Labs
Ce qu’on peut vous apporter :
Des projets data driven, divers et variés (traitements massifs d’images, de textes, time series etc.) pour des produits différents de Mirakl
Une culture orientée sur la veille technologique
Des projets qui ont un vrai impact business devant être déployés sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des données produit à partir des images et des descriptions
Modération automatique des produits
Mapping automatique des données produit
Identification des produits à fort potentiels
Détection de comportements frauduleux
Sentiment analysis sur les messages échangés entre clients et vendeurs et dans les évaluations
Détermination de prix optimaux
Monitoring de la qualité de service des vendeurs
Des applications d’inférence en synchrone de nos modèles de ML
Vous aimerez ce job si :
Vous êtes passionné(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous intéressez à la data science et avez des connaissances générales sur les algorithmes de Machine Learning
Vous avez un background en développement et avez évolué dans un environnement Data
Vous avez a minima 4 ans d’expérience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succès des applications Big Data faisant appel à du Machine Learning, du NLP, du traitement d’images dans des projets d'envergure, à fort volume de données
Votre maîtrisez Python, êtes un pro des frameworks data de la fondation Apache et êtes à l'aise dans un environnement AWS
Vous maîtrisez au moins un outil d’orchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous présentez vos travaux de manière simple et accessible
Vous faîtes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et français
Les plus pour le poste :
Vous avez une expérience significative dans le domaine du e-commerce
Vous avez déjà mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez déployé des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de données avec une approche CDC à l'aide de Debezium ou autre
Vous maîtrisez Java/Scala
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Voir moins",,2024-02-05,https://www.welcometothejungle.com/fr/companies/mirakl/jobs/senior-data-engineer_paris?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=07595e4c-0c62-47af-bedb-2877c0e00ca5,wttj
(Senior) Data Engineer,"{'name': 'MIRAKL', 'sector': 'SaaS / Cloud Services, E-commerce', 'employees': '750 collaborateurs', 'creation_year': '2012', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spécifié,Télétravail total,,> 4 ans,,"Descriptif du poste
Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.
A propos de Mirakl Labs
Nos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…
Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.
Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.
Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.
A propos du job
La solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerçants à travers le monde. Cette solution gère et produit de gros volumes de données qui présentent des challenges extrêmement intéressants pour les spécialistes de la donnée (produits, commandes, clients, niveaux de stock, prix, messages, appels API, données de navigation, séries temporelles, données géolocalisées etc.).
En tant que (Senior) Data Engineer au sein de l’équipe Data Mirakl, vos principales missions seront de :
contribuer à l'enrichissement de la Data Platform (ETL)
améliorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inférence real time etc.)
Intégré(e) dans une équipe de spécialistes de la donnée (data engineers, machine learning engineers, data scientists, data analysts), vous êtes un des acteurs clés pour garantir la place de Mirakl comme solution dominante sur son marché.
Notre stack et nos outils
Apache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, Ansible
Au quotidien, vous allez :
Participer à la définition et à l’implémentation d’une architecture performante, robuste, scalable et aux coûts maîtrisés pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (évaluation des feature stores, refactoring de DAG Airflow)
Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practices
Optimiser et améliorer la CI/CD de l’équipe en collaboration avec l’équipe SRE
Assurer la montée en compétence des membres de l’équipe sur les sujets de MLOps et Data Engineering
Réfléchir à la meilleure façon d'intégrer les données Google Analytics dans la data platform
Partager ses connaissances et présenter les travaux devant toutes les équipes Labs
Ce qu’on peut vous apporter :
Des projets data driven, divers et variés (traitements massifs d’images, de textes, time series etc.) pour des produits différents de Mirakl
Une culture orientée sur la veille technologique
Des projets qui ont un vrai impact business devant être déployés sur des centaines de clients dans un contexte multilingue
Quelques exemples de sujets en cours :
Enrichissement des données produit à partir des images et des descriptions
Modération automatique des produits
Mapping automatique des données produit
Identification des produits à fort potentiels
Détection de comportements frauduleux
Sentiment analysis sur les messages échangés entre clients et vendeurs et dans les évaluations
Détermination de prix optimaux
Monitoring de la qualité de service des vendeurs
Des applications d’inférence en synchrone de nos modèles de ML
Vous aimerez ce job si :
Vous êtes passionné(e) par la data et les technologies modernes permettant d'en tirer partie
Vous vous intéressez à la data science et avez des connaissances générales sur les algorithmes de Machine Learning
Vous avez un background en développement et avez évolué dans un environnement Data
Vous avez a minima 4 ans d’expérience en environnement Machine Learning et/ou Data
Vous avez mis en production avec succès des applications Big Data faisant appel à du Machine Learning, du NLP, du traitement d’images dans des projets d'envergure, à fort volume de données
Votre maîtrisez Python, êtes un pro des frameworks data de la fondation Apache et êtes à l'aise dans un environnement AWS
Vous maîtrisez au moins un outil d’orchestration (Airflow, Data Pipeline ou tout autre outil similaire)
Vous présentez vos travaux de manière simple et accessible
Vous faîtes preuve d'un bon relationnel et vous aimez mentorer des collaborateurs
Vous parlez couramment anglais et français
Les plus pour le poste :
Vous avez une expérience significative dans le domaine du e-commerce
Vous avez déjà mis en place un Data Lake, Data Warehouse ou une Data Platform
Vous avez déployé des applicatifs en environnement Kubernetes
Vous avez mis en place des pipelines d'ingestion de données avec une approche CDC à l'aide de Debezium ou autre
Vous maîtrisez Java/Scala
Mirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
Voir moins",,2024-02-05,https://www.welcometothejungle.com/fr/companies/mirakl/jobs/senior-data-engineer-paris-bordeaux_paris?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=111060af-0f36-4715-b7c7-7fd80cac2cb7,wttj
Data Engineer - Industrie (H/F),"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
Vous êtes motivé par les enjeux de la mobilité et de son évolution, MP DATA recrute un(e) Data Engineer - Industrie (H/F) mobile France afin de travailler sur des projets innovants et à impact auprès d’un acteur majeur du secteur des mobilités.
Votre mission principale consistera en la conception et le développement de solutions Data permettant la collecte, l’organisation, le stockage et la modélisation des données dans un environnement industriel. Les outils et données seront à destination des Data Analysts et Data Scientists en charge de valoriser les données dans un contexte de transformation Usine 4.0. Plus précisément, votre rôle sera clé afin de :
Permettre la collecte des données usine directement sur les machines et automates et mettre en place les flux de remontée de données
Assurer l’accès fiable, efficace et sécurisé aux différentes sources de données métier et processus
Mettre en place des outils et méthodes de contrôle et validation de la qualité des données
Optimiser les processus de collecte, transfert et stockage de la données (ETL) en assurant l’adéquation avec les contraintes techniques et opérationnelles
Maintenir les outils, technologies et processus à jour, en assurant une veille technique assidue et une supervision permanente de l’environnement
Accompagné par les équipes internes MP DATA, vous monterez en compétences sur la mise en place et le management des flux de données industriel. Vous veillerez à son traitement massif et qualitatif, ainsi qu’à son stockage et sa mise à disposition.
Voir moins","Profil recherché
Ingénieur d’une grande école (Centrale, Mines, Supaero, Supelec, …).Suite à votre cursus ingénieur ou vos expériences professionnelles, vous disposez de appétences métiers dans les domaines de l’industrie.
Vous êtes intéressés par l’industrie en :
Etant familier avec les protocoles de communication ou standards (OPC UA / OPC DA)
Ayant la fibre « Usine 4.0 »
Ayant des notions d’automatisme dans l’automobile
Connaissant les systèmes de contrôle type Scada
Connaissant des réseaux de télécommunication sur sites industriels
Vous êtes intéressés pour vous dépasser en data engineering et vous avez des premières expériences dans ce domaine, comme par exemple :
 C/C++ / Java / Rust
Spark / PySpark
Voir plus",2024-02-05,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-industrie-grand-est-h-f_boulogne-billancourt?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=2fbc0eae-fa2d-4eda-a3e6-692418084b80,wttj
Data Engineer F/H - CDI,"{'name': 'GROUPE ODALYS', 'sector': 'Hôtellerie, Tourisme', 'employees': '1300 collaborateurs', 'creation_year': '1998', 'turnover': '300M€', 'mean_age': None}",CDI,Aix-en-Provence,Non spécifié,Télétravail fréquent,,< 6 mois,,"Descriptif du poste
Vous êtes passionné(e) par la data et vous souhaitez participer à la transformation digitale d’une entreprise en pleine croissance ? Rejoignez-nous !
Nous recherchons un(e) data engineer pour intégrer notre DSI composée d’une quinzaine de personnes. Vous ferez partie de l’équipe Data et Statistiques, en charge de la collecte, du traitement et de la mise à disposition des données de l’entreprise.
Vous participerez au projet de mise en place d’une nouvelle data stack basée sur du cloud public, qui vise à moderniser notre infrastructure, nos outils et nos processus data. Vous travaillerez en collaboration avec les chefs de projets et les autres membres de l’équipe.
Vos missions principales seront :
Développer et maintenir les pipelines de données en utilisant SAS, Airflow et Python
Participer à la construction du datalake, en créant de nouveaux pipelines de données, en choisissant les outils adaptés et en optimisant les performances et les coûts
Assurer la qualité, la fiabilité et la sécurité des données
Tester et implémenter de nouveaux outils de reporting et d’analyse (Power BI, Tableau, etc.)
Accompagner la montée en compétences data de l’entreprise en animant et formant les équipes
Veiller aux innovations technologiques dans le domaine de la data et proposer, tester et valider des solutions adaptées
Voir moins","Profil recherché
Vous êtes titulaire d’un diplôme en informatique, mathématiques, statistiques ou équivalent
Vous avez une première expérience réussie dans le domaine de la data
Vous maîtrisez SQL et Python, et vous avez idéalement des connaissances en SAS
Une expérience avec Docker, GIT et d’autres outils de développement serait également appréciée
Vous avez une appétence pour les technologies cloud, notamment AWS
Vous êtes rigoureux(se), autonome et capable de vous adapter à un environnement dynamique et évolutif.
Vous avez un bon esprit d’équipe et un bon sens relationnel

Informations complémentaires : 
Type de contrat de travail : CDI
Date démarrage souhaité : Dès que possible
Temps de travail : Cadre forfait jours
Voir plus",2024-02-04,https://www.welcometothejungle.com/fr/companies/groupe-odalys/jobs/data-engineer-f-h-cdi_aix-en-provence_GO_6xGap3?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=7221243d-9366-4e35-9231-009048dedee3,wttj
,,,,,,,,,,,,https://www.welcometothejungle.com/fr/companies/orange-1/jobs/data-engineer-data-scientist-flux-vision-f-h_cesson-sevigne_ORANG_qQG8VYr?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=8560dd7c-4146-4b41-8ded-1a357b994f2b,wttj
DATA ENGINEER H/F,"{'name': 'HEROIKS', 'sector': 'Publicité', 'employees': '400 collaborateurs', 'creation_year': '2005', 'turnover': None, 'mean_age': '35 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail fréquent,,> 2 ans,,"Descriptif du poste
Vous souhaitez industrialiser des cas d’usage métier en étroite collaboration avec les Data Analysts, les Data Scientists et les équipes de l’IT?
Un Data Engineer chez Peak ace c’est qui ?
“ Elle/Il travaille avec des données riches et bénéficie d’une infrastructure de pointe en matière d’apprentissage automatique. Il collabore avec une équipe solide d’ingénieurs et de data scientists pour évaluer de nouvelles approches, développer des fonctionnalités et créer des algorithmes. Il a également la responsabilité d’expliquer des concepts sophistiqués de la science des données de manière claire et précise aux décideurs de l’entreprise. Il travaille principalement sur GCP et le stack technique repose sur les éléments suivants :
• Orchestrateur : Kubernetes
• Data processing: Google workflow, Airflow, Airbyte
• Stockage des données : Cloud Storage, Bigquery et MongoDB
• Processing: docker, cloud functions + code Python
• Dataviz : Datastudio principalement pour les dashboards + notre saasSAAS interne”
Afin de renforcer les équipes en place nous souhaitons intégrer un Data Engineer, qui aura pour responsabilités :
Le maintien, l’évolution et la création d’outils liés à la gestion des données. Elle/Il sera chargé(e) de répondre aux besoins des clients internes et de proposer des solutions optimales pour optimiser les opérations de l’entreprise :
Votre passion pour les données sera votre meilleur atout afin de développer des solutions pour traiter d’importants volumes de données et concevoir, collecter et transformer des données brutes en informations exploitables. Mais également créer des outils et des algorithmes.
Vous avez Habitude de travailler avec des Data Scientists et de gérer l’industrialisation de projets de Data Science, alors tout naturellement vous préparez les données pour les Data Analysts et sécuriser les pipelines de données.
Votre formation ingénieur sera le garant de votre capacité à organiser l’architecture du cloud, à transformer des ensembles de données volumineux et complexes en informations pragmatiques.
Votre curiosité et dynamisme assureront votre contribution à l’effort d’animation technique, de veille technologique et d’innovation.
Enfin vous serez un bon Team Player comme chacun des membres de nos équipes !
Pour vous convaincre?
Une agence au sein d’un groupe international
Des projets au cœur de l’innovation
Alors prêt(e) à nous rejoindre ?
Voir moins","Profil recherché
Orchestrateur : Kubernetes
• Data processing: Google workflow, Airflow, Airbyte
• Stockage des données : Cloud Storage, Bigquery et MongoDB
• Processing: docker, cloud functions + code Python
• Dataviz : Datastudio principalement pour les dashboards",2024-02-02,https://www.welcometothejungle.com/fr/companies/heroiks/jobs/data-engineer-h-f_levallois-perret?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=f757180b-e259-4833-ad92-1f70054c8158,wttj
Data Engineer,"{'name': 'WIREMIND', 'sector': 'Logiciels, Mobilité, SaaS / Cloud Services', 'employees': '91 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '29 ans'}","Stage
(6 mois)",Paris,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
At Wiremind, the Data Science team is responsible for the development, monitoring and evolution of all ML-powered forecasting and optimization algorithms in use in our Revenue Management systems. Our algorithms are divided in 2 parts:
A modelling of the unconstrained demand using ML models (e.g. deep learning, boosted trees) trained on historical data in the form of time-series
Constrained optimizations problems solved using linear programming techniques
The team is now entering a scaling phase where we will face the challenge to stay agile in terms of innovation while supporting and closely monitoring deployed algorithms.
This rapid growth comes with a multiplication of data sources and deployed predictive models. In order to maintain high prediction accuracies and ascertain data quality, we are looking for a Data Engineer Intern with a passion for software engineering and rigorous mind.
You will be joining a team shaped to have all profiles necessary to constitute an autonomous departement (devops, software and data engineering, data science, AIML, operational research).
There, you will support the ML engineers by improving our MLOps platform, work closely with software engineers to implement the data science algorithms in the client applications and exchange with the platform team to keep the infrastructure debt at a minimum.
As a Data Engineer Intern, you will be responsible for :
Help the team deploy our algorithms in production in a safe, scalable and maintainable way
Support the ML team in their use of the MLOPs framework
Technical stack:
Backend: Python 3.7+ with SQLAlchemy, Remoulade, Flask/FastAPI
Argo over an auto-scaled Kubernetes cluster for orchestration
Data-store: Postgresql, Elasticsearch, Redis
Gitlab for continuous delivery
Common ML libraries: TensorFlow, LightGBM, XGBooost, Pandas, Dask, Dash
THE BENEFITS OF THE JOB 🚀
International environment 🌍
Hyper-growth start-up: strong growth in our turnover and workforce 📈
Joining a committed team that offers you opportunities for development 🧑‍💻
Variety of tasks and a high degree of autonomy
Position based in the heart of Paris (Bd Poissonnière) ✨
Attractive remuneration indexed to performance 💪
Luncheon vouchers 🌮
A hybrid policy: 2 days’ remote a week and the possibility of occasionally working from abroad 💻
Start date: as soon as possible
Type of contract: internship
Voir moins","Profil recherché
Above average in terms of rigor and autonomy, you are proactive and curious.
Good general culture in computer science and you are looking for a quick progression perspective in an environment with best development practices.
Interested in solving business problems through technological solutions.",2024-02-02,https://www.welcometothejungle.com/fr/companies/wiremind/jobs/data-engineer_paris_WIREM_xmwzP3m?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=f494e4da-7bd1-464e-9cad-4bc27710d4bd,wttj
Stage Climate & Nature Data Engineer H/F,"{'name': 'ECOACT', 'sector': 'Environnement / Développement durable, Stratégie, Transformation', 'employees': '350 collaborateurs', 'creation_year': '2006', 'turnover': None, 'mean_age': '30 ans'}","Stage
(6 mois)",Paris,Non spécifié,Télétravail occasionnel,02 janvier 2024,,Bac +4,"Descriptif du poste
Rejoignez notre équipe d’analyse des données climatiques Climate Data Analytics (CDA) d’EcoAct et aidez-nous à accroître notre impact sur le changement climatique en développant des produits numériques qui aident nos clients à définir des stratégies à faible émission de carbone.
La vision d’EcoAct : un monde net zéro et durable 🌍
Notre mission : contribuer à l’échelle mondiale à la transformation net zero en proposant des solutions percutantes et innovantes.
Notre périmètre d’activité : tous les services liés au climat dont les entreprises et les territoires ont besoin pour réussir leur transformation (évaluation des risques climatiques, empreinte carbone & biodiversité, stratégie de réduction carbone, etc.).
Rôle de CDA : concevoir des méthodes et des outils innovants pour répondre aux besoins des clients liés au changement climatique.
MISSIONS
Capacités techniques et d’ingénierie des données pour prendre en charge l’analyse des données climatiques, y compris le développement de l’entrepôt de données EcoAct avec une couche d’IA.
Aider les équipes internes (NTBS, Advisory) à centraliser leurs données de projets et à exploiter les données existantes.
En collaboration avec les propriétaires de données et les contributeurs des lignes de services, identifier les opportunités dans l’écosystème de données climatiques et naturelles existant, identifier les lacunes et recommander des améliorations.
Garantir la qualité et la fiabilité des données.
Mettre en œuvre des solutions de données et d’analyse grâce à des systèmes de gestion, des techniques de science des données et des techniques de visualisation de données appropriées.
Établir des normes et des meilleures pratiques pour la gestion des données et transférer les connaissances aux collègues concernés.
Développer et maintenir une documentation complète sur les données qui fournit aux producteurs et aux consommateurs de données les outils nécessaires pour comprendre, découvrir et collaborer sur les données.
Centraliser la gestion des contrats de données et coordonner les échanges internes sur les usages de ces données.
Monitoring de l’usage des données.
Participer aux activités de veille technologique (nouvelles solutions apportant de la valeur) et des pratiques de marché autour de la donnée (data scraping, data crunching, data mining, feature engineering, etc.).
Voir moins","Profil recherché
Académique :
• Diplôme universitaire de niveau supérieur (bac+5) en informatique, ingénierie, statistiques, mathématiques ou domaines quantitatifs connexes.
• Diplôme d’ingénieur en ingénierie des données ou en science des données.
Professionnel :
• Expérience dans le domaine de l’informatique et des bases de données, dans la mise en œuvre de solutions techniques et de systèmes destinés à l’analyse de données, idéalement des données climatiques.
• Expérience de travail avec de grands ensembles de données structurées et non structurées.
• Expérience en extraction/structuration de données et en nettoyage de données.
• Capacité à écouter et à communiquer efficacement avec des publics techniques et non techniques.
• Anglais courant.
Outils :
Voir plus",2024-02-02,https://www.welcometothejungle.com/fr/companies/eco-act/jobs/climate-nature-data-engineer-internship_paris?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=afc15779-5f1a-4df5-9878-a90db9e07f7f,wttj
Data Engineer - Intern,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",Stage,Neuilly-sur-Seine,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
AXA IM est un gestionnaire d'actifs international faisant partie du groupe AXA, leader mondial de l’assurance. Notre équipe comprend de nombreuses compétences et expériences pour mieux répondre aux besoins de nos clients
Votre rôle de stagiaire Data Engineer sera rattaché au  et vous ferez partie du département AXAIM TECHNOLOGY - Data, Digital & Finance
DECOUVREZ votre opportunité 
Vos rôles et responsabilités : 
• Concevoir, construire et optimiser des pipelines de données évolutifs pour collecter, intégrer et transformer des données provenant de diverses sources dans un format unifié adapté à l'analyse et au reporting.• Travailler avec des données financières pour créer des rapports et des informations qui aident à soutenir les décisions commerciales clés• Créer et maintenir des tableaux de bord financiers, des métriques et des KPI pour les équipes Finance d'AXA IM• Effectuer une analyse de données ad hoc pour soutenir les décisions commerciales• Maintenir la documentation des sources de données, des méthodologies et des spécifications des rapports• Aider à identifier les opportunités d'amélioration des outils et des méthodologies de reporting financier.
Nous nous engageons à vous offrir un environnement où vous pourrez :
Développez votre potentiel : Intégrer une entreprise engagée sur le développement de ses collaborateurs via une mobilité interne dynamique et une large offre de parcours de formation personnalisés.
Personnalisez votre manière de travailler : Travailler pour une entreprise qui s'engage à garantir flexibilité et équilibre à ses employés, en vous offrant une large gamme d'avantages (intéressement, télétravail, avantages sociaux compétitifs, etc.).
Epanouissez-vous par la diversité de notre communauté : Jouer un rôle au sein d'une entreprise inclusive qui reconnaît et valorise activement les différences individuelles dans un environnement de travail diversifié et inclusif.
Faites avancer le monde : Rejoindre un employeur responsable qui agit en faveur des causes sociétales et environnementales en tant qu'investisseur, assureur et entreprise, notamment au travers de l'association AXA Atout Cœur. Dans le cadre de notre engagement en faveur de la durabilité et de la responsabilité environnemental, nous célèbrerons votre arrivée en plantant un arbre.
Voir moins","Profil recherché
PARTAGEZ votre expertise unique  Nous accueillons différentes combinaisons de compétences et d'expériences.  Vos diplômes et expériences 
Master 1 ou 2 en école d'ingénieur
Une première expérience sur un poste similaire est un plus 
Stage à pourvoir en Janvier/Février 2024
Compétences relationnelles et comportementales :
Rigueur
Esprit curieux et forte capacité d’analyse / goût pour le détail
Aptitude à travailler en équipe
Autonomie et initiative
Ouverture d’esprit et dynamisme
Flexibilité et capacité à travailler en parallèle sur différentes tâches selon les priorités
Anglais indispensable (contexte international)",2024-02-02,https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-intern_puteaux?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=51afdd35-0689-4708-9109-966bf1167a85,wttj
Data Engineer - Industries et Services - Metz,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Metz,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail :
Vous intervenez en régie directement chez notre client sur ses problématiques en lien avec la data.
Vos missions :
Vous participez aux sujets techniques data (engineering, Big Data) en lien avec la collecte et la mise à disposition des données.
Vous participez à l'industrialisation et à la mise en production des traitements sur les données
Vous effectuez la rédaction de spécification techniques et fonctionnelles, cette action nécessitant de travailler en anglais
Vous participez aux réunions projet
Environnement technologique/fonctionnel : Big Data : Cloudera, Hive, Spark,…, ETL : Talend, Bases données : SQL Server, Reporting : Power BI
Ce que nous vous proposons :
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.
Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor. Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ». - L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore).
Informations supplémentaires
Ce que nous vous proposons :
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.
Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor. Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ». - L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherché
Votre profil :
Vous avez développé de solides compétences en matière d'autonomie, d'adaptabilité et de communication.
Des compétences et/ou de solides connaissances en Talend sont fortement souhaitées.
Des compétences en Data Visualisation / data Viz peuvent être un plus sans être obligatoires
Vous avez un bon niveau d'anglais
Diplômé(e) d'une formation supérieur en informatique type Bac + 5 (école ingénieur, université ou équivalent), vous avez déjà acquis une expérience significative en data, de minimum 3 ans, principalement sur des sujets traitant de la data engineer et du big data.",2024-02-01,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-industries-et-services-metz_metz?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=24e9eaf0-2184-438d-bded-70f3767da616,wttj
Data Engineer – CDI,"{'name': 'WEBYN', 'sector': 'Intelligence artificielle / Machine Learning, SaaS / Cloud Services, AdTech / MarTech', 'employees': '7 collaborateurs', 'creation_year': '2023', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail total,01 mars 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
On est à la recherche d’un(e) Data Engineer motivé(e) qui adore utiliser les données pour guider les choix business et résoudre des problèmes complexes. Si tu as de l’expérience dans le traitement de gros jeux de données, et une bonne compréhension des pipelines complexes, synchrones et asynchrones, c’est toi qu’on veut ! Tu participeras à la conception et au développement de nos pipelines de données, qui transforment les actions des utilisateurs en expériences d’achat personnalisées. Ton objectif ultime ? Construire une machine pour ingérer et enrichir des Teraoctets de données quotidiennement.
Au sein de Webyn, tes missions seront de :
La conception, le développement et la maintenance de nos pipelines de données
La mise à disposition des données pour l’ensemble des parties prenantes (développeurs, data scientists, CSM, …)
Collaborer avec les équipes produits et plateforme pour développer de nouvelles fonctionnalités
Présenter les résultats et faire des recommandations aux équipes et aux clients
👫 Ta future équipe :
Tu seras rattaché(e) à Marie, Head of Data, ta future N+1
2 Developers / 2 Data (Recrutements en cours) + Vincent (CEO, CPO & CTO)
Voir moins","Profil recherché
Ce sera un match parfait si :
Tu as une formation supérieure de niveau Bac+5 dans un cursus de type Ingénieur ou Master Statistiques ou Informatiques, avec une spécialisation en Data
Tu as une expérience significative (> 2 ans) en Data Engineering
Tu as des capacités de développement en Python avec une maîtrise de principales librairies (pandas, numpy, sklearn, etc.), et en SQL.
Tu es autonome, organisé(e) et résilient(e)
Tu as envie d’apprendre vite
Fluent in English & in French
Nous serions encore plus impressionnés si :
Tu as déjà mis en place un pipeline data à fort trafic
Une bonne connaissance des solutions cloud Big Data
Tu as un intérêt pour l’e-commerce de manière générale",2024-02-01,https://www.welcometothejungle.com/fr/companies/webyn/jobs/data-engineer-cdi_paris?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=0bb75108-eefc-4601-92e0-c8114c38b2bd,wttj
Data Engineer F/H,"{'name': 'CENISIS - DATA AGENCY', 'sector': 'IT / Digital, Stratégie, Transformation, Collectivités publiques et territoriales', 'employees': '38 collaborateurs', 'creation_year': '1995', 'turnover': None, 'mean_age': '35 ans'}",CDI,Lille,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Tu souhaites rejoindre une communauté Data Addict à taille humaine ?
Nous recherchons un Data Engineer F/H qui aura un rôle à part entière dans la communauté CENISIS.
Nous t’apportons l’opportunité d’intervenir sur un large choix de projets mais également de faire partie de la CENISIS Academy.
Tes missions ?
Gérer et mettre en place les structures nécessaires ainsi que les données de type big data pour permettre l’exploitabilité par les data scientists
Permettre la collecte, le stockage et l’exploitabilité fluide des données
Constuire les outils de collecte et d’analyse de données (structurées et non structurées)
Choisir la ou les méthode(s)/technologie(s) les plus adaptée
Rejoindre CENISIS, c’est rejoindre une entreprise qui :
♟Positionne ses consultants au cœur de la stratégie de transformation digitale 🚀
⚡️Permet à ses collaborateurs d’avoir un réel impact, d’innover, tester et construire notre avenir 💥
🌏Choisit de porter des valeurs fortes et d’être avancé au niveau social et environnemental avec une forte politique de diversité et d’inclusion #TeamRSE 🍃
🏟 Anime des formations en interne et en externe #CENISISAcademy 📚
Ce qui nous anime ?
Nos valeurs basées sur l’audace, la cohésion, l’authenticité et la responsabilité nous poussent à l’innovation et à la croissance. Pour cela, en 2020, CENISIS a intégré l’accélérateur BPI dédié aux entreprises ambitieuses pour ainsi, devenir une Data Agency.
En tant qu’entreprise engagée dans une démarche responsable, nous accordons une grande importance à l’impact du bien-être personnel et collectif et à l’engagement envers la diversité, l’équité et l’inclusion.
Voir moins","Profil recherché
Ton profil ?
Tu es issu(e) d’une formation supérieure Bac+3/5 de type licence ou master dans le domaine de l’ingénierie avec une orientation Data. Idéalement tu possèdes une expérience significative de 3 ans dans la Data.
Ton savoir-être :
Ta capacité à fédérer une équipe et à contribuer à la réussite de celle-ci dans ses différents projets
Ta curiosité, ton envie de toujours innover, et ton autonomie
Tu es force de proposition et tu aimes le challenge et challenger les autres
Ta différence, ce qui fait ta force et ta richesse pour l’entreprise
Ton savoir-faire :
Ton expertise élevée dans les technologies de manipulation des données
Ta maîtrise des technologies de base de données (NoSql, SQL, …),
Ta maîtrise des technologies type Cassandra, Python, R, …
Ta compréhension des problématiques des datascientists
Voir plus",2024-02-01,https://www.welcometothejungle.com/fr/companies/cenisis/jobs/data-engineer_lille?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=bdb460ed-d7b2-4dd7-9889-4283726a46c4,wttj
Big Data Engineer,"{'name': 'TATA CONSULTANCY SERVICES', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '615000 collaborateurs', 'creation_year': '1968', 'turnover': '$ 28 milliards', 'mean_age': None}",CDI,Neuilly-sur-Seine,Non spécifié,Télétravail occasionnel,,> 4 ans,,"Descriptif du poste
Develop Big Data capabilities for bank, for the data lake on the public cloud.
Implement the fundamentals of software engineering.
Analyze, propose, and develop the necessary evolutions (study, monitoring / planning, reporting, alerts, risk management).
Contribute to the prototyping, validation, design and development of the solution in Java and/or Python and/or Scala.
Contribute to the optimization of the Run activity and the improvement of the quality of service.","Profil recherché
Environnement : Hive, Microstrategy, PL SQL, Python, SAS, SQL Server Database, Teradata, Vue.js Flask Spark, Elasticsearch, Linux/Unix",2024-02-01,https://www.welcometothejungle.com/fr/companies/tata-consultancy-services/jobs/big-data-engineer_puteaux?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=daf49ef9-ce96-4d72-9dd1-abc770956263,wttj
(PARIS) Data Engineer (H/F),"{'name': 'MERITIS', 'sector': 'IT / Digital, Finance', 'employees': '900 collaborateurs', 'creation_year': '2007', 'turnover': '87M€', 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,,,Bac +5 / Master,"Descriptif du poste
Dans le cadre de la modernisation du backend, le socle du processing de données est ré-écrit sur une technologie BigData, ce qui permet d'élargir l'offre de services proposée aux utilisateurs. 
Dans ce cadre, la mission consiste à : 
Contribuer à l'analyse des besoins des différents métiers : analyse de données, BI, Big Data.
Contribuer à la définition des solutions dans l'environnement applicatif (Cloud Platform / Spark Data processing). 
Récupérer les données sur les assets à partir d'une base de données RedShift.
Traiter les données afin de garantir une qualité de données optimale.
Exploiter les données et faire des restitutions dans les datasets / datamarts.
Appliquer les mises en forme et agrégations sur les données.
Etablir des comparaisons entre les données et des restitutions pertinentes selon les besoins métiers.","Profil recherché
Vous êtes titulaire d’un diplôme d’ingénieur ou universitaire Bac+5,
Vous avez à partir de 3 ans d’expérience,
Vous aimez travailler dans un environnement agile et novateur et êtes passionné.e de Big Data,
Avoir travaillé au moins sur Azure, AWS ou GCP
Vous maîtrisez un langage de programmation : Python ou Java
Vous maîtrisez les outils Big Data suivants : Spark, Scala, Hadoop 
Do you speak english ?",2024-02-01,https://www.welcometothejungle.com/fr/companies/meritis/jobs/paris-data-engineer-h-f_paris_MERIT_w7AOOLD?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=b13d99fb-8fed-4a2c-ab7b-9a56d8146e4e,wttj
Stagiaire de Fin d’Etudes Consultant Data Engineer - Paris - 2024 H/F,"{'name': 'MAZARS ET LA TECH', 'sector': 'IT / Digital', 'employees': '28000 collaborateurs', 'creation_year': '1945', 'turnover': '2,1 milliards', 'mean_age': '30 ans'}",CDI,Courbevoie,Non spécifié,Télétravail non autorisé,,> 6 mois,Bac +5 / Master,"Descriptif du poste
L’équipe Data Services de Mazars, c’est plus de 60 consultants spécialistes de la data, répartis sur 2 hubs (Paris La Défense, New-York).  Ils couvrent l’ensemble de la chaîne de valeur de la donnée : Data Strategy et qualification de cas d’usage, Gouvernance et qualité des données, Data Visualisation, Data Science, Data Engineering et Data Architecture.
Nous sommes convaincus que le Data Engineering est la pierre angulaire de cette industrie. Nous mobilisons, pour servir nos clients, une stack technologique riche et variée, tant sur les outils open-sources (Python, Pandas, PySpark, FastAPI, Vim, SQL/NoSQL, ...) que sur les solutions du marché (Snowflake, AWS, Azure, ...).
Notre équipe de Data Engineers travaille au quotidien avec les membres de Mazars R&D et nos Data Analysts. Pour nos clients, nous produisons des solutions qui intégrent le DevOps (GitLab, Ansible, Docker, Terraform, ...) dès la phase de conception.
Vous serez formé(e) à nos méthodologies et aurez l’opportunité de travailler au sein d’équipes pluridisciplinaires, y compris les équipes de R&D qui développent et maintiennent nos outils d’Analytics ainsi que notre infrastructure interne (GitLab-CI, VMs OpenNebula, CephFS, etc...).
Vous interviendrez de façon opérationnelle sur des missions de conseil data ambitieuses et innovantes pour nos clients du CAC40 et SBF120, en France et à l’international.
Vous participerez notamment à :
· L’amélioration de la performance opérationnelle de nos clients au travers de l’exploitation et la valorisation de données sur des cas d’usage métier concrets (stratégie, marketing et vente, R&D, finance, RSE, etc..).
· Le développement de bout en bout de flux de données, de l’extraction / transformation jusqu’à leur consommation (API, BI / Visualisation, ...)
· Le déploiement et l’intégration continus de pipelines sur plusieurs paradigmes : serverless cloud (AWS Lambdas, Azure Functions, GC Functions, Kubernetes) ou cloud privé (OpenNebula, CloudStack, CephFS)
Pourquoi nous rejoindre ?
· ACCOMPAGNEMENT PAR DES EXPERTS : Les Associés en charge de l’équipe Data Services cumulent une expertise rare dans leurs domaines respectifs, e.g. équipe pionnière du MLOps (CI/CD opérationnelle depuis 2013). Ils participent activement à la mise en place des activités les plus pointues du cabinet et de la création de start-up technologiques acquises par Mazars. Cet environnement à la fois exigeant et formateur vous propulsera au top des bonnes pratiques coding et opérationnelles pour assurer un delivery projet de qualité !
· AUTONOMIE ET AMBITION : Écosystème jeune, dynamique et très responsabilisant, aux fortes ambitions de croissance. Venez vous impliquer dans le développement du Lab Mazars et construire l’offre de service en conseil data du cabinet !
· HACKING SPIRIT : Veille technologique omniprésente, à la pointe des technologies open-source les plus performantes du moment. Nos consultant(e)s se forment en permanence pour élargir leur socle de compétences.
· CABINET INTERNATIONAL : Rejoindre Mazars c’est intégrer un cabinet aux dimensions internationales et bénéficier d’opportunités d’évolution de carrière : bootcamp data, learning center de pointe (Mazars Academy, LinkedIn learning, etc.) et mobilités internationales.
Venez partager avec nous cette fierté que nous avons d’apporter des réponses pertinentes à nos clients. Vous vous dépassez sur des sujets techniques variés et ambitieux, au sein d’une équipe humaine et bienveillante !
Voir moins","Profil recherché
De formation Bac+5 type école d’ingénieur généraliste ou spécialisée, ou d’un 3ème cycle dans un domaine connexe à la data (systèmes d’informations, traitements de données, big data, statistiques, génie logiciel, etc.) :
Vous avez déjà montré un intérêt pour le domaine du développement applicatif intégrant une composante Data, à travers des stages, cours ou projets personnels impliquant le développement back-end et/ou front-end d’une application.
Vous avez une expérience pratique et une bonne connaissance de :
- Un ou plusieurs langages de programmation analytique (Python, R, Haskell, Rust, etc.)
- Une ou plusieurs couches de persistance (MySQL, MongoDB, ElasticSearch, S3, Node4j)
Vous n’envisagez pas de travaux sérieux en dehors d’un système Linux (Ubuntu, Debian, CentOS), ou sans système de contrôle de version (Git), et l’utilisation d’une chaîne d’intégration vous parait naturelle
Vous pensez que l’écosystème tech open-source est un puissant terrain de jeu à la pointe de la technologie, qui met à disposition l’ensemble des outils nécessaires à la réalisation des projets les plus ambitieux.

Voir plus",2024-02-01,https://www.welcometothejungle.com/fr/companies/mazars-tech/jobs/stagiaire-de-fin-d-etudes-consultant-data-engineer-paris-2024-h-f_courbevoie_MELT_l08gGx?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=e3ba22cb-449f-42b1-814f-f071cbe02b8c,wttj
Stage – Data Engineer - F/H,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",Stage,Suresnes,Non spécifié,Télétravail fréquent,,,Bac +5 / Master,"Descriptif du poste
L’équipe « Big Data » de Direct Assurance a pour mission principale de contribuer à la dynamique continue d’innovation et de perfectionnement de l’entreprise en résolvant des problématiques business concrètes par la mise en place d’une plateforme Data dans le Cloud, ainsi que la conception et la réalisation de solutions techniques de data science en s’appuyant sur des sources de données variées tant en interne qu’en externe.
 Vos missions seront les suivantes :
·       Concevoir des tableaux de bord de suivi des dépenses (FinOps) pour aider les équipes Data à mieux comprendre la consommation Cloud associée à leurs traitements et garder le contrôle sur les coûts
·       Concevoir et mettre en œuvre les traitements d’alimentation du DataLake et de transformation des données
·       Garantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats
·       Identifier, collecter, explorer, comprendre et intégrer les données nécessaires à la résolution de problématiques métier et opérationnelles
·       Assurer le suivi de la production
·       Participer, avec l’équipe, au développement de la plateforme sur Azure et à la définition des bonnes pratiques de développement
·       Accompagner les équipes métier dans la prise en main de la plateforme Azure et les aider à monter en compétences en programmation en s’assurant du respect des standards internes
 Environnement technique : Spark, Scala, Python, SQL, Cloud Azure, PowerBI
L’Expérience Collaborateur est pour nous essentielle pour la réussite de notre entreprise.
Nous proposons des parcours de développement professionnel en adéquation avec la transformation digitale du secteur de l’assurance pour enrichir leur panel de compétences.
Nous avons à cœur de célébrer nos réussites. La convivialité qui nous anime est le fruit de la diversité des profils que nous recrutons.
Nos locaux proposent un cadre de travail moderne avec une mise à disposition d’espaces de détente (baby-foot, cafétéria) et de services (espace forme, places en crèche…) pour une Expérience Collaborateur réussie !
Nous nous engageons en faveur de la lutte contre les discriminations et soutenons la diversité et l'égalité des chances. Tous nos emplois sont ouverts aux personnes en situation de handicap.
Si ce poste vous intéresse et si la perspective de contribuer fortement au développement de l’entreprise dans un environnement innovant et dynamique vous motive, rejoignez-nous !
Voir moins","Profil recherché
De formation Bac+5 (ou plus) en développement informatique / data engineering, vous avez pu développer les compétences techniques suivantes :
·       Cloud Azure (DataFactory, ADLS, Databricks)
·       Spark
·       Scala + Python
·       Bonnes connaissances sur les architectures de données et le cloud
·       Connaissances des processus collaboratifs et outils de développement (DevOps, Git, CI/CD…)
·       SQL
·       Data visualisation
 Les qualités suivantes sont nécessaires :
·       Bonne faculté pour appréhender les couches technologiques et les outils
·       Capacité à travailler de manière collaborative au sein d’équipes pluridisciplinaires
·       Autonomie, grande rigueur, pragmatisme et réelle capacité à délivrer
Voir plus",2024-02-01,https://www.welcometothejungle.com/fr/companies/axa/jobs/stage-data-engineer-f-h_suresnes_AXA_OpM97gM?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=1c0dff9f-7b30-46fa-a275-e50708ed9f8d,wttj
Lead Data Engineer,"{'name': 'AXA', 'sector': 'Banque, Assurance, FinTech / InsurTech', 'employees': '34244 collaborateurs', 'creation_year': '1985', 'turnover': None, 'mean_age': '41 ans'}",CDI,Suresnes,Non spécifié,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
L’équipe « Big Data » a pour mission principale de contribuer à la dynamique continue d’innovation et de perfectionnement de l’entreprise en résolvant des problématiques business concrètes par la mise en place d’une plateforme Data dans le Cloud, ainsi que la conception et la réalisation de solutions techniques de data science en s’appuyant sur des sources de données variées tant en interne qu’en externe.
Vos missions seront les suivantes :
·       Prendre en charge la supervision, l'organisation et l'animation d'une équipe de data engineers
·       Participer au recrutement, à la formation et au coaching des data engineers
·       Proposer des architectures et orienter le choix des technologies adaptées aux besoins de différents projets Data
·       Concevoir et mettre en œuvre les traitements d’alimentation du DataLake et de transformation des données
·       Garantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats
·       Identifier, collecter, explorer, comprendre et intégrer les données nécessaires à la résolution de problématiques métier et opérationnelles
·       Participer, avec l’équipe, au développement de la plateforme sur Azure et à la définition des bonnes pratiques de développement
·       Accompagner les équipes métier dans la prise en main de la plateforme Azure et les aider à monter en compétences en programmation en s’assurant du respect des standards internes
Environnement technique : Spark, Scala, Python, Cloud Azure, OpenShift, SQL
L’Expérience Collaborateur est pour nous essentielle pour la réussite de notre entreprise.
Nous proposons des parcours de développement professionnel en adéquation avec la transformation digitale du secteur de l’assurance pour enrichir leur panel de compétences.
Nous avons à cœur de célébrer nos réussites. La convivialité qui nous anime est le fruit de la diversité des profils que nous recrutons.
Nos locaux proposent un cadre de travail moderne avec une mise à disposition d’espaces de détente (baby-foot, cafétéria) et de services (espace forme, places en crèche…) pour une Expérience Collaborateur réussie !
Nous nous engageons en faveur de la lutte contre les discriminations et soutenons la diversité et l'égalité des chances. Tous nos emplois sont ouverts aux personnes en situation de handicap.
Si ce poste vous intéresse et si la perspective de contribuer fortement au développement de l’entreprise dans un environnement innovant et dynamique vous motive, rejoignez-nous !
Voir moins","Profil recherché
Nous recherchons un profil…
 De formation Bac+5 (ou plus) en développement informatique / data engineering, vous justifiez a minima 2 ans sur un poste de Lead, au cours desquels vous avez pu développer les compétences techniques suivantes :
·       Cloud Azure (DataFactory, ADLS, Databricks)
·       Spark
·       Scala (obligatoire) + Python
·       Bonnes connaissances sur les architectures de données et le cloud
·       Solides connaissances des processus collaboratifs et outils de développement (DevOps, Git, CI/CD…)
·       SQL
Les qualités suivantes sont nécessaires :
·       Bonne faculté pour appréhender les couches technologiques et les outils
·       Capacité à travailler de manière collaborative au sein d’équipes pluridisciplinaires
·       Capacité à motiver et encadrer une équipe pour aider chacun à se développer
Voir plus",2024-02-01,https://www.welcometothejungle.com/fr/companies/axa/jobs/lead-data-engineer_suresnes?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=9485e935-18cb-4bf0-8b56-2e71b3e35ca5,wttj
Data engineer - Control Software,"{'name': 'PASQAL', 'sector': 'Ingénieries Spécialisées', 'employees': '210 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '34 ans'}",CDI,Massy,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
About Pasqal
PASQAL designs and develops Quantum Processing Units (QPUs) and associated software tools.
Our innovative technology enables us to address use cases that are currently beyond the reach of the most powerful supercomputers; these cases can concern industrial application challenges as well as fundamental science needs.
In addition to the exceptional computing power they provide, QPUs are highly energy efficient and will contribute to a significant reduction in the carbon footprint of the HPC industry. 
 Job Description
 As part of our strong growth, we are recruiting a Data Engineer to strengthen our team in charge of the control software of our QPUs (Quantum Processing Units): Embedded Software team.
During operations, the control software gathers a varied set of data from QPU devices, such as camera images, optical measurements, runtime processing and environmental data. These data are a key resource, used by several teams at Pasqal for analysis purposes: performance measurement, characterization, calibration, investigation.
You will contribute to development, integration and deployment of the data analysis infrastructure, including platform, databases, API, services, frontend / user interface.
 In this role, your main responsibilities will include:
Clarify needs with system engineers.
Implement features (including unit tests) on whole data lifecycle: collection, storage, management, access, analysis, display, back-up, migration
Develop automated tests, integrate them in CI pipelines
Define, deploy and maintain data infrastructure
Update existing or create new document to reflect implemented features.
Participate in code and doc review process for own and peers' tasks.
Investigate raised issues then propose and implement solution

About you
A master's degree or an engineering degree with a specialization in computer science
Over 3 years of experience in software development and data engineering
Ability to understand complex systems to propose and implement effective solutions
Your professional background has provided you with experience throughout the entire software development lifecycle
You demonstrate a genuine interest in new technologies and scientific challenges.
You have a strong ability to work independently and can take responsibility for your projects while collaborating with the rest of the team. 
 The required technical skills for this position include:
Experience in database (PostgreSQL, InfluxDB) management and query languages
Experience in Python for data engineering (including tools like pandas, numpy, matplotlib, plotly, streamlit) and API, development practices (coding standards, testing, review...), and tools (git, pytest)
Knowledge of Linux, Gitlab, docker
English professional proficiency
What we offer
Offices in Massy, France
A flexible rhythm of remote work (2 to 3 days per week)
Type of contract : CDI
A dynamic and close-knit international team
A key role in a growing scale-up

Recruitment process
An interview with our Talent Acquisition Specialist of 30'.
An exchange with the Engineering manager of Embedded Software team
A meeting with the team in our offices
An offer!
PASQAL is an equal opportunity employer. We are committed to creating a diverse and inclusive workplace, as inclusion and diversity are essential to achieving our mission. We encourage applications from all qualified candidates, regardless of gender, ethnicity, age, religion or sexual orientation.
Voir moins",,2024-01-31,https://www.welcometothejungle.com/fr/companies/pasqal/jobs/data-engineer-control-software_massy?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=8ad5cf87-1c73-4fa9-ba66-c46c1769a8ae,wttj
Data Engineer - Big Data,"{'name': 'APHP DSI', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, Santé', 'employees': '495 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '46 ans'}",CDD / Temporaire,Paris,Non spécifié,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
La mission de votre équipe
Afin de permettre le développement de projets de recherche innovants, en particulier dans le domaine de l’intelligence artificielle, l’AP–HP a mis en place une plateforme Big Data, infrastructure informatique propre, intégrant des capacités de stockage et de calcul pour l’exploitation sécurisée et performante des données de santé dont elle est dépositaire. Cette plateforme héberge notamment l’entrepôt de données de santé (EDS) de l’AP-HP.

L’Entrepôt de Données de Santé (EDS) de l’AP-HP intègre des données administratives et médicales de plus de 8 millions de patients hospitalisés ou venus en consultation au sein des 39 établissements de l’AP-HP (20 millions de dossiers médicaux, plus de 10 millions de diagnostics, 181 millions de résultats de laboratoires…). Cet entrepôt permet d’améliorer le pilotage de l’activité hospitalière et de faire avancer la recherche scientifique dans le domaine de la santé en favorisant la réalisation d’études sur données, la mise en place d’essais cliniques et le développement d’algorithmes d’aide à la décision.

La Plateforme Big Data de l’AP-HP compte actuellement +20 machines pour le cluster Hadoop (5To RAM, +850 Cores, 1.8Po d’espace disque), de machines GPU (56 Nvidia P40 et V100), de 20 machines dédiées aux environnements Jupyter pour l’analyse de données, et de nombreuses autres machines applicatives.

Votre équipe, le domaine « Plateforme Big Data », a pour mission l’intégration des données de santé massives et complexes (données structurés, textes, imagerie, voix, signaux physiologiques, etc.) et leur utilisation à grande échelle, de manière performante, ergonomique et sécurisée dans le respect des principes et règles de gouvernance des données définis par l’AP-HP.
Vos missions
Au sein de l’équipe en charge de la Plateforme Big Data de l’APHP, vous aurez pour missions de proposer et de développer des outils ou composants répondant aux attentes des médecins et chercheurs pour l’exploitation des données collectées dans le cadre de leurs projets de recherche. Ces développements s’inscrivent dans un contexte de standardisation des données selon le modèle de données commun OMOP et d’interopérabilité sur la base du standard d’échange HL7-FHIR.
En tant que data engineer - données massives, sous la responsabilité du chef d’équipe développement données massives, il s’agira de contribuer à la création d’outils d’intégration, de visualisation, d’exploration et d’enrichissement de données médicales pour la recherche, souvent en lien direct avec des personnels médicaux. Outre l’intégration technique des données cliniques, les développements relèvent globalement de la pseudonymisation des données pour assurer la confidentialité des dossiers médicaux, de la standardisation des modèles de données, de la mise en place de moteurs de recherche performant incluant des notions sémantiques et de l’analyse qualitative et statistique des données collectées. Selon la typologie des données (données structurés, imagerie, voix, signaux physiologiques, etc.) des outils plus spécifiques sont également mise en œuvre. Vos missions comportent typiquement des facettes suivantes :
Contribuez à la définition des besoins techniques et à l’accompagnement des datascientists, chercheurs, et médecins lors de la réalisation de projets de recherche impliquant de nouvelles sources de données
Analyserez les différents sources de données d’un point de vue technique (acquisition, stockage, transformation, exploitation, …)
Développerez, industrialiserez et maintiendrez des traitements de données (extraction, sélection, collecte et intégration) dans un contexte big data (développements en Spark/Scala)
Contribuerez à l’utilisation de ces nouvelles typologies de données (extraction, sélection, collecte et intégration) via des connecteurs spécifiques développés en java/scala, python ou d’autres langages
Aiderez à l’implémentation de standards et normes de mise à disposition des données (OMOP/FHIR)
Industrialiserez le code de génération du flux de données et assurer sa performance globale
Optimisation de la performance des outils dans un contexte big data (Hadoop / Spark)
Développerez des méthodologies standardisées pour l’intégration de nouvelles données
Mettrez en place des outils les processus de tests unitaires, de recette et de qualification des données
Travaillerez en collaboration avec des partenaires industriels dans le cadre des différents projets de recherche
Voir moins","Profil recherché
Idéalement, vous..
Avez un diplôme d’ingénieur ou équivalent (bac+4/5, master2) en informatique ou sciences avec formation complémentaire en informatique
Avez une expérience de développement sous Linux, des langagage Java/Scala et si possible Python
Avez une expérience dans la manipulation de données avec le langage SQL
Connaissez les standards en informatique de santé (HL7 v2, DICOM, HL7-FHIR, OMOP, …)
Avez le goût de l’intégration de systèmes informatiques hétérogènes
Avez des connaissances des bonnes pratiques de sécurité informatique et de la réglementation informatique et libertés
Adhérez aux valeurs du service public et vous avez un intérêt prononcé pour le domaine de la santé
Avez un niveau d’anglais courant
Vous avez un savoir faire dans un de ces domaines :
Voir plus",2024-01-31,https://www.welcometothejungle.com/fr/companies/aphp/jobs/data-engineer-modelisation-standardisation_paris?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=5a37664c-8b9a-4149-acc5-cbd2588b64dd,wttj
Data Engineer - Madonne Core (H/F),"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards € de PNB', 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous rejoignez l'équipe Core en charge de la maintenance évolutive des applications Madonne (Récolte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiée au coeur de l'IT Risque).

Au quotidien vous avez pour missions de :

Participer à l'adaptation de nos applications en adéquation avec les besoins métiers (nouveaux produits, nouvelles règlementations, nouveaux SI Front) ;
Participer activement à la modernisation de nos outils, modernisation de notre chaîne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;
Monter en compétences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous développerez une compréhension globale des chaînes de traitements ;
Participer à tous les travaux de modernisation de notre SI, et être donc engagé dans la migration de nombreux process vers le DataLake Risk.





#TransformativeFinance
Ce poste est basé à Paris avec la possibilité de télétravailler.
En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours.
Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.
Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise.
A propos du processus de recrutement
Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier).
Voir moins","Profil recherché
Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : Vous souhaitez bénéficier d'une première expérience significative en développement Spark et Scala. Vous maitrisez : * Les méthodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appétence pour la manipulation de la data. Vous êtes : * Reconnu par votre esprit d'équipe ; * Capable de communiquer avec des publics différents, notamment avec le métier ; * Autonome et ntéressé par l'environnement finance de marché. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous êtes intéressé en répondant à cette annonce.",2024-01-30,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-madonne-core-h-f_paris_NATIX_AbRY8dQ?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=ec18afb4-fadb-452d-8a4f-830f51e925cc,wttj
Cloud Data Engineer,"{'name': 'VISIAN', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Stratégie', 'employees': '80 collaborateurs', 'creation_year': '2017', 'turnover': ""14 Millions d'euros"", 'mean_age': '28 ans'}",CDI,Courbevoie,42 à 55 €,Télétravail fréquent,11 mars 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
Visian, Société de conseil spécialisée en innovation, design produit, gestion de projet IT et développement Data. Recherche un Cloud Data Engineer pour un de ces clients.
Nous recherchons un Cloud Data Engineer passionné et expérimenté pour rejoindre notre équipe dynamique. En tant que membre clé de notre équipe de données, vous serez responsable de la conception, du développement et de la maintenance des solutions de traitement et d’analyse de données chez nos clients. Vous contribuerez à la création d’une architecture robuste et évolutive dans le cloud pour répondre à aux besoins croissants de nos clients en matière de données.
Missions :
Concevoir et développer des pipelines de données efficaces et évolutifs.
Intégrer et traiter des données à partir de différentes sources pour alimenter des entrepôts de données.
Collaborer avec les équipes métier pour comprendre les besoins en données et fournir des solutions adaptées.
Mettre en œuvre des solutions de stockage et de gestion des données dans le cloud.
Optimiser les performances des requêtes et garantir la qualité des données.
Assurer la maintenance continue des infrastructures et des pipelines de données.
Stack :
Plateformes Cloud : AWS, Azure, GCP
Langages de Programmation : Python, SQL
Outils de Traitement de Données : Apache Spark, Apache Flink
Stockage de Données : Amazon S3, Azure Data Lake, Google Cloud Storage
Bases de Données : Amazon Redshift, Google BigQuery
Outils ETL : Apache Airflow, Talend
Infrastructure en tant que Code : Terraform
Voir moins","Profil recherché
+3ans d’expériences
Expérience pratique dans la conception et le développement de pipelines de données cloud.
Solides compétences en programmation, en particulier avec Python, et en requêtage SQL.
Connaissance approfondie d’un de ses plateformes cloud (AWS, Azure, GCP) et de leurs services associés.
Maîtrise des outils de traitement de données tels que Apache Spark et Apache Flink.
Expérience dans la mise en œuvre de solutions de stockage de données et d’entrepôts de données cloud.
Familiarité avec les principes du développement orienté objet avec une expertise en Python.
Capacité à travailler de manière autonome, à résoudre des problèmes complexes et à gérer plusieurs tâches simultanément.
Maîtrise de l’anglais (écrit et parlé) pour une communication efficace au sein d’une équipe internationale.
Voir plus",2024-01-30,https://www.welcometothejungle.com/fr/companies/visian/jobs/cloud-data-engineer_courbevoie?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=ea4f8c7e-2a4d-466b-9c51-87866590f4b4,wttj
Data Engineer (H/F) | POEI,"{'name': 'DATASCIENTEST', 'sector': 'SaaS / Cloud Services, EdTech, Formation', 'employees': '130 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}",CDI,Puteaux,35K à 48K €,Télétravail occasionnel,01 septembre 2023,> 1 an,Bac +5 / Master,"Descriptif du poste
En tant que Cloud Data Engineer, vous aurez pour missions de proposer les meilleures solutions aux entreprises afin d’optimiser leur activité, à travers les missions suivantes :
Développement de solutions permettant de traiter des volumes importants de données,
Conception, collection et fabrication des données brutes,
Création d’outils et algorithmes pour le traitement des données,
Préparation des données pour le Data Analyst,
Sécurisation des Pipelines données pour les Data Analysts et Data Scientists,
Organisation de l’architecture du cloud","Profil recherché
Ce que nous vous offrons :
Une certification de l’Ecole des Mines ParisTech
Un CDI auprès de notre partenaire JEMS Group, expert européen dans le traitement et l’exploitation des données
Un salaire attractif à la clé : 35 000€ à 48 000€ selon le profil
Votre profil :
Issu(e) d’une filière scientifique ou informatique vous disposez d’un bac+5 ou d’un diplôme d’ingénieur,
Vous disposez idéalement d’une expérience significative en développement informatique, en architecture réseaux ou dans la Data,
Vous maîtrisez un langage objet type Java, Python, C++, etc.
Vous êtes inscrit(e) à Pôle Emploi",2024-01-30,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/data-engineer-cloud-poei_puteaux_DATAS_5xMkPLa?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=151ae004-7b52-490d-a7ee-cdaf734e148c,wttj
Data Engineer Senior,"{'name': 'IN THE MEMORY', 'sector': 'Grande distribution, SaaS / Cloud Services, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2018', 'turnover': '17M€', 'mean_age': '28 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Nous recherchons un(e) Data Engineer expérimenté(e) (SQL, Python, Spark) pour accompagner le développement de la société et ses produits, en particulier dans le contexte de la multiplicité croissante des volumes, sources et types de données exploités par la société.
Intégré(e) en tant que collaborateur à l’équipe Data de Memory, ton rôle sera d’assurer l’exploitation optimale de la donnée exploitée dans la plateforme d’analyse Memory 360.
Tes principales responsabilités seront :
Editer le cahier des charges des données à collecter auprès de nos partenaires distributeurs et accompagner sur la partie data la mise en œuvre de la plateforme d’analyse Memory 360.
Faire un état des lieux du modèle de données de la société, qui intègre déjà plusieurs types de données issues de différentes sources, en particulier les données transactionnelles / de fidélité.
Prendre en main la gestion de la donnée dans le cloud de la société (Azure), pour optimiser les coûts et l’efficacité des analyses effectuées par l’équipe Analytics.
Utiliser Python, Apache Spark/Databricks, Apache Airflow et Docker pour créer des solutions de traitement de données efficaces et assurer la qualité, la sécurité et la conformité des données à toutes les étapes du processus.
Accompagner les équipes data / conseil / software sur l’ensemble des sujets liés à la data.
Anticiper les évolutions et participer aux choix structurants de la société liés à la gestion de la data ainsi que la stack technique.
Voir moins","Profil recherché
Nous recherchons un candidat qui possède les compétences suivantes :
Au moins 5 ans d’expérience sur un poste de Data Engineer.
Une solide expérience en Python, Apache Spark/Databricks, Apache Airflow et Docker.
Une connaissance approfondie d’un fournisseur de services cloud, de préférence Azure.
Familiarité avec Kubernetes.
Une connaissance de Kafka est un plus
Une compréhension approfondie des bonnes pratiques de gestion des données, de la sécurité et de la conformité.
Un esprit d’équipe et d’excellentes compétences en communication pour collaborer avec des équipes interfonctionnelles.
En rejoignant notre équipe, vous aurez l’opportunité de travailler sur des projets passionnants dans le secteur du retail, d’apprendre et de grandir dans un environnement stimulant.",2024-01-30,https://www.welcometothejungle.com/fr/companies/memory/jobs/data-manager_paris-03?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=5ccd2104-8aed-47a8-b213-154bea9e2ac1,wttj
Data Engineer & Data Scientist - CDI - Sicara - Paris,"{'name': 'SICARA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': '6,5M€', 'mean_age': '27 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,Bac +5 / Master,"Descriptif du poste
Présentation Sicara
Créée en novembre 2016 au sein du groupe M33 (Theodo group), un écosystème de 10 filiales et +650 personnes situées à Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, basée à Paris.
Notre mission : aider les startups, scaleups et grands comptes à résoudre leurs problématiques business grâce à la tech. Nos équipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. L’objectif : capitaliser sur le potentiel de la donnée.
Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en développant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.
Pourquoi on recrute un Data Software Engineer ?
Afin de contribuer à la croissance de Sicara, nous recrutons un Data Engineer & Scientist pour renforcer l'équipe de Sicara !
Tes missions
Comprendre le métier et les données de ton client.
Travailler en équipe avec 2 à 4 ingénieurs data, 1 Product Owner et 1 Lead Tech
Créer un produit qui crée de la valeur pour ton client avec : les algorithmes les plus adaptés, une base de code maintenable, testée et scalable des flux de données robustes et fiables
Concevoir l’architecture du produit et l’intégrer dans le SI du client pour le mettre en production
Générer de la connaissance technique sur un sujet d'expertise et le propager au sein de Sicara
Participer à la croissance de Sicara (selon tes préférences : recrutement, avant-ventes, marketing technique)
Contribuer à notre blog technique (+30 000 visiteurs mensuels) : www.sicara.ai/blog.
Contribuer à améliorer nos savoir-faire en expérimentant continuellement de nouvelles méthodes et de nouveaux outils afin d’améliorer l’efficacité des équipes.
En fonction de tes envies et de tes compétences, tu auras la possibilité de :
Devenir un(e) expert(e) sur les sujets techniques qui te passionnent
Devenir un(e) leader grâce au développement de compétences transverses : coaching, recrutement, commercial, management, marketing, etc
Monter une tribe ou une guilde pour développer un nouvelle offre et améliorer nos pratiques
Les avantages
Notre écosystème de startup tech est un véritable tremplin pour accélérer la progression et les carrières !
Des bureaux au coeur du quartier des Batignolles à Paris, partagés avec les autres startup tech du groupe Theodo
Un coach dédié pour accélérer la progression de carrière
La possibilité de participer à des conférences techniques internationales
Des conditions de télétravail flexibles
Un budget trimestriel pour acheter ton matériel tech (laptop, smartphone, casque,...)
Des événements réguliers de team building et un WE d'entreprise à chaque année
La possibilité de s'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les inégalités et la sécurité des données
Ton profil
Diplômé(e) d’une école d'ingénieur bac+5
Tu as une forte appétence pour le secteur de la data et tu as idéalement une première expérience dans le conseil ou dans la tech
Tu as une bonne connaissance de Python et tu connais ou as envie d’apprendre à utiliser l’un des Cloud Providers (AWS, Google Cloud Platform, Microsoft Azure)
Tu as envie de progresser et d’évoluer dans un environnement challengeant et bienveillant au quotidien
A très vite !
Voir moins",,2024-01-30,https://www.welcometothejungle.com/fr/companies/sicara/jobs/data-software-engineer-cdi-sicara-paris_paris?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=efc29741-5d72-41a3-af48-84aa0d332627,wttj
Data Engineer - Azure H/F,"{'name': 'SKIILS', 'sector': 'Intelligence artificielle / Machine Learning, Transformation, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2020', 'turnover': '11M€', 'mean_age': '34 ans'}",CDI,,60K à 85K €,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
🪄Tu as le pouvoir de créer des pipelines capables de transformer des données en véritables trésors exploitables, alors tu es peut-être notre Super Data Ingénieur !
🎯Tu es prêt à affronter des défis titanesques, à gérer des montagnes de données, à défendre la résilience des systèmes, et à affronter des flux de données massifs, l’équipe DATA Factorii t’ouvre ses portes comme un véritable repaire de super-héros !
🚀En tant que Super Data Engineer - Azure H/F, tes missions seront de :
Définir et déployer le socle technologique d’un Datalake
Conseiller et concevoir une architecture de données
Implémenter l’intégration des données au sein du Datalake
Identifier, étudier et prototyper des cas d’usage stratégiques
Industrialiser les projets Big Data en environnement cloud
Implémenter les méthodologies Devops pour optimiser les processus de développement
Participer à l’estimation des besoins utilisateurs.
Concevoir du code et le documenter.
Collaborer étroitement au sein de l’équipe SCRUM, comprenant le Product Owner, les développeurs, Quality Analyst, et le support, pour assurer le succès des projets.
🎁 Ce que nous t’offrons ?
Un salaire qui évolue comme une rock star sur scène !
Une carrière à la “James Bond” : à moyen et long terme, c’est toi le héros !
Ta mutuelle et ton titre de transport pris en charge à 100% (bye-bye les frais) !
Télétravail partiel : l’équilibre parfait entre pyjama et costume !
Et surtout, la chance de t’investir dans des projets ultra cool qui te propulseront techniquement vers l’infini et au-delà ! 🚀
Voir moins","Profil recherché
En 1er, un savoir être qui correspond à l’ADN de skiils !
Les processus agiles, c’est ton super-pouvoir ! Le Manifeste Agile, c’est ton livre de chevet, toujours prêt à l’action.
Comprendre l’environnement fonctionnel du client est ta mission principale, car tu sais que c’est là que se trouvent les indices cruciaux pour tes analyses héroïques.
Doté(e) d’une autonomie inébranlable, d’un dynamisme surpuissant et d’un sens des relations humaines extraordinaire, tu es une véritable icône.
En 2nd, un bagage technique qui tient la route :
Connaissance approfondie du cloud Azure.
De premières expériences sur Databricks.
Excellente communication écrite et orale pour la création de livrables et de rapports.
Bonne pratique du DBT.
Esprit analytique et orientation vers l’amélioration continue.",2024-01-29,https://www.welcometothejungle.com/fr/companies/skiils/jobs/data-engineer-azure-h-f?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=83f9f37c-2e11-42d3-9afe-940f7b2b37fd,wttj
STAGE - DATA ENGINEER F/H,"{'name': 'CDISCOUNT', 'sector': 'Logistique, SaaS / Cloud Services, E-commerce', 'employees': '2000 collaborateurs', 'creation_year': '1998', 'turnover': None, 'mean_age': '38 ans'}","Stage
(6 mois)",Bordeaux,Non spécifié,Télétravail occasionnel,,> 6 mois,Bac +5 / Master,"Descriptif du poste
Chez Cdiscount, nous sommes convaincus qu’un environnement de travail épanouissant contribue au développement de nos talents. Relève nos défis et viens participer au développement du leader français et engagé du e-commerce.
 
Dans le cadre de son développement, Cdiscount recrute un stagiaire Data Engineer pour intégrer le pôle décisionnel.
Tu interviendras principalement sur la mise en œuvre de nouvelles solutions et outils décisionnels. Tu participeras à l’ensemble des phases d’un projet BI, alliant les aspects fonctionnel et technique.
 
Tu auras pour missions principales les tâches suivantes : 
•    Développement de traitements d’extraction et de transformation de données
•    Alimentation du Datawarehouse
•    Réalisation et développement de tableaux de bords
•    Rédaction de documentations techniques
•    Maintenance corrective et évolutive
•    Gestion de bases de données
•    Collecte des besoins auprès des différentes BU
L’offre est à pourvoir à partir de juillet pour un stage de 6 mois.
Voir moins","Profil recherché
Description du profil :

Nous recherchons des collaborateurs ayant une énergie hors pair pour prendre part à une aventure humaine et professionnelle unique.
De formation BAC +5 (ingénieur ou équivalent), tu recherches un stage de fin d’études.Tu justifies d’une première expérience en BI ou en implémentation de flux de données et/ou analyse des données.
Tu as une bonne connaissance théorique et pratique des plateformes décisionnelle (ETL, DWH, outils de reporting) et tu maitrises le management de bases de données (langage SQL, modélisation). Une expérience avec Talend ou Google BigQuery serait un plus.
Autonome, organisé(e), méthodique, tu communiques avec aisance et avez le sens du service. Doté(e) d’un très bon relationnel avec les utilisateurs et les équipes, de qualités rédactionnelles et d’un goût prononcé pour la technique, tu pourras parfaire votre expertise et intégrer une équipe dynamique.
En tant que leader français et engagé du e-commerce, Cdiscount est un employeur investi en faveur de la diversité : du recrutement à l’évolution professionnelle, nous garantissons l’égalité des chances à tous nos collaborateurs. 




Voir plus",2024-01-29,https://www.welcometothejungle.com/fr/companies/cdiscount/jobs/stage-data-engineer-f-h_bordeaux-33_CDISC_P0AXdkk?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=57312ad4-27e7-49b9-8ed7-49be8a47039e,wttj
Data Engineer Senior - Spark/ Databricks,"{'name': 'PULSOVER', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, SaaS / Cloud Services, Big Data', 'employees': 'Créée en 2021', 'creation_year': 'Âge moyen : 34 ans', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Nous renforçons notre pôle Data pour accompagner la croissance de notre société en recherchant un.e Senior Data Engineer expérimenté.e.
Si tu es passionné.e par les données, que tu possèdes une expertise approfondie sur Spark, Databricks et AWS, cette offre d’emploi est faite pour toi.
En tant que Data Engineer Senior, tu joueras un rôle essentiel dans la création, la mise en œuvre et la gestion de nos pipelines de données. Tu seras responsable de concevoir des architectures de données robustes, de développer des solutions d’intégration de données efficaces et d’optimiser les performances de nos infrastructures de données.
Tes missions principales :
Participer à des projets de data engineerings basés sur un framework méthodologique
Développer, industrialiser et maintenir des pipelines de données (principalement ETL et ML)
Effectuer de l’exploration de données et du prototypage rapide
Mettre en application les meilleures pratiques : versioning, tests automatisés, CI/CD
Participer activement à l’automatisation des infrastructures basées sur des services de Cloud Computing
Implémenter des architectures de type Lakehouse pour casser les silos
Déployer des algorithmes de machine learning at scale et sur des flux de streaming
Collaborer avec l’ensemble des équipes depuis les spécifications fonctionnelles jusqu’aux validations métiers des solutions implémentées
Contribuer à la mise en place de méthodologies Agile de type Scrum
Socle technologique et méthodologique :
Stack technique du poste : Spark, Python, Scala, Scikit learn, MLFlow, Versionning (Git), CI/CD (GitHub Actions/ GitLab/ Jenkins)
Job orchestration : Apache Airflow
Data platform: Databricks, Snowflake
Cloud : AWS et/ ou GCP, Azure
Méthodo : développement Agile/ travail en équipe collaborative
Tests automatisés : Pytest, Scalatest, Cucumber
Les avantages :
Un environnement de travail collaboratif et stimulant, favorisant l’apprentissage continu et l’évolution professionnelle
Des opportunités de formation et de développement professionnel pour rester à jour sur les dernières technologies
La possibilité de travailler sur des projets de données complexes et stimulants, ayant un impact direct sur les décisions stratégiques de l’entreprise
Une rémunération compétitive et des avantages sociaux attractifs
Voir moins","Profil recherché
De formation ingénieur ou équivalent avec une expérience de 5 ans minimum dans ce domaine
Expérience significative en tant que Data Engineer, avec une expertise approfondie sur Spark, Databricks, AWS et/ ou GCP
Solide compréhension des principes de l’ingénierie des données, des architectures distribuées et des meilleures pratiques de gestion des données
Excellentes compétences en programmation, notamment dans les langages tels que Python ou Scala
Connaissance des technologies de bases de données, des outils ETL et de l’intégration de données
Capacité à travailler de manière autonome, à gérer plusieurs projets simultanément et à respecter les délais
Bon niveau en anglais pour nos projets dans un contexte international
Et surtout : bonne humeur et attitude positive sont essentielles ;)",2024-01-29,https://www.welcometothejungle.com/fr/companies/pulsover/jobs/data-engineer-senior-spark-databricks_paris?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=146b7235-61d1-4d6d-a681-2836f1f93ed9,wttj
Data Engineer confirmé(e) / AWS,"{'name': 'LIVINGPACKETS', 'sector': 'Environnement / Développement durable, Logistique, E-commerce', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '34 ans'}",CDI,,40K à 50K €,Télétravail fréquent,,> 3 ans,,"Descriptif du poste
Tu vas rejoindre la team Cloud & Data en tant que Data Engineer confirmé(e). Vous travaillerez en étroite collaboration pour mener à bien vos missions et répondre aux besoins.
Tu es responsable de la conception et l’optimisation de solutions technologiques pour le traitement de nos données et répondre aux besoins des utilisateurs/clients.
Tes missions :
Concevoir, développer et maintenir les pipelines, les analyses et les visualisations des données
Collecter, transformer et enrichir les données provenant de multiples data sources de l’entreprise
Garantir le bon fonctionnement, la disponibilité, l’évolution et la performance des outils
Accompagner les Data Analysts dans l’optimisation de leurs algorithmes et dans la vérification de la qualité des données et des processus
Participer à l’évolution de la stack technique
Partager ton expertise avec l’ensemble des équipes
Veille technologique
Stack Technique : AWS (RDS Aurora PostgreSQL, Glue, S3, Athena, QuickSight, Lambda), Python, SQL, Docker, Terraform, Kubernetes, Git, Github Actions …
Voir moins","Profil recherché
Au moins 3 ans d’expérience sur des projets Data engineering dont au moins une année d’expérience avec le Cloud AWS et ses services Data (RDS, Lambda, Kinesis, EMR, SageMaker, Glue, S3, Athena, etc) 
Une expérience dans la data visualisations (QuickSight, PowerBI, Tableau, QlikView, etc)
Une expérience dans le monde DevOps et de ses outils (Git, Github actions, GitLab, Terraform, AWS/GCP/Azure, etc)
Tu maîtrises python et/ou Java et tu as une expertise dans l’écriture et l’optimisation du code SQL
Tu as un esprit analytique et une appétence pour la Data/Big Data et la BI
Tu es rigoureux(se) et autonome
Tu fais preuve d’initiative et tu es force de proposition pour l’amélioration continue des processus existants
Ce qui fera la différence :
une bonne compréhension des solutions de stockage données (bases de données SQL / NoSQL, datawarehouse, datalake, data lakehouse)
Voir plus",2024-01-29,https://www.welcometothejungle.com/fr/companies/livingpackets/jobs/data-engineer-confirme-aws?q=f31da2dc2b8db5d9a36077fc3ab5ff2f&o=46806290-ecb0-4b50-abe1-930ba2b0b0e2,wttj
Data Engineer,"{'name': 'QWANT', 'sector': 'Big Data', 'employees': '84 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '37 ans'}",CDI,,Non spécifié,Télétravail fréquent,,> 3 ans,,"Descriptif du poste
Vous travaillez au sein de l’équipe technique chargée d’améliorer les pratiques data et de concevoir et maintenir des pipelines de données :
-        Définir une architecture data à long terme et assurer la cohérence (type data lake)
-        S’assurer de la disponibilité de la donnée
-        Conception et mise en œuvre de pipelines de données pour de la mesure de performance et l’entrainement de modèle de machine learning
-        Industrialisation de ces pipelines en collaboration avec l’équipe de ML
A ce titre les activités principales à effectuer sont :
-        Concevoir et mettre en œuvre un processus ETL automatisé de bout en bout afin de préparer les données pour l’apprentissage automatique et l’analyse ad hoc, y compris l’anonymisation des données
-        Structurer et déployer, en lien étroit avec les équipes de machine learning, l’export automatisé de données pour l’entrainement de modèles
-        Atteindre les objectifs en collaboration avec les équipes technique, produit et business
-        Faire monter en compétence les membres de l’équipe
Voir moins","Profil recherché
Hard skills souhaitées :
-        Expérience impérative de minimum 3 ans dans la mise en œuvre de pipelines de données idéalement dans un écosystème Python
-        Bonnes connaissances en architecture Big Data et systèmes ETL (on-premise)
-        Familier avec des systèmes de calcul distribué, type Spark
-        Connaissances des bonnes pratiques de développement : versioning, tests, code reviews, CI/CD etc.
Hard skills bonus :
-        Compétences en déploiement d’applications conteneurisées (Docker / Kubernetes / Argo Workflow)
-        Expériences avec des bases de données distribuées telles que Elasticsearch, Vespa
-        Connaissance de spark streaming, kafka stream ou similaire
-        Expérience en Rust
-        Expérience en langage SQL
Soft skills :
Voir plus",2024-01-29,https://www.welcometothejungle.com/fr/companies/qwant/jobs/data-engineer?q=32e055701e531e6d24ece135164a734a&o=ab2b3f7b-4bcd-47f0-99b8-bab716cda88c,wttj
Senior Data Engineer / Data Developper,"{'name': 'SOMM-IT', 'sector': 'Restauration, Boissons, FoodTech', 'employees': '15 collaborateurs', 'creation_year': '2015', 'turnover': '250k€', 'mean_age': '35 ans'}",CDI,Bordeaux,50K à 60K €,Télétravail fréquent,15 février 2024,> 5 ans,> Bac +5 / Doctorat,"Descriptif du poste
En votre qualité de Senior Data Engineer, vous serez notamment amené à accomplir les tâches suivantes en lien avec l’équipe Data :
• Développement du portail web interne utilisé pour l’ingestion et le traitement des données de nos clients à destination d’utilisateurs non techniques
• Développement des algorithmes de traitement de données.
• Déploiement d’outils de traitement de données et suivi de leurs performances.
• Transformation et intégration de sources de données externes, développement de liens API
• Définition des solutions de stockage et de sécurisation des données
• Mise en place et déploiement de l’infrastructure pour les projets Data
• Participation aux choix technologiques et organisationnels destinés à améliorer et rendre scalables les outils développés
Vous travaillerez sous la responsabilité de notre CTO, Polytechnicien et Docteur en Mathématiques, dans un environnement exigent et stimulant pour développer votre expérience, au sein d’une équipe technique de 10 personnes aux profils variés.
Si vous êtes bordelais, vous aurez la chance de travailler aux Chartrons dans une magnifique maison avec un jardin de 500m² et une piscine!
Comme tous les SOMM’ITers, vous deviendrez actionnaire de la société après un an d’ancienneté.
Voir moins","Profil recherché
Nous cherchons un profil ayant 5 ans d’expérience portant sur les compétences suivantes:
Les « technologies » - pré-requis : Python, SQL, AWS (S3, EC2, CloudWatch,…) , ElasticSearch, Github, Flask, Vue.js
Les « savoir-faire » techniques : Mise en production d’outils de traitement de données et suivi de leur performance. Développement d’applications internes.
Les « savoir-faire » comportementaux : Travail en équipe, anticipation de la charge de travail, méthodologie agile, clarté dans l’expression, un bon relationnel client est un plus.
D’un point de vue académique, vous êtes diplômé d’une grande école d’ingénieur.",2024-01-29,https://www.welcometothejungle.com/fr/companies/somm-it/jobs/senior-data-engineer-data-developper_bordeaux_SOMMI_qMGloA5?q=32e055701e531e6d24ece135164a734a&o=d651bd78-1739-496b-a3e1-586d7f702183,wttj
Full Stack Data Engineer | LLM/Python/Vue.js,"{'name': 'JUS MUNDI', 'sector': 'Intelligence artificielle / Machine Learning, Service juridique, Justice', 'employees': '64 collaborateurs', 'creation_year': '2018', 'turnover': '4 million ARR', 'mean_age': '35 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 3 ans,,"Descriptif du poste
Today we have and maintain two main Products:
Jus Connect: a Legal Professional Network to democratize access to visibility and data-driven profiles for legal professionals to empower their professional success.
Legal Research in International Law: Facilitate access to International Legal resources and automatize the data collection.
Each Software Engineer works inside an Impact Team for independent business units.
And today we are looking for an engineer to join our new Impact Team to work specifically around LLMs and ship more organic experiences to our users.
We’re leveraging LLM models to revolutionize legal research and build valuable products for our users. What we’re building in the short term? We’re developing interactive assistants and agents that leverage our database and perform tasks for our users and partners. But we want to do much more!
The legal industry is being revolutionised by LLMs. Lawyers are eagerly adopting cutting-edge technologies, and we are riding this wave! The moment is now.
We mainly follow a Kanban/Lean paradigm cherry-picking Events or Artefacts from other methods to create our own practice, matching our own organization.
We have an Engineering Culture. And have some practical principles.
Do what you say, Say what you do.
Communication builds Trust. Trust improves Performance.
Try, fail and, learn. Iterate until success.
Leave your ego at the door.
Big Ideas, Pragmatical Implementation.
Voir moins","Profil recherché
What you’ll do:
Create, test, maintain, and consume internal & external APIs (Python/Golang)
Conception Proposals and RFC
Help to create Proof Of Concept, Minimum Viable Product
Implement new features and fix bugs
Create and maintain a simple interface for the back office (Vue.js)
Work on LLM application (llama-2, GPT-4, etc…)
Do prompt engineering, one and few short learning and fine-tuning
Who you are:
You are passionate about your craft and can communicate it.
You are trustworthy.
You have 3+ years in the software industry and have mastered at least part of our Tech Stack.
You thrive in a fast-paced environment.
You are climbing the slope of enlightenment (Dunning–Kruger effect)
Voir plus",2024-01-29,https://www.welcometothejungle.com/fr/companies/jus-mundi/jobs/software-engineer-node-js-vue-js-llm_paris?q=32e055701e531e6d24ece135164a734a&o=90645ad0-cae8-4005-b56d-d31424d70f4b,wttj
[AIX] Data Engineer (H/F),"{'name': 'MERITIS', 'sector': 'IT / Digital, Finance', 'employees': '900 collaborateurs', 'creation_year': '2007', 'turnover': '87M€', 'mean_age': '30 ans'}",CDI,Aix-en-Provence,Non spécifié,Télétravail occasionnel,,,Bac +5 / Master,"Descriptif du poste
En collaboration avec l’architecte data, les experts data et le gestionnaire/propriétaire produit, vous serez amené à participer aux opérations et à l’implémentation de la roadmap technique de la plateforme d’orchestration. Voici vos missions :
Participer au cycle de développement du produit Airflow,
Assurer l’implémentation/développement de l’outillage et des fonctionnalités de la plateforme nécessaires avec accord de l’Architecte Data et les experts Data du groupe,
Contribuer au développement des graphes orientés acycliques (DAG) nécessaires à la bonne opérabilité des plateformes datalake et datamart (AWS et Snowflake),
Assurer le rôle de support technique auprès des end-users lors de leur usage de la plateforme,
Assurer les livraisons et déploiement du code,
Assurer le mode run de la plateforme,
Support niveau 2 expertise de la production et participation aux situations de crises,
Reporter au gestionnaire de la plateforme Airflow, les performances IT, l’état de santé temps réel et principaux risques opérationnels de la plateforme,
Contribuer à la communauté Data Orchestration,
Produire la documentation nécessaire à ce passage de connaissance : tuto, document d’exploitation, etc…
Assurer et animer les sessions de transfert de connaissances au travers de démos produit.
Voir moins","Profil recherché
Vous avez un diplôme d’ingénieur ou un Bac+5 équivalent
Vous avez 3 ans d'expérience en tant que Data Engineer
Vous avez une bonne conne connaissance de l'environnement cloud AWS
Vous avez une bonne maitrise de l'Orchestration des processus, notamment avec Airflow
Vous êtes familier avec les principes ETL/ELT
Vous avez déjà travaillé avec la méthodologie Agile Scrum/Kanban",2024-01-27,https://www.welcometothejungle.com/fr/companies/meritis/jobs/aix-data-engineer-h-f_aix-en-provence?q=32e055701e531e6d24ece135164a734a&o=d289abcc-8741-4dd1-8cc1-e6d5b9c18e70,wttj
"Senior Data Engineer (Paris, Madrid, Milan, London, Lux), VX and EU-AVS","{'name': 'AMAZON E-COMMERCE', 'sector': 'E-commerce', 'employees': '1300000 collaborateurs', 'creation_year': '1995', 'turnover': None, 'mean_age': None}",CDI,Clichy,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Amazon strives to be Earth’s most customer-centric company, where customers can find and discover anything they might want to buy online. By giving customers more of what they want - low prices, vast selection, and convenience - Amazon continues to grow and evolve as a world-class e-commerce website. Core to Amazon’s mission to delight and serve customers is a need to invent on behalf of vendors. Our team is at the forefront of two pivotal programs, EU AVS and WW VX, each integral to enhancing the end Customer Experience and contributing to Amazon’s Long-Term Free Cash Flow. The EU AVS program aims to provide an industry-leading account management service at the optimal cost-to-serve for Amazon that exceeds vendors’ expectations and expedites their growth on Amazon. The WW VX program vision is to make Amazon the most preferred, trusted, and efficient distribution option for vendors by building an industry-leading experience for every vendor across all global touchpoints.
Key job responsibilities
Our team is looking for an experienced Senior Data engineer to implement and support scalable data infrastructure solutions in one of the world's largest and most complex data warehouse environments. You will design, implement and support scalable data infrastructure solutions to integrate with multi heterogeneous data sources, aggregate and retrieve data in a fast and safe mode, curate data that can be used in reporting, analysis, machine learning models and ad-hoc data requests. You will be exposed to cutting edge AWS big data technologies. You should have excellent business and communication skills to be able to work with business owners and Tech leaders to gather infrastructure requirements, design data infrastructure, build up data pipelines and data-sets to meet business needs. You stay abreast of emerging technologies, investigating and implementing where appropriate. Position can be from Paris, Madrid, Milan, London, Amsterdam or Lux
A day in the life
Your major responsibilities will include:
• Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL and AWS big data technologies.
• Explore and learn AWS technologies to provide new capabilities and increase efficiencies.
• Designing and implementing complex pipelines and other BI solutions.
• Work closely with business owners, developers, Business Intelligence Engineer to explore new data sources and deliver the data.
About the team
The AVS and VX program teams are diverse organizations with employees across Europe and with partner teams around the globe. This role can be based in London, Paris, Madrid, or Luxembourg. These teams drive improvements in products, services, tools, processes, communication, and vendor education world-wide working with partner teams in Europe, North America, Japan, and emerging locales and are responsible for all elements of a vendor’s interaction with Amazon including listing, catalog management, ordering, supply chain, marketing, payments, value-added services, and vendor support.
We are open to hiring candidates to work out of one of the following locations:
Clichy, FRA
Voir moins","Profil recherché
• Bachelor's degree in Engineering, Computer Science, or a related technical discipline
• 5+ years of industry experience in Data Engineering, BI Engineer, or related field with a track record of and extracting value from bigdata
• Strong experience in distributed data, ETL pipelines and Data Warehousing
• Hands-on experience and advanced knowledge of SQL, Shell scripting and Python.",2024-01-26,https://www.welcometothejungle.com/fr/companies/amazon/jobs/senior-data-engineer-vx-and-eu-avs_clichy?q=32e055701e531e6d24ece135164a734a&o=44766036-5541-4bca-8f9f-259ca0a72154,wttj
Tech Lead Data Engineer,"{'name': 'SOCIÉTÉ GÉNÉRALE', 'sector': 'Banque, FinTech / InsurTech, Finance', 'employees': '117000 collaborateurs', 'creation_year': '1864', 'turnover': None, 'mean_age': None}",CDI,Neuilly-sur-Seine,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Vous avez envie d'un environnement vous permettant d'être à la pointe à la fois des technologies Cloud et Big data tout en mettant à profit vos soft skills ? Si vous êtes aussi à l'aise pour coder que pour co-concevoir dans un cadre méthodologique riche et complexe alors rejoignez-nous en tant que Technical Leader.

Dans un contexte de vaste transformation/réécriture d'un SI pour portage vers des technologies BigData et public Cloud, nous attendons des Technical Leader qu'ils soient les artisans du design et de l'implémentation technique de la plate-forme. Ils sont également référents pour une ou plusieurs Feature Team (Equipe Agile) auprès des développeurs.

En tant que Technical Leader de la FT Basis, concrètement, vous serez amené à :
Concevoir des solutions pour collecter, nettoyer, organiser et synthétiser de gros volumes de données (pour alimenter bases de données, datalakes et projets Big Data)
Co-élaborer le design technique du produit délivré
Apporter votre soutien sur les développements de votre équipe
En fonction du contexte, vous réaliserez les activités de Software Engineer pour des développements stratégiques
Développer, entretenir et utiliser votre expertise sur la stack Scala, BigData, Cloud
Vous serez responsable de l'intégration cohérente du zproduit dans le SI avec l'Architecte Technique
Contribuer à la veille technique de votre périmètre et à sa diffusion, faire progresser les équipes et contribuer à l'animation du chapter en collaboration avec les homologues tech lead d'autres directions


Et si c’était vous ?


Diplômé d'un Bac +5 en Informatique / École d'Ingénieur, vous avez une première expérience dans un environnement tech : Hadoop Hortonworks, Kafka, Nifi, etc.
Vous disposez a minima de 5 ans d'expérience en data Engineerig
Vous êtes Incollable sur Spark et Scala
Idéalement, vous avez une première expérience en tant que Lead/Tech Lead Data engineer.
Passionné de data, vous proposez des améliorations et partagez avec votre équipe
Vous êtes curieux, avec un bon esprit d'analyse et de synthèse
You're fluent in English

Plus qu'un poste, un tremplin


Notre vision est de jouer un rôle moteur dans les transformations positives du monde et de contribuer à un avenir plus écologique, respectueux de la planète !

Choisir Société Générale, c'est intégrer un Groupe où la culture d'entreprise est tournée vers l'inclusion, la diversité et l'esprit d'équipe !

C'est construire une carrière dynamique avec la possibilité de changer de poste en moyenne tous les 4 ans, en France et à l'international tout en bénéficiant de formations régulières !

Au regard de vos compétences, une rémunération attractive revue annuellement, composée d'un salaire fixe, d'une part variable individuelle et d'une prime d'intéressement et de participation vous sera proposée.

Vous bénéficiez également de tarifs préférentiels sur vos services bancaires, d'un compte épargne temps monétisable et d'un Plan d'Epargne Entreprise abondé.

Attentif à votre qualité de vie et conditions de travail, vous bénéficiez de nombreux avantages complémentaires :
À minima 2 jours de télétravail par semaine
26 à 28 jours de congés payés par an et 14 à 18 jours de RTT (suivant les années), des congés liés aux événements de la vie
Un Comité d'Entreprise (billetterie événements sportifs & culturels, primes et subventions vacances, garde d'enfants, chèque cadeaux à Noel)
Une offre variée de restaurants d'entreprise et de cafétérias à tarifs compétitifs ainsi que des titres restaurants dématérialisés quand vous êtes en télétravail

Pourquoi nous choisir ?


Chez Société Générale, nous sommes convaincus que vous êtes le moteur du changement, et que le monde de demain sera fait de toutes vos initiatives, des plus petites aux plus ambitieuses.

Aux 4 coins du monde, que vous nous rejoigniez pour quelques mois, quelques années ou toute votre carrière, ensemble nous avons les moyens d'avoir un impact positif sur l'avenir. Créer, oser, innover, entreprendre font partie de notre ADN.

Si vous aussi vous souhaitez être dans l'action, évoluer dans un environnement stimulant et bienveillant, vous sentir utile au quotidien et développer ou renforcer votre expertise, nous sommes faits pour nous rencontrer !

Vous hésitez encore ?
Sachez que nos collaborateurs peuvent s'engager quelques jours par an pour des actions de solidarité sur leur temps de travail : parrainer des personnes en difficulté dans leur orientation ou leur insertion professionnelle, participer à l'éducation financière de jeunes en apprentissage ou encore partager leurs compétences avec une association. Les formats d'engagement sont multiples.

Nous sommes un employeur garantissant l'égalité des chances et nous sommes fiers de faire de la diversité une force pour notre entreprise. Le groupe s'engage à reconnaître et à promouvoir tous les talents, quels que soient leurs croyances, âge, handicap, parentalité, origine ethnique, nationalité, identité de genre, orientation sexuelle, appartenance à une organisation politique, religieuse, syndicale ou à une minorité, ou toute autre caractéristique qui pourrait faire l'objet d'une discrimination.

Référence: 23000EUD
Entité: Fonctions centrales groupes
Date de début: immediat

Date de publication: 06/11/2023
Voir moins",,2024-01-25,https://www.welcometothejungle.com/fr/companies/societe-generale/jobs/tech-lead-data-engineer_puteaux?q=32e055701e531e6d24ece135164a734a&o=18214231-de9a-4d07-98c5-b39fe74885a8,wttj
Data Engineer @Aive (Inovexus community startup),"{'name': 'INOVEXUS', 'sector': ""SaaS / Cloud Services, Incubateur / Accélérateur, Accompagnement d'entreprises"", 'employees': '8 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 3 ans,,"Descriptif du poste
En temps que Data Engineer chez Aive, vos missions seront de :
Participer à la conception et l’implémentation de nouvelles fonctionnalités reposant sur l’analyse ou le traitement vidéo, audio ou textuel.
Concevoir ou appliquer des modèles, algorithmes et méthodes pour mettre un oeuvres ces fonctionnalités
Maintenir une veille technologique sur les sujets pertinents pour le produit
Collaborer avec les autres spécialités de l’équipe pour industrialiser le produit (qualité, performance, maintenance)
L’offre est ouverte pour toute la France, avec une préférence pour les candidats en région Parisienne ayant la possibilité de venir régulièrement dans les locaux.","Profil recherché
Une bonne connaissance des sujets et technologies suivants est appréciée (exemples tirés de nos projets récents ou à venir):
Languages: Python, Golang
Frameworks de machine learning: Torch, ONNX
Opération: Github CI, Docker, Kubernetes
Computer Vision (object/logo/face detection, shot/scene detection, feature extraction)
Signal Processing (automatic speech recognition, diarization)
Natural Language Processing (topic segmentation, summarization)
Les compétences et expériences suivantes seront fortement appréciées :
3 ans d’expérience préalable
Vous aimez travailler en équipe, partager vos connaissances et les approfondir au contact des autres
Recherchez l’efficacité dans la création d’algorithme à grande échelle et évolutifs
Si jamais vous ne remplissez pas tous ces critères, n’hésitez pas à nous contacter quand même, nous étudierons tous les profils intéressants !
Voir plus",2024-01-25,https://www.welcometothejungle.com/fr/companies/inovexus/jobs/data-engineer-aive-inovexus-community-startup_paris?q=32e055701e531e6d24ece135164a734a&o=3393fa79-1f01-4ffd-8b25-eea5d84d5f02,wttj
Data Engineer Internship (Altitude),"{'name': 'AXA CLIMATE', 'sector': 'Stratégie, SaaS / Cloud Services, EdTech', 'employees': '150 collaborateurs', 'creation_year': '2019', 'turnover': '18M €', 'mean_age': '36 ans'}","Stage
(5 à 6 mois)",Paris,Non spécifié,Télétravail fréquent,04 mars 2024,> 6 mois,Bac +5 / Master,"Descriptif du poste
AXA Climate and Altitude
AXA Climate has 5 business unit to support its clients and partners, based on expertise: Insurance, Training, Consulting, SaaS Products, and Regen. Globally, we are a team of +200 climate experts, headquartered in Paris, spread over 5 continents and driven by the same desire for impact. Our purpose is to help Planet Earth become a true stakeholder of all companies, in the same way that employees, customers and shareholders are!
Altitude is the brand of our SaaS business. Our purpose is Adaptation. We build solutions, for decision makers, to enable climate and environmental adaptation. Our products are tailor-made for each persona: Private Equity firms, Agricultural cooperative, etc. We are +20 people working on it: product managers, designers, developers, business developers, etc.
We are autonomous within AXA Climate, but we work closely with the consulting teams dedicated to Financial Services and Agri sectors. We strongly believe that success is collective and we play as one team.
Altitude for Finance
Altitude for Finance is our first product, launched un September 2022. It is a platform dedicated for Infrastructure and Private Equity funds, enabling risk screening in pre-acquisition Due-Diligence, and enabling portfolio monitoring for reporting (such as TCFD). It is an innovative one-stop-shop for sustainability and investment teams, screening climate and nature-related risks and opportunities within minutes, very easy to use, and fully automated.
You can know more about our product here: www.axa-altitude.com
In 2023, we signed +35 clients, totalizing +170bn€ of Asset Under Management. To keep developing and growing our positive impact on the investment industry, we are recruiting.
Your Mission, as a Data Engineer Intern
You will join the Data Team, which focuses on geospatial data and risk analysis.
As part of our data quality improvement objective, your main goals will be:
To define a framework for end-to-end testing of the data platform, based on recommendations from the science team, and normalized on the project’s infrastructure
To benchmark geospatial data formats, allowing us to to discover means of improving the platform’s performance
Optionally, a benchmark of geospatial data formats would also allow us to discover means of improving the platform’s performance.
While working on those goals, you will be fully integrated in the daily life of the data team, and the ecosystem as a whole:
Participate in the various rituals: daily, demo, retrospective, etc.
Understand the component and architecture of the data platform
Learn about geospatial data manipulation with Python
Participate in tasks related to current feature developments
Our technical stack:
Running on AWS
Entirely serverless: Lambda, Fargate, DynamoDB, etc.
Python (data) and TypeScript (front-end)
Managed via Terraform
Voir moins","Profil recherché
You are graduating from an engineering school, with a focus on data engineering
You have experience with Python and its ecosystem
You are rigorous and detail-oriented
You are proactive and autonomous in your work
You are able to deliver project on time and with the right level of quality
You have a strong interest for climate issues and challenges, and the science around it
A first experience with geospatial formats is a plus",2024-01-25,https://www.welcometothejungle.com/fr/companies/axa-climate/jobs/data-engineer-internship_paris?q=32e055701e531e6d24ece135164a734a&o=6aaab64a-ad0f-48bb-87c8-db643b46d034,wttj
Data Engineer BI,"{'name': 'BNP PARIBAS', 'sector': 'Banque', 'employees': '183883 collaborateurs', 'creation_year': '2000', 'turnover': '50,4 Mds€', 'mean_age': '40 ans'}",CDI,Nantes,Non spécifié,Télétravail fréquent,01 septembre 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
Data Engineer BI H/F
(Poste basé à NANTES (44) disponible à partir de septembre 2024)
BCEF IT, l'informatique de la Banque Commerciale en France travaille en mode Agile, en proximité du Business. Ensemble, ces équipes ont pour mission de développer des solutions fonctionnelles, innovantes et sécurisées pour répondre aux besoins et aux attentes des clients et des collaborateurs, en alignement avec les enjeux et les standards de place (Data, IA, Devops, Cloud, Numérique responsable, cybersécurité…).
Historiquement implantés en région parisienne, nous ouvrons un nouveau Campus à Nantes (7 boulevard de Berlin - 44000 Nantes) afin de renforcer nos compétences sur les métiers du développement et des métiers d'expertise.
Facile d'accès, à seulement 10 minutes de la gare, ce campus vous offrira un environnement de travail agréable et stimulant. Vous travaillerez en environnement Flex Office et télétravail en mode hybride avec l'accès aux outils collaboratifs digitaux (Teams, klaxoon…) et en étroite collaboration avec notre campus parisien.
Motivé(e) à relever ce nouveau challenge sur Nantes ? Rejoignez-nous !
Missions, équipe et environnement de travail, ça donne quoi ?
Au sein de la DSI de la Banque Commerciale En France (BCEF IT) et plus particulièrement dans le domaine transverse IT ""Data / IA & Foundations"", nous recherchons un Data Engineer BI.
Vos principales missions seront :
* De Concevoir et développer les features du sprint backlog
* d'Être force de proposition, participer aux choix techniques en lien avec les architectes du groupe et participer aux recrutements de l'équipe
* d'être garant des respects des bonnes pratiques de développement
* De participer sur des cadrages de projets IT ou métiers sur la plateforme en tant qu'Expert en lien étroit avec les architectes et autres experts (sécurité, data management,…)
* d'Etre en veille technologique

Au sein de la squad « Datafactory » avec des équipes à la fois sur notre site Nantais et notre site francilien, vous serez en charge des développements sur notre plateforme d'ingestion de flux.
Voir moins","Profil recherché
Etes-vous notre prochain Data Engineer BI - H/F ?
Oui, si vous disposez d'un BAC +5 en école d'ingénieur ou équivalent universitaire, avec une spécialisation en informatique.
Vous avez 3 années d'expériences minimum dans le domaine informatique et plus spécifiquement sur les technologies Data.
Vous avez des connaissances en Développement informatique, Tests informatiques, Architecture, Infrastructure informatique, Sécurité informatique et cyber sécurité et Relations IT / Business.
Votre capacité d'adaptation, capacité à décider, créativité & innovation/capacité à résoudre des problèmes, capacité à synthétiser/simplifier, Écoute active, orientation client, Capacité à synthétiser / simplifier seront autant d'atouts nécessaires pour réussir sur le poste.
Vous êtes reconnu pour votre Capacité à comprendre, expliquer et intégrer les enjeux de développement durable dans mon travail au quotidien, Capacité à incarner la Diversité, l'Egalité et l'Inclusion au sein du Groupe, Capacité à adopter et promouvoir l'état d'esprit Agile.
Voir plus",2024-01-25,https://www.welcometothejungle.com/fr/companies/bnp-paribas/jobs/data-engineer-bi_nantes?q=32e055701e531e6d24ece135164a734a&o=17e086a2-d38f-4acd-8fa8-6e9728df7b65,wttj
Lead Data Engineer FR,"{'name': 'PELICO', 'sector': 'Intelligence artificielle / Machine Learning', 'employees': '120 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
As a Lead Data Engineer within our company, you will play a pivotal role in overseeing and developing our team dedicated to data integration of our clients.
You will be responsible for leading but also contributing in the structure of data integration activities of our clients, by defining data pipelines architectures, automatisation process and make our Software & Data Engineering team grow.

What you’ll do & learn 📖
Plan, coordinate, and manage software and data integration projects, ensuring adherence to timelines and budgets agreed with the clients
Work closely with other departments to understand business needs and translate them into technical solutions.
Oversee the development, maintenance, and updating of practice, ensuring compliance with quality and security standards.
Establish rigorous testing processes to ensure application stability.
Supervise data collection, storage, quality, and security.
Collaborate with the Customer Operations team to extract valuable insights from data.
Efficiency through Standardization: Standardize processes across the organization. Reduces the risk of errors, improves consistency, and streamlines operations.
Optimization: Regularly assess processes, gather feedback from team members, and implement improvements to respond to changing needs.
Data-Driven Decision-Making: Utilize data and analytics to provide objective guidance to obtain the most significant impact
Alignment with customers to embrace a perfect data integration: Tailor your interactions and services to each customer's preferences and needs using data and insights to personalized experiences.
Embrace multiple channels to communicate with customers effectively.
Implement systems and processes to proactively identify and resolve issues before they impact the data integration experience.
Stay updated with relevant technological trends and advancements for the team.
Design, develop, maintain and evolve the data stack to answer both business and product needs (especially back end features within the platform)
Build data pipelines and configure the platform (incl. algorithms) to on-board new customers.

 What you embody 🎯
Pelico promotes inclusion and non-discrimination, and acts daily in favour of social mix, gender equality, senior citizens & disability
 At least 7 years of Data engineering experience, ideally in a SAAS environment
You are mastering on Python Javascript, C++, Kotlin, You-name-it… but note that we hire based on engineering fundamentals rather than familiarity with specific technologies
Experience in building data-rich products or complex data pipelines (professional or personal projects) or working with data (data transformation & event driven pipeline)
SQL expert
Bilingual English mandatory (verbal & written), French is a plus
Proactive, Autonomous, results oriented and you excel in stimulating environments
Willingness to create impact for customers and see the product in the hand of happy users
Team player and comfortable working with others
Comfortable in client facing if needed

Technical Stack 💻
Python
Airflow
PostgreSQL
Gitlab CI/CD
Linus
Docker
What we offer💡
Join an exciting adventure with a lot of challenges at all levels!
Work on a highly impactful product that users love!
Office location at the heart of Paris (75002)
Stock Options for every pelican
Remote flexibility & 6 weeks of Work from Anywhere
Premium health coverage : Alan Blue
50% meal allowance: 10€/day worked (Swile card)
50% public transportation or equivalent in sustainable mobility package
Team events every quarter
 Our recruitment Process 📣
HR Introduction of 45 mins by GG Meet
Tech Interview
Case Study (1h30)
Debrief with Chief Customer Officer or VP Eng
Ref check & offer letter to join Pelico within 48 hours
Voir moins",,2024-01-25,https://www.welcometothejungle.com/fr/companies/pelico/jobs/lead-data-engineer-fr_paris?q=32e055701e531e6d24ece135164a734a&o=b9ac11cb-32e0-4b0c-aec9-1c20912eaa68,wttj
Senior Software and Data Engineer,"{'name': 'PELICO', 'sector': 'Intelligence artificielle / Machine Learning', 'employees': '120 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
The Tech Delivery Team is the technical link between the Customer Operations and Customer Support with the rest of the company, we fix bugs when a client finds a problem, we help the CustOps with onboarding of new customers, the DevOps with the deployment of new products and features and we study how to make our client’s transition to Pelico SAAS smooth & easy.
We have identified several opportunities that will make today's processes and daily work easier for the CustOps onboarding new clients and adding new data to the current ones.
What you'll do & learn📖
You’ll play an instrumental role at maximizing the impact of the Pelico platform at customers:
Design, develop, maintain and evolve the data stack to answer both business and product needs (especially back end features within the platform)
Build data pipelines and configure the platform (incl. algorithms) to on-board new customers
Work closely with the customer operations & product strategy teams to iterate based on user feedback and bring impact to our clients
Own features end-to-end from technical design to dev.
Help your coworkers review code, spread your technical expertise, improve our tool chain
Play an integral role in establishing our engineering culture and best practices
Contribute actively in alignment between others technical teams in the Engineering department
Be a A player in product roadmap & engineering delivery towards business targets.

Technical Stack 💻
Stack :
Python
Kotlin
Flask with Blueprints
WebSocket
Pandas, numpy Parallelisation
Parallelisation Framework: ZMQ, Pub/Sub
Environment :
dedicated gcloud VM
boilerplate docker / docker-compose
Services :
GraphQL
PostgreSQL
Redis
RabbitMQ
ElasticSearch
InfluxDB
Processes Management :

Airflow (ETLs, management batches)
Gitlab CI / CD
Security :
Yubikeys
Keeper passwords
Gsuite SSO

What you embody 🎯
At least 5 years of Data engineering experience, ideally in a SAAS environment
You are mastering on Python Javascript, C++, Kotlin, You-name-it… but note that we hire based on engineering fundamentals rather than familiarity with specific technologies
Experience in building data-rich products or complex data pipelines (professional or personal projects) or working with data (data transformation & event driven pipeline)
SQL expert
Bilingual English mandatory (verbal & written), French is a plus
Proactive, Autonomous, results oriented and you excel in stimulating environments
Willingness to create impact for customers and see the product in the hand of happy users
Team player and comfortable working with others

 Pelico promotes inclusion and non-discrimination, and acts daily in favour of social mix, gender equality, senior citizens & disability

What we offer💡
Join an exciting adventure with a lot of challenges at all levels!
Work on a highly impactful product that users love!
Office location at the heart of Paris (75002)
Stock Options for every Pelican
Remote flexibility & 6 weeks of Work from Anywhere
Premium health coverage : Alan Blue
50% meal allowance: 10€/day worked (Swile card)
50% public transportation or equivalent in sustainable mobilty package
Afterwork every quarter
Voir moins",,2024-01-25,https://www.welcometothejungle.com/fr/companies/pelico/jobs/senior-software-and-data-engineer_paris?q=32e055701e531e6d24ece135164a734a&o=42ebad97-6777-4398-8a81-fcc3aba64fbf,wttj
Data Engineer - Italy 🇮🇹,"{'name': 'DOCTRINE', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Service juridique', 'employees': '120 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Notre mission ⚖️
Nous nous engageons pour un enjeu démocratique majeur : rendre le droit plus accessible et transparent aux justiciables et aux professionnels du droit.
Doctrine est la première plateforme d'intelligence juridique. Nous centralisons et organisons toute l'information juridique disponible pour permettre aux avocats et juristes de mieux conseiller et défendre leurs clients. Plus d'un million de personnes viennent tous les mois sur Doctrine se renseigner sur leurs droits, et déjà 12 000 professionnels du droit nous font confiance.
Nos valeurs 🤝
Challenge the status quo. Nous défendons les idées audacieuses et la prise de risque intelligente.
Liberty and responsibility. Nous promouvons l’autonomie, l’impact de chacun·e et l’ownership.
Knowledge is power. L'information est au cœur de la mission de Doctrine, et nous voulons toujours apprendre plus.
Release early, release often and listen to your customers. Nous croyons au pouvoir de l’itération et à l’importance d’écouter en permanence notre marché, nos client·e·s et leurs problématiques.
Le contexte
Suite à une croissance rapide et rentable en France, Doctrine pose les premières briques de son internationalisation en Italie. Nous sommes à la recherche de notre premier.e Data Engineer sur ce pays, pour nous aider à lancer la première plateforme d’intelligence juridique sur le marché italien.
C’est un rôle stratégique qui impactera la roadmap produit et les futurs succès de Doctrine en Italie.
A noter : le poste est basé à Paris, dans nos bureaux du 8ème arrondissement.
Tu peux trouver des détails sur l’ensemble de la stack  sur Github
A savoir : il n’est pas nécessaire d’avoir une expérience professionnelle dans le domaine du droit, cependant l’envie de s’investir et de monter en compétence dans la compréhension des documents juridiques est importante :)
Les missions 🛠
Concevoir, développer, monitorer les pipelines de données et les scripts d'acquisition utilisées pour tous les contenus de notre plateforme
Assurer la qualité de la donnée et son monitoring
Travailler main dans la main avec les ingénieurs machine learning en charge des parties équivalentes de leur côté
Contribuer à l’évolution de nos outils de pipeline de données (Airflow, Kubernetes, Dask, Amazon S3, PostgreSQL, Terraform, etc...), et faire en sorte d’en tirer le meilleur profit au quotidien
Au sein du Chapter Data Engineering, participer à l'élaboration de nos pratiques de modélisation et de traitement des données.
Le profil idéal 👀
De bonnes compétences en programmation Python
Une expérience des pratiques d'acquisition et de modélisation des données
Une bonne connaissance de SQL, NoSQL, Elasticsearch et du stockage objet
L’envie de partager tes connaissances pour participer à la progression de chacun.e
La maîtrise de la langue française car ce sera ta langue de travail avec tes collègues
Idéalement, des notions d’italien car tu seras amené à manipuler des données en italien
Les à côtés du poste 👁
Comme tous les ingénieurs de Doctrine, tu participeras à un de nos chapters transverses, en l’espèce le chapter Data Engineering. Au sein de ce chapter, tu contribueras à des projets internes pour améliorer nos process et notre vision long-terme. Le chapter se réunit toutes les deux semaines pour :
🤝 Partager des connaissances : amélioration continue, bonnes pratiques,…
🎯 Proposer des évolutions : nouveaux outils à expérimenter, nouveaux process à mettre en œuvre
Tu participeras également au 👩‍💻 recrutement : tous les contributeurs individuels rencontrent des candidats à l’occasion de tests techniques ou d’entretiens.
Ce qui t'attend si tu rejoins Doctrine 🤗
- Contribuer à un projet ambitieux, avec un impact réel et positif sur la société : rendre le droit plus accessible et plus ouvert.
- Un accompagnement sur mesure dès ton arrivée sur l'écosystème juridique pour t'aider à naviguer très vite dans cet environnement stimulant.
- Une aventure dans laquelle tu apprendras sans cesse et partageras tes connaissances à l’ensemble de tes collègues (talks internes/externes, meetups, Tech & Sales Monthly, blog Medium, etc.)
- Travailler au sein d’une équipe en ébullition qui cherche sans cesse à se renouveler : de la place pour innover et mener des projets en autonomie ou en équipe.
Nos avantages pour faire la différence ☀️
🏡 Une politique de télétravail flexible, avec 2 jours de présence au bureau par semaine (mardi et jeudi)
🌱 De nombreuses options pour ta carrière, et des mobilités internes ouvertes à toutes et tous chez Doctrine
🌴 Des vacances flexibles et illimitées
📚 Un vrai accent sur la formation individuelle et collective, avec un budget annuel de 750€ en usage libre et des formations en équipe et pour toute l'entreprise régulièrement
🏄‍♂️ Des évènements collectifs réguliers
👩‍⚕️ Une bonne assurance santé avec Alan
🚲 Un forfait mobilité durable à hauteur de 66 euros par mois
🏋️‍♀️ Un abonnement Gymlib pour les activités sportives et bien-être
🍱 Une carte Swile pour tes tickets restaurants
🧘 Un accès gratuit à la plateforme d'accompagnement à la santé mentale Moka.care
💡 Des centaines de réductions et avantages négociés grâce à notre CSE
🍏 Un équipement de travail neuf chez Apple
Notre processus de recrutement 🚀
- Un premier échange de 30 min avec l’un.e de nos Talent Acquisition Manager pour bien comprendre ton projet professionnel et te présenter ce qu'on construit chez Doctrine
- Une rencontre d’1h avec ton/ta futur.e manager, pour détailler le poste et le scope de l’équipe, mais aussi répondre à toutes tes questions.
- Un ou deux tests techniques pour évaluer concrètement tes compétences
- Un déjeuner avec 3 personnes de différents départements chez Doctrine, pour te donner un aperçu de tes futur.e.s collègues
- Un échange sur les valeurs de l’entreprise pour te partager notre vision
- Une rencontre avec Guillaume, notre CEO.
(si nécessaire le processus pourra être adapté pour répondre à tes contraintes personnelles et professionnelles)
Mesdames, autorisez-vous à candidater !
Certaines études scientifiques montrent qu'en particulier les femmes ont moins tendance à postuler à une offre d'emploi quand elles n'ont pas toutes les qualifications. Si cela peut vous rassurer, sachez que cette fiche de poste est indicative donc prenez la comme telle : c'est un guide, ni plus ni moins.
Si Doctrine vous intéresse, sachez que nous aurons plaisir à recevoir votre candidature !
Voir moins",,2024-01-25,https://www.welcometothejungle.com/fr/companies/doctrine/jobs/data-engineer-italy_paris?q=32e055701e531e6d24ece135164a734a&o=738abeb3-5738-4625-9d42-786109babe4c,wttj
Fullstack Data Engineer,"{'name': 'DOCTRINE', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Service juridique', 'employees': '120 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Notre mission ⚖️
Nous nous engageons pour un enjeu démocratique majeur : rendre le droit plus accessible et transparent aux justiciables et aux professionnels du droit.
Doctrine est la première plateforme d'intelligence juridique. Nous centralisons et organisons toute l'information juridique disponible pour permettre aux avocats et juristes de mieux conseiller et défendre leurs clients. Plus d'un million de personnes viennent tous les mois sur Doctrine se renseigner sur leurs droits, et déjà 12 000 professionnels du droit nous font confiance.
Nos valeurs 🤝
Challenge the status quo. Nous défendons les idées audacieuses et la prise de risque intelligente.
Liberty and responsibility. Nous promouvons l’autonomie, l’impact de chacun·e et l’ownership.
Knowledge is power. L'information est au cœur de la mission de Doctrine, et nous voulons toujours apprendre plus.
Release early, release often and listen to your customers. Nous croyons au pouvoir de l’itération et à l’importance d’écouter en permanence notre marché, nos client·e·s et leurs problématiques.
Le contexte
Nous recherchons un data engineer fullstack confirmé pour nous aider à construire des pipelines de traitement de documents en quasi temps réel. Tu verrais le cycle complet des données, depuis le moment où les documents sont fournis par l’utilisateur jusqu’aux modèles de machine learning qui les analyseront ensuite.
Tu rejoindrais la squad “Productivity” dont la mission est de révolutionner la manière dont travaillent les professionnels du droit en proposant des outils de productivité qui simplifient l’analyse et la rédaction de documents juridiques privés. Productivity est une nouvelle ligne de produit qui se développe chez Doctrine, où tout reste à construire !
Notre stack technique est basée sur Python, React, NodeJS, NextJS, NestJS.
Tu peux trouver des détails sur l’ensemble de la stack sur Github 
A savoir : il n’est pas nécessaire d’avoir une expérience professionnelle dans le domaine du droit, cependant l’envie de s’investir et de monter en compétence dans la compréhension des documents juridiques est importante :)
Les missions 🛠
Concevoir, développer, monitorer des architectures de pipelines et de services backend pour le traitement de données en quasi temps réel, utilisées pour tous types de documents juridiques.
Designer et implémenter des interfaces adaptées à l’acquisition des documents et à la présentation des résultats des analyses.
Travailler main dans la main avec des product managers, des designers, des ingénieurs fullstack et machine learning en charge des parties équivalentes de leur côté.
Participer à la diffusion interne et à la consolidation de nos bonnes pratiques ; contribuer à l’élaboration de notre stratégie Engineering.
Le profil idéal 👀
Une large expérience des pratiques d'acquisition et de modélisation des données.
Une bonne connaissance de SQL, Elasticsearch et du stockage objet.
De bonnes compétences en programmation Python.
Une bonne connaissance de NodeJS, TypeScript, React, NextJS, NestJS, ou d’autres frameworks frontend et backend.
De l’intérêt pour la qualité du code et pour les bonnes pratiques de développement en général (p. ex. tests, CI/CD) ; l’ambition de livrer des applications avec une haute fiabilité et une haute disponibilité.
Un fort intérêt pour les aspects produit, la compréhension du besoin utilisateur, et l’envie de contribuer à la définition de ce qu’on construit !
Les à côtés du poste 👁
Comme tous les ingénieurs de Doctrine, tu participeras à nos chapters transverses, en l’espèce les chapters Web et Data Engineering. Au sein de ces chapters, tu contribueras à des projets internes pour améliorer nos process et notre vision long-terme. Le chapter se réunit toutes les deux semaines pour :
🤝 Partager des connaissances : amélioration continue, bonnes pratiques,…
🎯 Proposer des évolutions : nouveaux outils à expérimenter, nouveaux process à mettre en œuvre
Tu participeras également au 👩‍💻 recrutement : tous les contributeurs individuels rencontrent des candidats à l’occasion de tests techniques ou d’entretiens.
Ce qui t'attend si tu rejoins Doctrine 🤗
- Contribuer à un projet ambitieux, avec un impact réel et positif sur la société : rendre le droit plus accessible et plus ouvert.
- Un accompagnement sur mesure dès ton arrivée sur l'écosystème juridique pour t'aider à naviguer très vite dans cet environnement stimulant.
- Une aventure dans laquelle tu apprendras sans cesse et partageras tes connaissances à l’ensemble de tes collègues (talks internes/externes, meetups, Tech & Sales Monthly, blog Medium, etc.)
- Travailler au sein d’une équipe en ébullition qui cherche sans cesse à se renouveler : de la place pour innover et mener des projets en autonomie ou en équipe.
Nos avantages pour faire la différence ☀️
🏡 Une politique de télétravail flexible, avec 2 jours de présence au bureau par semaine (mardi et jeudi)
🌱 De nombreuses options pour ta carrière, et des mobilités internes ouvertes à toutes et tous chez Doctrine
🌴 Des vacances flexibles et illimitées
📚 Un vrai accent sur la formation individuelle et collective, avec un budget annuel de 750€ en usage libre et des formations en équipe et pour toute l'entreprise régulièrement
🏄‍♂️ Des évènements collectifs réguliers
👩‍⚕️ Une bonne assurance santé avec Alan
🚲 Un forfait mobilité durable à hauteur de 66 euros par mois
🏋️‍♀️ Un abonnement Gymlib pour les activités sportives et bien-être
🍱 Une carte Swile pour tes tickets restaurants
🧘 Un accès gratuit à la plateforme d'accompagnement à la santé mentale Moka.care
💡 Des centaines de réductions et avantages négociés grâce à notre CSE
🍏 Un équipement de travail neuf chez Apple
Notre processus de recrutement 🚀
- Un premier échange de 30 min avec l’un.e de nos Talent Acquisition Manager pour bien comprendre ton projet professionnel et te présenter ce qu'on construit chez Doctrine
- Une rencontre d’1h avec ton/ta futur.e manager, pour détailler le poste et le scope de l’équipe, mais aussi répondre à toutes tes questions.
- Un ou deux tests techniques pour évaluer concrètement tes compétences
- Un déjeuner avec 3 personnes de différents départements chez Doctrine, pour te donner un aperçu de tes futur.e.s collègues
- Un échange sur les valeurs de l’entreprise pour te partager notre vision
- Une rencontre avec Guillaume, notre CEO.
(si nécessaire le processus pourra être adapté pour répondre à tes contraintes personnelles et professionnelles)
Mesdames, autorisez-vous à candidater !
Certaines études scientifiques montrent qu'en particulier les femmes ont moins tendance à postuler à une offre d'emploi quand elles n'ont pas toutes les qualifications. Si cela peut vous rassurer, sachez que cette fiche de poste est indicative donc prenez la comme telle : c'est un guide, ni plus ni moins.
Si Doctrine vous intéresse, sachez que nous aurons plaisir à recevoir votre candidature !
Voir moins",,2024-01-25,https://www.welcometothejungle.com/fr/companies/doctrine/jobs/fullstack-data-engineer_paris?q=32e055701e531e6d24ece135164a734a&o=12b461d8-aa10-4cbe-9aa1-388256d0b308,wttj
Data Engineer (Stage Mars 2024) - H/F,"{'name': 'SHOWROOMPRIVE.COM', 'sector': 'Application mobile, Mode, E-commerce', 'employees': '1050 collaborateurs', 'creation_year': '2006', 'turnover': '697.5M€', 'mean_age': '33 ans'}",Stage,Saint-Denis,Non spécifié,Télétravail fréquent,,> 6 mois,,"Descriptif du poste
Au cœur du pôle Data de Showroomprive, vous intègrerez l’équipe « Data Engineering».  
Vos missions seront axées autour de l’extraction, du traitement et du stockage de la donnée via le maintien et l’évolution d’un Datawarehouse utilisé par le reste des équipes Data (BI, Data Science, Marketing analyst).  
Vos missions se découperont en deux parties :  
Un projet principal à réaliser de A à Z autour de la donnée, de son traitement, de son contrôle ou encore de son accessibilité.  
Les taches du quotidien de l’équipe (développement de nouveaux flux, exports de données métier, requêtes ad hoc, gestion d’accès…). 
Pour mener à bien ses missions, notre équipe utilise des outils à la pointe du marché en matière de traitement de la donnée grâce à Airflow pour le pipeline et à l’utilisation d’une plateforme cloud leader du marché. 
Vous intégrerez une équipe Data Engineering de 4 personnes qui vous accompagneront au quotidien pour mener à bien vos missions, mais aussi un service Data de 20 personnes aux compétences diverses et pointues dans leurs domaines. ","Profil recherché
En fin de formation supérieure (Bac+5) de type Ecole d’Ingénieurs ou formation universitaire équivalente dans une filière liée à la Data ou au Software Engineering. 
Dans le cadre de vos études ou d’une expérience précédente, vous avez pu acquérir de solides bases en SQL et Python. Vous avez aussi développé une réelle appétence à découvrir par vous-même et vous êtes très curieux lorsqu’il s’agit de Data. 
Votre rigueur et votre dynamisme constitueront des atouts clés dans la réussite des missions qui vous seront confiées. ",2024-01-25,https://www.welcometothejungle.com/fr/companies/showroomprive/jobs/data-engineer-stage-mars-2024-h-f_saint-denis?q=32e055701e531e6d24ece135164a734a&o=77df743c-80bb-4e3d-abca-309e2aef5b61,wttj
Data Engineer - Energie - Ile-de-France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Courbevoie,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail : 
La division « Energie » accompagne les grands acteurs du secteur en France dans les domaines de la production et de la distribution thermique, hydraulique et nucléaire. Dans un contexte agile, nos équipes d'experts participent à des projets autour de la transformation numérique pour conduire nos clients vers une transition écologique.
Le défi que nous vous proposons de relever ? Mettre l'énergie au service des Smart Grid & Cities !
Sous la responsabilité d'un directeur de la Business Unit Energie, vous participez aux principaux grands projets de transformation numérique de ses secteurs.
Acteur majeur de l'avant-vente jusqu'à la livraison du produit final, vous intervenez sur un périmètre large, au sein d'un environnement technique innovant
Votre rôle et missions : 
Au sein d'une équipe Agile, accompagné par un chef de projet, en tant que Data Engineer et dans le cadre de nos projets de data management dans le secteur de l’énergie, vous intervenez dans le cadre de développement de projet BI (incluant la réalisation de datamarts, cubes ou rapports) complexes et à forte valeur ajoutée (Pilotage des trains, reporting financier, gestion des conducteurs). Votre rôle est donc prépondérant dans la réussite du projet.
Vous intervenez sur toute la chaîne de valeur du cycle projet :
- Vous rédigez des spécifications fonctionnelles générales ou détaillées sur la base d'expression de besoins
- Vous participez à la conception et au développement des applications Big Data, les tester, les faites évoluer et assurer leur maintenance.
- Vous assurez l’intégrité et la qualité de la donnée sur tout le processus d’ETL
- Vous industrialisez et optimisez la gestion des flux de données
- Vous participez à la conception de l’architecture et l'infrastructure de nos systèmes de collecte et de traitement des données.
- Vous pilotez et accompagnez les utilisateurs durant les phases de recette
- Vous accompagnez des key users et des utilisateurs finaux dans l'usage des nouveaux rapports (formations, support...)
- Vous contribuez à l'amélioration du reporting et du pilotage de la performance.
Grâce à votre excellent esprit collectif vous avez à cœur de partager votre savoir et contribuer à la progression des membres de l'équipe.
Environnement technologique riche : Talend, Power BI, Cloud computing, Java, Python, PostgreSQL, Cloudera, Spark...
 Informations supplémentaires
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. 
Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord
d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherché
Diplômé(e) d'une école d'Ingénieurs ou équivalent, vous justifiez d'une expérience technique de 3 ans minimum et souhaitez évoluer rapidement dans un contexte motivant.
Vous avez au moins l'une de ces compétences requises :
· Maîtrise des technologies de bases de données Relationnelles et NoSQL
· Maîtrise des technologies de traitement distribué de données (spark, Hadoop)
· Maîtrise d’au moins un framework de streaming de données (Kafka, RabbitMQ, etc.)
· Maîtrise de chaines CI/CD et de des bonnes pratiques de DataOps
· Maîtrise de solution de Virutualisation de données (Denodo, Dremio, etc.)
· Maîtrise d’au moins un environnement cloud public ou privé (Azure, AWS, Outscale, etc.)
Vous êtes attiré(e) par le monde du numérique, le Cloud et des technologies innovantes.
Vous avez un bon esprit d'analyse, êtes curieux(se) et passionné(e) et vous avez le sens du travail en équipe.",2024-01-25,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-energie-ile-de-france_courbevoie_SS_rqVwOGG?q=32e055701e531e6d24ece135164a734a&o=969c7a61-5d15-4046-bde0-32f720ef83d6,wttj
Data Engineer - Azure & Informatica IICS internship (H/F),"{'name': 'TATA CONSULTANCY SERVICES', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '615000 collaborateurs', 'creation_year': '1968', 'turnover': '$ 28 milliards', 'mean_age': None}","Stage
(4 à 6 mois)",Suresnes,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
We are seeking a highly skilled, proactive, and communicative Data Engineer with expertise in Azure and Informatica Intelligent Cloud Services (IICS) to join our IT team. The candidate will be responsible for designing, implementing, testing, and maintaining data ingestion pipelines. This role is crucial for transforming raw data into actionable insights for our international projects involving stakeholders from multiple countries. Fluent English communication skills are essential for this role.
Your missions:
Data Ingestion and Transformation
·       Help Architects & Tech Leads design and implement data ingestion pipelines using Azure services and Informatica IICS.
·       Transform raw data from various sources into a clean and structured format for analytical purposes.
Data Testing
·       Develop and execute test cases to ensure data integrity and quality.
·       Work closely with data analysts and senior data engineers and architects and Data Asset Owners to validate data sets for analytics.
Maintenance and Optimization
·       Monitor data pipelines and perform troubleshooting to ensure optimal performance.
·       Continuously improve existing codebase for scalability and maintainability.
Collaboration and Communication
·       Collaborate with cross-functional teams, including Project Management, Business Analysts, and Data Scientists.
·       Communicate effectively with international stakeholders to understand data requirements and deliver accordingly.
·       Fluent in English to ensure clear and effective communication across all levels of the organization.
Project Management and Reporting
·       Proactively update the Azure Board each day to track the progress of data engineering tasks.
·       Generate regular reports on data pipeline performance, issues, and resolutions.
Documentation
·       Create and maintain technical documentation for data pipelines, code, and data dictionaries.
·       Train end-users and technical staff on new data pipelines and transformations.
Voir moins","Profil recherché
Bachelor’s or Master’s degree in Computer Science, Engineering, or a related field.
·       Strong expertise in Azure Data Services like Azure Data Lake, Azure SQL Database, Azure Data Factory, etc.
·       Proficient in Informatica Intelligent Cloud Services (IICS) for data integration.
·       Familiarity with data modeling, data warehousing, and ETL processes.
·       Strong programming skills in Python, SQL, or other data-related languages.
·       Excellent problem-solving skills.
·       Strong communication skills, both written and verbal, with the ability to work in a collaborative team environment.
·       Proactive mindset with a focus on continuous improvement.
·       Fluent in English.
If you have strong interest in Digital Technologies, and if challenges are part of your DNA, so join us!",2024-01-24,https://www.welcometothejungle.com/fr/companies/tata-consultancy-services/jobs/data-engineer-azure-informatica-iics-internship-h-f_suresnes?q=32e055701e531e6d24ece135164a734a&o=a2adebd4-1351-4cee-8249-f3c0f97fe457,wttj
Data Engineer (H/F),"{'name': 'EKKIDEN TECHNOLOGIES', 'sector': 'IT / Digital, Transformation', 'employees': '230 collaborateurs', 'creation_year': '2019', 'turnover': '12 millions of euros', 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Le rôle : Data Engineer (H/F)Vous ferez partie d'une équipe SCRUM et vous vous focaliserez sur des fonctions spécifiques. Votre rôle sera de contribuer aux projets data, en apportant votre expertise technique.
Responsabilités :

Vous participerez activement aux différents projets métiers, en assurant leur réalisation.


Vous prendrez en charge les corrections nécessaires suite aux incidents ou anomalies.


Vous contribuerez à l'auto-formation et à l'accroissement des compétences au sein de l'équipe de développement.


Vous appliquerez les meilleures pratiques de développement et les normes associées.


Vous mettrez en œuvre les méthodes ""devops"".


Vous participerez aux chiffrages des usages ainsi qu'à la constitution des releases.


Vous travaillerez sur l’automatisation du delivery.


Vous développerez et documenterez votre code.


Vous collaborerez avec l’équipe SCRUM, incluant le Product Owner, les développeurs, les QA et le support.


Ce que nous recherchons :
Compétences techniques :

Vous disposez d'un diplôme Bac+5 en informatique ou équivalent, avec au moins 3 ans d'expérience en tant que Data Engineer.
Vous avez de l'expérience dans l'architecture de systèmes distribués Big Data.

Vous maîtrisez Scala ou Java, avec une expérience obligatoire dans l'un de ces langages.


Vous connaissez l'écosystème Big Data, incluant Hadoop, Spark, Apache Kafka, Avro, etc.


Vous maîtrisez les processus de CI/CD et les outils de déploiement et orchestration tels que Jenkins, GitLab, Kubernetes, Docker, Ansible.


Vous comprenez les concepts fondamentaux de Kafka.


Vous avez de l'expérience avec les bases de données NoSQL comme Cassandra ou BigTable.


Vous possédez des compétences en Kafka-Stream, une familiarité avec la Google Cloud Platform, et la pratique du Software Craftsmanship est valorisée.
Ce que nous proposons :
🤝 Nous rejoindre au bon moment pour faire ta place au sein d'une organisation en très forte croissance 
🚀 Des missions variées dans un environnement challengeant qui te permettront d'avoir un réel impact sur la boite
💪 La possibilité de travailler de façon autonome et d'être force de proposition pour grandir ensemble 
✨ Un parcours de carrière adapté à ta personnalité, aussi bien au niveau du rôle que de la localité 
👍 Une formation exigeante en continu pour libérer tout ton potentiel
🙌 Des conditions de travail flexibles (horaires, télétravail, …)
👩 Une culture de la performance avec de belles primes de résultats
❤️ Une mutuelle très complète (Alan) et des titres-restaurant (carte Swile)
Voir moins",,2024-01-23,https://www.welcometothejungle.com/fr/companies/ekkiden/jobs/data-engineer-h-f_paris?q=32e055701e531e6d24ece135164a734a&o=91086205-d871-4b6b-a81a-befb1bf33ef8,wttj
Data Engineer / Data Scientist Média,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spécifié,Télétravail occasionnel,12 février 2024,> 6 mois,Bac +5 / Master,"Descriptif du poste
MP DATA, recrute un Data Engineer afin de travailler pour notre client dans le secteur des Médias :
Vos missions seront les suivantes :
Renforcer notre connaissance 360 de nos clients/utilisateurs (segmentation, enrichissement, activation de la donnée…),
Superviser les alimentations de production grâce aux outils (AirFlow…),
Développer l’offre de ciblage publicitaire en TV segmentée,
Gestion et maintenance de l’offre,
⁠Apport d’une expertise sur l’offre de ciblage afin d’améliorer les recommandations,annonceurs/agences,
Travailler avec les Data Scientists à la mise en œuvre des modèles statistiques et algorithmiques,","Profil recherché
De formation Bac+5 (ou plus) en développement informatique / Data Engineering, vous justifiez d’une expérience professionnelle significative dans le secteur de la Publicité au cours de laquelle vous avez pu développer les compétences techniques suivantes :
Python
SQL
Pyspark
Streaming",2024-01-23,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-experimente_boulogne-billancourt_MD_r6VDXr?q=32e055701e531e6d24ece135164a734a&o=b49e3479-7796-41c7-bf16-d55ab6cae3c1,wttj
Data Engineer / Fullstack Data (Sénior),"{'name': 'HIBOO SYSTEMS SAS', 'sector': 'SaaS / Cloud Services', 'employees': '38 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spécifié,Télétravail total,,> 5 ans,,"Descriptif du poste
Nos valeurs
Nous avons défini notre Tech manifesto pour nous apporter de la clarté et un guide dans nos décisions. Pour en reprendre les grand thèmes :
Collaborative Minds over Solo Efforts
Engaged Accountability over Passive Compliance
Continuous Delivery over Perfectionism
Continuous improvement over Stagnation
Human-oriented Code over Machine-only Code
Done Means Live
Pourquoi nous rejoindre ?
Une équipe Tech réellement remote (La Réunion 🏝, Briançon 🧗‍♀️, Bordeaux 🍇, Béziers 🏖️, Tours 🏰, Paris 🥖…)
Une équipe expérimentée et qui cherche à s’améliorer (Dojos, Pair/Mob Programming, DDD, Clean Architecture, Tech meetup interne…)
Des défis technologiques importants : Collecte et traitement de données, Gestion de multiple sources de données, Analytics, Rapports et valorisation des données…
L’équipe tech n’est pas simplement “exécutante” mais pleinement empowered
Rémunération basée sur les compétences et pas la géographie
Une dimension écologique (Aider les industriels à mesurer leur impact et le réduire 🌿)
Voir moins","Profil recherché
En tant que Data Engineer chez Hiboo, tu seras en charge de la conception, du développement, de la maintenance et de l’optimisation des infrastructures de données. Cela implique :
Le développement des outils et des traitements permettant la migration de l’ingestion de nos différentes sources de données vers une architecture orientée big data
La construction de pipeline de données (batch et temps réel) permettant d’alimenter notre application, nos APIs, nos analytics et nos projets de data-science
Au quotidien, tu interviendras donc sur le déploiement et le monitoring des briques techniques nécessaires à l’infrastructure data d’Hiboo (plateforme d’ingestion, datalake, calcul distribué) mais également du code de collecte, structuration, mise en qualité, documentation et mise à disposition de la donnée. Tu contribueras également activement aux décisions concernant les choix produit et techniques, en lien avec le reste de l’équipe.
Voir plus",2024-01-23,https://www.welcometothejungle.com/fr/companies/hiboo/jobs/data-engineer_paris?q=32e055701e531e6d24ece135164a734a&o=37e549b3-22a6-408b-97e6-14f0d77a11b1,wttj
DATA ENGINEER (Azure Data Factory/MSBI Stack) H/F,"{'name': 'TREND-IT', 'sector': 'Logiciels', 'employees': '25 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '28 ans'}",CDI,Paris,50K à 70K €,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Nous recrutons un consultant BI confirmé ou senior pour travailler sur des projets de grande envergure avec des intervenants hautement qualifiés.
Le candidat doit comprendre et analyser les besoins de nos différents clients et partenaires, le tout se fait en équipe et dans un contexte d’agilité.
Il sera épaulé par le tech lead pour réaliser des audits permettant d’analyser la situation actuelle.
Il mettra à profit ses expériences antérieures pour établir une stratégie avec un plan d’actions avec les autres consultants de l’équipe BI.
Il travaillera sur des projets complexes à haute valeur ajoutée pour des clients grands comptes.
Les responsabilités
Analyser les besoins fonctionnels.
Localiser les données de production.
Déterminer les spécifications techniques.
Définir l’architecture.
Modéliser les datawarehouse (entrepôts de données) et les datamarts (magasins de données) dédiés à une fonction particulière dans l’entreprise.
Accompagner le client dans la réalisation du projet.
L’équipe
Vous rejoindrez l’équipe BI qui est composée d’ingénieurs et des alternants avec des spécialisations différentes mais complémentaires : Ingénieur SSIS/ADF, consultant Power BI, data engineer et des ingénieurs MSBI/ADF qui travaillent sur toute la chaîne décisionnelle.
Vous travaillerez suivant une méthodologie agile avec un PO Data et un consultant DevOps.
Voir moins","Profil recherché
Nous recherchons un Ingénieur BI confirmé ou senior sur la suite Microsoft BI et le Cloud Azure pour un poste en CDI.
Vous justifiez de 5 ans d’expérience ou plus, dans un environnement Microsoft et vous avez travaillé sur des projets from scratch.
Stack technique :
MSBI( SSIS, SSAS, SSRS)
Power BI
SQL Server : Suivi performance (Charge serveur/Optimisation/Log…)
Azure Data Factory
Savoir faire :
Rigueur
Esprit de synthèse
Capacités d’analyse
Autonomie
Maîtrise de l’anglais
Voir plus",2024-01-23,https://www.welcometothejungle.com/fr/companies/trend-it/jobs/data-engineer-azure-data-factory-msbi-stack-h-f_paris?q=32e055701e531e6d24ece135164a734a&o=46d0c0bc-e2c4-4850-8b31-79c051de4d83,wttj
Stage - Data Engineer,"{'name': 'NUMBERLY', 'sector': 'Logiciels, Digital Marketing / Data Marketing, Big Data', 'employees': '500 collaborateurs', 'creation_year': '2000', 'turnover': None, 'mean_age': '27 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Numberly recherche un(e) Data Engineer en stage pour rejoindre son équipe dédiée aux problématiques Data. Vous participerez aux traitements, transformations et restitutions des données auprès des équipes internes afin d’améliorer les performances des campagnes et des stratégies marketing de nos clients.
Vous :
Aimez la donnée sous toutes ses formes : brute, travaillée et analysée ;
Avez le désir de la comprendre et de la faire parler ;
Possédez une formation axée sur la big data, la fouille de données ou plus généralement en software engineering;
Appréciez le travail bien fait, avez le sens du détail et vous aimez comprendre les problématiques de vos clients ;
Aspirez à travailler pour des clients variés et prestigieux sur des problématiques pointues ;
Êtes à l’affût des nouveaux langages/technologies et des dernières tendances open source;
Êtes spontané(e) et appréciez le travail en équipe en collaborant avec différents métiers de la data;
Portez de l'intérêt au Marketing et souhaitez découvrir ce domaine.
 Stage de 6 mois débutant en février 2024.
Rémunération : 1400 € brut mensuel en M1 et 1700 € brut mensuel en M2.
 Voir moins","Profil recherché
Vous connaissez :
Modélisation
SQL 
Python
ETL
 Encore mieux si vous connaissez :
Workflows management platforms
Environnement Hadoop
Systèmes et calculs distribués
API REST, Web Services
Realtime / Streaming
Docker
 Ce que nous utilisons :
Voir plus",2024-01-22,https://www.welcometothejungle.com/fr/companies/numberly-1000mercis/jobs/stage-data-engineer_paris_NUMBE_QokZ29z?q=32e055701e531e6d24ece135164a734a&o=9258bf1e-a003-452f-a5bc-12661590c2a8,wttj
Data Engineer (F/H),"{'name': 'STACK LABS', 'sector': 'Application mobile, IT / Digital, SaaS / Cloud Services', 'employees': '40 collaborateurs', 'creation_year': '2017', 'turnover': '5M€', 'mean_age': '33 ans'}",CDI,,45K à 70K €,Télétravail fréquent,02 avril 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
Pour renforcer notre équipe Data et accompagner notre croissance, nous recherchons actuellement un Data Engineer, avec une appétence pour les solutions Cloud.
De part votre métier, vous serez amené(e) à intervenir dès les phases amont de projets de migration cloud pour des clients à forts enjeux de scalabilité sur du conseil technique et sur les fondamentaux du cloud public (sécurité, observabilité, réseau, billing, automatisation) jusqu’à la mise en service des solutions.
Reconnu(e) pour votre polyvalence au sein des équipes, vous êtes orienté(e) aussi bien vers la sphère technique que vers l’Humain. Vous participez notamment à :
L’audit de configuration cloud de client et des préconisations d’amélioration.
Proposition d’architectures data cloud native (GCP/AWS)
La mise en place d’entrepôts de données massivement scalable avec BigQuery, Redshift, MongoDB, Athena, CloudSQL, Firestore…
Le développement de pipelines de traitement de données avec Spark, Dataflow, PubSub, SQS…
L’analyse des données et leur mise à disposition de processus de Data science (Machine Learning)
L’onboarding de clients sur les bonnes pratiques et la philosophie cloud et devops.
La mise en place des bonnes pratiques d’automatisation (CI/CD, GitOps)
La conduite du déploiement, de l’intégration et du passage en opération de la solution
Notre écosystème technique (indicatif, variable en fonction des missions) :
Architecture Data : ETL, ELT, Dataflow, Spark, Airflow, GCP Workflows
Big Data: BigQuery, Firestore, Redshift, Athena, MongoDB
Containers & microservices : Docker, Kubernetes, Istio,…
Architectures orientées messages : Kafka, PubSub,..
Automatisation & Infrastructure as Code (IaC) : Terraform, CloudFormation, Ansible, GitLab, GitHub,…
Public Cloud : AWS, GCP, …
Langages de développement : Python, Go, Java…
Voir moins","Profil recherché
Vous disposez de plusieurs expériences en tant Data Engineer, notamment dans la mise en place de pipelines et le traitement automatisé des données. Vous avez une vraie appétence pour les technologies Cloud, et de l’expérience sur au moins un fournisseur Cloud.
Moteur au sein des équipes, vous êtes naturellement tourné(e) vers la proactivité, le partage et la bienveillance. Plus qu’un profil type, nous recherchons chez Stack Labs des personnes proches de notre ADN : passionnées de tech, curieuses et disposant d’une véritable “soif d’apprentissage”.",2024-01-22,https://www.welcometothejungle.com/fr/companies/stack-labs/jobs/data-engineer-f-h_toulouse?q=32e055701e531e6d24ece135164a734a&o=3141ea44-2b7d-442a-9640-f2962666ec45,wttj
Data Engineer - BORDEAUX H/F,"{'name': 'CAPGEMINI', 'sector': 'IT / Digital, Organisation / Management, Stratégie, Transformation', 'employees': '360000 collaborateurs', 'creation_year': '1967', 'turnover': '18 Mds €', 'mean_age': '37 ans'}",CDI,Bordeaux,Non spécifié,Télétravail non autorisé,,> 2 ans,Bac +5 / Master,"Descriptif du poste
VOTRE RÔLE
  Vous êtes passionné.e par le domaine de la DATA et vous souhaitez prendre part à un projet d’envergure dans le secteur Telecom ? Rejoignez notre équipe Hybrid Intelligence au sein de Capgemini Engineering en tant que DATA Engineer.
  Vous avez acquis une expérience solide dans le développement de pipelines de données et de solutions pour le traitement d'un grand volume de données. Vous êtes capable de créer des solutions qui répondent aux besoins de différentes parties prenantes telles que les spécialistes de la visualisation de données, les scientifiques de données et les analystes de données.
  En qualité de DATA Engineer, vos missions seront les suivantes :
▪ Concevoir et développer des solutions Data/IA à des fins analytics & dashboarding
▪ Accompagner les Métier dans la compréhension des Analytics et mise en œuvre de solution ""data driven""
▪ Collaborer avec les data scientiste et data ops dans la construction d'une culture axée sur les données
▪ Gérer un écosystème de partenaires data science et assurer un haut niveau d'expertise
▪ Assurer un rôle de veille technologique sur tous les outils autours de la data, IA et BI.


Voir moins","Profil recherché
Profile description:

VOTRE PROFIL
 Vous êtes issu.e d’une formation Ingénieur ou équivalent Bac + 5 Informatique spécialisé en DATA et vous justifiez d’une expérience réussie dans le domaine du développement de pipelines de données et de solution Data (5 ans min).
 Vous maîtrisez les technologies informatiques pour manipuler des bases de données de type : Oracle, Postgre, NoSQL,.. et framework : Hadoop, Spark, Hive, Oozie, Nifi, Jupyter, Kafka , … Votre maîtrise des langages : SQL, SCALA, Pyhton, JAVA, Shell…vous permettent d’être autonome sur la manipulation de données. Enfin, vous avez acquis une expérience dans les outils BI, data visualisation : Kibana, Qliksense, Power Bi… La maitrise de l’Anglais est nécessaire pour ce poste.




Voir plus",2024-01-22,https://www.welcometothejungle.com/fr/companies/capgemini/jobs/data-engineer-bordeaux-h-f_bordeaux?q=32e055701e531e6d24ece135164a734a&o=d6951a37-3524-45fd-9d84-87372f9ee091,wttj
Data Engineer - H/F,"{'name': 'FREEBOX', 'sector': 'Logistique, Electronique / Télécommunications', 'employees': '60 collaborateurs', 'creation_year': '2000', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,Sans diplôme,"Descriptif du poste
Située dans le 8e arrondissement de Paris, Freebox est la filiale R&D d’Iliad qui développe les produits triple play Free (décodeurs tv, servers et répéteurs). 
Le Data Engineer intégrera l’équipe Data Freebox. 
Pour valoriser les données nécessaires à l’amélioration et la conception des Freebox, tes missions seront les suivantes : 
Concevoir, développer, mettre en production et gérer les pipelines de streaming pour la transformation et ingestion de données dans Bigquery 
Gérer et faire évoluer l'architecture de la plateforme Data sur GCP
Automatiser en production le déploiement et l’exécution de la plateforme Data
Montrer et mettre en place des indicateurs de contrôle sur la plateforme Data 
Qui sommes-nous ? 
Depuis 20 ans, Freebox a gardé un fort esprit entrepreneurial. Nos 60 collaborateurs conçoivent, développent et industrialisent les produits utilisés par nos 7 millions de foyers d’abonnés.
Chez Freebox, la volonté de tout faire en interne permet à chaque collaborateur d’avoir un poste complet avec beaucoup d’autonomie. Avec peu de hiérarchie, chacun a une véritable valeur ajoutée dans son équipe et un impact réel sur les projets auxquels il participe. 
Entouré(e) d’experts, tu trouveras ta place chez Freebox si tu as un intérêt pour les nouvelles technologies et que tu aimes faire évoluer tes compétences techniques.
Ce que nous te proposons : 
Un environnement avec une forte culture tech et des projets à la hauteur de tes ambitions
De rejoindre une entreprise et une équipe à taille humaine 
Un environnement de travail unique au cœur de Paris
Un cadre social agréable et adapté (télétravail partiel, RTT, prise en charge des repas, etc.)
Etc. 
Ta future équipe : 
L’équipe Data est chargée d’accompagner l’innovation Freebox en imaginant et délivrant les outils et analyses autour de la donnée. 
Tes collègues : 
Un product manager
Une Data Analyst
Tu rejoindras une équipe transverse qui travaille en collaboration étroite avec les équipes produits R&D (set-top-box, gateway, Wi-Fi et applications).
Voir moins","Profil recherché
Expérience :
Tu as 7 ans d’expérience en tant que Data Engineer. 
Compétences : 
Maîtriser les langages/framework suivants : Java (Apache Beam en streaming) et Python (Flask)
Automatisation (Ansible, Shell Linux, Gitlab-CI, Docker)
GCP - BigQuery, Dataflow (Apache Beam en streaming), Cloud Run, Pub/Sub, Agipgateway, Memorystore (Redis)
Bonus :
Expérience sur kafka et kafka-stream
Tu trouveras ta place chez Freebox si tu :
Collabores avec toutes les parties prenantes afin d’identifier les nouveau besoins et de répondre aux retours d’expérience sur l’usage de la plateforme Data,
Es capable de comprendre l’utilisation des données et de t’informer sur les roadmaps des équipes pour identifier leurs futurs besoins.
Voir plus",2024-01-22,https://www.welcometothejungle.com/fr/companies/freebox/jobs/data-engineer-h-f_paris?q=32e055701e531e6d24ece135164a734a&o=1899390d-14a8-4f50-9eb5-5a1c6f623989,wttj
Senior Data Engineer (F/M/D) - Paris,"{'name': 'VESTIAIRE COLLECTIVE', 'sector': 'Luxe, Mode, E-commerce', 'employees': '800 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': '34 ans'}",Autres,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Vestiaire Collective is the leading global online marketplace for desirable pre-loved fashion. Our mission is to transform the fashion industry for a more sustainable future by empowering our community to promote the circular fashion movement. Vestiaire was founded in 2009 and is headquartered in Paris with offices in London, Berlin, New York, Singapore and Hong Kong and warehouses in Tourcoing (France), Crawley (UK), Hong Kong and New York.
We currently have a diverse global team of 700 employees representing over 50 nationalities. Our values are community, activism, transparency, dedication and greatness. We are proud to be a BCorp.
Senior Data Engineer (F/M/D)
Full-time, Permanent role based in Paris
About the role
Vestiaire Collective is hiring a Senior Data Engineer on our data platform team, to play a crucial role in developing and enhancing our data infrastructure, driving Vestiaire Collective's mission towards a sustainable fashion industry.
What you'll do
Real-Time Data Processing
Create real-time data processing applications, leveraging Kafka for timely data availability.
Ensure high throughput and low latency in data processing/service.
Data Platform Architecture:
Design and evolve our data platform's architecture for scalable, efficient data processing and analytics.
Participate in strategic planning for long-term alignment with business goals
Data Integration and Modeling
Implement robust, scalable data integration strategies.
Optimize data models for efficient storage, retrieval, and analytics.
Building ML Platform Ecosystem
Collaboratively develop a scalable, reliable ML platform, focusing on model serving, training, and essential MLOps features.
Prioritize efficiency, automation, and best practices in MLOps.
Workflow Automation
Develop automated solutions to enhance data operations.
Utilize Apache Airflow for effective data workflow management.
Continuous Learning and Improvement
Stay abreast of the latest data engineering trends and technologies.
Foster a culture of continuous learning and knowledge sharing.
Who you are
Concrete knowledge on Real-Time data processing (Apache Spark/Flink, Apache Beam)
Required Skills
Python
Expert in clean, efficient Python coding; proficient with data libraries and web frameworks
Skilled in asynchronous programming.
SQL: Strong in SQL syntax and query optimization.
Kafka:Proficient in Kafka architecture and stream processing.
ML Deployment / Optimization: Experienced in ML model deployment and MLOps principles.
Required Toolings
Spark/Flink (or any other framework): Experienced in distributed data processing
Apache Airflow: Expertise in workflow management.
FastAPI/Robyn: Skilled in FastAPI/Robyn development and features.
Git:Advanced knowledge in version control and CI/CD integration.
Cloud Services: AWS or similar cloud experience.
Data Visualization Tools: Proficient in tools like Streamlit.
Monitoring and Logging Tools: Experienced with tools like DataDog, Prometheus, and Grafana.
Nice to have skills
Terraform/Ansible: Skills in infrastructure automation.
Golang: Experience in Go programming and its ecosystem.
DBT: Proficient in DBT for data warehousing.
What we offer
A meaningful job with an impact on the way people consume fashion and promote sustainability
Flexible work possibilities
The opportunity to do career-defining work in a fast-growing French-born scale up
The possibility to work as part of a globally diverse team with more than 50 nationalities
Two days to help Project - reinforcing your activist journey and volunteer for an association
Significant investment in your learning and growth
Competitive compensation and benefits package
As full member of our entrepreneurial project, you will be eligible to free shares
Vestiaire Collective is an equal opportunities employer
Voir moins",,2024-01-20,https://www.welcometothejungle.com/fr/companies/vestiaire-collective/jobs/senior-data-engineer_paris?q=32e055701e531e6d24ece135164a734a&o=65bf016c-849d-4c53-99e8-12d97e2d3a3d,wttj
Principal Data Engineer,"{'name': 'OGURY', 'sector': 'Marketing / Communication, Publicité, AdTech / MarTech', 'employees': '521 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Ogury, the global leader in personified advertising, has created a breakthrough advertising engine that delivers comprehensive audience interests, brand performance, privacy protection and sustainability within one technology stack, built and optimised for mobile. Advertisers working with Ogury benefit from fully visible impactful ads, future-proof targeting and unwavering protection. Publishers enjoy the rewards of a respectful user experience, incremental revenues and premium demand with Ogury’s solutions. Founded in 2014, Ogury is a global organisation with 500+ people, including 100 engineers across 16 countries.
About the Role
This is an exciting opportunity to shape the future of Ogury’s data platform, make data available to all teams and enable them to take well-informed data-driven decisions.
The team worked hard in the past months to streamline and optimise our data load and transformation pipelines using Redshift, DBT, Airflow and CI tools (Jenkins). The next challenges ahead of us are:
- Near-real-time data reporting and analytics
- Enabling all engineering teams to load and transform their data
- Enforce the highest standards of data quality and reliability
All this at a truly large scale! Our data lake holds Petabytes of data and we ingest and transform several terabytes per day!
What you will be doing
Define the long-term vision and lead execution of Ogury’s data platform
Be hands-on: build and maintain the data platform from the pipeline itself to the documentation, dictionary, and critical support processes
Identify, design and implement solutions for data processing and governance. Current key areas of improvements include: Near-real-time reporting, end-to-end data documentation and self-service analytics.
Mentor other data engineers, drive excellency and software craftsmanship within the team and across the organization
Evangelize data engineering and architecture best practices in the engineering team, building a data culture based on the highest quality and reliability standards
About you
A high level of professional experience as a Data Engineer, focusing on building scalable data solutions
Strong proficiency in Python and SQL
Significant experience with a cloud provider (AWS preferred)
A track record of building and leading the technical development of large-scale data platforms
Experience with Cloud Data Warehouses or OLAP engines (Redshift, Snowflake, Clickhouse, Ocient, et al)
Strong experience modelling data warehouses and building data pipelines
Experience with Kafka, Airflow and dbt
Team-player, curious, always eager to improve our current tools
A proven track record of mentoring and leading other team members, technically
Keen sense of data as a product and how it can serve the company
Proficiency in English, both written and spoken
#LI-HP1 #LI-Hybrid
Benefits vary by location but you can expect:
Competitive salary with a bonus, paid quarterly.
Health Insurance via Willis Towers Watson.
Flexible approach to working hours and location.
Keeping our Ogurians happy and healthy is a priority for us, so we offer access to both physical and mental health and wellbeing benefits.
Company family mutuelle.
25 days holiday plus an extra 10 days.
Look after your family with a life assurance plan.
Daily lunch voucher.
Modern and collaborative working space in central Paris.
CSE benefits.
At Ogury we are a group of creative thinkers and action-takers that thrive in a diverse and inclusive workplace.
Voir moins",,2024-01-20,https://www.welcometothejungle.com/fr/companies/ogury/jobs/principal-data-engineer_paris?q=32e055701e531e6d24ece135164a734a&o=25dcd752-3a42-4707-bc0a-594b65d590e9,wttj
Stage Data Engineer (H/F/N) – PARIS,"{'name': 'EKIMETRICS', 'sector': 'IT / Digital, Stratégie, Audit, Big Data', 'employees': '400 collaborateurs', 'creation_year': '2006', 'turnover': None, 'mean_age': '29 ans'}",Stage,Paris,"1,8K € par mois",Télétravail fréquent,,,Bac +5 / Master,"Descriptif du poste
Ekimetrics est leader en data science et fournisseur de solutions AI. Depuis 2006, nous utilisons la data science au service de l’optimisation de performance marketing, business et de la transition vers une performance plus durable.
Si vous êtes passionné.e de data, ou de technologie en général, et que vous avez envie d’être acteur.rice de votre avenir professionnel, votre place est sûrement chez Ekimetrics !
📊 Ekimetrics, c'est:
· 400 expert.e.s en data science
· 1000 projets divers et variés pour plus de 350 clients
· 4 bureaux : Paris, Hong Kong, Londres et New York
· 1 milliard de $ de profits générés pour nos clients depuis 2006
· 7000 tonnes de CO2 évitées pour nos clients en 2022
🌱Chez Ekimetrics, nous avons l’ambition d’accompagner nos clients à repenser leur business model, en réconciliant performance économique et objectifs durables, grâce à la data science.
C’est pourquoi nous avons en interne toutes les compétences nous permettant de répondre aux besoins de nos clients : Product Managers, Product Designers, Data Architects, Lead Tech, Data Engineers, DevOps Engineers, Data Scientists.
Vous rejoignez l’équipe Data engineering composée de 30 personnes, dans un environnement de travail stimulant, et participez à plusieurs projets autour de la data science.
Votre rôle dans l’équipe :  
En tant que Data Engineer, vous avez pour missions : 
Concevoir et industrialiser des pipelines de données 
Développer avec des technologies et sur des plateformes data modernes 
Mettre en placedes processus de CI/CD 
Approfondir vos connaissances en Data Engineering et Data Science 
Participer aux activités de R&D (Veille technologique, formations, animation de Meetups, etc.) 
Profil recherché : 
Bac+ 5 Ecole d'ingénieur ou Équivalent 
Première expérience sur des sujets Data (Projet ou expérience professionnelle) 
Expérience dans l’industrialisation d’algorithmes 
Expérience dans un environnement Cloud 
Connaissances avancées en data engineering 
Appétence pour la Data Science. 
🤝 Pourquoi nous rejoindre ?
Rejoindre Ekimetrics, c’est intégrer une entreprise dont les valeurs s’appliquent au quotidien :
· Evoluer dans un environnement type start-up et non traditionnel (#curiosité)
· Être capable de prendre le feedback pour s’améliorer (#excellence)
· Se former dès son arrivée et en continu grâce à une expérience apprenante unique et riche de nombreuses ressources (internes, externes, live et digital) alliant savoirs techniques, savoir-être et savoir-faire (#transmission)
· Faire partie d’une « famille » soudée et unie (#plaisir)
· Imaginer des solutions inattendues & sortir de sa zone de confort (#créativité)
En 2023, Ekimetrics a obtenu le statut d’entreprise à mission qui témoigne de notre ambition forte en matière de RSE. Nous sommes également certifiés Great Place to Work.
🤩 Vous aurez accès à …
· Au catalogue de formation EkiA qui contient des programmes qui vous feront monter en compétences sur nos solutions et nos métiers, des parcours apprenants sur notre plateforme digitale ainsi que des programmes dédiés à nos enjeux prioritaires, dont la sensibilisation aux sujets environnementaux avec la Climate School AXA.
· Une vie sportive, artistique, musicale, ludique, caritative et engagée : de notre salle de sport privatisée à nos expositions d’art, en passant par des jeux vidéo et des concerts, ou encore les défis RSE sur la plateforme Vendredi ;
· De nombreux évènements et séminaires pour rester proche de votre communauté ;
· Des locaux modernes dans un quartier dynamique au cœur de Paris (Grands boulevards)
· Une politique de télétravail flexible.
🔄 Notre processus recrutement
🔸 Un entretien RH
🔸 Un entretien technique
🔸 Un entretien final
Nous serions ravi.e.s de vous donner de plus amples informations lors d’un entretien et attendons votre candidature avec impatience !
En tant qu’employeur, Ekimetrics offre à tous les mêmes opportunités d’accès à l’emploi sans distinction de genre, ethnicité, religion, orientation sexuelle, statut social, handicap et d’âge. Ekimetrics veille à développer un environnement de travail inclusif qui reflète la diversité dans ses équipes.
Voir moins",,2024-01-19,https://www.welcometothejungle.com/fr/companies/ekimetrics/jobs/stage-data-engineer-h-f-n-cdi-paris_paris?q=32e055701e531e6d24ece135164a734a&o=76f3e251-5cce-4454-9436-479435a04ad2,wttj
Data Engineer - Banque Data Factory - Nantes,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Nantes,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Description de l’entreprise
Sopra Steria, l’un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d’édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d’activité et des technologies innovantes à une approche résolument collaborative.
Sopra Steria place l’humain au centre de son action et s’engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 50 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d’affaires de 5,1 milliards d’euros en 2022.
The world is how we shape it.
Description du poste
Votre environnement de travail :
La division « Services Financiers » s’est développée autour des métiers de la banque de détail, de la banque privée et des services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compétences dans les domaines fonctionnels des Crédits, des Risques/Conformité et des Moyens de Paiement.
Si vous êtes passionné(e) par la valorisation de la donnée, rejoignez notre Data Factory localisée à Nantes et les quelques 100 Data Ingénieurs qui la composent. Vous y rencontrerez des experts de la mise en œuvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée.
Vous êtes accompagné(e) au développement de vos connaissances aux travers de différents parcours Data que ce soit pour l’ingestion, la construction de datahub, la transformation et valorisation de la donnée, la modélisation et mise à disposition.
Rejoindre la Data Factory Sopra Steria, c’est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.
Votre rôle et vos missions :
Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expérience et votre appétence pour l’un de nos chapitres Data ci-dessous, vous participez à :
La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analysis ;
La mise en œuvre de solution d’ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;
La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;
Le traitement de la donnée jusqu’à l’exposition au métier ;
La mise en place de la chaine CI/CD et de sa supervision ;
La veille technologie avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d’idéation pour nos clients.
Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, R
Qualifications
Votre profil :
Diplômé(e) d’une Ecole d’ingénieur ou formation équivalente, vous avez déjà participé à un projet Data (Big Data, BI) et vous avez une expérience de minimum 2 ans.
Vous accordez une importance particulière au développement de vos compétences sur plusieurs technologies. Vous souhaitez une évolution réelle de carrière à travers l’expérience projet. Vous êtes soucieux de l’apport de valeur pour vos clients. Et vous voulez transmettre votre savoir auprès de collaborateurs moins expérimentés. Alors, n’attendez-plus, ce poste est fait pour vous !
Informations supplémentaires
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.
Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s’engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L’opportunité de rejoindre le collectif Tech’Me UP (formations, conférences, veille, et bien plus encore…).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
Voir moins",,2024-01-19,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-banque-data-factory-nantes_nantes?q=32e055701e531e6d24ece135164a734a&o=84b419ec-33e9-4577-8d3b-d7254b8bb6b5,wttj
Alternance DATA ENGINEER (H/F),"{'name': 'LINEUP7', 'sector': 'Digital Marketing / Data Marketing, Big Data, Digital', 'employees': '90 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}","Alternance
(12 à 24 mois)",,Non spécifié,Télétravail occasionnel,02 septembre 2024,,,"Descriptif du poste
Au sein de la BU Data Tech, tu interviendras sur différents projets et tu accompagneras nos clients autour de leurs enjeux data et marketing. 
A ce titre, tu seras amené à réaliser les missions suivantes : 
Extraction et transformation de jeux de données (SQL, SparkSQL)
Construction de tableaux de bord / reportings (PowerBI, Apache Superset, autres) pour usage interne et externe (à destination de nos clients)
Participation à la création de nouveaux pipelines de données ou à l’amélioration des pipelines existants (Python, PySpark, Cloud AWS, Git).
Tu seras amené à échanger avec nos chefs de projets pour la prise de brief et le respect du cahier des charges, et accompagné par l’équipe opérationnelle.  
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.","Profil recherché
Master 1 ou 2 issue d’une formation ingénieur IT (école d’ingénieurs, université)
Bonne connaissance d’un ou plusieurs langages de programmation (Python, Java, Scala, C, R)
Connaissances d’un ou plusieurs langages/Framework data (SQL, Park, PostgreSQL)
Connaissances d’un ou plusieurs outils/environnement de travail (Git, PyCharm, Linux, Cloud AWS, JIRA)
Connaissance d’au moins d’un des services AWS (S3, Athena, EMR, RDS, Glue, Redshift, EC2)
Maîtrise de la communication écrite et orale
Niveau professionnel en anglais
Sensibilité à la notion de synergie parmi les métiers autour de la data (tech/marketing)
Capacité d’analyse et de résolution de problèmes
Curiosité, débrouillardise, dynamisme, autonomie, rigueur, esprit d’équipe et bon relationnel.",2024-01-19,https://www.welcometothejungle.com/fr/companies/lineup-7/jobs/data-engineer?q=32e055701e531e6d24ece135164a734a&o=12a1679a-8f74-4b83-af5c-08abe77d00b6,wttj
Data Engineer - F/H,"{'name': 'LYDIA', 'sector': 'Application mobile, Banque', 'employees': '220 collaborateurs', 'creation_year': '2013', 'turnover': None, 'mean_age': '27 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Created in 2013, Lydia quickly became the reference for payment between friends. The French fintech has gained great notoriety for this feature and now has more than 7 million users.In recent years, Lydia has developed other services - pot, current account, common account, savings, credit, investment... to become the daily and complete payment application for millions of French people.
With 250 employees based in Paris, Nantes, Bordeaux and Lyon, Lydia has set itself the task of changing the codes of the bank by offering all the essential services to manage your money on a daily basis through a simple, accessible and enjoyable customer experience.
We are now looking for an experienced Data Engineer to consolidate and improve our GCP Data stack.
What you will do:
Maintain and consolidate our ELT pipeline (Airflow, BigQuery, DBT, PubSub, Dataflow)
Standardize the design of our Kubernetes apps for APIs, leading initiatives for improved monitoring, instrumentation, and state-of-the-art continuous deployment
Standardize tooling across Lydia’s ML landscape, with a focus on MLOps for training and monitoring
Rigorously enforce and audit our GDPR landscape
Collaborate with Analytics Engineers and Data Scientists to support and facilitate their goals
Improve the test culture for both our BI and ML stacks
You are in the right place if:
You hold a Master’s degree in Computer Science or Engineering
You have at least three years of experience as a Data Engineer or backend engineer, preferably in a start-up environment
You are proficient in SQL and Python
You have strong analytical skills and a problem-solving mindset
You are a team player with a marked ability to start and lead new projects independently
You have excellent written and spoken communication skills in English
Recruitment Process:
Phone interview with our Talent Acquisition Recruiter
Home-assignment: technical and analytical test
Physical Interview with a Tech Lead
Video interview for debriefing

* Job is opened to Lydia’s Paris French office

At Lydia, we believe that diversity is a strength. Diversity is part of our culture and identity. We want to create an inclusive culture where all forms of diversity are seen as a real value to the company. Lydia is therefore proud to be an Equal Employment Opportunity employer. We do not discriminate based upon race, religion, colour, national origin, sex (including pregnancy, childbirth, reproductive health decisions, or related medical conditions), sexual orientation, gender identity, gender expression, physical characteristics (size, weight ... ).age, status as an individual with a disability, genetic information, or other applicable legally protected characteristics.
Voir moins",,2024-01-19,https://www.welcometothejungle.com/fr/companies/lydia/jobs/data-engineer-f-h_paris?q=32e055701e531e6d24ece135164a734a&o=23f19aba-37b6-4653-bc28-83e73b7b5a37,wttj
Senior Data Engineer F/H,"{'name': 'ECO COMPTEUR', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, Electronique / Télécommunications', 'employees': '150 collaborateurs', 'creation_year': '2000', 'turnover': None, 'mean_age': '38 ans'}",CDI,Lannion,Non spécifié,Télétravail non autorisé,,> 7 ans,Bac +5 / Master,"Descriptif du poste
Toi aussi tu veux avoir un impact dans la transformation des villes de demain et participer au développement du tourisme durable ? Rejoins-nous et deviens acteur dans le développement des villes intelligentes et la préservation des espaces naturels !
🚲Chez Eco Compteur, nous accompagnons les villes dans leur transition vers le développement des mobilités douces et aidons à la préservation des plus beaux sites naturels du monde !
L’objectif ? Donner aux gestionnaires d’espaces naturels et aux villes des données de fréquentation terrain fiables pour les aider à prendre des décisions objectives : « Faut-il pérenniser cette piste cyclable temporaire ? Faut-il moduler le nombre de visiteurs pour préserver ce site naturel protégé ? »
Depuis plus de 20 ans, nous proposons des solutions de comptage connectées de piétons et cyclistes en environnement urbain et naturel. Solutions qui vont des capteurs installés sur les pistes cyclables et les sentiers de randonnées aux logiciels d’interprétation des données, parce que compter c’est bien mais donner du sens aux chiffres c’est encore mieux !
Focalisés sur l’innovation et l’international, nous sommes leader mondial d’un métier que nous avons créé ! 💪
Implanté en Bretagne avec des filiales au Canada, en Allemagne et à Shangaï, Eco Compteur est aussi présent dans plus de 55 pays. C’est aussi et surtout une entreprise de taille humaine où chacun partage une vision et des valeurs : autonomie, responsabilité & transparence avec beaucoup de passion et de plaisir !
Nous sommes aujourd’hui à la recherche de notre prochain talent :
SENIOR DATA ENGINEER - LANNION/ RENNES - CDI
En tant que Data Engineer chez Eco-Compteur, tu évolueras dans le cercle (équipe) R&D Software et tu travailleras en étroite collaboration avec le cercle Data. Tu développeras des solutions innovantes qui permettront à nos clients une compréhension plus qualitative de la fréquentation et des déplacements sur leur territoire.
✏️Tes rôles :
Participer à la définition d’une architecture optimale pour :
les chaînes de traitement de données
l’extraction, la transformation et le chargement (ETL) de données à partir de multiples sources.
Collaborer avec des experts data (data scientist, géomaticien) à l’intégration de nouvelles données dans nos solutions
Développer, maintenir et industrialiser les flux d’intégration de données et les chaînes de traitement associés
Structurer et stocker la donnée en veillant à sa qualité
Assurer l’accès aux données afin d’exploiter les données dans nos solutions
Ce que l’on te met à disposition :
Un onboarding ultra complet qui te permettra d’avoir une vision 360 de l’entreprise
Des outils performants qui permettront d’exprimer pleinement tes talents
Une équipe de passionnés qui travaillera à tes côtés
Voir moins","Profil recherché
👉Et si c’était toi ?
On a besoin que tu apportes ton expertise, ton expérience : Tu possèdes donc au moins 5 années d’expérience sur un poste similaire (et surtout de l'expérience en Big Data). 
Tu as des compétences dans l’environnement technique suivant :
Langages: Java, Kotlin, Python, SQL, No SQL
Données: MySQL, PostgreSQL, Elasticsearch, Object storage (S3)
Traitement: Apache Airflow, Apache Kafka, Apache Spark
Visualisation : Tableau Software
Et comme on est jamais trop exigent, tu parles couramment Anglais (Interactions avec nos équipes et clients internationaux). 
Ton petit plus à toi ? Une expérience sur les plateformes Cloud (AWS, GCP, Azure), ou bien sur du traitement de données et visualisation SIG. 
TES QUALITÉS
Tu es autonome, force de proposition et tu prends souvent des initiatives 
Tu sais analyser les problèmes, être critique et constructif pour les résoudre
Voir plus",2024-01-18,https://www.welcometothejungle.com/fr/companies/eco-compteur/jobs/senior-data-engineer-f-h_lannion?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=2b5cc0a1-1541-4f99-b229-c7a87d45e134,wttj
Data Engineer F/H,"{'name': 'SAFRAN AIRCRAFT ENGINES', 'sector': 'Aéronautique / Spatiale', 'employees': '16400 collaborateurs', 'creation_year': '1945', 'turnover': '9,1€ milliard', 'mean_age': None}",CDI,Évry-Courcouronnes,Non spécifié,Télétravail non autorisé,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous souhaitez mettre vos talents au service de la transformation digitale ?

La direction Engineering du support et des Services souhaite dynamiser sa transformation digitale via ce poste renforcer l'équipe en charge de processus de collect et decodage des données de vols des avions.

Les données d'exploitation (données de vol, de health monitoring et de fiabilité) jouent un rôle de plus en plus important dans la gestion des flottes clients. Les équipes du support technique ont ainsi besoin d'outils de plus en plus performant pour leur faciliter l'accès et l'analyse de ces informations.

Au sein du département Fleet Data Engineering, dans l'unité Advanced Monitoring Systems, le data Engineer assura les fonctions suivantes :

* Specifier le besoin des évolutions des outils de collecte et de décodage dont vous avez le perimètre avec les key user.
* Capter les besoins d'évolution à venir , maintenir le backlog des besoins sur les outils .
* Piloter le développement des évolutions avec les integrateurs, en étroite collaboration avec les acteurs de la DSI
* Communiquer sur les évolutions des outils auprès des utilisateurs
- Réaliser/faire réaliser la validation/ recette métier des évolutions
* Réalisation des dashboard ( Power Bi, Python) suivant les besoins des utilisateurs.
* Capable de développer en Phyton/ devOps pour protypage rapide
- Connaissances globale du fonctionnement d'un moteur type LEAP/ CFM ainsi que les processus de service autour de support moteur seraient appréciées.
Voir moins","Profil recherché
* Vous avez déjà une expérience en developpment de solution IT
* Bonne connaissance dans le management de projet IT avec la méthodologie Agile
- Sens de l'innovation
* Sens du client
* Capacité de synthèse et communication efficace
* Pratique des outils bureautiques courants
- Pratique de l'anglais indispensable
* Pratique de langage de programmation usuel (python, VBA)
* Comptétence en PowerBI et base de donnée SQL serait apprécié
* Une bonne connaissance des métiers et processus du support et services des moteurs civils serait appréciée
* Connaissance des données de Vols( ACMS, EEC) serait apprécié
* Vous êtes reconnu pour votre ouverture d'esprit et votre bon relationnel.",2024-01-18,https://www.welcometothejungle.com/fr/companies/safran-aircraft-engines/jobs/data-engineer-collecting-and-decoding-of-data-for-fleet-data-engineering-f-h_evry_SAE_gGe7y03?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=c7ba4278-7fad-4bed-806d-68df28e8a73d,wttj
Data Engineer,"{'name': 'BLACK TIGER', 'sector': 'Logiciels, Digital Marketing / Data Marketing, Big Data', 'employees': '158 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Au sein des équipes de développement de Black Tiger, éditeur spécialisé dans le traitement des données personnelles, l’équipe de data engineering / intégration a pour mission de répondre aux besoins exprimés par nos clients pour faire face à leurs enjeux de Big Data. 
En rejoignant cette équipe en tant que Data Engineer, tu as la responsabilité de la mise en œuvre (paramétrage, développements spécifiques et déploiement) des briques logicielles de notre plateforme. C’est un poste à multiples facettes techniques (conception, modélisation et développement ; ops pour le déploiement ; implication dans la R&D de l’entreprise et dans les choix d’architecture et de technos) où tu te confronteras à de réels challenges techniques.
La stack est variée et s’articule, en plus des briques logicielles développées en interne, autour des technologies suivantes :  Spark/Scala, Python, MongoDB, Elasticsearch, Docker, Kafka…","Profil recherché
- Tu es titulaire d’un bac+5 en Data Engineering, Data Science, Développement informatique pour la Big Data ou équivalent ;
- Tu justifies de 3 années d’expérience ou plus en tant que Cloud / Data Engineer ;
- Tu maîtrises maîtrisez Spark/Scala, MongoDB et la modélisation orientée objet (UML) ;
- Tu as de l’expérience dans la mise en place de flux ETL et de bonnes connaissances en ingénierie logicielle (devops, CI/CD, tests automatisés).
Nous recherchons des personnes qui sont sensibles aux enjeux Big Data, avec une appétence tant pour le développement que pour l’analyse fonctionnelle et l’optimisation des performances. Il faut avoir envie de challenges techniques. Rigueur, curiosité et agilité requises !
Et on apprécie les gens sérieux qui ne se prennent pas au sérieux ;)",2024-01-18,https://www.welcometothejungle.com/fr/companies/blacktiger/jobs/data-engineer_paris_BT_bmPA38O?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=5ec682d2-2787-4ab7-a417-1fcf7cbdbb96,wttj
Ingénieur Data Sénior / Lead Data engineer F/H,"{'name': 'DIRECTION DU NUMÉRIQUE DES MINISTÈRES SOCIAUX', 'sector': 'Logiciels, Administration publique', 'employees': '240 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '45 ans'}","CDD / Temporaire
(36 mois)",Paris,Non spécifié,Télétravail fréquent,01 février 2024,> 5 ans,Bac +5 / Master,"Descriptif du poste
Le Data Office de la DNUM recherche un(une) Ingénieur des Données Sénior pour accompagner techniquement et opérationnellement l’équipe Data (Data Product Owner, DevOps, Data Engineer, Data Analystes, MLOps …) et travailler étroitement avec les équipes d’infrastructures pour le développement des projets innovants.
Disposant d’une solide connaissance des technologies et pratiques de valorisation des données, doté d’une hauteur de vue avec un gout pour la mise en œuvre opérationnelle, vous faites les choix techniques les plus adaptés en fonction des besoins identifiés.
Vos missions sont :
- Contribuer, avec les équipes du Data Office, à la conception d’un environnement industriel complet dédié à la fabrication des produits de données,
- Implémenter des flux de collecte, de transformation et de stockage des données multi- sources
- Concevoir des dispositifs pour nettoyer, transformer et valider les données,
- Assister les équipes de conception de produits,
- Assurer la mise en production des produits de données
En tant qu’expert reconnu de votre domaine, vous avez volonté d’élargir vos responsabilités, d’apporter une contribution plus stratégique et globale aux projets de données, et de continuer à évoluer vers des fonctions d’architecte des données.
Voir moins","Profil recherché
- Vous possédez au minimum 5 ans d’expérience professionnelle dans le domaine et avez contribué au déploiement d’une chaine CICD fortement automatisée, idéalement dans un contexte de cloud public de type OVH,
- Être membre actif d’une communauté en lien avec les technologies du numériques serait un plus.
Compétences techniques :
- Maitrise des aspects d’authentification, de sécurité, de containerisation et d’orchestration,
- Maîtrise des entrepôts de données notamment dans un contexte Cloud type OVH,
- Maitrise de plusieurs technologies parmi : PostgreSql, Elastic Search, Spark, Talend, Kubernetes, Docker,
- Bonne connaissance avec la programmation en SQL, Python, JavaScript et les outils de Dataviz (Power BI, DigDash),
- Familiarisé avec les principes de la virtualisation.
Compétences fonctionnelles :
Voir plus",2024-01-18,https://www.welcometothejungle.com/fr/companies/direction-du-numerique-des-ministeres-sociaux/jobs/ingenieur-data-senior-lead-data-engineer-f-h_paris?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=b8216f7b-7e65-45b7-a4f6-ea27ec5497b7,wttj
Data Engineer (H/F),"{'name': 'THALES', 'sector': 'Logiciels, Cybersécurité, Aéronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mds€', 'mean_age': None}",CDI,Sophia-Antipolis,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces.
Le département IA & Big Data recherche plusieurs Data Engineers (H/F) basés à Sophia Antipolis (06).
QUI ETES-VOUS ?
De formation Bac+4 ou Bac +5 (type école d’ingénieur), vous possédez de bonnes connaissances dans le domaine de la donnée (Data Science, Data Engineering, Stockage), en ingénierie logicielle globalement.
Une connaissance cloud serait un réel atout, qu’il soit public (AWS, GCP, AZURE) ou privé.
Les principales activités que vous réaliserez sont les suivantes :
Mise en place de pipelines de traitement de données
Utilisation de l’état de l’art des technologies actuelles dédiées à ces activités : Kafka / Spark / Spark Streaming / Flink / Storm
Développement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie)
Utilisation de tous les types de stockage actuels : 
SQL : Oracle, SQLServer, PostgreSQL
NoSQL : Cassandra / MongoDB / HBase
Objet : S3 / MinIO
Vous avez de bonnes expériences en développement logiciel et/ou scripting (principalement Scala & Java).
Vous êtes à l’aise en Anglais.
Vous êtes curieux et rigoureux.
Vous aimez travailler en équipe au quotidien, pour vous le succès n’est que collectif.
Vous vous reconnaissez ? Alors parlons missions …
CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :
Le département IA & Big Data fédère et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers d’une structure permettant d’accélérer la transformation des enjeux Data de nos clients.
Nos savoir-faire :
Big Data, Intelligence Artificielle, Algorithmie, Expertise Imagerie
Projets d’intégration système
Nos domaines métier :
Maintenance prédictive, Traitement d’image pour la santé
Archivage certifiant, Gestion de contenu, Analyse risque et optimisation de réponse
Aerospace : Centre de Mission et de Contrôle, Dynamique du Vol, Qualité Image, Occupation des sols, Sondage Atmosphérique
Nos partenaires :
Recherche : INRIA, CNRS, 3IA
Externes : Nvidia, Microsoft
En collaboration avec les membres de notre département :
Vous contribuerez au développement et à la scalabilité de nos plateformes au travers d’activités d’automatisation, de création de services managés et d’API.
Vous accompagnerez nos clients dans leurs projets de valorisation de données en proposant des solutions techniques et fonctionnelles, évaluées, choisies et opportunes.
Vous participerez à l’intégration des plateformes techniques sécurisées développées par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com)
Vous collaborerez à nos publications, conférences et webinars.
Vous serez partie prenante de la 3ème révolution industrielle impactant tous les secteurs d’activité, énergie, santé, industrie, …
La perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant à cette offre.
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Voir moins",,2024-01-18,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-h-f_sophia-antipolis?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=4708f2f5-05d8-4b5c-85c8-5ccfe9940533,wttj
Data Engineer F/H,"{'name': 'THALES', 'sector': 'Logiciels, Cybersécurité, Aéronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mds€', 'mean_age': None}",CDI,Vélizy-Villacoublay,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Sur le site de Vélizy, les équipes développent et installent des systèmes d’information de commandement et de renseignement, systèmes de sécurité nationale et solutions de sécurité pour les villes, les États et les infrastructures critiques, ainsi que des systèmes d’information critiques et de cyber sécurité.
QUI ETES-VOUS ?
Diplômé.e d'un Bac +5 et/ou école d'ingénieur orienté IT/data, vous disposez d'une expérience d'au moins 3 ans sur un poste similaire.Vous êtes à l'aise avec les technologies Python et Jupyter,
Vous maitrisez les bases de données S3 et Cassandra,
Vous avez une compréhension des processus et des technologies de data virtualisation via Superset, Grafana, etc.CE QUE NOUS POUVONS FAIRE ENSEMBLE :Au sein de la JV ATHEA, vous gérez les activités de data engineer pour participer au développement de différents Cas d’Usage de plateforme Artemis, dans ses différentes configurations, et aux formations associées dans l’équipe qui gère et faire évoluer la Solution.
A ce titre, vos principales missions sont
- Participer aux développements techniques de transformation de données par l’utilisation des technologies de transformation de données déployées dans le cadre du programme ; utilisation de Python, Jupyter.
- Encadrer les formations des équipes sur les fonctionnalités
- Gestion de base de données
Si cette offre vous correspond, n'hésitez pas à postuler,
Le poste pouvant nécessiter d'accéder à des informations relevant du secret de la défense nationale, la personne retenue fera l'objet d'une procédure d’habilitation, conformément aux dispositions des articles R.2311-1 et suivants du Code de la défense et de l’IGI 1300 SGDSN/PSE du 09 août 2021.
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Voir moins",,2024-01-18,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-f-h_velizy-villacoublay_THALE_OjlPYP?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=15bbff9e-7af3-4785-ae29-19ed6c252baf,wttj
Data Engineer (secteur aérien) - H/F,"{'name': 'THALES', 'sector': 'Logiciels, Cybersécurité, Aéronautique / Spatiale', 'employees': '80000 collaborateurs', 'creation_year': '2000', 'turnover': '19Mds€', 'mean_age': None}",CDI,Sophia-Antipolis,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
QUI SOMMES-NOUS ?
Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces.
QUI ETES-VOUS ? 
PROFIL ET COMPETENCES:
De formation Bac +5 (type école d’ingénieur), vous possédez de bonnes connaissances dans le domaine de la donnée (Data Science, Data engineering, Stockage), en ingénierie logicielle globalement. Une connaissance cloud serait un réel atout, qu’il soit public (AWS, GCP, de préférence AZURE) ou privé.
Principales activités que vous réaliserez :
Concevoir et coder des pipelines de données efficaces et évolutifs en utilisant des technologies big data dans un environnement cloud (Azure, Databricks).
Utilisation de l’état de l’art des technologies actuelles dédiées à ces activités : Kafka / Spark / Spark Streaming / Flink / Storm
Développement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie)
Utilisation de tous les types de stockage actuels : SQL : Oracle, SQLServer, PostgreSQL / NoSQL : Cassandra / MongoDB / HBase / Objet : S3 / MinIO
Vous avez de bonnes expériences en développement logiciel et/ou scripting (principalement Scala)
Vous avez plus de 2 ans d’expérience (alternance prise en compte)
Vous êtes à l’aise en Anglais
Vous avez une certaine appétence pour l’univers du voyage ?
Vous êtes curieux(se) et rigoureux(se) ?
Vous aimez travailler en équipe au quotidien. Pour vous le succès n’est que collectif.
CE QUE NOUS POUVONS FAIRE ENSEMBLE :
Le département IA & Big Data fédère et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers d’une structure permettant d’accélérer la transformation des enjeux Data de nos clients.
Nos savoir-faire :
Big Data, Intelligence Artificielle, Algorithmie, Expertise Imagerie
Projets d’intégration système
Votre mission :
Vous interviendrez dans un contexte international au sein d’équipes multiculturelles pour un acteur majeur de l’industrie du voyage. Plus particulièrement, vous participerez à l’amélioration de l’expérience de vente au profit de nombreuses compagnies aériennes.
Vous pourrez contribuer aux différentes phases du projet et serez en charge de :
Convertir les spécifications fonctionnelles en nouvelles solutions logicielles grâce à l'analyse des spécifications.
Proposer et concevoir des solutions techniques viables et réaliser des études de faisabilité.
Développer des logiciels conformément aux normes de notre client.
Participer à la phase de validation du cycle du produit, en procédant aux ajustements nécessaires pour finaliser le produit.
Soutenir le client en déboguant les solutions existantes en collaboration avec le chef de   produit ou l'analyste chargé de la définition du produit.
Produire la documentation logicielle nécessaire à l'application.
Nos partenaires :
Recherche : INRIA, CNRS, 3IA
Externes : Nvidia, Microsoft
En collaboration avec les membres de notre département :
Vous allez contribuer au développement et à la scalabilité de nos plateformes au travers d’activités d’automatisation, de création de services managés et d’API
Vous accompagnerez nos clients dans leurs projets de valorisation de données en proposant des solutions techniques et fonctionnelles, évaluées, choisies et opportunes.
Vous participerez à l’intégration des plateformes techniques sécurisées développées par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com)
Vous collaborerez à nos publications, conférences et webinars.
Vous serez partie prenante de la 3ème révolution industrielle impactant tous les secteurs d’activité, énergie, santé, industrie, …
VOTRE CARRIÈRE CHEZ THALESDifférentes opportunités vous permettront de découvrir d'autres domaines ou sites. Vous pourrez évoluer et développer vos compétences dans différents domaines :
Explorez un espace attentif au développement personnel
Développez vos talents dans un autre domaine du groupe Thales, en découvrant de nouveaux produits, de nouveaux clients, un nouveau pays ou en vous orientant vers une solution plus complexe
Choisissez entre une expertise technique ou un parcours de leadership
Construisez une carrière internationale au sein d'un groupe d'ingénierie de premier plan
Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
Voir moins",,2024-01-18,https://www.welcometothejungle.com/fr/companies/thales/jobs/data-engineer-secteur-aerien-h-f_sophia-antipolis?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=3e0e1fc0-76ea-42c2-9d5e-104f20539d03,wttj
Lead data engineer (H/F),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 M€', 'mean_age': '34 ans'}",CDI,Lille,45K à 60K €,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
SII Lille recherche un(e) : Lead data engineer (H/F)
En tant que Lead data engineer, vous avez l’opportunité d’intervenir sur des missions d’expertise et de conseils auprès de nos clients grands comptes. 
Vous concevez, faites évoluer et gérer des plateformes Data et outils associés ainsi que des flux entre les différentes sources de données de l'entreprise.  
Lors de ces missions d'expertise, vous allez :
<li>Analyser les besoins clients: animer des ateliers, préconiser des architectures, définir des méthodologies et plans de migration,</li><li>Intégrer les futurs services et outils dans un environnement cloud provider (GCP, AWS ou Microsoft Azure),</li><li>Construire des architectures de données résilients et sécurisées, mener les analyse d&#39;impacts et diffuser les bonnes pratiques,</li><li>Concevoir, automatiser, assurer la qualité des échanges et le traitement des données (flux, streams, dataops…),</li><li>Conseiller et participer à la conception, mise en place et/ou migration de data warehouses/data lakes,</li><li>Assurer le pilotage et l’optimisation des outils de transport et de traitement de la donnée.</li>
En complément de ces missions pour nos clients, nous vous proposons également d’intervenir en interne et au niveau national sur une mission d’expertise.
Vos 3 principales activités sont :
<li>Animation et encadrement de la communauté Data,</li><li>Accompagner et former nos consultants data junior,</li><li>Le développement et la valorisation de l’expertise du groupe SII (publications, conférences, webinaires...),</li><li>L’appui au business : participation à des phases d’avant-vente, aide au ciblage des clients, proposition de solutions…</li>
Vous disposerez d’un jour par semaine minimum pour mener à bien cette mission.
Vous bénéficierez de la dynamique de notre équipe d’experts, composée à terme d’une cinquantaine de personnes sur différents domaines d’expertise (Applicatif, Devops, Cloud, Data, IA,…)
Profil : Vous justifiez d’une expérience significative d’au moins 5 ans sur un poste similaire dans un environnement cloud.  Compétences techniques :o    Maitrise d’au moins un cloud public : AWS ou GCPo    Maitrise des langages suivants : SQL, Python (Java, Scala et/ou Spark serait un plus)o    Maitrise du fonctionnement des ETL/ESBo    Maitrise des architectures big datao    Connaissance d’un outil de stockage et de gestion de données sur le cloud : Snowflake, Cloudera, Databricso    Connaissance d’un outil de data visualisation : Looker, PowerBI, Tableauo    Maitrise des processus et bonnes pratiques de développemento    Anglais technique
Au-delà des compétences techniques, vous faîtes preuve de rigueur, d’une bonne capacité d’analyse et êtes force de proposition. Vous avez un bon relationnel et savez communiquer auprès des métiers pour recueillir leur besoin. Vous êtes à l'aise lorsque vous prenez la parole face à un large public.
Vous souhaitez mettre votre expérience au service des clients et mettre votre expertise au sein d’SII pour relever des challenges techniques en apportant de la valeur sur le domaine de la data.
Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés.En 2023, pour la 6e année consécutive, SII France a obtenu le label Great Place To Work®. Nous avons été reconnues entreprise de « + de 2500 salariés » où il fait bon vivre. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières.Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise.
Alors si ces valeurs vous parlent, rejoignez nous !
Voir moins","Profil recherché
Compétences requises : Big data, ETL, GCP, Power BI, SQL.
Qualités désirées : Capacités d'analyse, Force de proposition, Rigueur.
Avantages : Très bon CSE, Tickets restaurant.",2024-01-18,https://www.welcometothejungle.com/fr/companies/sii/jobs/lead-data-engineer-h-f_lille?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=a600dd9a-5dcb-4d3d-8e5b-9359944b1440,wttj
Data Engineer (H/F),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 M€', 'mean_age': '34 ans'}",CDI,La Défense,40K à 60K €,Télétravail non autorisé,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Dans le cadre du développement de notre agence Parisienne, nous recherchons un Data Engineer (h/f). Intégré(e) au sein des équipes chez l'un de nos Clients Grands Comptes
Vos missions :
<li>Proposer, tester et mettre en œuvre des solutions permettant aux data scientists de travailler et collaborer efficacement, dans un objectif de mettre en production des modèles de machine learning construits avec ces outils. Le périmètre va de la collecte des données à la mise en production, en passant par leur contrôle, stockage, traitement et modélisation.</li><li>Accompagner et conseiller les différentes équipes des produits dans la bonne mise en œuvre de ces outils.</li><li>Proposer, tester et mettre en place des méthodes d’anonymisation et désensibilisation des données.</li><li>Construire, collecter et documenter les bonnes pratiques liées au stockage et traitement des données dans le cloud.</li><li>Proposer, tester et mettre en place des méthodes de sécurisation de données plus poussées.</li>
Votre profil :
Vous êtes diplômé d’un Bac +5 ou d’un diplôme d’ingénieur et disposez au moins 5 ans d’expérience ainsi que des connaissances suivantes :
<li>Connaissance des pratiques de développement et opérations sur le Cloud</li><li>Connaissances des processus de déploiement : nos processus se basent sur les services du cloud provider et sur les produits internes existants assurant leur bonne configuration (Kubernetes, Pipeline CI/CD, IBM Cloud, en particulier les bases de données et l’object storage)</li><li>Connaissance des briques de base qui sont nécessaires à une platform de Data Science (Notebook, framewoks ML, Model serving)</li><li>La connaissance de KubeFlow est un plus</li><li>Connaissance des différentes technologies de transfert et traitement de données dans le cloud : streaming et transformation des données, dans un objectif d’ingestion des données</li><li>Qualités de pédagogie nécessaire vis à vis des projets et des architectes du groupe.</li>
Qui sommes-nous ?
Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés.
En 2023, pour la 6e année consécutive, SII France a obtenu le label Great Place To Work®. Nous avons été reconnus 3e entreprise de « + de 2500 salariés » où il fait bon vivre et nous en sommes très fiers ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières.
En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.
Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins",,2024-01-18,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer-h-f_paris_GS_NGxz0YZ?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=606b2399-6f89-4d4b-8690-5fc643959884,wttj
Data Engineer (F/H),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 M€', 'mean_age': '34 ans'}",CDI,Rouen,37K à 45K €,Télétravail fréquent,,,Bac +5 / Master,"Descriptif du poste
Nous recherchons un(e) Data Engineer (H/F) pour accompagner les développements faits auprès des applications de l’un de nos clients Grand Compte.En mode Agile et organisée en ""Feature Team"", l'équipe technophile vous permettra de participer à toute la chaîne projet.
En quête de défis techniques ? Alors n’hésitez plus, postulez! 
Votre mission :
Préparer les données à traiter,
Analyser les modèles,
Concevoir des algorithmes,
Programmer en back-end,
Interpréter et présenter les résultats,
Mettre en production des solutions.
Votre profil :Diplômé(e) d’un Bac+5 en informatique, mathématique ou statistique (Grandes Ecoles, Universités), vous justifiez d'au moins une première expérience significative dans le traitement de donnée avec utilisation ou connaissance d’un ETL (Talend ou Informatica).Vous êtes curieux(se), investi(e) et surtout passionné(e) par le monde du web. Vous savez travailler en équipe et vous vous intégrer rapidement, vous êtes autonome, organisé(e) et rigoureux (se), bon communiquant et doué(e) du sens de l'écoute.
Qui sommes-nous ?
Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés.
En 2023, pour la 6e année consécutive, SII France a obtenu le label Great Place To Work®. Nous avons été reconnus 3e entreprise de « + de 2500 salariés » où il fait bon vivre et nous en sommes très fiers ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières.
En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.
Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins","Profil recherché
Compétences requises : Informatica, Talend.
Qualités désirées : Esprit de synthèse, Adaptabilité, Capacités d'analyse, Autonomie, Bon relationnel, Organisation, Qualités rédactionnelles, Réactivité.
Avantages : Très bon CSE, Mutuelle et prévoyance, Tickets restaurant, Places en crèche, Participation aux bénéfices de l'entreprise, Participation aux frais de transport, Primes de cooptation, Télétravail.",2024-01-18,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer-f-h_paris?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=968e2332-c7fc-4eb7-9ebe-41dd13cb2145,wttj
Senior Data Engineer (H/F),"{'name': 'BELIEVE', 'sector': 'Musique', 'employees': '1600 collaborateurs', 'creation_year': '2005', 'turnover': None, 'mean_age': '35 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Contexte 
Le Tribe « Customer Finance » est composé de plusieurs Squad, parmi elles la squad Finance Ingestion qui a pour mission de développer des outils et des applications pour la collecte de royalties auprès des plateformes de streaming de musique ainsi que préparer les données afin de faire la distribution des royalties auprès des producteurs de musiques. 
En tant que Data Engineer, tu intégras une équipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette équipe est composée essentiellement de 5 Data Engineer et 1 Software Engineer. Nous avons un écosystème qui se compose  
une socle de gestion des données (Delta Lake) plus d’1.5 milliard de lignes /mois 
data engineering avec du Scala Spark utilisant le runtime de Databricks 
orchestration de nos data pipelines avec Airflow managé 
des APIs avec les Lambda AWS pour faire interagir les utilisateurs avec notre interface front (PHP) 
RDS pour hoster la base de données back-end sous PostgreSQL  
versionning du code sous GitLab avec un environnement de dev, staging et production 
infrastructures sous AWS    
Les missions du Data Engineer au sein de l’équipe : 
-          Interagir avec le Product Owner, le métier pour comprendre les besoins 
-          Interagir avec l’architecte, les équipes infrastructures et Cloud pour concevoir les solutions de data engineering 
-          Développer des flux de données (data pipelines) avec du Apache Spark et du Scala 
-          Faire de l’orchestration via Airflow avec du Python 
-          Maintenir et améliorer les modules existants de l’application 
-          Utiliser GitLab pour tester, builder et déployer son code sur les différents       environnements 
-          Effectuer des revues de codes des autres membres de l’équipe 
-          Interagir avec les membres de l’équipe pour atteindre l’objectif du sprint 
-          Faire du support applicatif et fonctionnel de l’application auprès des opérationnel 
Set the tone with us
Chez Believe, nous avons deux cœurs : nos collaborateurs et nos artistes.
Nous croyons en la force de nos collaborateurs, qui s'épanouissent chaque jour en développant leur potentiel... Notre objectif est d'offrir à nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'épanouir.
Rock the job
Programme de formation et de coaching sur mesure 
Une politique de télétravail
Un programme de bien-être ""Pauses"" avec de nombreuses activités et animations en interne
Accès à Eutelmed, la plateforme numérique de santé mentale et de bien-être qui permet de parler à un psychologue expérimenté
Un restaurant d'entreprise sain et éco-responsable
Une assurance santé individuelle ou familiale
Avantages CE 
Un rooftop
Une salle de sport avec des cours gratuits
 Sing in harmony
Des groupes d'ambassadeurs pour s'engager sur la réduction de l'empreinte carbone et environnementale de Believe et l’équité professionnelle Femme/Homme.
Mise en place du Forfait mobilité durable: remboursement jusqu’à 600€ des frais de transport en commun/avec une faible empreinte carbone.
Congé 2nd parent de 5 jours calendaires rémunérés à 100% (en plus du congé légal paternité ou du congé d’adoption, nous ne l’attribuons pas au congé maternité)
  Believe s’engage à garantir l’égalité des chances en matière d’emploi, sans tenir compte de l’origine, du sexe, des mœurs, de l’orientation sexuelle, du genre, de l’âge, de la situation de famille, de l’état de grossesse, d’une prétendue race, des opinions politiques, des activités syndicales, des convictions religieuses, de l’apparence physique, du nom de famille, du lieu de résidence, de l’état de santé, ou en situation de handicap.

Découvrez nos nouveaux locaux : bit.ly/believeoffice
Voir moins","Profil recherché
Qualifications du Data Engineer 
- 3-5 ans d’expérience dans la pratique de développement sous Scala 
- une très bonne maitrise du framework Spark avec du Scala, nous ne faisons pas de PySpark 
- une bonne maitrise de conception et développement des data pipelines 
- Développer avec un état d’esprit Keep it Simple, Stupid (KISS)  
- une bonne maitrise d’un outil de versionning de code tel que Gitlab 
- une bonne maitrise des APIs avec du Lambda   
- une expérience dans l’écosystème AWS ",2024-01-18,https://www.welcometothejungle.com/fr/companies/believe-digital/jobs/senior-data-engineer-h-f_paris_BELIE_3ZapL47?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=88970383-0697-4e53-919a-bffa4b3d39f2,wttj
Data engineer (H/F),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 M€', 'mean_age': '34 ans'}",CDI,Lille,33K à 45K €,Télétravail non autorisé,,,,"Descriptif du poste
Devenez le prochain collaborateur d'SII Nord en tant que :
Data Engineer (H/F)
Intégré chez l'un de nos clients, vous intervenez en tant que Data Engineer au sein de l’équipe IT Data. Vous développez et gérez la maintenance de la plateforme Data et d’autres outils mais aussi des flux entre les différentes sources de données de l’entreprise. Vous contribuez à :
Concevoir et développer les futures fonctionnalités de la plateforme Big Data sous Google Cloud Platform,
Concevoir les flux d’alimentation et les tables (structure de donnée),
Automatiser et industrialiser les flux,
Assurer le run applicatif, le cas échéant.
Profil : Dans l'idéal (oui uniquement dans l’idéal, chez nous on ne cherche pas qu’un CV mais une collaboration durable), de formations supérieure en informatique, type Bac+3/5, vous justifiez d’une expérience significative en développement sur un environnement BI et Big Data.  Compétences techniques :
Maitrise des langages suivants : SQL, Python (Java/Scala serait un plus)
Connaissances de Google Cloud Dataflow (Python)
Anglais nécessaire à l’écrit
Notion de programmation fonctionnelle
Au-delà des compétences techniques, vous faîtes preuve de rigueur, de curiosité et aimez relever les challenges. Vous êtes doté(e) d’un bon sens du service client, êtes organisé et pragmatique. Ces qualités vous permettent de mener à bien le projet. Vous vous reconnaissez dans ces compétences et qualités ? Vous souhaitez bousculer les codes, sortir des sentiers battus et rendre votre dynamisme contagieux ? Alors, rejoignez le mouvement #Fungénieur de SII dans lequel la créativité et l’esprit d’équipe sont mis à l’honneur ! Vous êtes les créateurs de demain, osez mettre en avant vos compétences, investissez-vous dans des projets innovants et venez relever de nouveaux défis technologiques.  Expertise, Innovation et fun est le mix que nous vous proposons ! 
Qui sommes-nous ?Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. En 2023, pour la 6ème année consécutive, SII France a obtenu le label Great Place To Work®. Nous avons été reconnus 3ème entreprise de « + de 2500 salariés» où il fait bon vivre. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés !
Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise.
Alors si ces valeurs vous parlent, rejoignez-nous !
 Voir moins","Profil recherché
Compétences requises : Python, Scala, Spark, SQL.
Qualités désirées : Organisation, Rigueur, Satisfaction client.
Avantages : Très bon CSE, Mutuelle et prévoyance, Tickets restaurant.",2024-01-18,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer-h-f_lille?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=d128fa20-2964-4f81-8fd5-c51ea7de250d,wttj
Senior Data Engineer (H/F),"{'name': 'BELIEVE', 'sector': 'Musique', 'employees': '1600 collaborateurs', 'creation_year': '2005', 'turnover': None, 'mean_age': '35 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Contexte
Le Tribe « Customer Finance » est composé de plusieurs Squad, parmi elles la squad Finance Ingestion qui a pour mission de développer des outils et des applications pour la collecte de royalties auprès des plateformes de streaming de musique ainsi que préparer les données afin de faire la distribution des royalties auprès des producteurs de musiques. 
En tant que Senior Data Engineer, tu intégras une équipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette équipe est composée essentiellement de 5 Data Engineer et 1 Software Engineer.  
Nous avons un écosystème composé de : 
Un socle de gestion des données (Delta Lake) plus d’1.5 milliard de lignes /mois 
Data processing avec Scala et Spark utilisant le runtime de Databricks 
Orchestration de nos data pipelines avec Airflow managé 
Des APIs déployées avec AWS Lambda et API Gateway pour faire interagir les utilisateurs avec notre interface front (PHP) 
AWS RDS pour hoster la base de données back-end sous PostgreSQL  
Versionning du code sous GitLab avec un environnement de dev, staging et production 
Infrastructure sous AWS    
Les missions du Senior Data Engineer au sein de l’équipe :
-          Accompagner les développeurs à écrire du code propre, qualitatif et conforme aux standards de l’équipe 
-          Interagir avec l’architecte, les équipes infrastructures Cloud pour concevoir les solutions de data engineering 
-          Proposer des améliorations continues et être garant de réduire les dettes techniques 
-          Développer des flux de données (data pipelines) avec de l’Apache Spark et du Scala 
-          Faire de l’orchestration via Airflow avec du Python 
-          Maintenir le workflow GitLab afin de garantir une bonne productivité de l’équipe de développement 
-          Effectuer des revues de codes des autres membres de l’équipe 
-          Collaborer les membres de l’équipe dev pour atteindre l’objectif du sprint 
-          Faire du support applicatif et fonctionnel de l’application auprès des opérationnel 
Set the tone with us
Chez Believe, nous avons deux cœurs : nos collaborateurs et nos artistes.
Nous croyons en la force de nos collaborateurs, qui s'épanouissent chaque jour en développant leur potentiel... Notre objectif est d'offrir à nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'épanouir.
Rock the job
Programme de formation et de coaching sur mesure 
Une politique de télétravail
Un programme de bien-être ""Pauses"" avec de nombreuses activités et animations en interne
Accès à Eutelmed, la plateforme numérique de santé mentale et de bien-être qui permet de parler à un psychologue expérimenté
Un restaurant d'entreprise sain et éco-responsable
Une assurance santé individuelle ou familiale
Avantages CE 
Un rooftop
Une salle de sport avec des cours gratuits
 Sing in harmony
Des groupes d'ambassadeurs pour s'engager sur la réduction de l'empreinte carbone et environnementale de Believe et l’équité professionnelle Femme/Homme.
Mise en place du Forfait mobilité durable: remboursement jusqu’à 600€ des frais de transport en commun/avec une faible empreinte carbone.
Congé 2nd parent de 5 jours calendaires rémunérés à 100% (en plus du congé légal paternité ou du congé d’adoption, nous ne l’attribuons pas au congé maternité)
  Believe s’engage à garantir l’égalité des chances en matière d’emploi, sans tenir compte de l’origine, du sexe, des mœurs, de l’orientation sexuelle, du genre, de l’âge, de la situation de famille, de l’état de grossesse, d’une prétendue race, des opinions politiques, des activités syndicales, des convictions religieuses, de l’apparence physique, du nom de famille, du lieu de résidence, de l’état de santé, ou en situation de handicap.

Découvrez nos nouveaux locaux : bit.ly/believeoffice
Voir moins","Profil recherché
Qualifications du Data Engineer 
-         5-8 ans d’expérience en Scala 
-         Une maitrise horizontale de tous les composants d’une plateforme de data 
-         Expérience en programmation fonctionnel 
-         Connaissance d’un effect system en Scala (ZIO ou cats) 
-         Excellente maîtrise de l’API Spark en Scala avec pour but de guider l’équipe sur les bonnes pratiques 
-         Expérience en développement backend  
-         Une bonne maitrise des services AWS (API Gateway, Lambda, SNS, SQS, S3, Cloudwatch, VPC) 
-         Développer avec un état d’esprit Keep it Simple, Stupid (KISS) 
-         Excellente compétence dans la gestion de relation avec une équipe en remote 
-         Bonne communication pour gérer les différents points de vue et expliquer les contraintes aux utilisateurs 
 Voir plus",2024-01-18,https://www.welcometothejungle.com/fr/companies/believe-digital/jobs/senior-data-engineer-h-f_paris_BELIE_z1gqKz8?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=876c2b2b-e146-477c-b096-8abeb8a5509b,wttj
Data engineer secteur retail (F/H),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 M€', 'mean_age': '34 ans'}",CDI,Lille,35K à 45K €,Télétravail fréquent,,,,"Descriptif du poste
Devenez le prochain collaborateur d'SII Nord en tant que :
Data Engineer (H/F)
Intégré chez l'un de nos clients dans le secteur du retail, vous intervenez en tant que Data Engineer (F/H) au sein de l’équipe Data et en étroite collaboration avec les autres spécialistes du domaine.
Vous développez et maintenez la plateforme Data et répondez à des problématiques complexes grâce à des solutions innovantes. 
Vous contribuez à :
Mettre en œuvre et maintenir les pipelines de données
Modéliser le patrimoine de données
Concevoir les flux d’alimentation
Créer et maintenir les dataset permettant le pilotage et la prise de décision
Profil : Vous justifiez d’une expérience significative en data sur les technologies suivantes :
GCP Big query ou AWS Datadog
ETL
Vous maitrisez au moins 2 des langages suivants : Spark, SQL, Python
Au-delà des compétences techniques, vous faîtes preuve de rigueur, de curiosité et aimez relever les challenges. Vous savez rédiger les specs et maitrisez le processus de CI/CD. Vous maitrisez l’anglais et avait des connaissances dans le secteur retail.
Qui sommes-nous ?
SII Nord c’est 180 collaborateurs, rassemblée autour de différents pôles d’expertise (chefferie de projet, développement informatique, ingénierie systèmes, data). Notre communauté Data est aujourd’hui dynamique au sein de l’agence de Lille et rayonne au niveau du groupe, à travers différents évènements organisés : ateliers, réalisation de speak-up, retours d’expérience.
Chez SII Nord vous êtes accompagnés au quotidien sur votre évolution de carrière par un manager de proximité qui vous suit tout au long de votre parcours
Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. En 2023, pour la 6ème année consécutive, SII France a obtenu le label Great Place To Work®. Nous avons été reconnus 3ème entreprise de « + de 2500 salariés» où il fait bon vivre. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés !
Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise.
Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins","Profil recherché
Compétences requises : AWS, ETL, GCP, Python, SQL.
Qualités désirées : Adaptabilité, Rigueur.
Avantages : Très bon CSE, Tickets restaurant, Participation aux frais de transport, Télétravail.",2024-01-18,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer-secteur-retail-f-h_lille?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=bbb2e0d8-3279-4c82-9b2e-afe98f5836c5,wttj
Data engineer secteur bancaire (F/H),"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 M€', 'mean_age': '34 ans'}",CDI,Lille,35K à 45K €,Télétravail non autorisé,,,,"Descriptif du poste
Devenez le prochain collaborateur d'SII Nord en tant que :
Data Engineer (H/F)
Intégré chez l'un de nos clients dans le secteur du bancaire, vous intervenez en tant que Data Engineer (F/H) au sein de l’équipe Data et en étroite collaboration avec les autres spécialistes du domaine.
Vous développez et maintenez la plateforme Data et répondez à des problématiques complexes grâce à des solutions innovantes. 
Vous contribuez à :
Mettre en œuvre et maintenir les pipelines de données
Modéliser le patrimoine de données
Concevoir les flux d’alimentation
Créer et maintenir les dataset permettant le pilotage et la prise de décision
Profil : Vous justifiez d’une expérience significative en data sur les technologies suivantes :
GCP Big query ou AWS Datadog
ETL
Vous maitrisez au moins 2 des langages suivants : Spark, SQL, Python
Au-delà des compétences techniques, vous faîtes preuve de rigueur, de curiosité et aimez relever les challenges. Vous maitrisez l’anglais. Vous êtes doté(e) d’un bon sens du service client, êtes organisé et pragmatique. Des connaissances dans le secteur bancaire est un plus.
Qui sommes-nous ? SII Nord c’est 180 collaborateurs, rassemblée autour de différents pôles d’expertise (chefferie de projet, développement informatique, ingénierie systèmes, data). Notre communauté Data est aujourd’hui dynamique au sein de l’agence de Lille et rayonne au niveau du groupe, à travers différents évènements organisés : ateliers, réalisation de speak-up, retours d’expérience.
Chez SII Nord vous êtes accompagnés au quotidien sur votre évolution de carrière par un manager de proximité qui vous suit tout au long de votre parcours
Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. En 2023, pour la 6ème année consécutive, SII France a obtenu le label Great Place To Work®. Nous avons été reconnus 3ème entreprise de « + de 2500 salariés» où il fait bon vivre. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés !
Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.
Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise.
Alors si ces valeurs vous parlent, rejoignez-nous !
Voir moins","Profil recherché
Compétences requises : AWS, ETL, GCP, Python, SQL.
Qualités désirées : Autonomie, Rigueur.
Avantages : Très bon CSE, Mutuelle et prévoyance, Tickets restaurant.",2024-01-18,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer-secteur-bancaire-f-h_lille?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=c3acf299-a835-4147-9846-06c4f2b886f7,wttj
Data Engineer H/F - Tours,"{'name': 'GROUPE SII', 'sector': 'IT / Digital', 'employees': '16000 collaborateurs', 'creation_year': '1979', 'turnover': '1 022.5 M€', 'mean_age': '34 ans'}",CDI,Tours,35K à 45K €,Télétravail fréquent,,,,"Descriptif du poste
Envie de changement, d’une nouvelle opportunité professionnelle et d’un cadre où il fait bon vivre ? Alors c’est bon, tu peux continuer à lire, c’est chez SII que ça se passe !
Dans le cadre du développement de notre agence, nous recherchons un ou une Data Engineer (H/F) pour mettre à profit son expertise au service de nos clients.
Intégré(e) au sein des équipes clients, tes futures missions sont :   
<li>Résolution d’incidents (niveau 2 ou 3) et mise en œuvre d’actions préventives</li><li>Conseil, assistance et expertise auprès des utilisateurs.  </li><li>Maintien en condition opérationnelle des outils ou systèmes (RUN)</li><li>Participation à l’évolution des cibles et trajectoires du SI (BUILD) </li>
Tes atouts pour le poste sont la maîtrise des technologies Big Data et notamment l’écosystème Hadoop ((Kafka, Solr, Hbase, Hive, Spark), Cloudera (Sentry, Kudu, Impala)
De formation BAC +5 (école d’ingénieurs ou universitaires), tu justifies d’une première expérience significative dans le domaine de la Data et tu possèdes également de bonnes connaissances dans le développement informatique et notamment sur la stack Java.
Compétences techniques requises :
Système et OS : Linux/Unix (RedHat, CentOS)
ETL : Talend, Talend Big Data Edition, TeraData.
Cloud (DataBricks,  DeltaLake), Azure, Amazon, PAAS (Open-Shift, Kubernetes), Confluent
Doté(e) d’un bon relationnel et appréciant le travail en équipe, tu aimes transmettre ton savoir sur ton domaine d’expertise.
Notre ADN
Dernière-née de l’agence SII Atlantique, SII Tours intervient dans les domaines de l'embarqué, des systèmes d'informations, du web, ou de la gestion de projet.
Fort de l’expertise du groupe, nous rejoindre te permettra une évolution au sein de nos projets (Grands comptes, PME, ETI).
Nous sommes situés au sein de locaux modernes dans le centre-ville de Tours (proche gare).
Le Groupe SII est au cœur de l’innovation au service de grands comptes dans des secteurs d’ingénierie variés.
En 2022, nous avons été labellisés Great Place To Work pour la 5e année consécutive et reconnus 3 e entreprise de « + de 2500 salariés » où il fait bon vivre. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés !
Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières.
Rejoint le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.
Notre nouvel accord télétravail permet de l’appliquer jusqu’à 50% de notre temps de travail en fonction de la mission.
Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise.
Ces valeurs te parlent ? Alors rejoins-nous !
Elodie, Julien et Lucas seront ravis de te rencontrer et de t’en dire plus.
Tu peux également nous suivre sur les réseaux sociaux : Facebook, Linkedin, Viadeo ou Twitter :@SII_Atlantique.
Voir moins","Profil recherché
Compétences requises : Hadoop, Hive, JAVA, Spark.
Qualités désirées : Adaptabilité, Capacités d'analyse, Autonomie, Bon relationnel.
Avantages : Très bon CSE, Participation aux bénéfices de l'entreprise, Télétravail.",2024-01-18,https://www.welcometothejungle.com/fr/companies/sii/jobs/data-engineer-h-f-tours_tours?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=15c3ff5c-5e05-4cdc-8a87-1ac83c97b347,wttj
Data Engineer GCP,"{'name': 'MERITIS', 'sector': 'IT / Digital, Finance', 'employees': '900 collaborateurs', 'creation_year': '2007', 'turnover': '87M€', 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
Notre client, leader mondial du secteur des cosmétiques, est à la recherche d'un Data Engineer pour renforcer son équipe IT. 
Cette équipe IT, qui opère au sein du pôle R&D de notre client, a effectué une migration de ses données de Cloudera vers GCP en 2021. 
Vos missions seront les suivantes : 
Challenger les choix faits durant la migration 
Ajout de nouvelles fonctionnalités sur la plateforme
Amélioration de la plateforme 
Intégration des données
Publication des données
Mise en place d'un Datalog","Profil recherché
Ce poste est-il fait pour vous?
Vous avez un diplôme Bac + 5 d'Ecole d'ingénieur/ équivalent avec une expérience minimum de 5 ans  dans le domaine de l'ingénierie de données.
Vous maitrisez Python et SQL.
Vous avez une expérience sur le cloud GCP (BigQuery est un plus).
Maitriser certains outils DevOps est un plus (cloud build / Terraform).
Vous êtes curieux, autonome et vous avez la capacité à vous adapter à différents outils. 
Vous savez challenger les métiers.",2024-01-18,https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-gcp_paris?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=6ffa9010-e8fe-418c-b125-8e63aca09c8e,wttj
Data Engineer (H/F),"{'name': 'MERITIS', 'sector': 'IT / Digital, Finance', 'employees': '900 collaborateurs', 'creation_year': '2007', 'turnover': '87M€', 'mean_age': '30 ans'}",CDI,Toulouse,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
Au sein du pôle Data , vous intégrerez les équipes qui sont responsables de la collecte des données, vous serez en charge de :
Récupérer, organiser et mettre en forme la donnée
Développer de nouvelles fonctionnalités
Réaliser les tests techniques
Faire évoluer l'architecture
Produire la documentation","Profil recherché
Vous avez un diplôme d'ingénieur ou équivalent Bac +5.
Vous avez un minimum de 3 ans d'expérience professionnelle en tant Data Engineer.
Vous disposez de plus de 3 ans d'expérience en développement Java
Vous êtes autonome, rigoureux.se et organisé.e
Vous parlez couramment anglais",2024-01-18,https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-h-f_toulouse_MERIT_LxaDXM5?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=71b0bc80-0868-412e-8cb7-4f5bfecaa02a,wttj
Data Engineer F/H,"{'name': 'ELDO', 'sector': 'SaaS / Cloud Services, Bâtiment / Travaux publics, Digital', 'employees': '56 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '30 ans'}",CDI,Toulouse,Non spécifié,Télétravail total,03 avril 2023,> 5 ans,Bac +5 / Master,"Descriptif du poste
Eldo, c’est la solution 7-en-1 permet aux pros et marques du BTP de se montrer sur le web, convertir leurs leads et s’améliorer au quotidien pour développer leur activité 🚀💚
À propos
Eldo accompagne depuis 2016 les professionnels et marques du secteur de l’amélioration de l’habitat dans la digitalisation de leur communication et gestion commerciale.
Notre mission : partager les savoirs qui construisent les belles histoires.
Nous construisons la première plateforme européenne de solutions digitales à destination des professionnels, marques et consommateurs du secteur de l’amélioration de l’habitat.
Nous sommes une équipe de passionnés qui souhaitent révolutionner le secteur de l’amélioration de l’habitat (76 milliards d’€).
Avec notre suite SaaS nous accompagnons les pros et marques du secteur à développer leur activité en optimisant chaque étape du cycle de vente avec leurs clients. Du moment où ils les trouvent sur le web, jusqu’à leur satisfaction à la fin des travaux.
Sur notre site B2C, nous aidons les particuliers à trouver des pros de confiance grâce aux avis et photos de leurs voisins, pour réaliser les travaux de leurs rêves.
Nous avons un positionnement et un service unique avec :
💻📲 une suite applicative SaaS, développée avec et pour les pros et marques du bâtiment
📷💬 + 100 000 avis accompagnés de photos, vidéos ;
👨‍🔧 des milliers d'entreprises référencées avec un taux de renouvellement/satisfaction de 90%.
🏡💰 un partenariat avec Google et une certification AFNOR encore renouvelée cette année ! (processus de collecte, modération et restitution des avis)
Lauréats de HEC Challenges + et soutenus par le Village by CA, Moovjee et des entrepreneurs à succès comme Alexandre Ricardo (meilleurtaux.com) ou encore Emmanuel Prevost (Meetic), nous avons pour ambitions de devenir d’ici 2030 la première plateforme mondiale de solutions digitales à destination des professionnels de l’amélioration de l’habitat.
 Descriptif du poste
Chez Eldo notre Dream Team s’agrandit ! 👩‍🚀
Dans un environnement fantastique, notre team Product Engineering a besoin de nouvelles recrues, et en ce sens, nous recherchons un(e) Data Engineer.
Si tu aimes la donnée et que les statistiques n’ont aucun secret pour toi… alors Alessandro et la team n’attendent que toi !
Regarde par la fenêtre de l’équipe Product Engineering ! 👁
La Team Product Engineering, c’est plus d'une dizaine de collaborateurs passionnés et ambitieux accompagnés par nos équipes marketing, sales, grands comptes…!
Ton rôle chez Eldo
Tu travailleras quotidiennement à l’amélioration de nos applications (modifications de l’actuel et création) en proposant des architectures, des pipelines data et des algorithmes sur de larges sets de data en assurant une qualité et granularité de cette dernière, le tout, en étant un support pour les équipes en interne.
Pour la partie “Engineer”, tu seras attendu sur la scalabilité de la partie Data, la mise en place d’architecture dédiée, la gestion de la sécurité de la data, la connexion entre l’architecture data et la partie applicative et développement produit.
Pour la partie “Analyste”, tu seras en charge de recueillir les données internes (bases de données, fichiers…) et externes (HubSpot, Google Analytics, Partoo…), puis de les centraliser au sein d’un datawarehouse pour ensuite permettre leur restitution via un outil dédié à la Business Intelligence (tu seras force de proposition sur les outils à utiliser).
Tu devras bien évidemment documenter et spécifier les éléments de services ou modèles développés, ainsi que maintenir une veille active sur les services utilisés et plus largement sur ton secteur d'expertise afin de pouvoir proposer les meilleures et plus adéquates solutions.
Ayant un rôle fortement orienté et drivé par l’Impact business et utilisateur, tu seras naturellement au sein de l’équipe Produit, composée de Product Manager, Product Designer.
Tes échanges quotidiens seront bien évidemment avec cette équipe, mais pas que.
Les développeurs et toutes les autres équipes seront pour toi des stakeholders privilégiés afin de répondre au mieux au besoin de la stratégie Produit et Entreprise.
Les équipes Product Engineering (PE) travaillent en utilisant la méthodologie Agile.
Ton environnement de travail sera le suivant: 
MySQL, PostgreSQL
ETL/ELT, Jobs Talend orchestrés par Airflow, Hevo data pour la partie no code.
APIs d’outils externes à une entreprise (ex : Google Analytics, HubSpot…).
Outils de reporting/dashboarding (Amazon QuickSight°. Toucan Toco pour la partie embed dans l’application)
Outils de documentation, Confluence, et outils de suivi des tâches/incidents, JIRA.
Environnement cloud (AWS)
 Cela pour être un super fit si en plus, tu as/es :
Soft skills
autonome
curieux(se)
une bonne communication
diplomate
un esprit de synthèse 
flexible 
Social skills
Ouverture d’esprit
Orienté Business
Bienveillance
Sens de l’initiative
 🔝😍 Ce que l’équipe aime par-dessus tout sur ce poste
L’humour au quotidien, via des petites blagues souvent de bonne qualité (mais pas toujours)
La team Product Engineering
Les afterworks
L’aventure d’une belle croissance
Pouvoir mettre sa pierre à l’édifice
👍 Les petits + qui font kiffer
Contrat forfait jour + RTT
Mutuelle ALAN 100% digitale qui rembourse super vite et prise en charge à 70%
Un club employé (billetterie, produits high-tech, voyage, etc..)
La carte tickets resto --> Swile est notre ami
Primes cooptations
Remote ponctuel où tu veux en France
Goodies, welcome lunch & drinks (et pas que de bienvenue)
1 break dans l’année dans une destination surprise
Eldo est la société qu’il te faut si tu aimes … 💚
Le management de proximité et impliquant
L’autonomie, les prises d’initiatives, les challenges #growthmindset
Évoluer au sein d’une équipe fun et bienveillante
Les moments de partage en équipe
L’idée de mettre ta pierre à l’édifice et de participer à une aventure humaine et professionnelle INCROYABLE
 🔎 Le process de recrutement chez Eldo
1 - Échange visio RH (45’)
2 - Use case 3 - Échange avec des membres de l'équipe Product Engineering ! (60')
4 - Échange avec ton futur manager, le CPTO (60')Ce poste peut-être en 100% en full remote avec des déplacements à prévoir 1 fois par mois sur Toulouse pris en charge par Eldo
 Alors, séduit(e) ? poste sans tarder ton CV et sors ta plus belle plume 😎
Eldo est une entreprise handi-accueillante
Voir moins",,2024-01-18,https://www.welcometothejungle.com/fr/companies/eldo/jobs/data-engineer-f-h_toulouse_ELDO_r9gzY5G?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=7b32ed53-cf38-4276-b2f7-3b78c9370639,wttj
Digital Factory - Data Engineer DevOps (M/F),"{'name': 'VEOLIA', 'sector': 'Environnement / Développement durable, Collectivités publiques et territoriales, Bâtiment / Travaux publics, Energie', 'employees': '213000 collaborateurs', 'creation_year': '1853', 'turnover': '42,9 Md€', 'mean_age': '44 ans'}",CDI,Saint-Maurice,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
We are looking for an experienced data engineer to join our team on this fantastic journey, working together to ensure that our customers get the best experience possible.
We have a huge potential for analytics and machine learning, based on our IoT and enterprise data, which require solid data engineering.
Your work will have very concrete outcomes and observable value.
You will be fully integrated into the development team, which is organised in an Agile Scrum fashion, and with an excellent team spirit.
You will:
Design, develop, and test data pipeline infrastructures and database systems
Collaborate with data analysts and data scientists to build and improve data models, algorithms and predictive models according to the busines’s requirements
Ensure that all current data infrastructures and processes meet industry standards
Utilise cutting edge data engineering technologies and software
Search for elements of the data collection and processing that need improvement, and improve them
Implement systems to monitor data quality for optimised accuracy and clarity
Design and implement scalable and high-performing solutions
Collaborate with several other teams: Product and Business Development teams for HUBGRADE, Corporate IS&T teams (Data Lake, Cybersecurity, ERP, Networking, FinOps, …), external Digital Partners.
Continuously transfer knowledge to the Run&Support team
Take part in L3 support
Identify synergies between software components and improve efficiency of development and code maintenance
Keep the product vision in mind while working on details
Help to build flexible, future-proof solutions
Continuously improve our agile development process, architecture, and engineering practices
Mentor and coach less experienced engineers on the team
The platform being very rich and diverse, you will have the opportunity to work on different areas and projects.
Additional Information
As an inclusive company, Veolia is committed to diversity and gives equal consideration to all applications, without discrimination.
Voir moins","Profil recherché
Education & Experience
Bachelor's degree in Computer Science
5+ years of experience in software development or data-related fields (DWH, …), with at least 2 years in pure data engineering / big data, using modern programming languages, frameworks, and technologies
Experience working in an agile cross-functional team
Technical skills
Skilled with Git, Python or R, Big Data frameworks (especially Spark)
Skilled with relational and NoSQL databases
Skilled with data modelling and popular data viz tools
Fully operational on public Cloud technologies, especially AWS and its managed services (Glue, Kinesis, Athena, Lambda, IoT Core, EventBridge, …)
Fully operational on Agile practice
Familiar with event-driven architectures
Familiar with automation and IaC tools (CI/CD, Terraform, AWS SAM)
Voir plus",2024-01-18,https://www.welcometothejungle.com/fr/companies/veolia/jobs/digital-factory-data-engineer-devops-m-f_saint-maurice?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=4ef12938-e964-40cd-8c7d-8404834e4179,wttj
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Tours,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Vos missions sont :
- Recueillir les besoins métiers et des équipes data
- Concevoir et mettre en place les traitements de données
- Réaliser les tests de validation
- Assurer l’alimentation du dataware
- Réaliser les ordonnancements des traitements
- Être garant de la mise en place, du suivi et de l’exploitation des outils déployés
- Assurer une veille technologique régulière

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).","Profil recherché
- Passionné(e) d’informatique et de données, vous aimez le travail en équipe, apprendre et partager. Vous êtes également doté(e) d'un esprit audacieux et ambitieux.
- Vous faites preuve d’initiative et travaillez sur le long terme.
- Vous justifiez de 2 à 5 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil dans le domaine de la Data.
- Vous disposez d'une vision large des technologies et vous maîtrisez au moins une technologie Big Data.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-18,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-f-h_tours?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=be0df855-0caf-47ce-bcbb-13870065277a,wttj
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Limoges,Non spécifié,Télétravail fréquent,,> 2 ans,,"Descriptif du poste
Alors venez rejoindre nos équipes de Data Engineer. Vous pouvez être amené à intervenir sur tout ou partie de ces missions :

• Modélisation des Data Concepts ;
• Développement et maintenance des traitements d'intégration et de transformation de données ;
• Intégration des développements dans la chaine CI/CD ;
• Documentation technique et fonctionnelle ;
• Rédaction de plan de tests ;
• Réalisation de tests unitaires/qualifications.

Au sein de la communauté Data, vous serez accompagné et vous pourrez échanger avec des collègues expérimentés et experts vous permettant de vous développer, de grandir et d’accomplir pleinement vos missions de conseil.
L’accompagnement managérial, la communauté Data et de nombreux évènements tout au long de l’année nous permettront de vous aider à atteindre vos objectifs dans un esprit de convivialité.
Voir moins","Profil recherché
Vous aimez travailler en équipe, vous avez une formation Bac+3/5 en informatique, au minimum 2 ans d’expériences et des aptitudes sur l’un ou plusieurs des domaines suivants :

• ETL : Informatica PowerCenter, PowerExchange, Talend…
• Bases de données : Oracle, PostGres, MySQL, Mongo db, Sybase…
• Outils : Mantis, Jira, Confluence, Mega Hopex…
• Data Visualisation : SAP Business Object, Need4Viz …
• Langages : SQL, Hadoop, Python, R…
• Technos cloud : Azure, databricks, snowflake…

Les avantages CGI c’est :

- Un programme d’accompagnement durant ta première année chez CGI (référents, séminaire d’intégration…)
- Un équilibre vie pro/vie perso respecté (télétravail, charte de droit à la déconnexion…)
- L’université CGI permettant de développer et d’acquérir de nouvelles compétences
- De nombreux avantages sociaux (Régime d’Achat d’Action, forfait mobilité durable, mutuelle à 100%…)
- Une politique RSE ambitieuse (Mécénat de Compétences, clean walk…)
- Une Mission Emploi Handicap très développée

Prêt à en discuter ?
Voir plus",2024-01-18,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-f-h_limoges?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=0936d480-b38a-4577-bf0a-5acf77894518,wttj
Data Engineer Splunk F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Toulouse,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Vous disposez d’une connaissance approfondie de l’écosystème des solutions RTM du marché (Splunk (de préférence), ELK, Dynatrace, …) ainsi qu’une connaissance d’un ou plusieurs outils de déploiement automatisés et DevOps (DOCKER, ANSIBLE, KUBERNETES…).
Vous savez développer et manipuler des données grâce aux langages Python et/ou Java et Javascript.

En tant que Data Engineer Splunk, vous intègrerez un pôle de consultants spécialistes du Real Time Monitoring d’une quarantaine de consultants basés sur les sites de CGI Montpelier et CGI Toulouse.
Vos missions seront les suivantes :
-Mener des ateliers fonctionnels, analyser et comprendre le besoin, synthétiser les aspects techniques et fonctionnels afin de mieux définir la trajectoire de mise en œuvre de la solution Splunk chez nos clients
-Travailler en collaboration avec les ingénieurs techniques et autres experts afin de rechercher et fournir des réponses aux problématiques techniques
-Réaliser les travaux d’implémentation de la solution SPLUNK :
Paramétrage de la collecte de données
Structuration et normalisation
Développement de dashboard
Définition de la stratégie de migration
Configuration des algorithmes, notamment en vue de les adapter au Machine Learning, Deep Learning, etc.
Préparation des données
Bonnes pratiques de développement et respect de conventions de nommage
Conception et mise en œuvre de nouveaux scénarios de détection
Optimisation des requêtes Splunk

-Produire les projets en mode agile avec des processus et outils de développement de dernière génération
-Participer à l'élaboration et la révision de normes / documentation technique
-Animer des formations internes. Accompagner la montée en compétences des équipes
-Assurer un support technique Splunk aux équipes et aux clients au quotidien

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
Vous justifiez de 3 à 5 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil dans le Domaine du Data Monitoring.

Vous êtes ou avez :
-Esprit d'équipe
-Esprit audacieux et ambitieux
-Force de proposition
-Maitrise au moins d'une technologie Real Time Monitoring, de préférence Splunk

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-18,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-splunk-h-f_toulouse_CGI_LOjrRDA?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=16c71596-ea52-44f1-9cf8-5822e6dc83bb,wttj
Data Engineer Cloud Data F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Montpellier,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
- Vous êtes passionné(e) par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …
- Vous disposez de solides connaissances sur les architectures de données et le cloud (AWS, GCP ou Azure).

Vos missions sont :
- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place
- Travailler en collaboration avec les ingénieurs techniques et autres experts afin de rechercher et fournir des réponses aux problématiques techniques
- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)
- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)
- Participer à l'élaboration et la révision de normes / documentation technique
- Animer des formations internes.
- Accompagner la montée en compétences des équipes
- Assurer un support technique aux équipes Data et aux clients au quotidien

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
- Passionné(e) d’informatique et de données, vous aimez le travail en équipe, apprendre et partager.
- Vous êtes également doté(e) d'un esprit audacieux et ambitieux.
- Vous faites preuve d’initiative et travaillez sur le long terme.
- Vous avez un minimum de 2 années d’expérience sur des projets Cloud (AWS, GCP ou Azure).
- Vous maitrisez un ou plusieurs services : Snowflake, Synapse, Databricks, Azure DevOps, Terraform, BigQuery, EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB etc.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-18,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-cloud-data-azure-f-h_montpellier?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=72e2391f-597c-4fe8-a38f-593128548371,wttj
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Lyon,Non spécifié,Télétravail fréquent,,> 2 ans,,"Descriptif du poste
Développement, traitement de haute volumétrie, cloud transformation/ migration seront autant d’enjeux qui rythmeront votre quotidien aux côtés de nos professionnels.
Vous intégrerez une équipe de taille humaine spécialisée sur les domaines de l'Energie, de la chimie & des métiers de la santé.

Aux côtés des autres membres de l’équipe et de communauté Data Grand-Est , vous perfectionnerez vos compétences pour devenir un Data Engineer senior sur les technologies les plus modernes du marché Data.

Au sein de l’équipe, vous serez en interaction avec toutes les parties prenantes du projet, allant du business, aux équipes d’expert et de déploiement des solutions.
Vous participerez au développement stratégique d’un projet d’un client et vous évoluerez dans un contexte international, et bénéficierez de l’expertise de consultants CGI, en immersion chez le client.

A ce titre vos principales responsabilités seront :

• Appréhender le contexte et les enjeux Métier du client ;
• Comprendre et expérimenter le cadre Agile et Lean ;
• Analyser les besoins fonctionnels et déterminer le modèle de données nécessaire avec l’accompagnement de Consultant senior ;
• Participer au développement de ces indicateurs au sein de la plateforme Cloud cible (AWS, GCP , Azure) et des outils de restitution (ex : Power BI, Qliksense) ;
• Établir et dérouler des scénarios de tests ;
• Participer à la vie de la communauté Data.

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
• De formation bac+5 ou de formation supérieure en informatique, vous disposez de 2 ans expériences réussie dans le déploiement de plateforme de type Kafka , Datalake AWS , Datalake CGP ;
• Des connaissances métiers dans le domaine de l'Energie, de la chimie & des métiers de la santé , alliés à des compétences techniques fortes sont également des atouts pour la réussite de ce projet ;
• Votre capacité d'adaptation, votre autonomie, votre sens du service ainsi que vos qualités relationnelles seront vos atouts pour réussir et évoluer ;
• Vous aimez évoluer dans des contextes internationaux, avec une très bonne maitrise du français et de l'anglais à l’écrit comme à l’oral.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.

Rejoindre CGI, c’est :

- Des suivis réguliers avec son manager ;
- Un accès à une plateforme avec de nombreuses formations disponibles dès son arrivée ;
- De nombreuses communautés techniques et métiers ;
- Une mobilité interne facilitée ;
- Un programme de buddy pour être accompagné(e) durant la première année chez CGI ;
- Un équilibre vie professionnelle /vie personnelle respecté (dont 0 à 3 j de télétravail/semaine) ;
- Des événements réguliers (sport, afterworks,…) ;
- De nombreux avantages sociaux (Régime d’Achat d’Action, forfait mobilité durable, mutuelle à 100%…) ;
- Une politique RSE ambitieuse ;
- Un programme de Mécénat de Compétences ;
- Une Mission Emploi Handicap très développée ;
Voir plus",2024-01-18,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-h-f_lyon_CGI_pmKAW4J?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=edae74c5-3b4b-400c-a84b-48b7c3ac665e,wttj
Data Engineer Cloud Data F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Tours,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
- Vous êtes passionné(e) par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …
- Vous disposez de solides connaissances sur les architectures de données et le cloud (AWS, GCP ou Azure).

Vos missions sont :
- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place
- Travailler en collaboration avec les ingénieurs techniques et autres experts afin de rechercher et fournir des réponses aux problématiques techniques
- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)
- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)
- Participer à l'élaboration et la révision de normes / documentation technique
- Animer des formations internes.
- Accompagner la montée en compétences des équipes
- Assurer un support technique aux équipes Data et aux clients au quotidien

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
- Passionné(e) d’informatique et de données, vous aimez le travail en équipe, apprendre et partager.
- Vous êtes également doté(e) d'un esprit audacieux et ambitieux.
- Vous faites preuve d’initiative et travaillez sur le long terme.
- Vous avez un minimum de 2 années d’expérience sur des projets Cloud (AWS, GCP ou Azure).
- Vous maitrisez un ou plusieurs services : Snowflake, Synapse, Databricks, Azure DevOps, Terraform, BigQuery, EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB etc.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-18,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-cloud-data-azure-f-h_tours?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=1fea9a60-1360-40d4-b8c7-d8c65311dc8e,wttj
Data Engineer (F/M/D),"{'name': 'VESTIAIRE COLLECTIVE', 'sector': 'Luxe, Mode, E-commerce', 'employees': '800 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': '34 ans'}",Autres,Paris,Non spécifié,Télétravail non autorisé,,> 2 ans,,"Descriptif du poste
Vestiaire Collective is the leading global online marketplace for desirable pre-loved fashion. Our mission is to transform the fashion industry for a more sustainable future by empowering our community to promote the circular fashion movement. Vestiaire was founded in 2009 and is headquartered in Paris with offices in London, Berlin, New York, Singapore, Ho Chi Minh and Hong Kong and warehouses in Tourcoing (France), Crawley (UK), Hong Kong and New York.
We currently have a diverse global team of 800 employees representing more than 50 nationalities. Our values are community, activism, transparency, dedication and greatness. We are proud to be a BCorp.
Data Engineer (F/M/D)
Permanent position based in Paris
About the role
You will be part of the CRM team as a Data Engineer, and your objective will be to ensure that data is properly orchestrated between our internal Data Platforms, and our CRM Tool (Braze) to have proper reporting and monitoring, so that our teams have the necessary tools to take the right decisions, as well as to get the right information to our users at the right time.
What you’ll be doing
Co-creating and continuously developing the technical architecture of the Vestiaire Collective Data Platform
Setting up foundational data models as well as implementing data ingestion strategies for diverse data sources, such as internal databases, third-party sources, user data trackers that will then be used by analysts and business members,
Optimize, redesign and define best practices for data transformations and data model development in dbt for our analysts.
Maintaining and improving reverse ETL to feed our external platforms with the information needed for our CRM operations
Build new automations for manual processes to improve our team efficiency and speed up decision making
Working closely with Data Scientists to ensure smooth and quick implementation of algorithms in production
Implementing tools for task scheduling, data quality controls, stability monitoring and alerting
Continuous learning and staying up-to-date with the latest developments in the data technology space in order to keep the team ahead of the curve.
Who you are
2+ years of working experience, including work with relational databases, Hadoop, NOSQL and/or cloud infrastructure (e.g. AWS)
Educational background in Computer Science / Data Engineering / Data Science / Data analytics fields
Solid understanding of database concepts and experience with data processing tools (SQL, dbt...) - mandatory
Hands-on experience with at least one of the following: Python, Airflow, Kafka, K8S, Git and curiosity to learn others. Tableau & Braze are a plus.
Creative approach toward problem solving, passion for exploring new technologies
Experience with version control technology (Git)
Experience in creating and maintaining high volume data models
Experience designing and implementing a data warehouse, with modern BI architecture
Excellent communication skills
You do not need to be micromanaged; to accomplish team and company goals, you can wear multiple hats and pick up new technologies and languages.
You need to be able to defend your technical choice in English. French is a huge plus.
What we offer
A meaningful job with an impact on the way people consume fashion and promote sustainability
The opportunity to do career defining work in a fast growing French-born scale up
The possibility to work as part of a global diverse team with more than 50 nationalities
2 days to help Project - reinforcing your activist journey and volunteer for an association
Significant investment in your learning and growth
Competitive compensation and benefits package
Vestiaire Collective is an equal opportunities employer
Voir moins",,2024-01-18,https://www.welcometothejungle.com/fr/companies/vestiaire-collective/jobs/crm-data-engineer-f-m-d_paris?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=4fbac420-5a16-40aa-aaf5-8f04ae11a6b5,wttj
Senior Data Engineer (H/F),"{'name': 'PUBLICIS FRANCE', 'sector': 'Marketing / Communication, Publicité, Digital, Relations publiques, AdTech / MarTech, Evénementiel, Design', 'employees': '5000 collaborateurs', 'creation_year': '1926', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 3 ans,,"Descriptif du poste
Capability
L'équipe Data est composée d'une quinzaine de collaborateurs regroupant Data Scientists, Data Engineers, Data Analysts et Data Strategists, travaillant sur la co-construction d'outils générant de la valeur à partir de la donnée de nos clients.
Si vous aussi, vous partagez cette vision et souhaitez profiter et contribuer à notre communauté internationale sur le sujet, rejoignez-nous !
Vous interviendrez chez nos clients et serez en charge des missions suivantes : 
Travailler étroitement avec les parties prenantes à la compréhension fonctionnelle de leurs projets au travers d’ateliers de spécification et de modélisation 
Construire des pipelines d’ingestion, de transformation et de valorisation de leurs données au service de la réalisation de produits décisionnels (BI), de data science/machine learning ou d’analytique opérationnelle 
S’assurer de la qualité du code réalisé en adéquation avec les normes et standards du projet et mettre en place les tests de validation  
Documenter ces projets jusqu’à leur industrialisation opérationnelle et le support nécessaire à la vie du produit. 
Vous contribuerez également à la veille collective et à l’émulation commune lors de nos journées de partage au sein de la craft Data engineer, à la rédaction d’articles ou à la participation de projets internes.
Voir moins","Profil recherché
Vous disposez de plus de 3 ans d’expérience dans la réalisation de pipelines de données, dans des contextes de construction de la plateforme data à l’échelle, dont notamment dans l’usage des technologies suivantes : 
Python 3 : programmation de traitement de la donnée sous la forme de Notebook, utilisant des librairies orientées data et analytique tels que PySpark et/ou Panda, en mode batch ou streaming 
SQL pour manipuler les données stockées et réaliser des traitements de transformation avancées et à l’échelle 
Collecte et publication utilisant les protocoles de brokers de messages en streaming tels que Kafka, API REST, GRPC, fichiers avec SFTP ou Objet (S3, GCS, ADLS) 
Formatage de la donnée JSON, Avro ou Parquet et SQL Apache Iceberg, Delta Lake 
Cloud native platform AWS (S3, Glue, Athena, RDS, Kinesis, ...), GCP (Cloud Storage, Big Query, Pub/Sub, Data Flow), Azure (ADLS, Synapse, Stream Analytics) 
Principes d’automatisation et de gestion de release, usage d’outillage de gestion de configuration et de pipeline de CI/CD. 
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/publicis-france-1/jobs/senior-data-engineer-h-f_paris_PF_eXRgQa7?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=02b4cba9-519d-4b04-9334-be24f1cca478,wttj
Data Engineer,"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, Cybersécurité', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232M€', 'mean_age': None}",CDI,Sophia-Antipolis,Non spécifié,Télétravail non autorisé,,> 3 ans,,"Descriptif du poste
💥 Découvrez la Vie Apsidienne 📹et vous aussi, devenez Apsidien //
On aurait pu demander à Chat GPT de vous démontrer en quoi Apside est l’ESN qu’il vous faut, mais on préfère que vous le découvriez vous-mêmes 👇😏
🔥 Découvrez votre future mission //
👉 Contexte
Collaborateur(rice) Apsidien(ne) de l’agence de Sophia-Antipolis, vous accompagnez l’un de nos clients en tant que Data Engineer (F/H).
😎 Mission
Intégré(e) au sein d'une équipe Agile, vous êtes responsable de la collecte, du stockage, du traitement et de la distribution des données chez le client.
Collecter et stocker les données provenant de différentes sources
Préparer les données pour les analyses
Développer et maintenir les pipelines de données
Construire et maintenir les bases de données
Partager les données avec les utilisateurs finaux
📍 Localisation
Technopôle de Sophia-Antipolis
Télétravail hybride
💰 Le package salarial que nous vous proposons //
Contrat : CDI
Rémunération : selon profil
(D’abord on échange, on comprend vos compétences/aspirations professionnelles et ensuite on s’entend sur le salaire. 😊)
Avantages groupe : carte ticket restaurant Swile, prime de mobilité, RTT, accord télétravail, Mutuelle, prime de cooptation…
Formation : certifications techniques, cours particuliers d’anglais en interne, accès à un catalogue de formations grâce à notre plateforme en e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherché
🔮 Ô vous futur Apsidien, qui êtes-vous ? //
Issu(e) d’une Grande Ecole avec un parcours spécialisé Data, ou Master Data avec 3 ans d'expérience
Une expérience réussie est fortement appréciée
Compétences techniques :
Kafka, Spark, Spark Streaming …
Hadoop
SQL, PostgreSQL, MongoDB, APIs
Connaissances Scala appréciées
Anglais courant obligatoire
Travail en contexte agile, scrum
😏 Apside a suscité votre curiosité ? //
Dans un environnement marqué par une accélération des évolutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients à créer de la valeur et à adresser leurs enjeux stratégiques en leur mettant à disposition des expertises technologiques () et une expérience sectorielle (). Pour un accompagnement global, le groupe propose des offres transverses autour du (Apsid’EA), du , et du .
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/apside/jobs/data-engineer_sophia-antipolis?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=4f74589a-d2cc-4194-980c-adbe3e7d811a,wttj
Consultant(e) Data Engineer - secteur Luxe F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Accompagner nos clients – interlocuteurs métier & IT dans la compréhension de leurs besoins et dans la définition de solutions technologiques et/ou organisationnelles ;

Concevoir et mettre en œuvre des solutions en s’appuyant sur les technologies cloud ( GCP et / ou Azure), les technologies de conteneurisation et l’automatisation (Ansible, Terraform, Kubernetes…)

Mettre en place des solutions intégrant les pratiques DevOps pour renforcer l’agilité et la capacité à innover de nos clients

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).","Profil recherché
- Maîtrise des architectures Big Data / Data Warehouse / Data Lake
- Maîtrise des services DATA de GCP (Bigquery principalement)
- Développement les solutions data (Alimentation, stockage, modélisation, restitution)

Vous êtes issu d'une formation bac+5 en école d'ingénieur ou informatique et disposez à minima de 3 années d'expérience sur un poste de data ingénieur.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-17,https://www.welcometothejungle.com/fr/companies/cgi/jobs/consultant-gcp-secteur-luxe-et-cosmetiques-f-h_paris_CGI_Xd4MRO2?q=67df9aa9ee7a87c1c25bcc5f5a80d64a&o=62521b9d-047e-4d0d-8d8f-14ecd79f6855,wttj
Data Engineer Splunk F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Toulouse,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Vous disposez d’une connaissance approfondie de l’écosystème des solutions RTM du marché (Splunk (de préférence), ELK, Dynatrace, …) ainsi qu’une connaissance d’un ou plusieurs outils de déploiement automatisés et DevOps (DOCKER, ANSIBLE, KUBERNETES…).
Vous savez développer et manipuler des données grâce aux langages Python et/ou Java et Javascript.

En tant que Data Engineer Splunk, vous intègrerez un pôle de consultants spécialistes du Real Time Monitoring d’une quarantaine de consultants basés sur les sites de CGI Montpelier et CGI Toulouse.
Vos missions seront les suivantes :
-Mener des ateliers fonctionnels, analyser et comprendre le besoin, synthétiser les aspects techniques et fonctionnels afin de mieux définir la trajectoire de mise en œuvre de la solution Splunk chez nos clients
-Travailler en collaboration avec les ingénieurs techniques et autres experts afin de rechercher et fournir des réponses aux problématiques techniques
-Réaliser les travaux d’implémentation de la solution SPLUNK :
Paramétrage de la collecte de données
Structuration et normalisation
Développement de dashboard
Définition de la stratégie de migration
Configuration des algorithmes, notamment en vue de les adapter au Machine Learning, Deep Learning, etc.
Préparation des données
Bonnes pratiques de développement et respect de conventions de nommage
Conception et mise en œuvre de nouveaux scénarios de détection
Optimisation des requêtes Splunk

-Produire les projets en mode agile avec des processus et outils de développement de dernière génération
-Participer à l'élaboration et la révision de normes / documentation technique
-Animer des formations internes. Accompagner la montée en compétences des équipes
-Assurer un support technique Splunk aux équipes et aux clients au quotidien

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
Vous justifiez de 3 à 5 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil dans le Domaine du Data Monitoring.

Vous êtes ou avez :
-Esprit d'équipe
-Esprit audacieux et ambitieux
-Force de proposition
-Maitrise au moins d'une technologie Real Time Monitoring, de préférence Splunk

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-17,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-splunk-h-f_toulouse_CGI_V6A77NN?q=be8a9c69da66ddfa053c664b1e1e4e02&o=15ac264f-b4eb-4616-9cc7-63e5162ebc16,wttj
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Niort,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Vos responsabilités seront les suivantes:

-Maintenir et développer des solutions basées sur les services AWS pour le stockage, le traitement et l'analyse de données
-Utiliser les services AWS appropriés tels que Amazon EC2, S3, RDS, Lambda, etc., pour répondre aux exigences du projet.
-Créer et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS
-Participer à la maintenance et à la mise en place d'environnements OpenShift pour l'hébergement d'applications et de services
-Gérer et administrer les clusters Kafka pour garantir la disponibilité, la performance et la sécurité du système de messagerie
Participer à l’assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data
-Travailler avec les projets et les devOps pour assurer un traitement efficace des données

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
Ayant une première expérience en tant que Data Engineer, vous avez une première expérience relative aux points suivants:
-Développement et intégration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop
-Connaissance avancée de l'administration Kafka, y compris la configuration, la gestion et la résolution des problèmes
-Mise en œuvre de l'infrastructure en tant que code à l'aide de Terraform
-Bonne compréhension des bonnes pratiques de sécurité pour les systèmes cloud, les clusters Kafka et les plateformes Hadoop

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-17,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-f-h_niort?q=be8a9c69da66ddfa053c664b1e1e4e02&o=84ad553b-ca68-4df0-b682-551f5864192c,wttj
Data Engineer Microsoft Azure F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Lyon,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Le poste de Data Engineer est à pourvoir dans notre équipe de 6 personnes basée à LYON. C’est une mission à durée indéterminée dans un contexte internationale car les clients sont suisses ou hollandais. Pas de présence sur le site client, cela se déroulera dans les locaux de l’agence CGI de Lyon;

En tant que Data Engineer, vous serez au cœur de la transformation digitale des entreprises et de la société.
Développement, ingestion et traitement de données, cloud transformation/ migration seront autant d’enjeux qui rythmeront votre quotidien aux côtés de nos professionnels.
Vous intégrerez une équipe de taille humaine spécialisée sur les domaines de la chimie & du manufacturing.
Aux côtés des autres membres de l’équipe et de la communauté Data Grand-Est, vous perfectionnerez vos compétences pour devenir un Data Engineer senior sur les technologies les plus modernes du marché Data à l’internationale.
Au sein de l’équipe de support, vous serez en interaction avec toutes les parties prenantes du client, allant du business, aux équipes d’expert et de déploiement des solutions.
Vous participerez au maintien en condition opérationnelle de la plateforme data de nos clients et vous évoluerez dans un contexte international, et bénéficierez de l’expertise de consultants CGI

Responsabilités et tâches principales :

• Appréhender le contexte client ;
• Comprendre et expérimenter le cadre Agile ;
• Traiter les demandes clients et la maintenance du périmètre cloud data en place ;
• Analyser les besoins fonctionnels et déterminer le modèle de données nécessaire avec l’accompagnement de Consultants seniors ;
• Participer au développement de ces indicateurs au sein de la plateforme Cloud cible (Azure et AWS) et des outils de restitution (ex : Power BI, Tableau, Qliksense) ;
• Établir et dérouler des scénarios de tests ;
• Participer à la vie de la communauté Data.


Environnement technique :

• Cloud provider : Azure, AWS
• Data Acquisition : Spark, Azure Data Factory, Synapse, Talend
• Base de données : SQL Server, PostgreSQL
• Script : JSON, SQL, Python, Shell, Javascript
• Environnement : Linux, Docker, Kubernetes
• Outils : DevOps, GITLAB CI
• Ticketing : Service Now
• Reporting: Power BI, Tableau, Qliksense
• Langue : Anglais courant souhaité

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
De formation bac+5 ou de formation supérieure en informatique, vous disposez de 5 ans expériences réussies dans le design et l’implémentation de plateforme de type Data Warehouse ET Data LakeCloud.
Des connaissances métiers dans le domaine de l’énergie et alliés à des compétences techniques fortes sont également des atouts pour la réussite de ce projet.
Votre capacité d'adaptation, votre autonomie, votre sens du service ainsi que vos qualités relationnelles seront vos atouts pour réussir et évoluer.
Vous devrez être en capacité de participer voire animer des ateliers en anglais.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-17,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-microsoft-azure-f-h-lyon_lyon?q=be8a9c69da66ddfa053c664b1e1e4e02&o=c4114155-19d7-4ae4-b2b3-c540edeacfa0,wttj
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Nantes,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Sous la responsabilité d'un Chef de Projet / Scrum Master, vos principales missions sont :
- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions techniques mises en place
- Recueillir les besoins métiers et des équipes data
- Assurer une veille technologique régulière
- Concevoir et mettre en place les traitements de données
- Tester et valider les développements réalisés
- Réaliser la documentation technique des développements réalisés
- Participer à l'élaboration et la révision de normes / documentation technique dans le cadre du projet
- Développer ses compétences et connaissances des architectures Data
- Etre garant de la mise en place, du suivi et de l'exploitation des outils déployés

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). 
Voir moins","Profil recherché
De formation Bac +5, vous disposez d'une expérience d'au moins deux ans dans la conception et le développement.

Vous maîtrisez un ou plusieurs ETL.

Véritable passionné, vous êtes rigoureux et doté d'un bon sens de la collaboration.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-17,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-f-h_nantes?q=be8a9c69da66ddfa053c664b1e1e4e02&o=a3418dcb-07ec-4cb5-9b55-b7197bcdc107,wttj
Data Engineer Cloud Data F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Toulouse,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
- Vous êtes passionné(e) par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …
- Vous disposez de solides connaissances sur les architectures de données et le cloud (AWS, GCP ou Azure).

Vos missions sont :
- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place
- Travailler en collaboration avec les ingénieurs techniques et autres experts afin de rechercher et fournir des réponses aux problématiques techniques
- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)
- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)
- Participer à l'élaboration et la révision de normes / documentation technique
- Animer des formations internes.
- Accompagner la montée en compétences des équipes
- Assurer un support technique aux équipes Data et aux clients au quotidien

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
- Passionné(e) d’informatique et de données, vous aimez le travail en équipe, apprendre et partager.
- Vous êtes également doté(e) d'un esprit audacieux et ambitieux.
- Vous faites preuve d’initiative et travaillez sur le long terme.
- Vous avez un minimum de 2 années d’expérience sur des projets Cloud (AWS, GCP ou Azure).
- Vous maitrisez un ou plusieurs services : Snowflake, Synapse, Databricks, Azure DevOps, Terraform, BigQuery, EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB etc.

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.",2024-01-17,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-cloud-data-azure-f-h_toulouse?q=be8a9c69da66ddfa053c664b1e1e4e02&o=6b187873-9eb1-4f44-adff-0cd11d6a7fca,wttj
Data Engineer F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Alors venez rejoindre nos équipes de Data Engineer. Vous pouvez être amené à intervenir sur tout ou partie de ces missions :

- Modélisation des Data Concepts d'un DataLake
- Développement et maintenance des traitements d'intégration et de transformation de données
- Intégration des développements dans la chaine CI/CD
- Documentation technique et fonctionnelle
- Rédaction de plan de tests
- Réalisation de tests unitaires/qualifications

Au sein de la communauté Data, vous serez accompagné et vous pourrez échanger avec des collègues expérimentés et experts vous permettant de vous développer, de grandir et d’accomplir pleinement vos missions de conseil.
L’accompagnement managérial, la communauté Data et de nombreux évènements tout au long de l’année nous permettront de vous aider à atteindre vos objectifs dans un esprit de convivialité.

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
Vous avez une formation Bac+3/5 en informatique, au minimum 1 an d’expérience et des aptitudes sur l’un ou plusieurs des domaines suivants :

Vous maitrisez :
- Data Visualisation : Power BI, MicroStrategy, Tableau, Cognos…
- Langages : SQL, Python, DAX, R…
- Applications Cloud : Azure, Snowflake, Databricks, AWS…
- Bases de données : Oracle, PostgreSQL, MySQL, Mongo db, Sybase…
- ETL : Datastage, Talend, Informatica (PowerCenter) …

Vous avez/ Vous êtes :
- Passionné du monde de la data
- Curieux et appréciez le travail en équipe

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-f-h_paris?q=be8a9c69da66ddfa053c664b1e1e4e02&o=ef0da4af-af2e-4a1f-a327-ec1416788d84,wttj
Data Engineer - Financial Services F/H,"{'name': 'CGI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '14500 collaborateurs', 'creation_year': '1976', 'turnover': '12 Mds € en 2022', 'mean_age': '36 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 3 ans,,"Descriptif du poste
Vos responsabilités sont les suivantes :

- Concevoir, développer et déployer des pipelines de transformations de données en environnement Big Data
- Définir des solutions globales permettant de répondre aux besoins métiers en prenant en compte les problématiques de performances, d’industrialisation, d’exploitation et de sécurité.
- Paramétrer et maintenir des clusters Big Data (MapR, Cloudera), ou des composants connexes (Nifi, Kafka, …)
- Faire des prototypes sur des technologies et de la veille technologique sur le Big Data
- Accompagner & supporter les équipes projet en coaching et expertise
- Animer et faire progresser des juniors et stagiaires
- Assurer le rôle de Lead Tech dans une équipe

En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…).
Voir moins","Profil recherché
De formation Bac+5 option informatique en école d’Ingénieurs ou équivalent avec une expérience d’au moins 3 ans d’expérience sur des fonctions IT de conception / développement en environnement Big Data.

Vous maîtrisez les compétences suivantes autour des produits Data / Big Data :
- Solution Hadoop (HDFS, YARN, Hive, Hue, Oozie…) et outillage associé
- PySpark, Python
- Bases NoSQL (Mongo, HBase, Couchbase, Marklogic…)
- Anglais niveau B2
- Compétences de Tech Lead appréciées : une capacité à coacher des juniors voire d’encadrer une équipe

Vous avez :
- Une excellente organisation
- Un sens des priorités

CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-financial-services-f-h_paris?q=be8a9c69da66ddfa053c664b1e1e4e02&o=665425ef-7048-46e7-8882-82969ffd3ae0,wttj
Big Data Engineer,"{'name': 'EQUATIV', 'sector': 'AdTech / MarTech', 'employees': '600 collaborateurs', 'creation_year': '2001', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
👫 About the team
At Equativ, we’re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 3 millions requests per second managed by 3,000 servers.
Our innovation team based in Paris, Nantes, Limoges, Krakow and Berlin is composed of 100+ straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.
Our data engineering team is composed of 10 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 140+ engineers spread across Paris, Nantes, Limoges, Kraków and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.
Our Mission 👇
Data Engineering team is central to Equativ’s data centric business and is responsible to ingest, transform, model and redistribute all data coming from our adtech platform.
We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle massive log ingestion (tens of billions per day), short & long term data storage, complex data modelling, real-time and batch ELT as well as providing external access through dedicated APIs.
Data Engineers serve Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science algorithms (clustering and optimization), customer reporting, invoicing and more.
Equativ Data Engineering team is engaged in an ambitious migration of its main data stack (Hadoop on-premise) to GCP with the objective to increase reporting features, lower maintenance time, improve performances and simplify the access to our raw data.
What you'll do ✏️
As a Big Data Engineer, you’ll primarily focus on maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIs
Design, develop, test, promote and industrialize all data components from data ingestion to datawarehouse delivery (ClickHouse, BigQuery)
- Propose and develop innovative solutions to achieve the best levels of scalability and performance for our Big Data engines
- Automate and streamline our real-time and batch data pipelines (on-premise and in the cloud) in order to simplify access to our data by other teams and lower amount of work spent by other teams on ETL processes
- Perform end-to-end monitoring to ensure high availability of production data processing, data quality and reliability
- Apply best in class Devops guidelines and secure deployments
Brainstorm with other team members working on our data backend (datawarehouse modelling and data exposure through our reporting APIs) on optimizing our architecture and support them in the use of our pipelines
Contribute to data roadmap definition in coordination with other R&D and product teams in order to build a best in class data infrastructure that will generate insights for Equativ’s analytics
Take part in improving and deploy data engineering standards, procedures, processes and operational guidelines around target data components at Equativ
💪 About you
Master degree in Computer Science or similar technical field of study
3+ years of software development with open source technologies
Fluent in Java and/or in Scala. SQL mastery
Very good understanding of Devops principles (Gitlab, Docker, Kubernetes, Gradle, ci/cd)
Experience with large-scale data engineering technologies (ClickHouse, Flink, Kafka, Hadoop, Spark, Hbase)
Experience on building data pipelines on Google Cloud Platform (BigQuery, Dataflow, GCS, Cloud Run, Airflow …) would be a big plus
Experience in working with high QPS Rest APIs is a plus
Entrepreneurial spirit and know-how to identify opportunities of improvement
Working proficiency and communication skills in verbal and written English
Passion for playing with large volume of data
🚀 How you'll grow
Within 1 month:
You'll be just finishing your onboarding.
You'll probably have tackled a few small tasks in peer-coding
Within 4 months:
You'll have an overview of 50% of the stack, CI/CD and team’s main processes. You’ll be able to work on more complex developments
You'll now have enough knowledge to participate to deployments of chosen applications
Within 9 months:
You'll be autonomous on most of our stack and will have participated to major projects
You’ll be helping the team on production matters
👋 About us 
Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus — four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.
Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.
The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times’ FT 1000: Europe’s Fastest-Growing Companies.
Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.
Come and lead the charge with us in building a transparent ecosystem based on quality!
----------------------
Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/equativ/jobs/big-data-engineer_paris?q=be8a9c69da66ddfa053c664b1e1e4e02&o=2dcf9db6-c09d-4a7f-9e02-c5885d7c3440,wttj
Stage - Data Engineer,"{'name': 'EXOTEC', 'sector': 'Logistique, Objets connectés, Robotique', 'employees': '600 collaborateurs', 'creation_year': '2015', 'turnover': '126 M€', 'mean_age': '31 ans'}",Stage,Lille,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Au sein du pôle Data, de la DSI d'Exotec, votre rôle sera de participer au développement de l'environnement et de l'infrastructure Data d'Exotec.
Pour cela :
Vous participez à la mise en œuvre des composants techniques de la plateforme de données d'Exotec
Vous travaillez sur la collecte dans la plateforme de données provenant de sources multiples : Salesforce, ERP, logiciels développés en interne
Vous nettoyez, mettez en qualité et préparez les données afin de les rendre disponibles pour les différents cas d'usage qui en ont besoin
Vous migrez des reportings existants vers la plateforme de données et mettez en œuvre de nouveaux cas d'usage pour répondre aux besoins de l'entreprise
Vous travaillerez au sein de l'équipe data et en étroite collaboration avec la software factory, ainsi qu’avec les utilisateurs des métiers qui ont besoin de rendre intelligibles les données disponibles
Requirements
Vous êtes étudiant(e) d’une école d’Ingénieur généraliste avec une spécialisation programmation ou informatique
Vous recherchez un stage de fin d’études d’une durée de 4 à 6 mois
Vous avez idéalement une première expérience en Data Engineering et le développement de pipeline de données
Vous maitrisez Python, l'ETL et SQL,
Curieux(se) et rigoureux(se), vous souhaitez rejoindre une équipe jeune et dynamique ainsi que vous investir dans des projets complexes et excitants
Vous avez un niveau d’anglais courant

Chez Exotec, nous garantissons l’égalité des chances dans notre processus de recrutement. L’ensemble des candidatures reçues sont étudiées indépendamment de l’âge, du genre, de l’origine, de la religion, de la couleur de peau, de la nationalité, du sexe, du handicap, de l’orientation sexuelle ou de toute autre distinction protégée par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les différences. En rejoignant le Pacte Parité, Exotec s’engage pour un écosystème French Tech plus paritaire.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/exotec/jobs/stage-data-engineer_lille?q=be8a9c69da66ddfa053c664b1e1e4e02&o=084be02e-ca07-4ab2-9503-4dcc2c8b80f4,wttj
R&D Data Engineer,"{'name': 'EXOTEC', 'sector': 'Logistique, Objets connectés, Robotique', 'employees': '600 collaborateurs', 'creation_year': '2015', 'turnover': '126 M€', 'mean_age': '31 ans'}",CDI,Lille,Non spécifié,Télétravail non autorisé,,,Bac +5 / Master,"Descriptif du poste
Exotec is at the forefront of technological excellence, redefining the relationship between humans and robots. Our solutions are contributing to the success of some of the largest brands in retail and e-Commerce by revolutionizing the way they fulfill their orders to the end consumers, all while mitigating labor constraints and increasing workplace safety.
Through the unification of artificial intelligence and high-performance hardware, our robotic solutions are now deployed across the globe and our exponential growth has led us to become the first industrial unicorn in France.
Working at Exotec is an exciting opportunity to give purpose to your skills. Learn and grow with over 600 ExoPeople around the world to help turn your ideas into a reality.
The robotics revolution is just the beginning at Exotec. Will you be part of it?
 We are seeking a talented and experienced Data Engineer to join our team in the Product Department.
As a Data Engineer at Exotec, you will play a key role in designing, developing and maintaining our data infrastructure.
 Responsibilities
Collaborate with cross-functional teams to understand data requirements and design scalable data solutions.
Collect data coming from our different client sites
Design and implement an event driven data lake
Provide the data to applications and end user
Requirements
IT/Software Engineer or related field.
Proven experience as a Data Engineer or similar role
Strong proficiency in Python
Hands-on experience with Terraform for Infrastructure as Code
Knowledge of containerization and orchestration tools like Docker and Kubernetes
Familiarity with AWS
Strong problem-solving and analytical skills
Excellent communication and collaboration skills
Nice to have:
Familiarity with Kafka or other message queuing system
Hands-on experience with Apache Airflow or Dagster
Familiarity with machine learning frameworks and concepts
Benefits
Couverture mutuelle et prévoyance santé compétitive
Primes collectives et attribution de BSPCE
Politique famille avantageuse
Programme de mobilité interne et internationale
Nombreuses opportunités de formation et de développement
Chez Exotec, nous garantissons l’égalité des chances dans notre processus de recrutement. L’ensemble des candidatures reçues sont étudiées indépendamment de l’âge, du genre, de l’origine, de la religion, de la couleur de peau, de la nationalité, du sexe, du handicap, de l’orientation sexuelle ou de toute autre distinction protégée par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les différences. En rejoignant le Pacte Parité, Exotec s’engage pour un écosystème French Tech plus paritaire.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/exotec/jobs/r-d-data-engineer_lille_EXOTE_mmDZ01?q=be8a9c69da66ddfa053c664b1e1e4e02&o=0a349886-2e3e-465d-bc0c-28a3e8ab80cc,wttj
Data Engineer - F/H,"{'name': 'CS', 'sector': 'Ingénieries Spécialisées, Aéronautique / Spatiale, Energie', 'employees': '2700 collaborateurs', 'creation_year': '1968', 'turnover': '300 000 000€', 'mean_age': '40 ans'}",CDI,Toulouse,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Nous recrutons un.e Ingénieur Data Engineer pour rejoindre notre Business Unit INDUSTRIE au sein de la Business Line Data Intelligence. Elle accompagne nos clients dans leurs problématiques associées à la transformation digitale. Nos offres se déclinent autour de la data intelligence & de la maintenance prédictive.
Votre mission :
Dans le cadre de nos projets, vous rejoindrez notre équipe et participerez aux missions suivantes :
- Concevoir,  développer, industrialiser et déployer des outils de traitements de données

- Monitoring et analyse de flux de données

- Accompagner nos clients sur les conceptions d'architecture des systèmes

- Rédiger les rapports d’analyse de données, et assurer la présentation au client
Environnement technique :

Méthodologie: Agile, Kanban, SAFe

Framework: Hadoop, Hortonworks, Spark

Base de données: Relationnelle & NoSQL

Langages: Python, Scala

Outils : Git, connaissance en containerisation (Docker)
Voir moins","Profil recherché
Qui êtes-vous ?
Vous avez une première expérience (a minima 1 an sur un poste similaire) en Data Engineering, idéalement dans le secteur aéronautique.
La connaissance des techniques et méthodes de développement logiciel serait un plus dans l’exercice de votre fonction. 
Un niveau d’anglais professionnel est requis.

Vous êtes autonome et rigoureux,  et vous savez faire preuve de capacité d’analyse ? Vous êtes bon communiquant et créatif ? Alors vous êtes la pépite que nous recherchons !
A compétences égales, ce poste est ouvert aux personnes en situation de handicap.",2024-01-17,https://www.welcometothejungle.com/fr/companies/cs-group/jobs/data-engineer-f-h_toulouse_CS_W3LY8qN?q=be8a9c69da66ddfa053c664b1e1e4e02&o=e6689d98-03e9-4a56-af97-bcb385c9a883,wttj
Senior Data Engineer,"{'name': 'DOCTRINE', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Service juridique', 'employees': '120 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Notre mission ⚖️
Nous nous engageons pour un enjeu démocratique majeur : rendre le droit plus accessible et transparent aux justiciables et aux professionnels du droit.
Doctrine est la première plateforme d'intelligence juridique. Nous centralisons et organisons toute l'information juridique disponible pour permettre aux avocats et juristes de mieux conseiller et défendre leurs clients. Plus d'un million de personnes viennent tous les mois sur Doctrine se renseigner sur leurs droits, et déjà 12 000 professionnels du droit nous font confiance.
Nos valeurs 🤝
Challenge the status quo. Nous défendons les idées audacieuses et la prise de risque intelligente.
Liberty and responsibility. Nous promouvons l’autonomie, l’impact de chacun·e et l’ownership.
Knowledge is power. L'information est au cœur de la mission de Doctrine, et nous voulons toujours apprendre plus.
Release early, release often and listen to your customers. Nous croyons au pouvoir de l’itération et à l’importance d’écouter en permanence notre marché, nos client·e·s et leurs problématiques.
Le contexte
Nous sommes actuellement à la recherche d'un Senior Data Engineer pour rejoindre l’une de nos squads et participer à la construction de la première plateforme d’intelligence juridique.
Tu rejoindras une squad dont la mission est de permettre le scale à la fois en terme de quantité mais aussi de diversité de données de notre plateforme.
Tu peux trouver des détails sur l’ensemble de la stack sur Github !
A savoir : il n’est pas nécessaire d’avoir une expérience professionnelle dans le domaine du droit, cependant l’envie de s’investir et de monter en compétence dans la compréhension des documents juridiques est importante :)
Les missions 🛠
Concevoir, développer, monitorer les pipelines de données et les scripts d'acquisition utilisées pour tous les contenus de notre plateforme
Assurer la qualité de la donnée et son monitoring
Travailler main dans la main avec des ingénieurs data et machine learning en charge des parties équivalentes de leur côté
Contribuer à l’évolution de nos outils de pipeline de données (Airflow, Kubernetes, Dask, Amazon S3, PostgreSQL, Terraform, etc...), et faire en sorte d’en tirer le meilleur profit au quotidien
Faire monter en compétence les autres ingénieurs de l'équipe
Au sein du Chapter Data Engineering, participer à l'élaboration de nos pratiques de modélisation et de traitement des données.
Le profil idéal 👀
De bonnes compétences en programmation Python
Une expérience des pratiques d'acquisition et de modélisation des données
Une bonne connaissance de SQL, NoSQL, Elasticsearch et du stockage objet
L’envie de partager tes connaissances pour participer à la progression de chacun.e
La maîtrise de la langue française, car tu seras amené.e à manipuler des données juridiques en français.
Les à côtés du poste 👁
Comme tous les ingénieurs de Doctrine, tu participeras à un de nos chapters transverses, en l’espèce le chapter Data Engineering. Au sein de ce chapter, tu contribueras à des projets internes pour améliorer nos process et notre vision long-terme. Le chapter se réunit toutes les deux semaines pour :
🤝 Partager des connaissances : amélioration continue, bonnes pratiques,…
🎯 Proposer des évolutions : nouveaux outils à expérimenter, nouveaux process à mettre en œuvre
Tu participeras également au 👩‍💻 recrutement : tous les contributeurs individuels rencontrent des candidats à l’occasion de tests techniques ou d’entretiens.
Ce qui t'attend si tu rejoins Doctrine 🤗
- Contribuer à un projet ambitieux, avec un impact réel et positif sur la société : rendre le droit plus accessible et plus ouvert.
- Un accompagnement sur mesure dès ton arrivée sur l'écosystème juridique pour t'aider à naviguer très vite dans cet environnement stimulant.
- Une aventure dans laquelle tu apprendras sans cesse et partageras tes connaissances à l’ensemble de tes collègues (talks internes/externes, meetups, Tech & Sales Monthly, blog Medium, etc.)
- Travailler au sein d’une équipe en ébullition qui cherche sans cesse à se renouveler : de la place pour innover et mener des projets en autonomie ou en équipe.
Nos avantages pour faire la différence ☀️
🏡 Une politique de télétravail flexible, avec 2 jours de présence au bureau par semaine (mardi et jeudi)
🌱 De nombreuses options pour ta carrière, et des mobilités internes ouvertes à toutes et tous chez Doctrine
🌴 Des vacances flexibles et illimitées
📚 Un vrai accent sur la formation individuelle et collective, avec un budget annuel de 750€ en usage libre et des formations en équipe et pour toute l'entreprise régulièrement
🏄‍♂️ Des évènements collectifs réguliers
👩‍⚕️ Une bonne assurance santé avec Alan
🚲 Un forfait mobilité durable à hauteur de 66 euros par mois
🏋️‍♀️ Un abonnement Gymlib pour les activités sportives et bien-être
🍱 Une carte Swile pour tes tickets restaurants
🧘 Un accès gratuit à la plateforme d'accompagnement à la santé mentale Moka.care
💡 Des centaines de réductions et avantages négociés grâce à notre CSE
🍏 Un équipement de travail neuf chez Apple
Notre processus de recrutement 🚀
- Un premier échange de 30 min avec l’un.e de nos Talent Acquisition Manager pour bien comprendre ton projet professionnel et te présenter ce qu'on construit chez Doctrine
- Une rencontre d’1h avec ton/ta futur.e manager, pour détailler le poste et le scope de l’équipe, mais aussi répondre à toutes tes questions.
- Un ou deux tests techniques pour évaluer concrètement tes compétences
- Un déjeuner avec 3 personnes de différents départements chez Doctrine, pour te donner un aperçu de tes futur.e.s collègues
- Un échange sur les valeurs de l’entreprise pour te partager notre vision
- Une rencontre avec Guillaume, notre CEO.
(si nécessaire le processus pourra être adapté pour répondre à tes contraintes personnelles et professionnelles)
Mesdames, autorisez-vous à candidater !
Certaines études scientifiques montrent qu'en particulier les femmes ont moins tendance à postuler à une offre d'emploi quand elles n'ont pas toutes les qualifications. Si cela peut vous rassurer, sachez que cette fiche de poste est indicative donc prenez la comme telle : c'est un guide, ni plus ni moins.
Si Doctrine vous intéresse, sachez que nous aurons plaisir à recevoir votre candidature !
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/doctrine/jobs/senior-data-engineer_paris_DOCTR_MorZ0KD?q=be8a9c69da66ddfa053c664b1e1e4e02&o=2c85a8dc-da3e-4214-92e0-ebf3c48aced7,wttj
Data Engineer Senior H/F,"{'name': 'MEILLEURTAUX', 'sector': 'FinTech / InsurTech, Immobilier commercial, Immobilier particulier', 'employees': '2000 collaborateurs', 'creation_year': '1999', 'turnover': None, 'mean_age': '34 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Vous souhaitez rejoindre la fintech leader en crédit et en assurance, en forte croissance, innovante, dynamique et débordante de projets ? Ce qui suit va vous intéresser !
Contexte de ce recrutement 🚀
Nous sommes engagés dans le développement d’une Customer Data Platform. 
Cette plateforme de données est au cœur de la stratégie de croissance de l’entreprise va nous permettre de :
- Augmenter la Customer Lifetime Value (CLTV) de nos clients,
- D'intégrer dans tous nos produits des composants IA innovants, 
- Réduire nos coûts d’acquisition,
- Faciliter le pilotage du business à travers une optimisation de nos outils de BI.
Vous vous épanouirez dans notre environnement en évolution rapide, où l'adaptabilité est essentielle. Au-delà de la résolution de défis techniques, nous souhaitons que vous contribuiez activement à la construction de la culture d'ingénierie de Meilleurtaux, à l'amélioration des pratiques et à la promotion d'un environnement collaboratif et innovant.
Vos missions 📝
Créer et maintenir une infrastructure de données de pointe en permettant aux utilisateurs finaux d'accéder à de la donnée précise et de qualité ;
Développer de nouveaux modèles de données et des pipelines.
Ils ont auront pour objectif de prendre en charge une grande variété de cas d'utilisation (de l'analyse et du reporting à l'apprentissage automatique et à l'innovation de produits) ;
Explorer en permanence de nouvelles technologies de données ;
Tester les solutions les plus innovantes et prometteuses du marché en vue de pouvoir améliorer nos capacités en matière de données ;
Recruter, encadrer et accompagner votre équipe de Data Engineers au quotidien ;
Partager et défendre vos meilleures pratiques d'ingénierie de données au sein des principaux organes de décision de l'entreprise.
Notre stack technique 🛠 
Développement : Python, React, java, Salesforce
CI-CD :  Git, Docker
Infrastructure cloud : GCP et Azure
Bases de données : Google BigQuery et Databricks
BI : Qliqsense
Ce poste nécessite d'interagir avec de nombreuses équipes au sein de Meilleurtaux que ce soit sur le plan technique (équipes IT, Data Scientist et BI) et/ou fonctionnel (Product Managers).
Ceci n’est qu’un avant-goût de la superbe aventure que vous vous apprêtez à rejoindre, le poste étant évidemment amené à évoluer en fonction de vous et vos propositions.
Voir moins","Profil recherché
Pourquoi êtes-vous notre TOP candidat ? 🧐
Avec une expérience d'au moins 8 ans dans la Data, vous aviez été amené(e) à manager une petite équipe (entre 1 à 3 personnes) de Data Engineers.
Vous savez créer des architectures de données efficaces, évolutives et robustes.
Vous concevez des systèmes adaptés au présent mais également à l'avenir et qui résistent à l'épreuve du temps.
Bien entendu, il est important que vous ayez de très bonnes compétences techniques que ce soit en Python ; SQL et les autres outils pouvant exister en ingénierie de données.
La Big Data n'a plus de secret pour vous. Spark & Hadoop sont vos plateformes de référence sur ce domaine.
Vous avez déjà participé au déploiement d'infrastructure en Big Data.
Idéalement, vous faîtes partie d'une communauté de professionnels de la Data vous permettant d'être toujours au fait des dernières actualités.
Le must : cette expertise a été acquise au sein de l'industrie Fintech / Assurtech ou secteur équivalent. 
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/meilleurtaux-com/jobs/data-engineer-senior-h-f_paris_MEILL_qmLOArV?q=be8a9c69da66ddfa053c664b1e1e4e02&o=efcb51fb-95b6-4bf1-be67-a6a2455d5568,wttj
Consultant Senior Data Engineer (H/F) - Paris - 2024,"{'name': 'MAZARS ET LA TECH', 'sector': 'IT / Digital', 'employees': '28000 collaborateurs', 'creation_year': '1945', 'turnover': '2,1 milliards', 'mean_age': '30 ans'}",CDI,Courbevoie,Non spécifié,Télétravail non autorisé,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Rejoindre l’équipe Data Services de Mazars, c’est rejoindre une équipe de plus de 30 consultants spécialistes de la data, répartis sur 2 hubs (Paris La Défense, New-York).  
Au sein du DataLab, nos domaines d’expertises couvrent l’ensemble de la chaîne de valeur de la donnée : Data Strategy et qualification de cas d’usage, Gouvernance et qualité des données, Gestion des données de référence (MDM), Data transformation, Data Architecture, Data Engineering, Data Science, Data Visualisation et Analytics,
Formation à tous niveaux sur ces précédents sujets.  
Vous serez formé(e) à nos méthodologies et aurez l'opportunité de travailler au sein d'équipes pluridisciplinaires, y compris les équipes de R&D qui développent et maintiennent nos outils d'Analytics ainsi que notre infrastructure interne (GitLab-CI, Cloud privé OpenNebula, CephFS, etc...).

Vous interviendrez de façon opérationnelle sur des missions de conseil data ambitieuses et innovantes pour nos clients du CAC40 et SBF120, en France et à l'international. Vous participerez notamment à :

• L'amélioration de la performance opérationnelle de nos clients au travers de l’exploitation et la valorisation de données sur des cas d’usage métier concrets (stratégie, marketing et vente, R&D, finance, etc..).
• L’interaction directe avec nos clients dont nous analysons les problématiques pour les aider à implémenter des solutions technologiques sur-mesure.
• Le développement de bout en bout de flux de données, depuis l'extraction et la transformation des données de nos clients, jusqu’à leur consommation par des systèmes ou applications web et tableaux de bord que nous concevons pour eux, en passant par les datalake, data-warehouse, data-marts ou API qui exposent ces données.
• Déploiement de pipelines de données dans le paradigme serverless cloud (AWS Lambdas, Azure Functions, GC Functions, etc.) mais aussi utilisation de techniques DevOps et de virtualisation bare-metal avancées au sein d'une équipe pionnière du MLOps (équipe opérationnelle en CI/CD depuis 2013).
Voir moins","Profil recherché
Profil recherché

De formation Bac+5 type école d’ingénieur généraliste ou spécialisée, ou d'un 3ème cycle dans un domaine connexe à la data (systèmes d’informations, traitements de données, big data, statistiques, génie logiciel, etc.) :
Vous avez déjà montré un intérêt pour le domaine du développement applicatif intégrant une composante Data, à travers des stages, cours ou projets personnels impliquant le développement back-end et/ou front-end d’une application.
 Vous avez une expérience pratique et une bonne connaissance de :
Un ou plusieurs langages de programmation analytique (Python, SQL, R, etc.)
Une ou plusieurs couches de persistance (SGBD relationnel : MySQL / MSSQL / PostgreSQL, No- SQL : MongoDB / ElasticSearch / Node4j, ou encore S3)
La conception et/ou l’implémentation et/ou la manipulation de datalakes, data warehouses ou data- marts
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/mazars-tech/jobs/consultant-senior-data-engineer-h-f-paris-2024_courbevoie?q=be8a9c69da66ddfa053c664b1e1e4e02&o=7fda3a88-ab69-424b-b55e-3fdfe06f4057,wttj
[SFR] Stage Data Engineer - Prévisions & Analyse Réseaux,"{'name': 'ALTICE FRANCE SFR RMC BFM', 'sector': 'Média, Télévision / Production audiovisuelle, Electronique / Télécommunications', 'employees': '11000 collaborateurs', 'creation_year': '1987', 'turnover': '11 milliards en 2022', 'mean_age': None}",Stage,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Intitulé du poste
Au sein de la Direction Développement Réseaux, vous intégrerez l'équipe ""Prévisions et Analyses Réseaux"".
L'équipe a pour principales missions de : 
- donner - en fonction de la stratégie ""group"" adoptée - la vision des évolutions de trafics des réseaux fixe et mobile à court et moyen terme (1 à 5 ans),
- comprendre les habitudes et les évolutions de consommation des services voix/data/vidéo de ses clients,
- anticiper les changements ou ruptures technologiques,
- maitriser les investissements réseaux,
 - détecter des leviers actionnables par des analyses data réseau afin de garantir la meilleure qualité de service à ses clients.
Vos rôles et missions sont, dans le cadre de la rationalisation de l'infrastructure BigData existante et de sa migration dans le Cloud, de :
- analyser la structure des bases de données existantes (Cloudera/Teradata/Oracle) et leur utilisation,
- transformer / organiser / structurer et documenter les données du réseau exploitées par ces bases,
- contribuer à la définition du processus de migration des scripts existants,
- réaliser la migration des reportings et dataviz d'aide à la décision dans le nouvel environnement,
- automatiser les imports de données internes à la société ou disponibles en open data (csv, json, ...),
- explorer l'eco-systeme Cloud et prototyper de nouvelles fonctionnalités (IA, cartographie, ...).
Profil
Etudiant(e) Bac+4 ou 5 en école d'ingénieur ou universitaire, spécialisé(e) en Informatique, vous avez envie d'effectuer votre stage, durant le premier semestre 2024, dans un environnement technique bigdata riche et novateur.
Vous maitrisez les principales bases de données (Hive/Impala/Teradata/Oracle), le SQL et les environnements de BigData dans le Cloud, tel que Google Cloud.
Vous connaissez le langage R et des outils de Dataviz (Tableau Software / R-Shiny).
Vous avez des connaissances en ETL, en robots d'indexation et savez structurer des données.
Vous êtes rigoureux(se), curieux(se), force de proposition, avez le sens de l'organisation, aimez travailler en équipe et relever des défis.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/altice-france/jobs/sfr-stage-data-engineer-previsions-analyse-reseaux_paris?q=be8a9c69da66ddfa053c664b1e1e4e02&o=8d2f89ae-8bfb-4589-a266-a649878b1d40,wttj
Data Engineer (F/H),"{'name': 'ASI', 'sector': 'IT / Digital, Transformation, Big Data', 'employees': '500 collaborateurs', 'creation_year': '1993', 'turnover': '42,5 M€', 'mean_age': '34 ans'}",CDI,Lyon,Non spécifié,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
VOS MISSIONS 
Analyser et comprendre les besoins client
Participer aux différentes phases :
           - Conception d’architecture décisionnelle et technique
           - Rédaction des spécifications fonctionnelles et techniques
           - Traitement de la donnée, concevoir et spécifier les jobs d’alimentation
           - Construction de cubes de données
           - Développement des rapports
           - Tests et recettes
           - Mise en production","Profil recherché
Vous êtes prêt à monter en compétences sur de nouvelles solutions, vous avez envie d’élargir votre spectre technologique.
Vous êtes curieux, rigoureux, analytique, dynamique et doté d'une grande capacité d'adaptation.
Vous avez de l'appétence et/ou connaissance des nouveaux concepts de la data (Data Mining, Data Visualisation, Data Lake, …)
De formation supérieure, vous avez une expérience réussie sur un poste similaire avec les compétences suivantes :
           - Travailler sur des projets de Data Intelligence, de façon autonome ou au sein d’une équipe
           - Maîtrise d’une ou plusieurs solutions du marché
           - Alimentation et stockage de données : SSIS, Talend, Oracle Data Integrator, SAP Data Services, …
           - Analyse : SSAS, SAS, …
            - Restitution : SSRS, SAP BO, QlikView, Qlik Sense, Power BI
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/asi/jobs/data-engineer-f-h_lyon_ASI_0ppkge0?q=be8a9c69da66ddfa053c664b1e1e4e02&o=3d05dbfd-0645-4e84-aa2a-f3447fe8a19b,wttj
Data Engineer / Azure (H/F),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail non autorisé,,> 4 ans,Bac +5 / Master,"Descriptif du poste
En résumé :
Poste : Data Engineer /Azure
Localité : Levallois-Perret
Type de contrat : CDI
Niveau d’expérience : au moins 3 ans
Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.
Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !
Vous accompagnez nos clients à travers toutes les étapes de leur transformation numérique dans un environnement Microsoft Azure : De la définition des axes stratégiques d'adoption du cloud, du design, au déploiement des outils, à la migration des applications et services. Vous aidez nos clients à gagner en performance, agilité, flexibilité du SI et à intégrer les Innovations les plus avancées.
Dans vos missions quotidiennes, vous serez amené(e) à : 
Apporter votre expertise à nos clients pour garantir une valeur ajoutée rigoureuse et innovante
Participer activement à la réalisation technique des projets de nos clients
Accompagner et conseiller les clients sur les meilleures pratiques, les technologies et outils les plus adaptés au contexte.
Réaliser des présentations, démonstrations, POC ou Pilotes pour mettre en lumière les recommandations technologiques.
Être constamment en veille technologique
Transférer des compétences spécifiques aux équipes techniques de nos clients
Voir moins","Profil recherché
Vous avez un minimum de 3 années d’expérience sur des projets Data dont au moins une sur des projets Cloud Microsoft Azure ou à défaut une certification Azure avec l’ambition de vous préparer à d’autres. 
Vous maîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R) ; 
Vous avez une maitrise des théories et outils de modélisation de données, 
Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, 
Solide Expérience Technique Dans Les Domaines Suivants
Azure Data Factory
Azure Synapse Pipeline
Spark/Scala
pyspark
Python
SQL, PL-SQL
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-azure-h-f_levallois-perret_MICRO_6r4mxw?q=be8a9c69da66ddfa053c664b1e1e4e02&o=8049d877-7608-4c1a-8a19-d7e3b6567cae,wttj
Data Engineer / Talend Big Data (H/F),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail non autorisé,,> 4 ans,Bac +5 / Master,"Descriptif du poste
En résumé :
Poste : Data Engineer Talend Big Data
Localité : Levallois-Perret
Type de contrat : CDI
Niveau d’expérience : au moins 3 ans
Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.
Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !
Au sein de notre agence basée à Levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer - Talend Big Data (F/H) , vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance. 
Dans vos missions quotidiennes, vous serez amené(e) à : 
Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; 
Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; 
Réaliser une veille technologique pour être à la pointe sur les solutions Cloud & Data ; 
Participer au développement de notre centre d’excellence. 
Voir moins","Profil recherché
Vos compétences techniques : 
Vous avez un minimum de 3 années d’expérience sur des projets Data avec Talend Spark ou SSIS. 
Vous maîtrisez au minimum un langage de programmation (Spark, Scala ou SQL) ; 
Vous avez une maitrise des théories et outils de modélisation de données, 
Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, 
Vos  atouts: 
Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; 
Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; 
Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. 
Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud et des solutions Data. 
#LI-LL3
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-talend-big-data-h-f_levallois-perret_MICRO_k83AexK?q=be8a9c69da66ddfa053c664b1e1e4e02&o=959b4769-20e3-40cc-b984-5af592a1d681,wttj
Data Engineer Confirmé (F/H),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Niort,Non spécifié,Télétravail non autorisé,,> 3 ans,,"Descriptif du poste
Comme nous, vous êtes passionné(e) par la donnée et convaincu(e) que la validation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez accompagner les entreprises dans leur stratégie data driver et les aider à se transformer grâce aux nouvelles technologies qu'amène le Cloud, pour préparer dès à présent leur futur ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitales, au sein d’une agence à taille humaine où règnent entraide et convivialité et engagée en faveur d’un numérique plus responsable au service de clients principalement implantés régionalement ? 
Rejoignez l'aventure Micropole à Niort !
Vous viendrez renforcer une équipe niortaise soudée qui porte l’esprit d’équipe, ayant à cœur de faire de votre intégration un succès et de vous accompagner dans votre montée en compétences. 
En intégrant Micropole vous aurez l'opportunité d'intervenir sur des projets data innovants, riches et variés et participerez activement au rayonnement de l'agence sur le bassin niortais.
Dans vos missions quotidiennes, vous serez amené(e) à:
Participer au recueil des besoins des métiers ;
Rédiger les dossiers de conception technique ;
Modéliser les entrepôts de données ;
Développer des flux de données via des ETL,
Concevoir des tableaux de bord via des outils de reporting et datavisualisation ;
Accompagner la maîtrise d’ouvrage dans la validation de livrables, les tests, l’assistance à la recette et la conduite du changement sur le projet.
Voir moins","Profil recherché
Vos compétences techniques : 
Vous maîtrisez la manipulation des données (préparation, modélisation, restitution),
Vous maîtrisez parfaitement au moins un ETL du marché (Informatica, Talend, BigQuery, Datafactory,...) et la création de tableaux de bord (Power BI, Tableau, QlikSense, SAP BO, ...),
Python ou SQL n’ont plus de secrets pour vous,
Vos atouts : 
Diplômé(e) d’une formation supérieure en Informatique parcours BI, Data, Aide à la Décision,
Vous possédez une expérience d'au moins 3 ans dans la fonction,
Votre esprit d’analyse, de synthèse, votre organisation et vos capacités rédactionnelles sont souvent reconnus,
Vous appréciez travailler en équipe, dans un contexte multi-projets.
DEVENIR #INNOVATIVE PEOPLE C’EST : 
Intégrer une communauté de 1200 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine.
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/consultant-bi-dataviz-f-h_niort?q=be8a9c69da66ddfa053c664b1e1e4e02&o=4bdd37e1-8a80-4db7-b8f7-1bccdfcb3b26,wttj
Data Engineer F/H,"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Villeurbanne,Non spécifié,Télétravail non autorisé,,> 4 ans,Bac +5 / Master,"Descriptif du poste
Enrésumé :
Poste: Data Engineer F/H
Secteur de l'entreprise :experts conseil dans les secteurs de la banque-assurance, le luxe-retail etl’Industrie
Localité : Lyon
Type de contrat : CDI
Niveau d’expérience :au moins 3 ans
Vous êtes passionné(e)s par la data ? Vous êtesconvaincus que l’optimisation du patrimoine data des entreprises est laclé de leur performance ? Vous voulez rendre les entreprises data drivenet les aider à se transformer pour préparer dès à présent leur futur? Vous êtes au fait des dernières tendances et prêt à explorer de nouveauxterritoires ?
Vous souhaitez rejoindre un groupe pionnier des grandesinnovations data et digitale ?
Si vous avez répondu « Oui » à chacune de cesquestions alors devenez Data Engineer pour nos clients grands-comptesdans les secteurs de le luxe/retail, la banque/assurance et l’industrie/services.
Alors,prêt à rejoindre l’aventure Micropole ? N’attendez plus !
EN TANT QUE DATA ENGINEER :
Vous rejoignez notre entité Data Analytics basée à Lyon, oùvous interviendrez sur l’intégralité de plusieurs projets avec une vision« Data 360° », mêlant Conseil, Architecture, Intégration et DataScience. En tant que Data Engineer, vous accompagnerezles directions métiers dans l'évaluation de l'efficacité de leur processus etdans leur stratégie pour optimiser leur performance.  Vous serez rattaché(e) à l’équipe Data Analytics,composée de 50 #InnovativePeople.
Dans vos missions quotidiennes, vous serezamenés :
A comprendrele besoin de nos clients au travers de missions de type : aide aux choixd’outils, cadrage des besoins, Proof Of Concept ;
Accompagnerles équipes commerciales sur des rendez-vous client et en phase d’avant-vente ;
Recueilliret analyser les besoins et proposer une architecture technique adaptée aux casd’usage des clients ;
A réalisernos projets de construction de Data Platform au travers des activités : refonte,migration ou développement de tableaux de bord dans le respect des exigences dequalité et sécurité ;
Rédiger ladocumentation des livrables pour rendre les utilisateurs autonomes et lesformer ;
Rédiger ladocumentation permettant à l'IT d'assurer la maintenance ;
Accompagnerles consultants moins expérimentés dans leur montée en compétence ;
Capitaliseret partager les bonnes pratiques, connaissances et retours d’expérience ;
Voir moins","Profil recherché
Vos compétences techniques :
Vous avez un minimum de 3années d’expérience sur des projets Data sur les outils ETL (Talend, SQLServer) et Reporting (Power BI, Tableau Software).
Idéalement au moins unepremière expérience sur des projets Cloud AWS ou Azure
Vous maîtrisez au minimumun langage de programmation (Python, Spark, Scala, R) ;
Vous avez une maitrise desthéories et outils de modélisation de données,
Vous maitrisez des conceptsd’industrialisation, Ia C, CI/CD et/ou gestion de version, 
Vos atouts :
Véritablecoéquipier, vous avez à cœur de contribuer à la montée en compétence de votreéquipe,
Vousrecherchez la variété et l’excellence dans votre travail. Autonome et impliqué(e),vous avez le goût du challenge,
Doté(e) d’unexcellent relationnel et du sens du service, vous avez la capacité de gérer unerelation client,
Vousdévelopperez votre créativité et votre curiosité grâce à une veilletechnologique accrue qui vous permettra de challenger les besoins de vosclients.
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer_villeurbanne?q=be8a9c69da66ddfa053c664b1e1e4e02&o=de30d4e2-246c-4e43-9cb9-a12bf5823ae0,wttj
Data Engineer / Databricks (H/F),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail non autorisé,,> 4 ans,Bac +5 / Master,"Descriptif du poste
En résumé :
Poste : Data Engineer / Databricks
Localité : Levallois-Perret
Type de contrat : CDI
Niveau d’expérience : au moins 3 ans
Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.
Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !
Au sein de notre agence basée à levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer Databricks (F/H) , vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance. 
Dans vos missions quotidiennes, vous serez amené(e) à : 
Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Databricks. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; 
Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; 
Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; 
Participer au développement de notre centre d’excellence. 
Voir moins","Profil recherché
Vos compétences techniques : 
Vous avez un minimum de 3 années d’expérience sur des projets Data dont au moins une sur des projets Databricks (sur GCP et/ou Azure), ou à défaut une certification Databricks avec l’ambition de vous préparer à d’autres. 
Vous maîtrisez au minimum un langage de programmation (Spark, Scala ou SQL) ; 
Vous avez une maitrise des théories et outils de modélisation de données, 
Vous maîtrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, 
Vos  atouts: 
Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; 
Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; 
Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. 
Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud et des solutions Data. 
#LI-LL3
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-databricks-h-f_levallois-perret_MICRO_3R8kwd5?q=be8a9c69da66ddfa053c664b1e1e4e02&o=f2478345-954b-46e3-b6b3-6c7ec9313bdb,wttj
Cloud & Data Engineer (F/H),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Nantes,Non spécifié,Télétravail non autorisé,,> 4 ans,Bac +5 / Master,"Descriptif du poste
Micropole accompagne les entreprises à devenir Data Driven grâce à la puissance du Cloud. Forte de ses consultants, experts techniques et architectes spécialisés dans les solutions AWS, Azure et GCP, Micropole aide les entreprises à devenir plus agiles, et à améliorer leur niveau de performance.  
Au sein de notre agence située dans le centre-ville de Nantes, vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance en tant que Cloud & Data Engineer (F/H).
 Dans vos missions quotidiennes, vous serez amené(e) à : 
Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data/Cloud
Modéliser et analyser des données dans le Cloud ;
Garantir la sécurité et la compliance des données ; 
Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. 
Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; 
Réaliser une veille technologique pour être à la pointe sur les solutions Cloud & Data ; 
Participer au développement de notre centre d’excellence GCP
Voir moins","Profil recherché
Vos compétences techniques : 
Vous avez un minimum de 3 années d’expérience en tant que Data Engineer dont au moins une première sur des projets  Azure et GCP ou AWS ;
Vous êtes idéalement certifié(e) ou à défaut avez l’ambition de le devenir ;
Vous êtes à l'aise avec un langage de programmation (Spark, Scala, Python, Java ou R) ; 
Vous maitrisez les théories et outils de modélisation de données ;
Des connaissances en industrialisation, CI/CD et/ou gestion de version seront particulièrement appréciées 
Vos  atouts: 
Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; 
Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients ;
Vous souhaitez vous impliquer dans le développement de communautés techniques autour du Cloud GCP et des solutions Data. 
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-f-h_nantes?q=be8a9c69da66ddfa053c664b1e1e4e02&o=d46435d7-d1f7-4260-9a1b-860f376fb490,wttj
SENIOR DATA ENGINEER AWS (F/H),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail non autorisé,,> 7 ans,,"Descriptif du poste
Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez aider les entreprises à devenir plus agiles,et à améliorer leur niveau de performance grâceà la puissance du Cloud ? Vous voulez rendre les entreprises data intelligentes etles aider à se transformer au travers des nouvelles technologies qu’amène le cloud ? Vous souhaitez rejoindre un groupe pionnier desgrandes innovations data, cloud et digitales ? 
 Si vous avez répondu« Oui » à chacune de ces questions alorsdevenez Consultant Senior pour l’un de nos clientsgrands-comptes. 
Prêt(e) à rejoindre l’aventure  Micropole ? N’attendezplus ! 
Dans le cadre du développement de notreentité Cloud4Data, nous recherchons nos futurs collaborateurs souhaitantdevelopper leur carrière professionnelle dans les enjeux de la Data.Cloud4Data est spécialisée dans la transformation des entreprises par la Dataen utilisant toute la puissance des solutions Cloud. 
Nous accompagnons nos clients par du conseil(stratégie de transformation par la Data) et par de l'expertise (projet de DataPlatform) sur leurs principaux enjeux BI, décisionnelles, analytiques, BigData, AI/ML/GenAI. Nos expertises sont principalement sur AWS, GCP, MicrosoftAzure, Snowflake et Databricks. Nos équipes sont principalement constituéesd'architecte Data/Cloud, Data ingénieur, Data analyste, Data scientiste etDevOps/SRE.
En tant que Consultant Sénior : 
 Au sein de notre agence basée à Levallois-Perret, vousrejoindrez nos experts Cloud4Data . En tant que Senior Data Engineer AWS, vousaccompagnerez les directions métiers dans l'évaluation de l'efficacité de leurprocessus et dans leur stratégie pour optimiser leur performance. 
Dans vos missionsquotidiennes, vous serez amené(e) à : 
·       40% : développeret maintenir des cas d’usages clients avec les outils et les infrastructuresBig Data / Cloud AWS. Modéliser et analyser des données dans le Cloud. Garantirla sécurité / compliance des données ; 
·       40% : apportervotre réflexion sur des problématiques métiers à travers l’exploitation et lacompréhension des données. Identifier les sources de données les pluspertinentes et restituer des résultats de façon concise et visuelle ; 
·       10% : réaliserune veille technologique pour être à la pointe sur les solutions cloud &Data ; 
·       10% : participerau développement de notre entité Cloud4Data
Voir moins","Profil recherché
Vos compétences techniques :
Vous avez un minimum de 3 années d’expérience sur des projets Data et idéalement au moins une année d’expérience sur des projets Cloud AWS (EC2, RDS, Lambda, Kinesis, Redshift, EMR, Connect, SageMaker etc), 
Vous maîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java, R) ; 
Vous avez une maitrise des théories et outils de modélisation de données, 
Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version,  
Vous avez passé au moins une certification AWS technique, et vous avez l’ambition de vous préparer à d’autres. 
Vos atouts : 
Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; 
Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; 
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/senior-data-engineer-aws-f-h_levallois-perret_MICRO_5Akw3LX?q=be8a9c69da66ddfa053c664b1e1e4e02&o=6d475aa0-425a-4b7b-8391-372ebd1adb90,wttj
Data Engineer / GCP (H/F),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail non autorisé,,> 4 ans,Bac +5 / Master,"Descriptif du poste
En résumé :
Poste : Data Engineer / GCP
Localité : Levallois-Perret
Type de contrat : CDI
Niveau d’expérience : au moins 3 ans
Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?
Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?
Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.
Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !
Au sein de notre agence basée à levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance. 
Dans vos missions quotidiennes, vous serez amené(e) à : 
Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Cloud GCP. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; 
Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; 
Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; 
Participer au développement de notre centre d’excellence GCP. 
Voir moins","Profil recherché
Vos compétences techniques : 
Vous avez un minimum de 3 années d’expérience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou à défaut une certification GCP avec l’ambition de vous préparer à d’autres. 
Vous maîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R) ; 
Vous avez une maitrise des théories et outils de modélisation de données, 
Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, 
Vos  atouts: 
Vous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; 
Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; 
Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. 
#LI-LL3
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-h-f_levallois-perret_MICRO_Pl4NJMk?q=be8a9c69da66ddfa053c664b1e1e4e02&o=e5557cdd-5995-4d25-8c16-2dd54b268b56,wttj
DATA ENGINEER AWS (F/H),"{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail non autorisé,,> 4 ans,,"Descriptif du poste
Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leurperformance ? Vous voulez aider lesentreprises à devenir plus agiles, età améliorer leur niveau de performance grâce à la puissance du Cloud ? Vous voulez rendre lesentreprises data intelligentes et lesaider à se transformer au travers des nouvelles technologies qu’amène le cloud ? Voussouhaitez rejoindre un groupe pionnier des grandes innovations data, cloud etdigitales ? 
 Si vous avez répondu« Oui » à chacune de ces questions alors devenez Consultant Confirmé pour l’un de nos clients grands-comptes. 
Prêt(e) à rejoindrel’aventure  Micropole ? N’attendez plus ! 
Dans le cadre du développement de notre entité Cloud4Data, nous recherchons nos futurscollaborateurs souhaitant developper leur carrière professionnelle dansles enjeux de la Data. Cloud4Data est spécialisée dans la transformation desentreprises par la Data en utilisant toute la puissance des solutionsCloud. 
Nous accompagnons nos clients par du conseil (stratégie detransformation par la Data) et par de l'expertise (projet de Data Platform) surleurs principaux enjeux BI, décisionnelles, analytiques, Big Data, AI/ML/GenAI.Nos expertises sont principalement sur AWS, GCP, Microsoft Azure, Snowflake etDatabricks. Nos équipes sont principalement constituées d'architecteData/Cloud, Data ingénieur, Data analyste, Data scientiste et DevOps/SRE.
En tant que ConsultantConfirmé : 
Au sein de notre agence basée à Levallois-Perret, vousrejoindrez nos experts Cloud4Data . En tant que Data Engineer Confirmé AWS,vous accompagnerez les directions métiers dans l'évaluation de l'efficacité deleur processus et dans leur stratégie pour optimiser leur performance. 
Dans vos missionsquotidiennes, vous serez amené(e) à : 
·       40% : développer etmaintenir des cas d’usages clients avec les outils et les infrastructures BigData / Cloud AWS. Modéliser et analyser des données dans le Cloud. Garantir lasécurité / compliance des données ; 
·       40% : apporter votreréflexion sur des problématiques métiers à travers l’exploitation et lacompréhension des données. Identifier les sources de données les pluspertinentes et restituer des résultats de façon concise et visuelle ; 
·       10% : réaliser une veilletechnologique pour être à la pointe sur les solutions cloud & Data ; 
·       10% : participer audéveloppement de notre entité Cloud4Data.
Voir moins","Profil recherché
Voscompétences techniques :
·   
Vousavez un minimum de 2 années d’expérience sur des projets Data et idéalement aumoins une première expérience sur des projets Cloud AWS (EC2, RDS, Lambda,Kinesis, Redshift, EMR, Connect, SageMaker etc), 
·       Vousmaîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java,R) ; 
·       Vousavez une maitrise des théories et outils de modélisation de données, 
·       Vousmaitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestionde version,  
·       Vousavez passé au moins une certification AWS technique, et vous avez l’ambition devous préparer à d’autres. 
Vos atouts : 
·       Vousêtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; 
·       Vousavez un bon niveau d’anglais qui vous permet d’intervenir sur des projets àdimension internationale ; 
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-aws-f-h_levallois-perret?q=be8a9c69da66ddfa053c664b1e1e4e02&o=5e6628dd-fa1d-4042-84e0-779a82198877,wttj
Senior Data Engineer (H/F),"{'name': 'EPSILON FRANCE', 'sector': 'Digital Marketing / Data Marketing, Big Data, AdTech / MarTech', 'employees': '600 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '38 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 5 ans,Bac +4,"Descriptif du poste
Dans le cadre du développement de notre pôle Data & Analytics Platform (cadrage fonctionnel et technique, définition de use-cases, stratégie des moyens, accompagnement du changement, mise en œuvre, maintenance et commercialisation de solutions), nous recherchons un(e) Consultant Sénior Data Engineer qui aura pour missions : 
-      Délivrer des projets Data Lake / Big Data (ingestion de sources, pipeline de traitements de données, modélisation, tests, déploiements) dans un contexte de plus en plus DevOps,
-      Comprendre les besoins des équipes digitales, principalement associées aux projets Data Science et leurs technologies / outils (Jupyter, Zeppelin, R, Python,  …),
-      Être capable de faire le lien avec les contraintes techniques (IT, sécurité, accès, outils) d’une DSI,
-      Assurer la veille technologique sur les composants d’une plateforme Datalake, Cloud
-      Maintenir les environnements techniques et partager ses connaissances (capitalisation, séminaires, formations, KM en ligne),
-      Rédiger des documents projets (design, réalisation, déploiement, …),
-      Gérer l’évolution des solutions proposées, et possiblement en assurer la TMA.
Voir moins","Profil recherché
De formation Bac + 4/5 en informatique, vous avez au moins 5 ans d'expérience d’un projet de type Datalake en environnement HDFS et/ou cloud (GCP, Azure), une connaissance des DWH (sur technologie traditionnelle et/ou cloud), des méthodes agiles, voire du DataOps (industrialisation de modèles de ML).
Vous possédez de bonnes compétences en Linux/Unix, Java, Spark, Scala… ainsi que sur les problématiques d’intégration (fichiers, messages, data) avec la connaissance d’au moins une plateforme Big Data Cloudera, Hortonworks (administration, configuration, monitoring, débogage, mise en œuvre) et d’une solution cloud (GCP ou Azure).
Vous connaissez les technologies Hadoop/HDFS, Hive, Python et le requêtage de données (Impala, Hive, ...).
Votre expérience dans le traitement de flux en streaming (KafKa) est un plus.
Votre niveau d’Anglais est opérationnel.",2024-01-17,https://www.welcometothejungle.com/fr/companies/epsilon/jobs/senior-data-engineer-h-f_paris_EF_D1z5Ry0?q=be8a9c69da66ddfa053c664b1e1e4e02&o=9281da8c-f8d0-43a0-8a9f-4c812b6be180,wttj
Data Engineer H/F,"{'name': 'BETCLIC GROUP', 'sector': 'Application mobile', 'employees': '1050 collaborateurs', 'creation_year': '2005', 'turnover': '835M€', 'mean_age': '33 ans'}",CDI,Bordeaux,Non spécifié,Télétravail total,,,,"Descriptif du poste
WE ARE BETCLIC
Betclic est une société tech de jeu en ligne et leader du pari sportif dans plusieurs pays Européens. Tous les jours Betclic s'engage à satisfaire la passion du sport en fournissant la meilleure expérience de divertissement à ses joueurs grâce à des technologies de pointe innovantes qui leur assurent un environnement de jeu sûr et sain. 
Betclic, dont le siège français est à Bordeaux, est une entreprise multiculturelle et internationale comptant près de 950 collaborateurs répartis dans 5 pays d'Europe : France, Italie, Malte, Pologne, et Portugal.  
L'univers du sport et du jeu te fait vibrer ? Tu aimes les défis, tu es passionné par la tech et participer à l'effort collectif ? Rejoins l'aventure ! 
NO TECH NO GAME  
Betclic place la performance technologique au cœur de ses activités :  
Des applications entièrement développées en interne pour une maîtrise optimale de la chaîne de valeur : segmentation en temps réel, sensibilisation et intégration de règles pour protéger les joueurs, détection des risques …  
Des interfaces conçues pour une expérience joueur immersive : hautement sécurisées, capables de gérer de forts pics de connexion et d'intégrer les événements sportifs en streaming. 
Des équipes Tech organisées en squads et tribus autonomes, chacune responsable d'un domaine fonctionnel et technique qui permettent de gérer des projets de A à Z : développement, test de charge, livraison, suivi de production (monitoring, alerting).  
ENTER THE GAME
En tant que Data Engineer, tu intégreras une équipe agile IT afin de construire les pipelines de transformation data. Dans ce cadre, tu travailleras étroitement avec les développeurs et le PO de l'équipe ainsi que les Data Architect sur la partie modélisation. 
YOUR ROLE WITHIN BETCLIC
Au sein d'une tribe Betclic et accompagné par une guild de data engineers DBT, tes missions principales seront de : 
Participer aux phases de conception et de développement des projets de transformation data 
Développer l'ensemble de la chaîne de transformation (Extract Load Transform / Extract Transform Load) au sein du Data Lake (Snowflake). Construction du Lake House et des couches Silver/Gold à partir de la couche Bronze du Lake. 
Automatiser le déploiement des pipelines data (DBT cloud, CICD Jenkins) 
Gérer l'évolution des solutions proposées, et en assurer la maintenance 
Rédiger la documentation relative aux projets 
TECHNICAL ENVIRONMENT
Snowflake
DBT Core / DBT Cloud AWS
Jenkins 
Github
WHO WE ARE LOOKING FOR?
Des collaborateurs avec une bonne dose d'humour, du respect et de la bienveillance, un amour pour la tech, un peu de zèle et une réelle passion pour leur métier !
Ce job est fait pour toi si :
Tu es diplômé(e) d'une école d'ingénieur, école informatique, MIAGE
Tu disposes d'une expérience professionnelle réussie de 3 ans minimum en tant que Data Engineer / Data Ops / ML Ops dans un environnement Cloud Public
Tu es doté(e) de fortes compétences en développement, d'une appétence pour l'automatisation (CI/CD) et le scripting et tu souhaites rejoindre un environnement professionnel challengeant.
Tu es sensible à la performance, la fiabilité, la maintenabilité et la scalabilité de votre code et des architectures que tu conçois
Tu maîtrises impérativement un des langages de développement Python, Scala, Java et tu as une expérience réussie avec l'Infrastructure As Code
Et enfin, tu parles anglais couramment
WHAT ARE THE RECRUITMENT STEPS? 
Si ta candidature est sélectionnée, tu seras contacté par Maxime sous une semaine pour une préqualification RH (30 minutes) 
Nous te demanderons ensuite de réaliser le Test AssessFirst (personnalité, motivations et réflexion) 
Tu rencontreras ensuite ton futur manager puis Laurent le manager de la Data Platform qui t'évaluera techniquement.
Enfin, Maxime te recevra en entretien final RH et vous débrieferez ensemble ton Test AssessFirst 
Afin d'offrir une expérience candidat idéale, le processus de recrutement Betclic dure, en moyenne, 4 à 6 semaines.
WHAT CAN YOU EXPECT?
25 jours de congés payés et 10 jours de « RTT » 
Une carte Ticket Restaurant® créditée de 10€ par jour (financée à hauteur de 50%) 
Une mutuelle prise en charge à 100% pour toi et tes enfants  
Un abonnement de transport pris en charge à hauteur de 50% ou une prime annuelle de mobilité durable (200€ pour les trajets domicile – travail en transport durable) 
Un accord de télétravail avantageux 
Un programme de formation annuel personnalisé 
Des locaux hors du commun avec un rooftop pour profiter de pauses et de déjeuners au soleil face à la Cité du Vin 
Des animations internes pour pimenter ton quotidien  
Des cours de sports gratuits dans nos locaux 
Et surtout, l'opportunité de travailler dans une atmosphère jeune, conviviale et fun ! 
Poste en CDI à pourvoir dès que possible à Bordeaux
Betclic Group - 117 quai de Bacalan 33300 BORDEAUX
Tous nos postes sont ouverts aux personnes en situation de handicap.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/betclic/jobs/data-engineer-h-f_bordeaux?q=be8a9c69da66ddfa053c664b1e1e4e02&o=5693b075-b3d8-41b9-b66c-bd51cd7f323f,wttj
Stage - LLM Data Engineer (H/F),"{'name': 'WITHINGS', 'sector': 'Objets connectés', 'employees': '400 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",Stage,Issy-les-Moulineaux,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Chez Withings, nous souhaitons redonner aux individus le contrôle de leur santé.
Nous avons l’obsession de créer des produits beaux et intuitifs, afin que chacun puisse les utiliser facilement au quotidien; nos balances connectées, montres hybrides, tensiomètres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd’hui utilisés par des millions d’utilisateurs.
Notre objectif : permettre la prévention, le dépistage et l’accompagnement d’un certain nombre de maladies chroniques via des produits et des services innovants, afin de révolutionner la manière dont on prend soin de notre santé.
Sur ce poste à mi-chemin entre le traitement du langage naturel et le Data Engineering, tes responsabilités seront les suivantes :
Développer des pipelines de données utilisant des modèles de langage via API (OpenAI notamment)
Participer à l'ingénierie des prompts pour optimiser l'utilisation de ces modèles
Entraîner les modèles de langage pour améliorer leur performance
Tester, entraîner et déployer des modèles de langage open-source pour une utilisation on-premise
Développer et tester des pipelines d’agents (Langchain)
Intégrer des bases de connaissances (Langchain, Llama Index)
Participer à la maintenance et l’administration de base de données (ClickHouse / PostgresSQL / ElasticSearch)
Modélisation de données en SQL (SQL - dbt)
Maintenance et administration de machines virtuelles (Unix)
Soutien technique à l'équipe et formation des équipes métiers aux bases de SQL
Challenger les équipes métier sur les usages qui peuvent être faits des LLM (notamment Support Client et Marketing)
Requirements
Fortes compétences informatiques : SQL, Python, Linux, développement de connexions API…
Expérience ou intérêt marqué pour le traitement du langage naturel (NLP) et les Large Language Models
Appétence forte pour les challenges techniques : stack on-premise, outils open-source, contraintes physiques des serveurs, sécurité forte liée à l’utilisation de données de santé…
Rigueur, autonomie, prise d'initiatives, curiosité...
Maîtrise parfaite de la communication en français et en anglais, aussi bien à l’écrit qu’à l’oral
Stage de césure ou stage de fin d’études uniquement
Benefits
Rejoindre l’aventure Withings, c’est :
Intégrer un des pionniers et leaders mondiaux de la santé connectée, plusieurs fois primé au Consumer Electronic Show
Contribuer à des projets innovants et ambitieux pour la santé de demain dans un environnement agile et en constante évolution
Intégrer une entreprise internationale, membre de la FrenchTech 120, dont les équipes sont basées à Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer à l’amélioration continue de nos produits et services en les bêta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collègues
Bénéficier de nombreux avantages : Réductions pour des activités culturelles et sportives, restaurant d’entreprise, et bien plus encore
Participer à la Withings Med Academy en assistant à des conférences de professionnels de santé afin de renforcer ses connaissances dans le domaine médical
Collaborer avec des collègues passionnés et célébrer ensemble chacune de nos réussites !
Toutes les candidatures reçues sont étudiées indépendamment de l’origine ethnique, des croyances, de la religion, du genre, de l’orientation sexuelle ou de la santé des candidats. Withings aspire à offrir et garantir l’égalité des chances aux candidats et seules les personnes habilitées (RH et Management) auront accès aux informations concernant votre candidature.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/withings/jobs/stage-nlp-engineer-h-f_issy-les-moulineaux?q=be8a9c69da66ddfa053c664b1e1e4e02&o=a238a0db-b4da-4d84-9260-c8270693a11b,wttj
Data Engineer - Machine Learning (H/F),"{'name': 'WITHINGS', 'sector': 'Objets connectés', 'employees': '400 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",CDI,Issy-les-Moulineaux,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Withings is on a mission to be the trusted leader in clinical-grade smart health devices. Already the leading innovator of smart scales, our product portfolio includes connected scales, connected blood pressure monitors, sleep monitors, thermometers, and health/activity wearables.
The mission of the Machine Learning team is to craft algorithms that leverage sensor data from our products to identify heart diseases, categorize sleep stages, estimate heart rate, among other functions. Given that many of these algorithms are integrated directly into our products and must adhere to strict requirements in terms of performance, speed, and memory usage, the team is actively seeking to enhance its expertise in software development.
Reporting directly to the Head of Machine Learning, the primary role of the Data Engineer in the Machine Learning team is to structure
the data flow from the sensors to the user end
the data storage within the Machine Learning team
As a Data Engineer, you will be responsible for:
Design and maintenance of the data structures which embed the measures and algorithms acquired or computed by our devices, and sent through our servers to the user end 
Guidelines and processes to ensure proper usage of these data structures
Design and maintenance of the storage system of the ML datasets
Design of the internal structure of the ML datasets 
Design and maintenance of the storage system of the ML models
Provide regular support to the MLOps tasks within the team
Requirements
Master's degree in computer science or engineering with an track record of at least 2 years in a similar role.
Highly skilled in Python and SQL programming (excellent coding practices)
Excellent knowledge of data structures
Familiar with ML or other related algorithmic field.
Benefits
Joining the Withings adventure means :
Joining one of the world's pioneers and leaders in connected health, winner of several awards at the Consumer Electronic Show,
Contributing to innovative and ambitious projects for the health of tomorrow in an agile and constantly evolving environment,
Join an international company, member of the FrenchTech 120, with teams based in Issy-les-Moulineaux, Boston, Hong-Kong and Shenzhen,
Participate in the continuous improvement of our products and services by beta-testing them before their release, especially during our numerous sports sessions with colleagues,
Benefit from numerous advantages: Stock Options, smartphone and computer of your choice, discounts for cultural and sports activities, company restaurant, and much more,
Participate in the Withings Med Academy by attending lectures by healthcare professionals to strengthen your knowledge in the medical field,
Collaborate with passionate colleagues and celebrate each of our successes together!
At Withings, we know that diversity, equity and inclusivity are paramount to fostering innovation. We rely on the unique skill sets, life experiences and perspectives of each team member to accomplish our mission—creating technology that people love, to make better health part of everyday life.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/withings/jobs/data-engineer-machine-learning-h-f_issy-les-moulineaux?q=be8a9c69da66ddfa053c664b1e1e4e02&o=4047b8c3-b783-4f88-8c4c-ae6fa5381e3f,wttj
Stage - Data Engineer - ML (H/F),"{'name': 'WITHINGS', 'sector': 'Objets connectés', 'employees': '400 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '32 ans'}",Stage,Issy-les-Moulineaux,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Chez Withings, nous développons des appareils de santé connectée : nos balances connectées, montres hybrides, tensiomètres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd’hui utilisés par des millions d’utilisateurs. Notre objectif est de permettre la prévention, le dépistage et l’accompagnement d’un certain nombre de maladies chroniques via des produits et des services innovants afin de révolutionner la manière dont on prend soin de notre santé.
Au sein de l’équipe Machine Learning, nous développons des algorithmes pour extraire des informations physiologiques et médicales pour nos utilisateurs tels que le SPO2, la fréquence cardiaque, la détection de diverses pathologies comme la fibrillation atriale, l’apnée du sommeil…
Intégré.e au sein de l’équipe Machine Learning, tu auras une ou plusieurs des responsabilités suivantes :
Développer un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de sécurité ;
Construire des dashboards de visualisation ;
Construire un système d’alerte pour notifier les contributeurs d’éventuels problèmes ;
Développer des outils permettant de corriger les éventuels problèmes de façon automatisée ;
Requirements
À la recherche d'un stage d'une durée de 3 à 6 mois ;
Préparation d’un Master en école d’ingénieur ou équivalent / année de césure possible ;
Maîtrise de Python ;
Maîtrise de Debian ou de Ubuntu, de Shell et de l’environnement Linux ;
Première expérience sur du développement logiciel ;
Culture DevOps (omniprésence du monitoring, automatisation des tâches, …)
Compréhension de la culture et des besoins des différents membres de l’équipe ;
Rigueur, autonomie, prise d’initiative, curiosité.
Benefits
Rejoindre l’aventure Withings, c’est :
Intégrer un des pionniers et leaders mondiaux de la santé connectée, plusieurs fois primé au Consumer Electronic Show
Contribuer à des projets innovants et ambitieux pour la santé de demain dans un environnement agile et en constante évolution
Intégrer une entreprise internationale, membre de la FrenchTech 120, dont les équipes sont basées à Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen
Participer à l’amélioration continue de nos produits et services en les bêta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collègues
Participer à la Withings Med Academy en assistant à des conférences de professionnels de santé afin de renforcer ses connaissances dans le domaine médical
Collaborer avec des collègues passionnés et célébrer ensemble chacune de nos réussites !
Toutes les candidatures reçues sont étudiées indépendamment de l’origine ethnique, des croyances, de la religion, du genre, de l’orientation sexuelle ou de la santé des candidats. Withings aspire à offrir et garantir l’égalité des chances aux candidats et seules les personnes habilitées (RH et Management) auront accès aux informations concernant votre candidature.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/withings/jobs/stage-data-engineer-h-f_issy-les-moulineaux?q=be8a9c69da66ddfa053c664b1e1e4e02&o=36d83bfa-3de3-4d03-befc-7ea2849d86f3,wttj
Creative Tech - FINANCE - Data Engineer F/H,"{'name': 'DEVOTEAM CREATIVE TECH', 'sector': 'IT / Digital, Transformation, SaaS / Cloud Services', 'employees': '850 collaborateurs', 'creation_year': '2021', 'turnover': '100M€', 'mean_age': '30 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Tu auras pour mission d’accompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data. 
Intégré(e) à une équipe d’experts techniques, tu auras pour missions de :
Analyser les besoins clients
Animer des ateliers afin d’étudier et cadrer les besoins clients
Préconiser les solutions et architectures cibles
Définir les méthodologies de déploiement et plans de migration
Rédiger les dossiers d’architecture et spécifications techniques
Construire les architectures de données
Concevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels)
Construire et déployer les pipelines de données (ETL)
Assurer la migration des données vers les nouveaux environnements
Analyser les données
Analyser les données sources afin d’identifier et évaluer des cas d’usage métier
Mettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio…)
Sélectionner, entraîner, évaluer et déployer des modèles prédictifs en s’appuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn)
Accompagner et former
Assurer une veille technologique continue sur les solutions cloud
Accompagner et former les équipes clients aux méthodes et concepts du cloud
Tu seras accompagné(e) en interne pour monter rapidement en compétences sur GCP dans l’objectif de devenir certifié Google sur ta practice.
Voir moins","Profil recherché
Diplômé(e) d'une école d'ingénieurs ou d'un Master 2 en Informatique, tu disposes d'une expérience significative au sein de projets Data : architecture, traitement ou analyse de données.
Tu maîtrises au minimum un langage de programmation appliqué à l’analyse de données (Scala, R, Python).
Tu as de bonnes compétences dans de l’architecture des systèmes, bases de données, méthodologies d’analyse
Tu es passionné(e) par la Business Intelligence, le Big Data, l’Internet des objets (IoT) et le Machine Learning
Une connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, …) est un plus.
Tu as une solide compréhension de la dimension technique et fonctionnelle des projets IT
Curieux(se), autonome et à l’écoute, tu possèdes un réel esprit d’analyse
Ta maîtrise de l'anglais te permettra de gérer des projets en contexte international",2024-01-17,https://www.welcometothejungle.com/fr/companies/devoteam-creative-tech/jobs/creative-tech-finance-data-engineer-f-h_levallois-perret_DCT_lOp0RZK?q=c8f40c347a4aff59a08f837b100c6ea4&o=13e5892d-0480-414a-8050-096633f9ed83,wttj
Data Engineer EMEA (F/M/D),"{'name': 'FLOWDESK', 'sector': 'FinTech / InsurTech, SaaS / Cloud Services, Blockchain', 'employees': '100 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
Flowdesk is seeking a highly motivated Data Engineer to join the team and managed by the Quentin, the Lead Data!
The data engineer will be an integral part of the growing data team, working closely with our trading and quantitative departments to provide a platform and tools to answer their analytical needs. The data platform revolves around Dagster deployed on Kubernetes for the orchestration, dbt on BigQuery for the transformations, and Looker for the visualization.
Among our current challenges, we are currently focusing on the real-time ingestion and processing of terabytes of market data.
Responsibilities
Design, build, and maintain efficient, scalable, and reliable batch and streaming data pipelines to support Flowdesk's trading infrastructure.
Develop and maintain data warehouses, data lakes, and other data management systems with a strong focus on logical and physical modeling.
Contribute early on to the definition of the data team's data products to maximize ease of access, data quality, and related documentation.
Collaborate with the software engineering team to integrate data-related functionality into Flowdesk's trading infrastructure and other applications.
Leverage cutting-edge data engineering technologies to continually improve the speed, reliability, and scalability of Flowdesk's data processing capabilities.
Develop and maintain strong processes and procedures for data quality control, data validation, data documentation and, data integration.
Collaborate with cross-functional teams including traders, developers, and compliance officers to ensure that all data used by Flowdesk is accurate, timely, and compliant with relevant regulations and requirements.
Requirements
Bachelor's or Master's degree in Computer Science, Engineering, or related field.
3+ years of experience in data engineering or related field.
Awareness of software, data, and analytics engineering best practices (e.g. programming standards, data modelization, code idempotency....)
General understanding of systems architecture and concepts (distributed computing, lake-house architecture, ci/cd workflows...)
Experience optimizing modern data warehousing platforms (BigQuery is a plus).
Strong communication skills and ability to work collaboratively in a fast-paced international environment.
Knowledge of the data engineering ecosystem (contribution to open source projects is a plus).
Strong analytical and problem-solving skills with a keen attention to detail.
Benefits
💸 BSPCE
🌍 International environment (English is the main language)
🚃 50% of transportation costs & a sustainable mobility agreement
🍔 Swile lunch voucher (€9.25 per day, 60% covered)
🏥 100% Alan Blue covered for you and your children
💻 Top of the range equipment: Macbook, keyboard, laptop stand, 4K monitor & headphones
🎉 Team events and offsites
🔜 Coming soon : gym memberships, international mobility & lot of other cool benefits !
Recruitment process
👀 Are you interested in this job but feel you haven't ticked all the boxes? Don't hesitate to apply and tell us in the cover letter section why we should meet!
📝 Here's what you can expect if you apply:
HR interview (30')
Technical test
Technical interview (60')
Chat with the Head of People (30') and the Head of Department (30')
On the agenda: discussions rather than trick questions! These moments of exchange will allow you to understand how Flowdesk works and its values. But they are also (and above all) an opportunity for you to present your career path and your expectations for your next job!
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/flowdesk/jobs/data-engineer-emea-f-m-d_paris?q=c8f40c347a4aff59a08f837b100c6ea4&o=1c6f5f1c-6441-4b3d-b37d-63aeed6fd5f2,wttj
Senior Data Engineer (H/F),"{'name': 'PUBLICIS FRANCE', 'sector': 'Marketing / Communication, Publicité, Digital, Relations publiques, AdTech / MarTech, Evénementiel, Design', 'employees': '5000 collaborateurs', 'creation_year': '1926', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 5 ans,Bac +4,"Descriptif du poste
Dans le cadre du développement de notre pôle Data & Analytics Platform (cadrage fonctionnel et technique, définition de use-cases, stratégie des moyens, accompagnement du changement, mise en œuvre, maintenance et commercialisation de solutions), nous recherchons un(e) Consultant Sénior Data Engineer qui aura pour missions : 
-      Délivrer des projets Data Lake / Big Data (ingestion de sources, pipeline de traitements de données, modélisation, tests, déploiements) dans un contexte de plus en plus DevOps,
-      Comprendre les besoins des équipes digitales, principalement associées aux projets Data Science et leurs technologies / outils (Jupyter, Zeppelin, R, Python,  …),
-      Être capable de faire le lien avec les contraintes techniques (IT, sécurité, accès, outils) d’une DSI,
-      Assurer la veille technologique sur les composants d’une plateforme Datalake, Cloud
-      Maintenir les environnements techniques et partager ses connaissances (capitalisation, séminaires, formations, KM en ligne),
-      Rédiger des documents projets (design, réalisation, déploiement, …),
-      Gérer l’évolution des solutions proposées, et possiblement en assurer la TMA.
Voir moins","Profil recherché
De formation Bac + 4/5 en informatique, vous avez au moins 5 ans d'expérience d’un projet de type Datalake en environnement HDFS et/ou cloud (GCP, Azure), une connaissance des DWH (sur technologie traditionnelle et/ou cloud), des méthodes agiles, voire du DataOps (industrialisation de modèles de ML).
Vous possédez de bonnes compétences en Linux/Unix, Java, Spark, Scala… ainsi que sur les problématiques d’intégration (fichiers, messages, data) avec la connaissance d’au moins une plateforme Big Data Cloudera, Hortonworks (administration, configuration, monitoring, débogage, mise en œuvre) et d’une solution cloud (GCP ou Azure).
Vous connaissez les technologies Hadoop/HDFS, Hive, Python et le requêtage de données (Impala, Hive, ...).
Votre expérience dans le traitement de flux en streaming (KafKa) est un plus.
Votre niveau d’Anglais est opérationnel.",2024-01-17,https://www.welcometothejungle.com/fr/companies/publicis-france-1/jobs/senior-data-engineer-h-f_paris_PF_RKLVZZe?q=c8f40c347a4aff59a08f837b100c6ea4&o=823886fd-63b7-44e8-b949-c77826896445,wttj
Data Engineer,"{'name': 'AQEMIA', 'sector': 'Intelligence artificielle / Machine Learning, Pharmaceutique / Biotechnologique, Santé', 'employees': '60 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 4 ans,,"Descriptif du poste
About the team you’ll join
As a Data Engineer, you will join the Data Engineering Team and contribute to design and build a modern, reliable and scalable Data Platform for Aqemia's engineering teams. 
You will also support engineering Teams to build their Data pipeline and assets.
This way, you will be instrumental in all engineering teams' success!
Your role as a data engineer at Aqemia
Contribute in defining the relevant Data Architecture and stack for Aqemia
Contribute to build the relevant Data infrastructure for Aqemia in AWS
In a data mesh oriented organization provide engineering teams with the right tools and practices to build their own pipelines and data assets
Support engineering team in designing their Data pipelines and assets
Bring the Data Engineering expertise in engineering projects from design to delivery
The competencies we are looking for
4+ years experience as a Data or Software engineer in an engineering team of 4+ engineers
Knowledge of Cloud infrastructure and products (AWS, other cloud experience is a plus)
Good knowledge of Data Engineering building blocks (storage, orchestrator)
Fluent in object-oriented language development (ideally python)
Experience in delivering technical projects from start to finish
Preferred skills
Proficient in SQL
Experience in backend engineering
Experience in infrastructure-as-code techniques (ideally Terraform)
Knowledge in ML Ops and DevOps
You know how to interact with technical stakeholders
Preferred mindset
You are eager to play an active role in contributing to Aqemia’s strategy to develop drugs for patients.
You are anxious to bring your wealth of knowledge and skills to the table to inspire and coach brilliant people from diverse backgrounds.
You are keen to solve tough problems on issues that truly matter, with a proactive and a can-do attitude.
You thrive on working collaboratively in a fast-paced, interdisciplinary environment that keeps everyone on track.
Our recruitment process
1 - Hiring Manager’s interview: you’ll meet directly with your future manager Benoît (1h, visio call)
2 - Technical assessment of your skills: live coding exercise in Python (45min, visio call)
3 - Technical assessment of your skills: system design collaborative exercise, plus a tour of our offices (1h, in office)
4 - Cultural fit interview with our co-founder and COO Emmanuelle (45min)
5 - Final interview with our co-founder and CEO Maximilien (45min)
About who we are and our workplace environment 
• We signed a contract with Sanofi of $140M to accelerate their drug discovery
• Our approach is completely unique in the industry as we use AI & deep physics to discover new drugs
• We are a team of +50 people from world-class institutions (AstraZeneca, GSK, Sanofi, Harvard, Ecole Normale Supérieure, Ecole Polytechnique, BCG)
• Our Founders boast : 10+ years experience in research at Ecole Normale Supérieure in Paris, not to mention a stint in Oxford and Cambridge / 10+ years experience in strategy consulting at BCG.
• We are located in the center of Paris (1 Bd Pasteur), with a possibility of up to 2 days of remote work.
• We are part of the French Tech 2030 program (https://lafrenchtech.com/fr/la-france-aide-les-startup/french-tech-2030/).
• Our working language is English
• We work for a mission: joining us means bringing your own impact on changing the way medicines are discovered and be involved in shaping the direction of our fast growing business and team.
If you feel that you fit only 70% to 80% of this job description but you’re still excited to join, then please get in touch! 
‍
Aqemia is an Equal Employment Opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion or belief, sex, sexual orientation, gender perception or identity, national origin, age, marital status, disability status or any other basis under applicable law.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/aqemia/jobs/data-engineer_paris_AQEMI_qRy8e1y?q=c8f40c347a4aff59a08f837b100c6ea4&o=63cd0559-a0a8-4985-b42c-e3ebefa7367e,wttj
DATA ENGINEER SQL -H/F (Stage Avril/Mai 2024),"{'name': 'SHOWROOMPRIVE.COM', 'sector': 'Application mobile, Mode, E-commerce', 'employees': '1050 collaborateurs', 'creation_year': '2006', 'turnover': '697.5M€', 'mean_age': '33 ans'}",Stage,Saint-Denis,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Au cœur du pôle Data de Showroomprive, vous intègrerez l’équipe « Data Domain ».  
Vos missions seront axées autour de l’extraction, du traitement et du stockage de la donnée via le maintien et l’évolution d’un Datawarehouse utilisé par le reste des équipes Data (BI, Data Science, Marketing analyst).  
Vos missions se découperont en deux parties :  
Un projet principal à réaliser de A à Z autour de la donnée, de son traitement, de son contrôle ou encore de son accessibilité.  
Les taches du quotidien de l’équipe (développement de nouveaux flux, exports de données métier, requêtes ad hoc, gestion d’accès…). 
Pour mener à bien ses missions, notre équipe utilise des outils à la pointe du marché en matière de traitement de la donnée grâce à Dataiku pour le pipeline et à l’utilisation d’une plateforme cloud leader du marché. 
Vous intégrerez une équipe Data Domain de 2 personnes qui vous accompagneront au quotidien pour mener à bien vos missions, mais aussi un service Data de 20 personnes aux compétences diverses et pointues dans leurs domaines. ","Profil recherché
En fin de formation supérieure (Bac+4 /+5) de type Ecole d’Ingénieurs ou formation universitaire équivalente dans une filière liée à la Business Intelligence ou au Data Engineering.
Dans le cadre de vos études ou d’une expérience précédente, vous avez pu acquérir de solides bases en SQL. Vous avez aussi développé une réelle appétence à découvrir par vous-même et vous êtes très curieux lorsqu’il s’agit de Data. 
Votre rigueur et votre dynamisme constitueront des atouts clés dans la réussite des missions qui vous seront confiées. ",2024-01-17,https://www.welcometothejungle.com/fr/companies/showroomprive/jobs/data-engineer-sql-h-f-stage-avril-mai-2024_saint-denis?q=c8f40c347a4aff59a08f837b100c6ea4&o=206b7912-382e-4d2a-926d-f3c8a61d0443,wttj
Data engineer H/F,"{'name': 'EXTIA', 'sector': 'Ingénieries Spécialisées, IT / Digital, Stratégie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Vous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse…
Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes.
Vous serez en charge de :
● Participer à la définition des besoins et à la rédaction des User Stories,
● Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,
● Concevoir et construire des architectures de données,
● Intégrer des sources de données,
● Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,
● Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux
#LI-GG1","Profil recherché
● Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple,
● Vous maitrisez les bases de l’analyse statistique,
● Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
● Vous maitrisez Spark et Hadoop
● Vous êtes familiarisé avec l’environnement Linux,
● Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts.",2024-01-17,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_Xb9mz97?q=c8f40c347a4aff59a08f837b100c6ea4&o=f1b09765-a900-4bc7-9bbf-76027a19838f,wttj
Data Engineer H/F,"{'name': 'EXTIA', 'sector': 'Ingénieries Spécialisées, IT / Digital, Stratégie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Lille,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Participer à la définition des besoins et à la rédaction des User Stories,
Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,
Concevoir et construire des architectures de données,
Intégrer des sources de données,
S'assurer que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,
Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux.
#LI-DOP","Profil recherché
Rigoureux(se), vous ne laissez rien au hasard,
Efficace, vous ne remettez pas à demain ce qui peut être fait dès aujourd’hui,
Autonome, vous savez mener vos missions à bien sans aide.",2024-01-17,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_er3ObdL?q=c8f40c347a4aff59a08f837b100c6ea4&o=bdaebc97-8578-4e90-bf29-95b2c55afa96,wttj
Data Engineer Devops H/F,"{'name': 'EXTIA', 'sector': 'Ingénieries Spécialisées, IT / Digital, Stratégie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Dans le cadre de votre mission, vos taches principales sont:
L'implémentation de solutions techniques
Sens de l’échange avec les différents équipiers, contributeurs de la division Data.
Échanges et préparation de demos avec les IT métiers.
Maintien d'une veille technologique permanente.
Les compétences techniques :
Analyse et développement
Développement en Java jusqu’à l’intégration avec les chaines CI/CD
Maitrise des langages de programmation Java, Scala et Python
Maîtrise de Ansible, Terraform, Kubernetes…
Maîtrise de l’écosystème Hadoop, Spark, Kafka, ElasticSearch
#LI-GG1","Profil recherché
● Curieux, vous adorez partager les dernières idées innovantes que vous avez découvertes
● Rigoureux, vous ne laissez rien au hasard
● Persévérant, vous ne perdez jamais, soit vous gagnez, soit vous apprenez",2024-01-17,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-devops-h-f_paris_EXTIA_x9wwxVY?q=c8f40c347a4aff59a08f837b100c6ea4&o=bd0835a0-892e-4d7e-af80-ab03c9724981,wttj
Data Engineer (H/F),"{'name': 'EXTIA', 'sector': 'Ingénieries Spécialisées, IT / Digital, Stratégie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Lyon,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Vous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse…
Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer à la définition des besoins et à la rédaction des User Stories,
Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,
Concevoir et construire des architectures de données,
Intégrer des sources de données,
S'assurer que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,
Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux.
Profil recherché :
Maitrise de l’écosystème Microsoft Azure Data Factory, Azure Data Lake est un plus
Maitrise Technologie autour de la data : Power BI, Spark, Airflow, Python, Scala…
Maitrise des bonnes pratiques de développement et méthodes agiles
Base de données : SQL, Postgré SQL (Paas) et modélisation de la donnée
Connaissance des systèmes de gestionnaire de conteneur (Kubernetes,…)
Connaissance des outils de déploiements : Jenkins, Git, maven, Ansible
Qualités relationnelles et capacité à gérer nombreuses interactions
Dynamisme, autonomie et envie de découvrir des manières différentes/innovantes de faire
#LI-YKH
Voir moins","Profil recherché
Rigoureux, vous ne laissez rien au hasard,
Efficace, vous ne remettez pas à demain ce qui peut être fait dès aujourd’hui,
Autonome, vous savez mener vos missions à bien sans aide.",2024-01-17,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_lyon_EXTIA_2Rz8OgO?q=c8f40c347a4aff59a08f837b100c6ea4&o=55ec8a2b-39c1-467b-b38a-640520a7a1c0,wttj
Data engineer H/F,"{'name': 'EXTIA', 'sector': 'Ingénieries Spécialisées, IT / Digital, Stratégie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Vous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse…
Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer à la définition des besoins et à la rédaction des User Stories,
Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,
Concevoir et construire des architectures de données,
Intégrer des sources de données,
Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,
Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux.
Profil :
Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple,
Vous maitrisez les bases de l’analyse statistique,
Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
Vous êtes familiarisé avec l’environnement Linux,
Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts.
#LI-AL7
Voir moins","Profil recherché
Rigoureux, vous ne laissez rien au hasard
Persévérant, vous ne perdez jamais, soit vous gagnez, soit vous apprenez
Efficace, vous ne remettez pas à demain ce qui peut être fait dès aujourd’hui",2024-01-17,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_1j0KdJ5?q=c8f40c347a4aff59a08f837b100c6ea4&o=4c5a1233-f8bc-4743-99dc-2eee06bc432f,wttj
Data Engineer (H/F),"{'name': 'EXTIA', 'sector': 'Ingénieries Spécialisées, IT / Digital, Stratégie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Montpellier,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Ensuite quoi ?
Vous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse…
Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes.
Vous serez en charge de :
Participer à la définition des besoins et à la rédaction des User Stories,
Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,
Concevoir et construire des architectures de données,
Intégrer des sources de données,
Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,
Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux.
Profil recherché
Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple,
Vous maitrisez les bases de l’analyse statistique,
Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
Vous êtes familiarisé avec l’environnement Linux,
Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts.
#LI-RP1
Voir moins","Profil recherché
D'abord qui ?
Ingénieux, votre imagination débordante vient à bout de chaque problématique,
Attentif aux détails, vous avez un œil de Lynx pour repérer les incohérences,
Efficace, vous ne remettez pas à demain ce qui peut être fait dès aujourd’hui.",2024-01-17,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_montpellier_EXTIA_R9WrV08?q=c8f40c347a4aff59a08f837b100c6ea4&o=04006995-12ed-41ee-995a-4642dd32ce48,wttj
Data Engineer (H/F),"{'name': 'EXTIA', 'sector': 'Ingénieries Spécialisées, IT / Digital, Stratégie', 'employees': '2500 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '31 ans'}",CDI,Bordeaux,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Vous serez en charge de :
Participer à la définition des besoins et à la rédaction des User Stories,
Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,
Concevoir et construire des architectures de données,
Intégrer des sources de données,
Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,
Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux.
#LI-JH1","Profil recherché
Vous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple,
Vous maitrisez les bases de l’analyse statistique,
Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,
Vous êtes familiarisé avec l’environnement Linux,
Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts.",2024-01-17,https://www.welcometothejungle.com/fr/companies/extia/jobs/data-engineer-h-f_paris_EXTIA_mdwL947?q=c8f40c347a4aff59a08f837b100c6ea4&o=ed69c839-c77b-4220-b844-82d3eb99cc8e,wttj
Code Busters - Data Engineer - Practice Data Engineering (H/F),"{'name': 'CODE BUSTERS', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '35 collaborateurs', 'creation_year': '2021', 'turnover': '4.2 M€', 'mean_age': '29 ans'}",Autres,Paris,40K à 90K €,Télétravail fréquent,,,,"Descriptif du poste
Code Busters c'est :
🎓Un espace de partage et de transmission qui permet à chaque membre de la communauté de se dépasser. Les Busters ont des grades attribués en fonction de leur niveau de maturité technique (l'expérience importe peu, seul le talent compte).
👨‍👨‍👦‍👦Une organisation en squads pour un management ""dev by dev"" et des moments privilégiés pour apprendre des valeurs humaines fortes.
📈 une communauté qui prône la transparence et proposent un modèle de rémunération redistributif et déplafonné.
L'ambition
Depuis notre création début 2021, nous grandissons sans faire de compromis entre qualité d'intervention et d'accompagnement des Busters. En seulement 2 ans, nous sommes passés de 2 à 40 personnes et nous réalisons un chiffre d’affaires de 4.2M€ en 2022.
Notre objectif : faire de Code Busters la référence française sur les problématiques de développement applicatif grâce à l’expertise de notre équipe technique.
L'organisation
Nous sommes convaincus que le langage informatique n'est qu'un outil. Pourtant, avant de devenir agnostique aux langages il est primordial de devenir un Software Engineer aguerri. Ils se sont organisés en 6 Practices technologiques (Typescript, Java, C#, C++/Rust, Python et DevOps).
✨ Ta mission
Tu veilles à délivrer les meilleures interventions clients :
Tu contribues au développement de produits à fort impact business. Tu développes de nouvelles features sur divers projets clients en fournissant un code de qualité: maintenabe & scalable. Tu es proactif et tends vers une approche conseil pour tes clients en leur proposant de nouvelles technos, et nouvelles methodologies pour les rendre plus performants.
Tu aspires à devenir meilleur de jour en jour :
La Tech est un environnement exigeant et en perpétuelle évolution. Afin de délivrer les meilleures interventions, tu dois apprendre sans cesse et rester à jour. Faire preuve d'humilité et être capable de remettre en question tes acquis.
Tu aies de l’impact au sein de la communauté :
C’est le rôle de chaque Buster de contribuer au développement de la communauté. Tu pourras t’impliquer sur les sujets suivants :
Construction du SI de la communauté Recrutement de nouveaux Busters
Coaching et diffusion de tes compétences
Développer des compétences transverses : coaching, recrutement, commercial, management
Ton environnement technique:
Pour intégrer la Practice Data Ingé une grande appétence pour le back tu auras..
Back : Python ou Scala
Infrastructure/DevOps : Docker, k8s, Cloud, Jenkins
Tes Managers
Durant les 10 dernières années, Laurent & Valmon ont travaillé dans le domaine de la finance de marché avec différentes équipes techniques et métiers pour produire des applications à forte valeur ajoutée pour les utilisateurs. Ils ont pu travaillé sur différents type de projets comme par exemple la récupération de données via des grabbers d'APIs, sur leur ingestion dans un datalake et sur leur manipulation en Scala ou Python. Ils sont toujours motivés par les possibilités d'apprendre et de progresser et ils mettent tout en place pour transmettre au mieux leur passion et les meilleures pratiques de développement.
Ce que tu vas trouver chez nous
Une communautés de développeurs passionnés où chacun est responsabilisé selon ses aspirations professionnelles.
Un système de grade basé sur ta maturité technique et le recul que tu as sur ton métier. On identifie ensemble tes axes d’amélioration et on t’offre un accompagnement personnalisé dev by dev pour booster tes compétences et atteindre les grades supérieurs.
On t’offre une possibilité de travailler sur des problématiques techniques variées afin de perfectionner tes compétences et chercher constamment à améliorer les outils et les méthodes employées.
Un salaire transparent et méritocratique qui évolue (exponentiellement 😎) au fur et à mesure de ta progression.
Et les plus de Code Busters alors ?
💰Une rémunération transparente composée d’un salaire fixe entre 40k€ et 70k€ qui dépend de ton grade et un bonus déplafonné dépourvu de toute subjectivité !
💥Un environnement de travail énergique et bienveillant
💻Un budget formation annuel de 2000€
🤝Une ascension professionnelle épaulée par ton squad leader au quotidien
🤫Un séminaire annuel, pas besoin de t’en dire plus on te laisse découvrir…
🍽 Carte tickets restaurants Swile
🚇Titre de transport pris en charge à 100%
😍Assurance santé prise en charge à 100%
Tes Perspectives d'évolution
Notre ambition est de former les leaders de la tech de demain. Nous avons créer un parcours en grade pour t'aider à construire ta carrière par étapes. Grâce au coaching et formations que l’on propose, tu pourras :
Développer de l’expertise technique sur les sujets tech qui te passionnent
Développer des compétences transverses : coaching, recrutement, commercial, management
Participer à des guildes d’expertises pour améliorer tes pratiques et celles de ton équipe.
Process de recrutement 
30’ par téléphone pour faire connaissance et t’en dire plus sur Code Busters.
60’ en visio : pour comprendre en détails les choix de ton parcours professionnel et tes aspirations. C’est également l’occasion de poser toutes les questions que tu as sur Code Busters. 
60’ d’échange technique théorique & pratique: L’objectif est de faire un état des lieux de tes connaissances techniques. Il nous permet d’estimer le grade que tu aurais en rejoignant la communauté. Tu pourras aussi en profiter pour avoir un REX d’un Buster sur sa vie dans la communauté. 
60’ de Buster Fit : Confirmer que notre modèle et tes ambitions feront de toi le prochain Buster 😍
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/code-busters/jobs/data-engineer-practice-data-engineering-h-f-cb_paris?q=c8f40c347a4aff59a08f837b100c6ea4&o=2e954879-fe8c-4ddd-be02-94ce6984ce03,wttj
Consultant Confirmé Data Engineer on Data Platforms - F/H/N,"{'name': 'OCTO TECHNOLOGY', 'sector': 'IT / Digital, Organisation / Management, Transformation', 'employees': 'Créée en 1998', 'creation_year': 'Âge moyen : 33 ans', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
Vous faites partie de celles et ceux qui pensent que même avec plusieurs années d’expérience, on continue à apprendre ? Alors nous sommes sur la même longueur d'onde ! Et si on en parlait ?
Au sein de l’Atelier Data & AI, on retrouve des communautés de pratique organisées par tribus. L’idée, c’est de se retrouver et de partager des expertises communes, de développer ses compétences en équipes à taille humaine. Vous aurez donc pour missions de faire du conseil, du delivery et de la R&D.
Être Data Engineer on Data Platforms chez OCTO, c’est : 
1- Faire du conseil autant que du delivery : accompagner nos clients dans la mise en œuvre de solutions autour de la gestion et transformation de leur Data. Participer au développement agile et à l’implémentation d’applications dans le respect des bonnes pratiques. Et bien sûr, qui dit conseil, dit convictions : proposer la solution la plus adaptée, c’est aussi savoir et oser challenger nos clients (et c’est dans notre ADN !) 
2- Participer aux réponses aux appels d’offres et avant-ventes
3- Participer activement à la R&D “Data & IA” : au programme, veille technologique & bonnes pratiques. Quelques sujets “chauds” du moment ? Le Green AI , Green Data et AI4Green 🌱
4- Former & mentorer : le partage de connaissances et la montée en compétences des collaborateurs vous importent ? Nous sommes convaincus et prônons haut et fort la valeur de transmission. Mentoring et gestion de votre carrière seront donc à l’honneur. Et oui, chez OCTO le savoir n’est pas chasse gardée !
Voir moins","Profil recherché
Promis pas de liste à rallonge, mais des compétences clés pour vous permettre de réussir chez nous : 
1- Un socle de savoir-faire techniques et des expériences significatives sur : 
Différents systèmes d’exploitation et systèmes de gestion de bases de données (SQL, NoSQL, New SQL, DWH dans le cloud…)
Plusieurs protocoles de connexion (REST, SOAP, FTP, HTTP, ODBC…)
Les outils Docker et/ou Kubernetes
Les écosystèmes cloud (AWS, Azure ou GCP)
Les plateformes de données dans le cloud telles que Snowflake, Dataiku, Databricks, Alteryx, SAS, Palantir…
Les langages de manipulation de données (SQL, Scala, Python…) et divers frameworks de programmation (Java, Bash/Shell, Spark, Pandas…)
Les méthodologies agiles (une connaissance des méthodologies DevOps ou DataOps est un plus  )
…Last but not least : une bonne maîtrise de l’anglais, à l’oral comme à l’écrit 🙂
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/octo-technology/jobs/consultant-confirme-data-engineer-on-data-platforms-f-h-n_paris_OT_dMrrWkd?q=c8f40c347a4aff59a08f837b100c6ea4&o=9509755f-571e-443e-a23b-f964b4bb86c2,wttj
Engineering Manager (Data Engineer) - CDI - Sicara - Paris,"{'name': 'SICARA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': '6,5M€', 'mean_age': '27 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,06 mai 2024,> 7 ans,Bac +5 / Master,"Descriptif du poste
Présentation Sicara
Créée en novembre 2016 au sein du groupe M33 (Theodo group), un écosystème de 10 filiales et +650 personnes situées à Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, basée à Paris.
Notre mission : aider les startups, scaleups et grands comptes à résoudre leurs problématiques business grâce à la tech. Nos équipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. L’objectif : capitaliser sur le potentiel de la donnée.
Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en développant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.
Pourquoi on recrute un Engineering Manager (Data Software Engineering) ?
Afin de contribuer à la croissance de Sicara et pour renforcer les équipes Data Software Engineering de Sicara, nous cherchons un profil expérimenté pour accroître la montée en compétences de nos Sicariotes et pour répondre aux attentes techniques de nos clients.
L'équipe technique de Sicara ; c'est 40 Data Engineers et Data Scientists, Tech Leads ou architectes issus des meilleures écoles d'ingénieur, et en particulier 5 Engineering Manager et 1 CTO pour les faire réussir.
A chaque lancement de projets, nous mettons en place une équipe diverse d’experts techniques, d’experts métiers, et d’experts de l’Agile et du Lean Management. Grâce à ce fonctionnement, nous allons rapidement en production et avons un impact direct sur la réussite des objectifs business de nos clients.
Tes missions :
Améliorer la qualité des produits réalisés par les tech leads sur leurs projets
Garantir la satisfaction du sponsor technique client, en aidant le tech lead à concevoir les features qui délivrent un maximum de valeur et tout en étant intransigeant sur la qualité
Aider le tech lead sur le delivery et la conception d’architectures robustes et scalables
Veiller à la progression des techs en les aidant à développer leur thought leadership et à progresser en continu sur la Tech
Epauler notre CTO sur des sujets de positionnement technique, d'organisation d'équipe et d'évolution des systèmes de Sicara
Les avantages
Notre écosystème de startup tech est un véritable tremplin pour accélérer la progression et les carrières !
Des bureaux au coeur du quartier des Batignolles à Paris, partagés avec les autres startup tech du groupe Theodo
Un coach dédié pour accélérer ta progression de carrière
La possibilité de participer à des conférences techniques internationales
Des conditions de télétravail flexibles
Un budget trimestriel pour acheter ton matériel tech (laptop, smartphone, casque,...)
Des événements réguliers de team building et un WE d'entreprise à chaque année
La possibilité de s'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les inégalités et la sécurité des données
Tes moyens pour réussir
Management en direct par le CTO de Sicara
Collaboration avec les EM de Sicara et du groupe M33
Formations au Lean management
Écosystème M33 avec +500 expert(e)s tech & produit,
Plusieurs dojos (sessions de mise en pratique) par semaine : ""archi dojo"", ""projet dojo"", etc...
Ton profil
Tu disposes d'une connaissance forte de la data (marché, techno, archi)
Tu es capable de débloquer des tech leads sur des challenges techniques complexes
Tu as une expérience significative en management d'équipe technique
Tu sais animer une équipe exigeante et performante
Tu es doté d'un excellent leadership et contact client : tu donnes envie aux autres de te suivre !
Tu es guidé par une énorme envie de progresser, dans un environnement startup, qui évolue rapidement ? Alors Sicara pourrait être le bon endroit pour toi !
A très vite !
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/sicara/jobs/engineering-manager-data-engineer-cdi-sicara-paris_paris?q=c8f40c347a4aff59a08f837b100c6ea4&o=703198dc-68ff-4a87-b9e1-c0341c999c74,wttj
Lead Data Engineer - CDI - Sicara - Paris,"{'name': 'SICARA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '70 collaborateurs', 'creation_year': '2016', 'turnover': '6,5M€', 'mean_age': '27 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,04 mars 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
Présentation Sicara
Créée en novembre 2016 au sein du groupe M33 (Theodo group), un écosystème de 10 filiales et +650 personnes situées à Paris, Londres, New York et Casablanca, Sicara est une startup experte en Data, basée à Paris.
Notre mission : aider les startups, scaleups et grands comptes à résoudre leurs problématiques business grâce à la tech. Nos équipes construisent des ETL et des algo scalables pour les clients et les utilisateurs finaux. L’objectif : capitaliser sur le potentiel de la donnée.
Actuellement 70 personnes chez Sicara, notre ambition est de poursuivre notre croissance en développant de nouveaux portefeuilles et en recrutant les leaders de la tech de demain.
Pourquoi on recrute un Lead Data Software Engineer ?
Pour contribuer à la croissance de Sicara et pour renforcer les équipes Data Software Engineering de Sicara, nous cherchons un profil expérimenté.
Tes missions
Analyser les données sources et échanger avec les experts métier afin d’identifier et évaluer des cas d’usage métier
Leader une équipe de 2 à 5 data software engineers dans le delivery de la solution à implémenter au quotidien
Concevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels)
Définir les méthodologies de déploiement et plans de migration
Construire et déployer les pipelines de données (ETL et ELT)
Assurer la migration des données vers les nouveaux environnements
Choisir et mettre en oeuvre des outils de data analyse et/ou data visualisation
Mettre en place des outils de contrôle de la qualité de la donnée
Accompagner et former les équipes clients
Au sein de Sicara :
Tu seras amené(e) à accompagner et former les équipes au data software engineering
Tu assureras une veille technologique continue sur les solutions de l’état de l’art
Tu interviendras dans la réflexion sur la stratégie technique à proposer en phases d’avant-vente de nos projets
Encadré par l’équipe dirigeante, tu généreras de la connaissance technique sur des sujets d’expertises pour les propager au sein de Sicara
En fonction de tes envies et de tes compétences, tu auras la possibilité de :
Devenir un(e) expert(e) sur les sujets techniques qui te passionnent.
Devenir un(e) leader grâce au développement de compétences transverses : coaching, recrutement, commercial, management, marketing, etc.
Monter une tribe ou une guilde pour développer un nouvelle offre et améliorer nos pratiques.
Les avantages
Notre écosystème de startup tech est un véritable tremplin pour accélérer la progression et les carrières !
Des bureaux au coeur du quartier des Batignolles à Paris, partagés avec les autres startup tech du groupe Theodo
Un coach dédié pour accélérer la progression de carrière
La possibilité de participer à des conférences techniques internationales
Des conditions de télétravail flexibles
Un budget trimestriel pour acheter ton matériel tech (laptop, smartphone, casque,...)
Des événements réguliers de team building et un WE d'entreprise à chaque année
La possibilité de s'investir dans les associations partenaires de la Fondation M33, qui agissent sur 3 piliers : l'environnement, la lutte contre les inégalités et la sécurité des données
Ton profil
Tu as entre deux à quatre ans d’expérience sur des sujets de Data Software Engineering
Tu es diplômé d’une école d’ingénieur en Bac+5
Tu as une bonne connaissance de Python et tu as déjà utilisé des technologies Big Data (Spark, Hadoop, Airflow, Terraform)
Tu souhaites participer à la conception de produits à fort impact business
Tu veux être accompagné pour exploiter à fond ton potentiel et réaliser ton ambition
A très vite !
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/sicara/jobs/lead-data-engineer-cdi-sicara-paris_paris?q=c8f40c347a4aff59a08f837b100c6ea4&o=021f194f-1207-485a-8382-db3385bb2eec,wttj
Consultant.e Data Engineer Expérimenté.e,"{'name': 'THE INFORMATION LAB', 'sector': 'Logiciels, IT / Digital, Big Data', 'employees': '38 collaborateurs', 'creation_year': '2015', 'turnover': '5M€', 'mean_age': None}",CDI,Paris,45K à 60K €,Télétravail fréquent,,,,"Descriptif du poste
Qui sommes-nous ?
Véritables passionnés de data, nous avons construit The Information Lab autour des solutions Tableau, Alteryx et Snowflake. Nous sommes convaincus que ce sont les meilleures technologies pour accomplir la transformation digitale de nos clients.
Notre spécialisation nous permet d’être les premiers partenaires de ces éditeurs et d’être les experts reconnus de ces solutions en France et en Europe.
En nous rejoignant vous pourrez partager votre passion avec vos pairs, travailler dans une ambiance décontractée pour remplir notre mission : ""Helping people make sense of data”.
Description du poste
Rattaché(e) au pôle Expertise et Conseil, vous intervenez sur des missions pour des clients de toutes tailles (grands groupes, ETI, mais aussi start-up et PME), tous métiers. Vos missions ont pour objet le traitement, l’analyse, l’enrichissement des données de nos clients et l’adoption par nos clients des technologies que nous proposons. Au sein d’une équipe de 5 à 8 personnes, vous réalisez vos missions en autonomie, ou avec un junior que vous encadrez, sous la supervision de votre “pod leader” (chef d’équipe).
Votre rôle consiste à :
Intervenir en avant-vente et cadrer vos missions
Conseiller nos clients et prendre en charge tout ou partie du delivery, sur des missions de quelques jours à quelques mois
Mener des projets de bout en bout, en méthode classique ou agile, en coordination avec les équipes de nos clients, nos équipes internes et les éditeurs partenaires
Présenter les livrables de vos missions et mettre en avant leur ROI
Former nos clients à nos technologies
Mettre vos compétences au service de vos collègues au-delà des missions dont vous avez la charge et participer au développement des compétences en partageant vos retours d’expérience
Participer aux activités d’évangélisation, par exemple : rédaction de posts de blogs, participation aux communautés des éditeurs, interventions lors d’événements (salons, conférences, webinaires)
Participer aux projets internes (BI interne, méthodes & qualités)
Les solutions que vous construisez reposent principalement sur les technologies de nos partenaires (Snowflake, Alteryx, Tableau), mais aussi selon le contexte client sur des technologies similaires.
Vos principales qualités :
Excellentes facultés d’écoute et de communication, orale et écrite
Aptitude à travailler sur plusieurs sujets en parallèle, à prioriser
Humilité et capacité à apprendre ainsi qu’à transmettre ses connaissances
Sens du service, un bon relationnel avec les clients et la rigueur nécessaire au succès de leurs projets
Team player
Compétences méthodologiques :
Analyse du besoin et cadrage de mission
Construction d’indicateurs métiers à partir de données brutes
Idéalement connaissance d’un ou plusieurs métiers et de leurs indicateurs clés
Préparation de données complexes à des fins d’analyse
Méthodes de gestion de projet (classique et agile)
Capacité prouvée à réaliser des démonstrations d’outils
Compétences techniques :
Connaissance d’au moins Alteryx Designer ou Tableau Prep (idéalement vous avez déjà une expérience solide sur ces outils)
Maîtrise d’autres outils d’analyse de données
Connaissance de la modélisation de données à des fins d’analyse
Expérience professionnelle : vous bénéficiez d’au moins 5 ans d’expérience professionnelle, dont 3 ans sur un poste similaire ou dans un poste qui vous aura permis d’utiliser les technologies similaires aux nôtres. Idéalement, vous avez déjà une expérience dans un cabinet de conseil ou une ESN.
Langues : Français, Anglais professionnel
Quoi d’autre ?
Situation géographique : Ile-de-France. Déplacements en France à prévoir.
Rémunération : 45 à 60 k€, selon expérience.
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/the-information-lab/jobs/consultant-e-data-engineer-experimente-e_paris?q=c8f40c347a4aff59a08f837b100c6ea4&o=be1cfe82-a153-4098-a40a-c5d04d362922,wttj
Data Engineer - Energie & Retail - Lyon,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Limonest,Non spécifié,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
Votre futur environnement de travail :La division « Energie & Utilities » accompagne les grands acteurs du secteur en France dans les domaines de la production et la distribution thermique, hydraulique et nucléaire. Dans un contexte agile, nos équipes d'experts participent à des projets autour de la transformation digitale pour conduire nos clients vers une transition écologique. Le défi que nous vous proposons de relever ? Mettre l'énergie au service des Smart Grid & Cities ! Rejoignez les équipes et l'esprit « E&YOU » !
Votre rôle et vos missions :
- Participation aux phases de développement d'applications Big Data (ETL, création de pipelines, développement de dashboards, gestion et administration des flux de données)- Traitement des problématiques full-stack sur des technologies JAVA- Conception architectures innovantes, basées sur AWS ou Azure- Assurer l'amélioration continue du projet et de ses membres- Travailler avec des méthodologies : SAFe, DevOps
 Votre immersion dans nos projets vous permettra d'acquérir une expérience significative aux environnements techniques et fonctionnels de nos clients et de leurs métiers.Nous vous offrons la possibilité de capitaliser sur vos qualités professionnelles et personnelles afin d'évoluer dans un environnement dynamique et convivial, sur de nombreux projets innovants, variés et passionnants.
Informations supplémentaires
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. 
Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherché
Votre profil :
Vous êtes diplômé(e) d'une école d'Ingénieur ou équivalent Universitaire, et disposez d'une première expérience significative en ingénierie de la donnée de 3 ans minimum sur une fonction similaire. 
Vous maîtrisez différentes technologies telles que Nifi, Elastic Search, Hadoop, Spark, Google Cloud Al Platform ou encore Java.
Vous avez un bon esprit d’analyse et de synthèse, le sens du relationnel, vous êtes polyvalent(e) et autonome.
Vous aimez travailler sur des sujets qui allient challenge technique et innovation ? Alors venez profiter d’une atmosphère propice à l'entrepreneuriat et à votre évolution.
Vous vous reconnaissez ? Nous sommes impatients de vous rencontrer !",2024-01-17,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-energie-retail-lyon_limonest?q=c8f40c347a4aff59a08f837b100c6ea4&o=9617fcda-a929-4716-977d-4811c6e5b7a2,wttj
Data Engineer Senior - DataOps / AWS / Archi Distribuée (f/m/x),"{'name': 'LEBONCOIN', 'sector': 'Économie collaborative, E-commerce', 'employees': '1500 collaborateurs', 'creation_year': '2006', 'turnover': '500M€', 'mean_age': '34 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Vous êtes rattaché.e à l'équipe Data Engineering, composée de data engineers et de SRE. Cette équipe vous accompagne sur la stack technique data, vous permet d'échanger sur des sujets transverses et de participer aux rituels data engineering (guilde, rétro…). Cette équipe appartient à  la tribe ""Data Tools & Services"", qui regroupe les services data centrauxLa stack :
Développement sous Ubuntu en Java, Python et SQL avec IntelliJ, Gradle, Travis, Docker, Github, Ansible, Terraform, Concourse, Helm
Dans un environnement à la pointe des technologies actuelles : Airflow, Spark, Elasticsearch, Kafka / Kafka Stream / Kafka Connect, AWS (S3, Redshift, Athena, Glue, DynamoDB), Kubernetes, Jupyter, MLFlow, Hudi
Ce que vous ferez :
Développer des applicatifs complexes assurant une circulation optimale des données, et assurer leur fiabilité : API d'exposition de données, applications de streaming, industrialisation de modèles de machine learning
Optimiser notre architecture et notre environnement AWS : stockage, sécurité, automatisation, scalabilité
Assurer la sécurité des données de nos utilisateurs sur la data platform, dans le respect de la réglementation en vigueur (GDPR, e-privacy)
Participer activement à la veille technologique et à l'effort de R&D
Garantir le bon fonctionnement, la disponibilité, l'évolution et la performance des outils
Assurer l'interface avec les équipes techniques du produit
Vous avez au moins 6 ans en tant que Data Engineer 
Vous connaissez les environnements Unix, et possédez un niveau avancé en Java / Python.
Vous êtes familier avec l'environnement cloud AWS, et avez de solides notions d'architecture distribuée et de gestion de data platform à forte volumétrie.
Vous êtes à l'aise en anglais tant à l'écrit qu'à l'oral.
Poste basé à Paris 10 
Les étapes : 
Premier échange avec Kader (RH)
Entretien managérial avec Thomas (Engineering Manager)
Entretien technique avec deux membres de l'équipe (Data Eng)
Entretien Fit/RH avec Julien (directeur data) et Kader (RH)
Voir moins",,2024-01-17,https://www.welcometothejungle.com/fr/companies/leboncoin/jobs/data-engineer-senior-dataops-aws-archi-distribuee-f-m-x_paris_LEBON_D7G09AM?q=c8f40c347a4aff59a08f837b100c6ea4&o=5777b2e1-5507-4462-9584-358a931d7d78,wttj
Data Engineer AWS (F/H),"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, Cybersécurité', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232M€', 'mean_age': None}",CDI,La Garenne-Colombes,Non spécifié,Télétravail non autorisé,,> 5 ans,,"Descriptif du poste
💥 Découvrez la Vie Apsidienne 📹 et vous aussi, devenez Apsidien
On aurait pu demander à Chat GPT de vous démontrer en quoi Apside est l’ESN qu’il vous faut, mais on préfère que vous le découvriez vous-mêmes 👇😏
🔥 Découvrez votre future mission
👉 Contexte
Rejoignez notre Practise Cloud/Data, afin d’intervenir sur des sujets à haute valeur ajoutée !
L’un de nos clients a lancé un large programme de transformation autour des données et de l’Intelligence Artificielle dans un contexte de transformation globale de la DSI. Le programme, piloté par le Chief Data Officer (CDO) et sous sponsoring de la Direction Générale, comporte plusieurs objectifs, dont celui de la mise en place de la plateforme Data & IA, qui a vocation à devenir le cœur du SI du client. En parallèle, le chantier de transformation Cloud en cours induit d’importantes adhérences avec les travaux d’industrialisation de la plateforme Data & IA. La Domaine Plateforme Data & IA, au sein de la Direction Data a la responsabilité de l’industrialisation de la Plateforme Data & IA ainsi que la réalisation du comptoir de données pour les métiers Finance et Risques
Secteur  : Banque/Finance
Méthode de travail : SAFE
😎 Mission
Vous serez en charge de réaliser les traitements d'intégration de données du pipeline d'alimentation du comptoir, ainsi que l'exposition des données en API.
Environnement technique :
SQL
Python/Spark
Cloud AWS: AWS Glue, AWS Lambda (possibilité de vous former sur AWS)
Stockage objet (AWS S3)
Orchestration et scheduling de tâches (Apache Airflow)
Bases analytiques et bases NoSQL (ElasticSearch, AWS Athena)
📍 Localisation
La Garenne Colombes à A 10 min de la Défense Accessible via T2-Arrêt Charlebourg / Ligne L - Arrêt La Garenne Colombes
💰 Le package salarial que nous vous proposons
Contrat : CDI
Avantages groupe : carte ticket restaurant Swile, prime de mobilité, RTT, accord télétravail, Mutuelle, prime de cooptation, avantages CE, prise en charge de la mutuelle à 100% etc…
Avantages agence : intégration de la Practise Cloud/Data, afterworks, communauté techlead...
Formation : certifications techniques, cours particuliers d’anglais en interne, accès à un catalogue de formations grâce à notre plateforme e-learning (Academy by Apside) ou via nos organismes partenaires.
Voir moins","Profil recherché
🔮 Ô vous futur Apsidien, qui êtes-vous ?
A minima 5 ans d'expérience en tant que Data Engineer
Connaissance du monde bancaire
Maitrise de Spark, Python
Connaissance de AWS
😏 Apside a suscité votre curiosité ?
Dans un environnement marqué par une accélération des évolutions technologiques, de transformations des usages et de disruptions majeures, Apside est un partenaire de confiance qui accompagne ses clients à créer de la valeur et à adresser leurs enjeux stratégiques en leur mettant à disposition des expertises technologiques (Data / IA, Cloud, Cyber) et une expérience sectorielle (Industrie, Banque, Assurance, Service, Secteur Public). Pour un accompagnement global, le groupe propose des offres transverses autour du Handicap (Apsid’EA), du Digital Learning, et du Conseil.
🤔 Et votre place dans tout ça ?
👉 Notre volonté est de vous accompagner dans la construction et l’épanouissement de votre carrière en nous appuyant notamment
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/apside/jobs/data-engineer-aws-f-h_la-garenne-colombes?q=c8f40c347a4aff59a08f837b100c6ea4&o=9c34c97e-2c0e-44bb-852f-dc3138d249d2,wttj
Data Engineer GCP (F/H),"{'name': 'APSIDE', 'sector': 'SaaS / Cloud Services, Big Data, Cybersécurité', 'employees': '3000 collaborateurs', 'creation_year': '1976', 'turnover': '232M€', 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Le poste :
Pour le compte de notre client acteur mondial de la beauté et cosmétique, tu interviendras dans la transformation d’un projet worlwide, où tu devras développer la Data Platform et l'ensemble des services Data qui seront exposés aux différentes équipes du client. Aussi, tu seras amené à développer des use cases data.
Dans ce sens, tes missions seront les suivantes :
Designer l'architecture et développer la solution
Définir et développer les Data Model
Être garant de la qualité du code
Être DevOps (Utilisation/mise en place de chaine CI/CD et support niveau L3 des développements)
Environnement technique :
GCP (BigQuery, Cloud Run, Cloud Build)
SQL
Python
DevOps (Github)
API Development
Terraform
Méthodologie Agile
Voir moins","Profil recherché
Envie de rejoindre une entreprise apprenante ? Engagée pour t’accompagner dans ton évolution professionnelle et dans tes projets personnels ?
Rejoins Apside Paris pour travailler sur nos projets de demain !
Toi ?
Tu as déjà travaillé sur Google Cloud Platform (GCP) ?
Tu es autonome, rigoureux, et bon communiquant ?
Tu souhaites participer à un projet d’envergure associant cloud et Big Data ?
Alors ce poste de Data Engineer GCP est fait pour toi !
Et la suite ?
Tu rencontres d’abord l’équipe RH pour parler de tes attentes, ton projet, ton futur !
Puis les managers pour parler concret : missions, projets, parcours de carrière, et bien sûr salaire et avantages :)
Et tu discutes avec un de nos Tech Leads, pour évaluer tes compétences et te challenger.
Les infos en plus !
Voir plus",2024-01-17,https://www.welcometothejungle.com/fr/companies/apside/jobs/data-engineer-gcp-f-h_paris?q=c8f40c347a4aff59a08f837b100c6ea4&o=6b6aabb9-8690-43d3-ae3b-c187b81e72c0,wttj
Data Engineer - Energie & Retail - Lyon,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Limonest,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Description de l’entreprise
Sopra Steria, l’un des leaders européens de la Tech reconnu pour ses activités de conseil, de services numériques et d’édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d’activité et des technologies innovantes à une approche résolument collaborative.
Sopra Steria place l’humain au centre de son action et s’engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 50 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d’affaires de 5,1 milliards d’euros en 2022.
The world is how we shape it
Description du poste
Notre promesse :
“Avoir l’opportunité d’évoluer et de développer expertises et compétences grâce à des expériences variées au sein d’un Groupe multi-métiers et multisectoriels, intervenant auprès des plus grandes entreprises Européennes”.
Dans ce cadre, pourquoi ne pas devenir Architecte ou encore Directeur/rice technique dans l’avenir ?
Votre futur environnement de travail :
Vous intégrez une équipe de data engineer’s, directement chez notre client basé dans le 7e arrondissement de Lyon.
Notre client est spécialisé dans les métiers de l’énergie. Vous travaillez sur différents contextes métier comme la production, le transport ou encore la fourniture de gaz et d’électricité :
Solution de supervision de la production et consommation d’électricité en temps réel, afin de contrôler l’équilibre offre / demande ;
Solution « big data » qui permet à notre client de stocker, exploiter et valoriser l’ensemble des données collectées et gérées dans le cadre de son activité.
Votre rôle et vos missions :
Participer aux phases de développement d’applications Big Data (ETL, création de pipelines, développement de dashboards, gestion et administration des flux de données) ;
Traiter des problématiques full-stack ;
Concevoir des architectures innovantes ;
Assurer l’amélioration continue du projet et de ses membres ;
Travailler avec des méthodologies SAFe ou DevOps.
Vous travaillez autour des technologies Spark, Hadoop, Nifi, Elastic search, Java, AWS et Azure.
Qualifications
Votre profil :
Vous êtes diplômé(e) d’une école d’Ingénieur ou équivalent Universitaire, et disposez d’une première expérience significative en ingénierie de la donnée de 3 ans minimum sur une fonction similaire ;
Vous maîtrisez différentes technologies telles que Nifi, Elastic Search, Hadoop, Spark, Google Cloud Al Platform ou encore Java ;
Vous avez un bon esprit d’analyse et de synthèse, le sens du relationnel, vous êtes polyvalent(e) et autonome.
Informations supplémentaires
Les avantages à nous rejoindre :
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.
Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s’engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L’opportunité de rejoindre le collectif Tech’Me UP (formations, conférences, veille, et bien plus encore…).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
Voir moins",,2024-01-16,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-energie-retail-lyon_limonest_SS_Za867VL?q=c8f40c347a4aff59a08f837b100c6ea4&o=de4376bf-1f0d-46a4-8a15-6235603c908e,wttj
Data Engineer (Internship),"{'name': 'WIREMIND', 'sector': 'Logiciels, Mobilité, SaaS / Cloud Services', 'employees': '91 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '29 ans'}","Stage
(6 mois)",Paris,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
At Wiremind, the Data Science team is responsible for the development, monitoring and evolution of all ML-powered forecasting and optimization algorithms in use in our Revenue Management systems. Our algorithms are divided in 2 parts:
A modelling of the unconstrained demand using ML models (e.g. deep learning, boosted trees) trained on historical data in the form of time-series
Constrained optimizations problems solved using linear programming techniques
The team is now entering a scaling phase where we will face the challenge to stay agile in terms of innovation while supporting and closely monitoring deployed algorithms.
This rapid growth comes with a multiplication of data sources and deployed predictive models. In order to maintain high prediction accuracies and ascertain data quality, we are looking for a Data Engineer Intern with a passion for software engineering and rigorous mind.
You will be joining a team shaped to have all profiles necessary to constitute an autonomous departement (devops, software and data engineering, data science, AIML, operational research).
There, you will support the ML engineers by improving our MLOps platform, work closely with software engineers to implement the data science algorithms in the client applications and exchange with the platform team to keep the infrastructure debt at a minimum.
As a Data Engineer Intern, you will be responsible for :
Help the team deploy our algorithms in production in a safe, scalable and maintainable way
Support the ML team in their use of the MLOPs framework
Technical stack:
Backend: Python 3.7+ with SQLAlchemy, Remoulade, Flask/FastAPI
Argo over an auto-scaled Kubernetes cluster for orchestration
Data-store: Postgresql, Elasticsearch, Redis
Gitlab for continuous delivery
Common ML libraries: TensorFlow, LightGBM, XGBooost, Pandas, Dask, Dash
THE BENEFITS OF THE JOB 🚀
International environment 🌍
Hyper-growth start-up: strong growth in our turnover and workforce 📈
Joining a committed team that offers you opportunities for development 🧑‍💻
Variety of tasks and a high degree of autonomy
Position based in the heart of Paris (Bd Poissonnière) ✨
Attractive remuneration indexed to performance 💪
Luncheon vouchers 🌮
A hybrid policy: 2 days’ remote a week and the possibility of occasionally working from abroad 💻
Start date: as soon as possible
Type of contract: internship
Voir moins","Profil recherché
Above average in terms of rigor and autonomy, you are proactive and curious.
Good general culture in computer science and you are looking for a quick progression perspective in an environment with best development practices.
Interested in solving business problems through technological solutions.",2024-01-15,https://www.welcometothejungle.com/fr/companies/wiremind/jobs/data-engineer-internship_paris?q=c8f40c347a4aff59a08f837b100c6ea4&o=d9a27039-daf5-4a9b-ac18-617b1d028bb7,wttj
Consultant·e Cloud Data Engineer GCP/Azure,"{'name': 'SAEGUS', 'sector': 'IT / Digital, Stratégie', 'employees': '120 collaborateurs', 'creation_year': '2014', 'turnover': '14M€', 'mean_age': '30 ans'}",CDI,Paris,42K à 60K €,Télétravail occasionnel,26 février 2024,> 3 ans,Bac +5 / Master,"Descriptif du poste
Concrètement, quelle sera la mission et les réalisations attendues ❓
En tant que Consultant·e Data Engineer, tu seras intégré·e à l’équipe Smart Data dont la mission est d’aider ses clients à tirer profit des technologies les plus innovantes pour valoriser leurs données. De l’acquisition à la restitution, tu interviens sur chaque étape du processus d’aide à la décision.
Tu participeras aux missions de conseil et d’expertise afin de contribuer à l’atteinte des objectifs majeurs de nos clients et contribueras à la réalisation de projets tels que :
⚡️ Le design d’une plateforme Azure Cloud et la mise en place de pipeline d’ingestion et exposition de données pour la mise à disposition de données métiers, rafraichies toutes les 30mn
⚡️ La mise en place des bonnes pratiques et l’initialisation du Datalab pour un grand groupe d’assurance, et l’accompagnement à l’industrialisation des algorithmes pour les usages métiers
⚡️ L’ensemble des traitements d’ingestion et préparation des datasets afin d’alimenter des Dashboard de monitoring de l’activité digitale Worldwide d’un grand groupe cosmétique afin de mesurer l’empreinte des marques sur les médias et réseaux sociaux
⚡️ L’accompagnement à la création et l’activité d’une Data Factory pour traiter l’ensemble des données d’un grand groupe de distribution et mettre à disposition des données qualifiées pour les différents use cases métiers
Nous recherchons un.e passionné.e possédant une envie de de fédérer et faire monter en valeur les consultants autour des thématiques Data Engineering recouvrant la mise en place de Plateforme de données, des bonnes pratiques de développements et des process DataOps, l’industrialisation de pipeline de traitements de données pouvant aller jusqu’à la Data Visualisation.
➜ Dans quel environnement ?
En fonction de tes missions et réalisations projet, tu seras amené·e à intégrer des équipes composées de Data Engineer, Data Scientist, Data Architects, organisées en mode agile. Tes activités s’appuieront sur les méthodes et savoir-faire de Saegus et sur son catalogue d’outils et technologies sur lesquels tu as une maîtrise sur plusieurs d’entre eux :
✅ Bonnes connaissances sur les architectures data et cloud (connaissance d’un environnement Cloud) :
Azure (Data Factory, Synapse, ADLS, Databricks)
Google GCP (BigQuery, Composer, Data Studio)
✅ SQL, Python
✅ Spark, PySpark
✅ Airflow, Kafka, Jenkins
✅ Solides connaissances des processus collaboratifs et outils de développement (DevOps, Git, CI/CD…)
Les connaissances suivantes seraient un plus ⤵️
OpenShift, Docker, Kubernetes
Data visualisation
Bases NoSQL
Certification Data Engineer (Azure Data Engineer, Google Professional Data Engineer ou Snowflake SnowPro)
Ce que nous t’apportons
💫 FORMATIONS ET DÉVELOPPEMENT DE CARRIÈRE
Une journée de formation incluse dans ton parcours d’onboarding lors de ton premier mois d’arrivée pour partager sur les fondamentaux et répondre à tes questions
Accès à un coach interne et consultant comme toi pour t’accompagner dans ton quotidien (questions en particulier, aide, montée en compétences)
Un plan de formations et de certifications ambitieux (minimum 1 certification offerte par an)
⭐️ AVANTAGES
Remboursement de tes frais de transports (remboursement à 100% de ton pass navigo ou forfait mobilité durable jusqu’à 700€ par an pour l’utilisation et l’aide à l’achat de matériel de mobilité douce)
Titres restaurant à hauteur de 216€/mois pris en charge à 60% par Saegus (Carte Swile)
Prime vacances (versée en juin)
Prime téléphone 25€/mois
Prime d’intéressement aux résultats de l’entreprise
Prise en charge par Saegus de la mutuelle à la hauteur de 75%
👋 COHÉSION ET CONVIVIALITÉ
Organisation de deux activités par mois (fun, solidaire ou excellence) par notre Team Anim
Un séminaire annuel pour favoriser la cohésion entre Saegusiens
Accès aux locaux de Saegus, très accueillants dans le centre de Paris notamment lors de nos SaegUp mensuel
Voir moins","Profil recherché
🎯 Idéalement, en termes de compétences, nous recherchons :
Un profil de formation supérieure (Bac + 5 minimum), ingénieur ou équivalent, avec une expérience d’au moins 3 ou 4 ans minimum dans le domaine du Big Data.
Tu as déjà mené avec succès plusieurs projets Big Data avec des références significatives dans la mise en place de flux de données et de traitement de l’information.
Tu interviens en autonomie sur tes projets et as une première expérience d’encadrement technique.
Tu es motivé.e pour intégrer une structure alliant l’exigence d’un cabinet de conseil et le dynamisme et l’agilité d’une start-up.
Tu es un·e très bon·ne communiquant·e et as un fort esprit d’initiative, un goût prononcé pour les nouvelles technologies et un bon esprit de synthèse.
Ton sens du service et ton écoute client te permettront de t’inscrire parfaitement dans la culture de notre cabinet de conseil.
La maîtrise de l’anglais et du français à l’écrit et à l’oral est indispensable.
Voir plus",2024-01-15,https://www.welcometothejungle.com/fr/companies/saegus/jobs/consultant-confirme-data_paris?q=c8f40c347a4aff59a08f837b100c6ea4&o=6c29726a-ea58-491d-a646-a6f7ef9540ad,wttj
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 M€', 'mean_age': '34 ans'}",CDI,,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous ! 
Vous serez amené à travailler sur :
Elaboration d’architectures optimisées dans un contexte Snowflake,
Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),
Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coûts d utilisation Snowflake (FinOps)","Profil recherché
Vous êtes issu d’une école d’ingénieur ou d’un Master 2 
 Vous avez une première expérience sur du Snowflake ou au moins 2  ans de SQL",2024-01-15,https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-data-engineer-snowflake?q=c8f40c347a4aff59a08f837b100c6ea4&o=4554ef97-cc0b-42ee-8a85-828f7e6506d6,wttj
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 M€', 'mean_age': '34 ans'}",CDI,Saint-Herblain,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous ! 
Vous serez amené à travailler sur :
Elaboration d’architectures optimisées dans un contexte Snowflake,
Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),
Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coûts d utilisation Snowflake (FinOps)","Profil recherché
Vous êtes issu d’une école d’ingénieur ou d’un Master 2 
 Vous avez une première expérience sur du Snowflake ou au moins 2  ans de SQL",2024-01-15,https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-data-engineer-snowflake_saint-herblain_KC_GpN24oz?q=c8f40c347a4aff59a08f837b100c6ea4&o=65f4d9e7-9715-4ea4-95a7-82bb9784a6f4,wttj
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 M€', 'mean_age': '34 ans'}",CDI,,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous ! 
Vous serez amené à travailler sur :
Elaboration d’architectures optimisées dans un contexte Snowflake,
Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),
Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coûts d utilisation Snowflake (FinOps)","Profil recherché
Vous êtes issu d’une école d’ingénieur ou d’un Master 2 
 Vous avez une première expérience sur du Snowflake ou au moins 2  ans de SQL",2024-01-15,https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-data-engineer-snowflake_KC_zNjo2gl?q=c8f40c347a4aff59a08f837b100c6ea4&o=66842ad1-8281-47f6-acde-2db2b9385dae,wttj
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 M€', 'mean_age': '34 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous ! 
Vous serez amené à travailler sur :
Elaboration d’architectures optimisées dans un contexte Snowflake,
Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),
Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coûts d utilisation Snowflake (FinOps)","Profil recherché
Vous êtes issu d’une école d’ingénieur ou d’un Master 2 
 Vous avez une première expérience sur du Snowflake ou au moins 2  ans de SQL",2024-01-15,https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-data-engineer-snowflake_levallois-perret?q=c8f40c347a4aff59a08f837b100c6ea4&o=3abcf01b-9714-4233-b584-5ad38e2a561e,wttj
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 M€', 'mean_age': '34 ans'}",CDI,Villeurbanne,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous ! 
Vous serez amené à travailler sur :
Elaboration d’architectures optimisées dans un contexte Snowflake,
Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),
Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coûts d utilisation Snowflake (FinOps)","Profil recherché
Vous êtes issu d’une école d’ingénieur ou d’un Master 2 
 Vous avez une première expérience sur du Snowflake ou au moins 2  ans de SQL",2024-01-15,https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-data-engineer-snowflake_villeurbanne?q=c8f40c347a4aff59a08f837b100c6ea4&o=38c0d978-ac4a-4515-b171-149375e54991,wttj
Consultant(e) Data Engineer Snowflake,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 M€', 'mean_age': '34 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification. 
Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous ! 
Vous serez amené à travailler sur :
Elaboration d’architectures optimisées dans un contexte Snowflake,
Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),
Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOps
Mise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOps
Optimisation des performances et des coûts d utilisation Snowflake (FinOps)","Profil recherché
Vous êtes issu d’une école d’ingénieur ou d’un Master 2 
 Vous avez une première expérience sur du Snowflake ou au moins 2  ans de SQL",2024-01-15,https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-data-engineer-snowflake_levallois-perret_KC_6K9a85j?q=c8f40c347a4aff59a08f837b100c6ea4&o=652077ee-3d5e-4301-899c-6ac7e22a9f4d,wttj
Data engineer (H/F),"{'name': 'EKINOX', 'sector': 'Logiciels, Intelligence artificielle / Machine Learning, Incubateur / Accélérateur', 'employees': '20 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 2 ans,Bac +5 / Master,"Descriptif du poste
A propos de votre mission :
Avec nous, vous travaillerez en équipe. Vous vous entraînerez avec des coéquipiers à votre image (et donc à notre image) dans un cadre agile (souvent Scrum), jusqu’à entrer en résonance avec eux. Lorsque vous travaillez pour votre client, votre sens de l’empathie vous pousse à toujours mieux comprendre ses problématiques de fond. Votre socle méthodologique sera sérieusement constitué de TDD, BDD, pair programming et autres principes établis de qualité tirées notamment des pratiques prônées par Extreme Programming ou du Craftsmanship Manifesto. Fortement impliqué dans la vision produit, vous considérez le Product Manager au même titre que n’importe quel autre de vos coéquipiers.","Profil recherché
Ce qu’Ekinox recherche chez vous :
Vous avez une expérience de 2 ans ou plus (mais on peut toujours en discuter)
Vous vous sentez concerné·e par le software craftsmanship et faites de la veille technologique
Vous aimez travailler en équipe et partager vos connaissances
Vous êtes ouvert·e aux autres et acceptez leurs points de vue avec bienveillance
Vous contribuez à la progression des personnes qui vous entourent
Compétences techniques :
Voici une liste non-exhaustive des technologies que nous utilisons. Vous aurez pour mission de produire de la valeur avec un certain nombre d’entre elles:
Langages de programmation suivants : Python, Java, Scala
Outils d’industrialisation : Gitlab CI / Github Actions / Google Cloud Build
Infrastructure et déploiement : Docker / Kubernetes, Terraform
Travail en équipe : Git
Web : Spring et autres frameworks
Voir plus",2024-01-15,https://www.welcometothejungle.com/fr/companies/ekinox/jobs/data-engineer_paris?q=4312f2244a62de3032cd18401125b56f&o=d00e3955-fd83-4faf-9b75-e600d0f0c6a9,wttj
Data Engineer Stagiaire,"{'name': 'JAKALA', 'sector': 'Digital Marketing / Data Marketing, Big Data, E-commerce', 'employees': '150 collaborateurs', 'creation_year': '2023', 'turnover': '15M€', 'mean_age': '31 ans'}","Stage
(6 mois)",Caen,Non spécifié,Télétravail fréquent,,> 6 mois,Bac +5 / Master,"Descriptif du poste
En tant que Stagiaire Data Engineer, vous évoluez au sein d’une équipe d’une vingtaine de développeurs, ingénieurs en science des données, algorithmiciens, intégrateurs et graphistes.
Sujet 1 : Streaming
Vous avez pour mission de concevoir et d’implémenter différents frameworks dans des environnements cloud permettant de traiter en temps réel  des données provenant d’objets connectés (IOT).
Ces frameworks seront à implémenter sur les différents environnements cloud (AWS, GCP, Azure, OVH).
Sujet 2 : Développement ETL - Kedro
Vous avez pour mission de développer des pipelines Python en utilisant l’outil Kedro sur différents environnements cloud.
Thématiques abordées :
pipelines
multi threading
algorithmie
data catalog
CICD
Viz
Voir moins","Profil recherché
En dernière année d’école d’Ingénieur ou universitaire, vous avez une grande appétence pour l’environnement Big Data.
Compétences attendues:
Bonne connaissance dans le développement logiciel 
Bon niveau en Python 
API REST
scripts et logiciel
data visualisation
pré étude via Notebooks Jupyter
Bon niveau en Java
Bonne connaissance de l’environnement container Docker (Kubernetes est un plus)
Bonne connaissance de SQL et d’un système de SGBDr (PostgreSQL, MySQL)
Connaissance des environnements cloud (VM, Containers)
Connaissance de Git et travail en équipe
Curieux.se, passionné.e et rigoureux.se, vous évoluez dans un contexte innovant, challengeant et bienveillant.
Voir plus",2024-01-15,https://www.welcometothejungle.com/fr/companies/soyhuce/jobs/stagiaire-data-engineer?q=4312f2244a62de3032cd18401125b56f&o=575c0e15-e699-4dc3-9235-4ae82be6c31f,wttj
DATA ENGINEER (F/H),"{'name': 'ACTINVISION', 'sector': 'Intelligence artificielle / Machine Learning, Transformation, Big Data', 'employees': '50 collaborateurs', 'creation_year': '2014', 'turnover': '5M€', 'mean_age': '29 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Vous serez amené(e) à travailler sur différents projets innovants, pour des clients de toute taille, dans des secteurs divers et variés tels que l’agroalimentaire, le commerce, la distribution, la banque, la finance, le luxe, l’énergie, l’industrie, la pharma/chimie ou encore la santé.
En tant que Data Engineer passionné(e), vous aiderez nos clients à relever les challenges d’aujourd’hui et de demain en intégrant leurs données au sein d’infrastructures, On-Premise et Cloud. A la suite d’une période d’intégration destinée à vous familiariser avec la méthodologie Actinvision, vous interviendrez dans toutes les phases de projets, de l’analyse du besoin client à la livraison de la solution technique en passant par le chiffrage et les développements. Vous évoluerez en équipe mais également de manière autonome dans un environnement technique porteur d’innovations incluant par exemple la modélisation et la construction d’entrepôts de données (Data Warehouses), le design de flux d’intégration au moyen d’outils (Matillion etc. ) permettant l’alimentation de ces derniers, ou encore la mise en place et l’optimisation dans le respect des bonnes pratiques d’architectures Data, notamment Cloud (e.g. Snowflake ou Azure).
Le développement des compétences est un aspect primordial. Ce développement continu est appuyé par les ressources officielles mises à disposition par l’ensemble des éditeurs partenaire d’Actinvision et complété par des ressources internes. Les compétences acquises pourront être valorisées aux travers de certifications éditeurs hautement qualifiantes.
MISSIONS PRINCIPALES : • Participer en équipe ou de façon autonome à la mise en œuvre de projets Data/Business Intelligence (BI), en se focalisant principalement sur les partie intégration et stockage de la donnée • Recueil du besoin client technico-fonctionnel permettant la mise en place d’architectures pour la collecte et l’extraction de données depuis diverses sources (bases de données Cloud, applications métier, API, etc.), la manipulation et la transformation de ces données, puis le chargement de ses dernières au sein de base de données de type Data Warehouses (DWH) • Design des infrastructures/architectures Data et modélisation des DWH cibles, lesquels seront principalement utilisés dans le cadre d’opérations de Reporting et/ou de Data Visualisation • Réalisation de flux d’intégration et transformation de donnée
Voir moins","Profil recherché
De formation Bac+5 en informatique, vous disposez de minimum 1 an d’expérience sur un poste similaire.
Savoir-faire, compétences techniques requises :
• Langage SQL et modélisation DWH
• Pratique d’un outil d’intégration ETL / ELT
• Connaissances en bases de données relationnelles (e.g. SQL Server ou MySQL)
• Connaissances sur une plateforme Cloud Data (Snowflake, Azure, AWS ou GCP)
• Connaissances de la chaîne de valeur de la Data, et particulièrement de la BI
Savoir-faire, compétences techniques appréciées :
• Connaissances en architectures Cloud (sécurité, performances, maîtrise des coûts, etc.)
• Programmation procédurale, e.g. T-SQL ou PL/SQL
• Un langage de programmation orienté objet, e.g. Java ou Python
• A l’aise avec l’utilisation d’API / de Web Services
• Notions sur l’ESB
Savoir-être, compétences fonctionnelles :
• Passion pour la Data
• Autonomie / Travail et esprit d’équipe (incluant le partage des connaissances)
• Force de proposition / Capacité à rechercher et trouver des solutions
• Créativité et curiosité
• Dynamisme et réactivité
• Sens du service
• Capacité à participer à l’animation de la communauté (interne et externe)
• Anglais technique
• Pour un poste confirmé : Expérience probante dans les domaines du DWH et de l’intégration de données (cloud et/ou on-prem)
Voir plus",2024-01-12,https://www.welcometothejungle.com/fr/companies/actinvision/jobs/data-engineer-f-h_paris?q=4312f2244a62de3032cd18401125b56f&o=6d1265f3-884b-4d02-8b6e-0d9f4762ea06,wttj
DATA ENGINEER (F/H),"{'name': 'ACTINVISION', 'sector': 'Intelligence artificielle / Machine Learning, Transformation, Big Data', 'employees': '50 collaborateurs', 'creation_year': '2014', 'turnover': '5M€', 'mean_age': '29 ans'}",CDI,Strasbourg,Non spécifié,Télétravail occasionnel,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Vous serez amené(e) à travailler sur différents projets innovants, pour des clients de toute taille, dans des secteurs divers et variés tels que l’agroalimentaire, le commerce, la distribution, la banque, la finance, le luxe, l’énergie, l’industrie, la pharma/chimie ou encore la santé.
En tant que Data Engineer passionné(e), vous aiderez nos clients à relever les challenges d’aujourd’hui et de demain en intégrant leurs données au sein d’infrastructures, On-Premise et Cloud. A la suite d’une période d’intégration destinée à vous familiariser avec la méthodologie Actinvision, vous interviendrez dans toutes les phases de projets, de l’analyse du besoin client à la livraison de la solution technique en passant par le chiffrage et les développements. Vous évoluerez en équipe mais également de manière autonome dans un environnement technique porteur d’innovations incluant par exemple la modélisation et la construction d’entrepôts de données (Data Warehouses), le design de flux d’intégration au moyen d’outils (Matillion etc. ) permettant l’alimentation de ces derniers, ou encore la mise en place et l’optimisation dans le respect des bonnes pratiques d’architectures Data, notamment Cloud (e.g. Snowflake ou Azure).
Le développement des compétences est un aspect primordial. Ce développement continu est appuyé par les ressources officielles mises à disposition par l’ensemble des éditeurs partenaire d’Actinvision et complété par des ressources internes. Les compétences acquises pourront être valorisées aux travers de certifications éditeurs hautement qualifiantes.
MISSIONS PRINCIPALES : • Participer en équipe ou de façon autonome à la mise en œuvre de projets Data/Business Intelligence (BI), en se focalisant principalement sur les partie intégration et stockage de la donnée • Recueil du besoin client technico-fonctionnel permettant la mise en place d’architectures pour la collecte et l’extraction de données depuis diverses sources (bases de données Cloud, applications métier, API, etc.), la manipulation et la transformation de ces données, puis le chargement de ses dernières au sein de base de données de type Data Warehouses (DWH) • Design des infrastructures/architectures Data et modélisation des DWH cibles, lesquels seront principalement utilisés dans le cadre d’opérations de Reporting et/ou de Data Visualisation • Réalisation de flux d’intégration et transformation de donnée
Voir moins","Profil recherché
De formation Bac+5 en informatique, vous disposez de minimum 1 an d’expérience sur un poste similaire.
Savoir-faire, compétences techniques requises :
• Langage SQL et modélisation DWH
• Pratique d’un outil d’intégration ETL / ELT
• Connaissances en bases de données relationnelles (e.g. SQL Server ou MySQL)
• Connaissances sur une plateforme Cloud Data (Snowflake, Azure, AWS ou GCP)
• Connaissances de la chaîne de valeur de la Data, et particulièrement de la BI
Savoir-faire, compétences techniques appréciées :
• Connaissances en architectures Cloud (sécurité, performances, maîtrise des coûts, etc.)
• Programmation procédurale, e.g. T-SQL ou PL/SQL
• Un langage de programmation orienté objet, e.g. Java ou Python
• A l’aise avec l’utilisation d’API / de Web Services
• Notions sur l’ESB
Savoir-être, compétences fonctionnelles :
• Passion pour la Data
• Autonomie / Travail et esprit d’équipe (incluant le partage des connaissances)
• Force de proposition / Capacité à rechercher et trouver des solutions
• Créativité et curiosité
• Dynamisme et réactivité
• Sens du service
• Capacité à participer à l’animation de la communauté (interne et externe)
• Anglais technique
• Pour un poste confirmé : Expérience probante dans les domaines du DWH et de l’intégration de données (cloud et/ou on-prem)
Voir plus",2024-01-12,https://www.welcometothejungle.com/fr/companies/actinvision/jobs/data-engineer-f-h_strasbourg_ACTIN_Wkz1Jaz?q=4312f2244a62de3032cd18401125b56f&o=37b1d86d-ec9d-4ac9-b70e-4b2a541f6a77,wttj
Data Engineer - Services Financiers - Ile de France,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Courbevoie,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Description de l’entreprise
Sopra Steria, acteur majeur de la Tech en Europe, reconnu pour ses activités de conseil, de services numériques et d’édition de logiciels, aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Il apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d’activité et des technologies innovantes à une approche résolument collaborative.
Sopra Steria place l’humain au centre de son action et s’engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif.
Fort de 50 000 collaborateurs dans près de 30 pays, le Groupe a réalisé un chiffre d’affaires de 5,1 milliards d’euros en 2022.
The world is how we shape it
Description du poste
Votre futur environnement de travail :
Sous la supervision d’un Chef de Projet, vous êtes pleinement impliqué(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi à leur succès. Vous avez l’occasion de développer vos compétences techniques et fonctionnelles de manière approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.
Votre rôle et vos missions :
Vous avez pour rôle la mise en place de pipelines de données fiables, sécurisés et à l’échelle pour soutenir la mise à disposition des données aux cas d’usage métier qui en ont besoin.
Vos activités principales sont les suivantes :
Vous travaillez avec le client pour évaluer, concevoir, déployer, améliorer et maintenir les pipelines de données ;
Vous vous assurez que les pipelines de données créés sont résilients, sécurisés et accessibles ;
Vous définissez le modèle opérationnel pour monitorer et supporter les pipelines de données
Vous fournissez une expertise à nos clients sur leurs données pour assurer leur optimisation et leur sécurité par rapport à leurs besoins ;
Vous apportez un savoir en gestion de la qualité et la gouvernance de la donnée pour assurer le suivi de la conformité à la gouvernance de la donnée
Vous faites de la veille technologique dans le domaine afin d’enrichir les roadmaps technologiques et fournir des solutions modernes à nos clients.
Qualifications
Votre profil :
De formation Master 2 Ecole d’Ingénieurs ou Informatique, ou équivalent, vous justifiez d’une expérience technique de 3 ans minimum et souhaitez évoluer rapidement dans un contexte motivant.
Vous avez au moins l’une de ces compétences requises :
Maîtrise des technologies de bases de données Relationnelles et NoSQL
Maîtrise d’au moins un outil d’ETL/ELT (Informatica, datastage, etc.)
Maîtrise des technologies de traitement distribué de données (spark, Hadoop)
Maîtrise d’au moins un framework de streaming de données (Kafka, RabbitMQ, etc.)
Maîtrise de chaines CI/CD et de des bonnes pratiques de DataOps
Maîtrise de solution de Virutualisation de données (Denodo, Dremio, etc.)
Maîtrise d’au moins un environnement cloud public ou privé (Azure, AWS, Outscale, etc.)
Vous êtes attiré(e) par le monde du numérique, le Cloud et des technologies innovantes.
Vous avez un bon esprit d’analyse, êtes curieux(se) et passionné(e) et vous avez le sens du travail en équipe.
Informations supplémentaires
Ce que nous vous proposons :
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.
Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
.La possibilité de s’engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L’opportunité de rejoindre le collectif Tech’Me UP (formations, conférences, veille, et bien plus encore).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
Voir moins",,2024-01-12,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-services-financiers-ile-de-france_courbevoie?q=4312f2244a62de3032cd18401125b56f&o=4c5793d1-d180-4abb-bc0e-17e1cd527665,wttj
Senior Data Engineer – CDI – Paris,"{'name': 'IODA GROUP', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Stratégie', 'employees': '39 collaborateurs', 'creation_year': '2010', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Le Job 💻
En tant que Senior Data Engineer chez IODA Group, tu seras aux commandes des missions suivantes :
·       Développer de nouveaux modèles de données et des pipelines
·       Tester les solutions les plus innovantes et prometteuses du marché en vue de pouvoir améliorer nos capacités en matière de données
·       Comprendre les enjeux business et savoir les traduire dans un environnement technique
·       Assister nos clients dans le cadrage des projets et contribuer au design fonctionnel et technique avec une vision avant-gardiste
·       Assumer le rôle de référent, coacher les consultants juniors et faire évoluer son équipe
Compétences techniques requises 🔧
Pour ce poste, nous recherchons une personne aux compétences multiples avec :
·       Une expérience approfondie des technologies liées aux données, y compris les modèles d’architecture Big Data (Spark, Hive, Impala…)
·       Une expérience approfondie des services Cloud (AWS / Azure / GCP)
·       Une expertise en langages de programmation : Python, Java, et si possible Scala
·       Une mise en production de cas d’usage Data, notamment en Machine Learning
·       Une capacité à mettre en place des modèles de données flexibles et évolutifs (optimisation de stockage et traitement, regroupement, agrégation, partitionnement…)
·       Une maitrise des bases de données SQL (conception, exploitation …)
·       Une connaissance en DevOps et en développement de flux de données (data pipelines) avec une maîtrise de Docker/Kubernetes et des chaînes CI/CD seraient un plus
Voir moins","Profil recherché
Profil recherché 🌟
Si tu es diplômé(e) d’une école d’ingénieur / génie informatique Bac+5, que tu as à minima 4 ans d’expérience et que tu as une expérience solide dans le monde de la Data, alors nous voulons te rencontrer !
Si tu es une personne entreprenante, capable de travailler en équipe en s’adaptant à divers profils, de superviser, de prioriser et de gérer plusieurs actions, d’avoir d’excellentes compétences en communication, présentation et coordination, nous souhaitons toujours te rencontrer !
De plus, si tu as des compétences avérées en analyse et résolution de problèmes, associées à une aptitude à assimiler rapidement de nouvelles technologies, tu es bien la personne qu’il nous faut !
Ce qui t’attend chez IODA Group 🌈
En nous rejoignant, tu auras droit à :
·       Une équipe dynamique et motivée qui reconnaîtra et encouragera tes talents et tes idées
·       Une diversité de projets stimulants dans différents secteurs d’activités
·       Des plateformes internes de R&D pour toujours être à la pointe de la technologie
·       Des perspectives d’évolution concrètes pour faire décoller ta carrière
·       Un CDI avec une rémunération fixe attractive et une part variable selon ton profil (voire des bonus complémentaires si tu surperformes !)
·       Deux jours de télétravail par semaine après la période d’essai
·       Des avantages tels que des tickets restaurants, une participation au titre de transport, une mutuelle…
·       Une participation active à la vie de l’entreprise avec des afterworks, des événements, des séminaires et bien plus encore !
Voir plus",2024-01-11,https://www.welcometothejungle.com/fr/companies/ioda/jobs/senior-data-engineer-cdi-paris_paris?q=4312f2244a62de3032cd18401125b56f&o=1a1e2378-26f6-40c5-8b6f-b010fa81497d,wttj
Stage - 6 mois - Market Risk IT Data Engineer F/H,"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards € de PNB', 'mean_age': None}","Stage
(6 mois)",Charenton-le-Pont,Non spécifié,Télétravail non autorisé,,< 6 mois,Bac +5 / Master,"Descriptif du poste
Votre MISSION & bien plus encore…
Vous rejoignez notre équipe ""Risk DPM Sensitivities"" de Natixis , qui recherche un Développeur Hadoop Scala, pour un stage de 6 mois dès maintenant.
Cela se traduit par des calculs et intégrations de sensibilités de marchés quotidiens, des problématiques de stockage, et de distribution des données.
En collaboration avec votre tuteur vos missions principales seront :
Comprendre le positionnement de l'application dans le système d'information de Natixis et ses fonctionnalités ;
Etudier les besoins de monitoring des différentes équipes (Département des risques, équipe support à Lisbonne, Equipes projets à Paris) ;
Etudier les outils similaires déjà utilisés chez Natixis ;
Etudier la faisabilité de certaines solutions de visualisation des données afin de choisir la plus appropriée ;
Designer les écrans de monitoring qui devront être mis en œuvre ;
#FinanceTransformative
En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours.
Vous évoluez dans un environnement de travail inclusif et favorisant le collaboratif qui vous donnera toutes les chances de réussir cette nouvelle mission.
Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise.
Vous bénéficiez d'une indemnité de stage en fonction de votre formation et de votre niveau d'études, également d'un remboursement de votre titre de transport à hauteur de 60 %, d'un jour d'absence autorisé payé pour chaque mois travaillé et de l'accès au restaurant de l'entreprise.




Voir moins","Profil recherché
Étudiant de niveau BAC+5, vous préparez un diplôme d'école d'ingénieur en informatique ou un master 2 universitaire.
Vous êtes curieux et proactif et vous vous challengez constamment et cherchez à toujours développer de nouvelles compétences.
And last but not least, you are perfectly fluent in English.
Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier. Un moment d'échange idéal pour mettre en avant votre personnalité ainsi que votre projet.",2024-01-10,https://www.welcometothejungle.com/fr/companies/natixis/jobs/stage-6-mois-market-risk-it-data-engineer-f-h_paris?q=4312f2244a62de3032cd18401125b56f&o=9f499875-71f1-415d-a3f0-5fe39179bf90,wttj
Data Engineer AWS,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Paris,45K à 60K €,Télétravail fréquent,,,,"Descriptif du poste
Nous recherchons un Data Engineer expérimenté pour rejoindre notre équipe. En tant que Data Engineer, vous serez responsable de la conception, du développement et de la mise en œuvre de pipelines de traitement de données en temps réel à grande échelle. Vous travaillerez avec des technologies telles que Kafka, Flink, Kinesis et vous utiliserez les services du cloud AWS pour stocker et traiter les données.
Vos responsabilités :
Utiliser Kafka pour le traitement de flux de données en temps réel à grande échelle, en travaillant avec les producteurs, les consommateurs et les topics.
Mettre en œuvre des pipelines de traitement de données en streaming avec Flink, en appliquant des transformations complexes et en gérant les états.
Écrire du code efficace et maintenable en Java / Python pour manipuler et analyser les données en temps réel.
Utiliser Kubernetes pour déployer et gérer des applications conteneurisées à grande échelle, en assurant la résilience et l’évolutivité des services.
Utiliser les services AWS tels que Amazon S3, AWS Lambda, Elastic Kubernetes Service (EKS), Elastic Container Service (ECS) et Elastic Compute Cloud (EC2) pour le stockage, le traitement et le calcul des données en temps réel.
Suivre les meilleures pratiques pour une utilisation efficace du cloud, en assurant la gestion des coûts, la sécurité des données et la disponibilité des services.
Collaborer avec l’équipe de développement logiciel et la gestion de projets pour assurer un flux de développement fluide et une livraison efficace des fonctionnalités.
Voir moins","Profil recherché
Formation de niveau Bac +5 en informatique, en data science, ou en statistiques.
Expérience pratique dans le traitement en temps réel avec Kafka, Flink, et les services AWS.
Maîtrise de Java / python et expertise dans l’écriture et l’optimisation du code SQL.
Expérience significative dans un environnement industriel en mode DevOps, avec des outils tels que CICD, gitlab, Jenkins, Sonar, Nexus, XLdeploy, Camunda, etc.",2024-01-09,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/cloud-data-engineer-aws_paris?q=4312f2244a62de3032cd18401125b56f&o=5680f024-9edb-44d7-93e6-b3e9135199a6,wttj
Cloud Data Engineer Azure,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,Boulogne-Billancourt,Non spécifié,Télétravail fréquent,02 janvier 2023,> 6 mois,> Bac +5 / Doctorat,"Descriptif du poste
Nous recrutons un(e) Cloud Data Engineer (H/F) afin de travailler pour un client, acteur majeur du secteur des transports. Vous interviendrez au sein du Département Data Platform (environ 15 Data Engineers et Développeurs).
Vous travaillerez sur la totalité des phases projet :
Proposer des architectures et orienter le choix des technologies adaptées aux besoins de différents projets Data
Concevoir et mettre en œuvre les traitements d’alimentation du DataLake et de transformation des données
Garantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats
Identifier, collecter, explorer, comprendre et intégrer les données nécessaires à la résolution de problématiques métier et opérationnelles
Assurer le suivi de la production
Participer, avec l’équipe, au développement de la plateforme sur Azure et à la définition des bonnes pratiques de développement
Accompagner les équipes métier dans la prise en main de la plateforme Azure et les aider à monter en compétences en programmation en s’assurant du respect des standards internes
Environnement technique : Spark, Python, SQL, Microsoft Azure, DataBricks Docker, Kubernetes, Teradata
Voir moins","Profil recherché
Profil Ingénieur Grande École
Compétences :
Python, SQL
Microsoft Azure (DataFactory, Azure DevOps, Databricks)
Bonnes connaissances sur les architectures de données et le cloud
Connaissance de l’approche DevOps : Git, CI/CD…
Vous avez envie de participer à une mission Data passionnante avec les marqueurs “Qualité de Vie au Travail” (QVT) et “Responsabilité Sociétale et Environnementale” (RSE) au centre de notre stratégie de développement (séminaires, évents fun et pro, partenariat associatif, …).",2024-01-09,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/cloud-data-engineer-azure_boulogne-billancourt?q=4312f2244a62de3032cd18401125b56f&o=2488fa18-a8f6-4728-8a5b-09445d148c9c,wttj
Data Engineer (F/H),"{'name': 'FINAXYS', 'sector': 'Banque, Logiciels, SaaS / Cloud Services, Big Data', 'employees': '400 collaborateurs', 'creation_year': '2008', 'turnover': '40 M€', 'mean_age': '32 ans'}",CDI,Puteaux,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Réaliser des analyses techniques et des études d’impacts en amont des développements
Concevoir et développer des solutions en respectant les bonnes pratiques de développements
Participer à l’amélioration continue de son processus de développement : méthodes, techniques, etc.
Participer à la conception des environnements et des outils nécessaires pour assurer les développements
Assurer le support aux équipes d’homologation lors des phases de recette","Profil recherché
Data Engineer avec une première expérience significative (2 ans minimum)
Capacité d’analyse et de conceptualisation
Esprit de synthèse
Curiosité technologique (Architecture, Big Data, DevOps)",2024-01-09,https://www.welcometothejungle.com/fr/companies/finaxys/jobs/data-engineer-f-h_puteaux?q=4312f2244a62de3032cd18401125b56f&o=c9533aee-9046-4ebe-993f-24b5dfcfe1b2,wttj
Data Engineer - STAGE (F/H),"{'name': 'CARREFOUR', 'sector': 'Grande distribution, E-commerce, Grande consommation', 'employees': '100000 collaborateurs', 'creation_year': '1959', 'turnover': None, 'mean_age': None}","Stage
(1 mois)",Oloron-Sainte-Marie,Non spécifié,Télétravail non autorisé,15 janvier 2024,< 6 mois,Bac +4,"Descriptif du poste
Nous rejoindre, c'est rejoindre l'un des leaders mondiaux de la distribution qui met l'accent au quotidien sur la diversité, la RSE et le digital, pour satisfaire nos clients et nos collaborateurs. En tant que partenaire premium des Jeux Olympiques et Paralympiques de Paris 2024, nous partageons les valeurs du sport en permettant à nos équipes de se dépasser et encourageons une alimentation saine au juste prix pour tous.
Vous cherchez à travailler dans une entreprise dynamique où votre travail rime avec impact social et environnemental ? Bienvenue chez nous !
Porteuse de cette ambition, la Direction Stratégie et Transformation Groupe et France recrute un(e) :
Data Engineer (F/H)- stage
DATE DEBUT STAGE : JANVIER 2024


🎯 Vos Missions
Le stagiaire se verra confier le développement du dashboard v1 afin de :
- Continuer à automatiser et fiabiliser les principaux KPIs
marketing qui alimentent le tableau de bord de suivi.
- Optimiser son fonctionnement et améliorer son interface
utilisateur pour le faire évoluer vers sur une v2
Il travaillera avec les différents pays du groupe afin de 1) récupérer les
données dans un data lake central et de continuer à construire et
2) d'analyser les indicateurs business, media et marketing : ventes, part
de marché, évolution du poids promotionnelle et prix, investissement et
performance média, évolution du nombre de clients, panier moyen,
fréquence d'achat et segments clients prioritaires.


Activité du poste:
- Développer des solutions techniques de collecte de la donnée
(automatisation de la collecte des données)
- Travailler sur les évolutions du dashboard de suivi groupe
- Collaborer avec les différents pays du groupe (8 pays) afin de
récupérer les données et les insérer dans un data lake central et les
updater de manière automatique
- Analyser et interpréter les données récoltées
- Reporter l'activité auprès du chef de projet
Voir moins","Profil recherché
👥 Votre profil
Vous préparez un diplôme d'ingénieurs
Manipulation de bases de données (Google cloud, et datalake de
chaque pays)
- Connaissance des langages de programmation
- Analyse et interprétation de données
- Maîtrise de l'anglais",2024-01-09,https://www.welcometothejungle.com/fr/companies/carrefour/jobs/data-engineer-stage-f-h_massy?q=4312f2244a62de3032cd18401125b56f&o=2df77f13-3dce-4d4f-bd94-6af440b62bf9,wttj
Un(e) assistant(e) Data Engineer/Data Scientist(e),"{'name': 'FRANCE TÉLÉVISIONS PUBLICITÉ', 'sector': 'Média, Télévision / Production audiovisuelle, Publicité', 'employees': '300 collaborateurs', 'creation_year': '1989', 'turnover': '425M€', 'mean_age': '40 ans'}","Alternance
(12 à 24 mois)",Boulogne-Billancourt,Non spécifié,Télétravail fréquent,04 mars 2024,,Bac +3,"Descriptif du poste
L’alternant Data Engineer joue un rôle clé au sein du pôle de data de l’entreprise.
Il est responsable de la collecte, du traitement, du stockage et de la mise à disposition des données pour répondre aux besoins de l’entreprise en matière d’analyse de données. L’alternant Data Engineer travaille en étroite collaboration avec les équipes Data et d’autres équipes pour garantir la qualité et l’intégrité des données
Responsabilités clés :
Collecte de données : Extraire des données à partir de différentes sources, telles que des bases de données, des API, des fichiers CSV, etc.
Transformation des données : Nettoyer, normaliser et transformer les données brutes en un format utilisable pour l’analyse.
Stockage des données : Concevoir et gérer des bases de données pour stocker efficacement les données, en utilisant des technologies telles que SQL, NoSQL ou des solutions de Big Data.
Automatisation des flux de données : Mettre en place des processus d’ETL (Extract, Transform, Load) automatisés pour garantir la mise à jour régulière des données.
  Qualité des données : Mettre en place des mécanismes de validation et de contrôle de la qualité des données pour garantir leur exactitude et leur cohérence.
Sécurité des données : Assurer la sécurité des données en mettant en place des mesures de protection et de conformité avec les réglementations en vigueur.
Documentation : Tenir à jour une documentation complète sur les flux de données, les schémas de bases de données, les procédures, etc.
Analyse de données : Utiliser des techniques statistiques et d’apprentissage automatique pour analyser les données et identifier des tendances, des modèles et des relations.
Modélisation prédictive : Développer des modèles prédictifs et des algorithmes pour résoudre des problèmes d’entreprise, tels que la prévision des inventaires etc.
Évaluation des modèles : Évaluer la performance des modèles et ajuster les paramètres pour améliorer leur précision.
Voir moins","Profil recherché
Formation en informatique, en génie logiciel, en mathématiques, en statistiques ou dans un domaine connexe.
Connaissance des langages de programmation, tels que Python, Java, ou Scala.
Maîtrise des technologies de base de données, telles que SQL, NoSQL, Hadoop, ou Spark.
Compréhension des techniques d’ETL (Extract, Transform, Load) et des outils associés.
Capacité à travailler avec des outils de gestion de version comme Git.
Connaissance des bonnes pratiques en matière de sécurité des données.
Fortes compétences en résolution de problèmes et en communication.
Capacité à travailler en équipe et à apprendre rapidement.
L’alternant Data Engineer joue un rôle essentiel dans la création de bases de données de qualité, essentielles à la prise de décisions basées sur les données au sein de l’entreprise. Il contribue également à l’amélioration des processus et des flux de données, contribuant ainsi à la croissance et au succès de l’entreprise dans l’économie axée sur les données d’aujourd’hui.
Voir plus",2024-01-09,https://www.welcometothejungle.com/fr/companies/francetvpub/jobs/assistant-data-engineer-data-scientist_boulogne-billancourt?q=4312f2244a62de3032cd18401125b56f&o=2667c777-c447-4ad8-a177-de8df8064bc0,wttj
Senior Data engineer F/M,"{'name': 'ACC - AUTOMOTIVE CELLS COMPANY', 'sector': 'Ingénieries Spécialisées, Energie, Automobile', 'employees': '1200 collaborateurs', 'creation_year': '2020', 'turnover': None, 'mean_age': '38 ans'}",CDI,Bruges,Non spécifié,Télétravail total,01 avril 2024,> 5 ans,Bac +5 / Master,"Descriptif du poste
Job description

Data engineers collect, transform and store data using pipelines and storage systems. This involves extracting data from various data source systems, transforming it into the staging area, and loading it into database, data warehouse or datalake systems.
The Data Engineer ensures quantitative and qualitative access to data sources. He/she ensures availability of data and guarantees the quality of its use in-order-to facilitate its exploitation by Data analysts and Data scientists.
His/her scope of intervention is focused on application systems around data management and processing and on Big Data, IoT platforms.

MAIN MISSIONS, OBJECTIVES AND KPIS RELATED
- Analyze and organize raw data
- Build data systems and pipelines
- Evaluate business needs and objectives on data processing
- Conduct report on data pipelines and data consumption
- Prepare data for prescriptive and predictive modeling
- Combine raw information from different sources
- Explore ways to enhance data quality and reliability
- Identify opportunities for data acquisition
- Develop analytical tools and programs
- Collaborate with data scientists and architects on several projects

Voir moins","Profil recherché
EXPERIENCE
5 years of experience as a data engineer or in a similar role
Technical expertise with data models, data mining
Hands-on experience with Cloud Data Platform
Specific knowledge  : SQL database, Data bricks, Architecture médaillon, Node-red, Docker, Apache Airflow, Hive, Spark, Git
QUALIFICATIONS
Degree in Computer Science, IT, or similar field
A Master’s is a plus Data engineering certification (e.g IBM Certified Data Engineer) is a plus

KEY BEHAVIOURS
To succeed in this data engineering position, you should have strong analytical skills and the ability to combine data from different sources.
 
Some extra skills which make the difference
Data engineer skills also include familiarity with several programming languages and knowledge of learning machine methods.
If you are detail-oriented, with excellent organizational skills and experience in this field, we’d like to hear from you.
 Voir plus",2024-01-09,https://www.welcometothejungle.com/fr/companies/acc-automotive-cells-company/jobs/senior-data-engineer-f-m_bruges?q=4312f2244a62de3032cd18401125b56f&o=dade1025-6499-431d-bea4-3dc083291adf,wttj
Data Engineer (H/F) | Stage,"{'name': 'DATASCIENTEST', 'sector': 'SaaS / Cloud Services, EdTech, Formation', 'employees': '130 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}","Stage
(6 mois)",Puteaux,"< 1,5K € par mois",Télétravail occasionnel,01 septembre 2023,,,"Descriptif du poste
Au sein de l’équipe data-science, votre rôle s’articule autour des axes suivants :
Contribution active au développement d’un produit de formation à venir. C’est l’occasion rêvée pour acquérir les compétences de demain… avant tout le monde
Mentorat et accompagnement sur des produits existants
(Si souhaité) Participation à la stratégie R&D du département Tech","Profil recherché
Chez Datascientest, nous valorisons la diversité des profils et sommes convaincus par la force du collectif. Cette offre d’emploi est ouverte à tous, quel que soit votre niveau d’expérience.
Issu(e) d’une formation orientée data-engineering vous êtes :
Capable de gérer des charges de travail parfois élevées.
Bonne maîtrise de Python.
La maîtrise de la programmation orienté objet, de SQL, de technologies NoSQL et/ou du cloud computing est un plus.
La connaissance de Spark, Docker, Git, Airflow ou encore Kubernetes est appréciée
Bonne culture informatique et attrait pour l’actualité relative au data-engineering au sens large.
Bon niveau rédactionnel et oral en français/anglais.
Prêt à énormément apprendre et à vivre une expérience unique dans un environnement start-up.
Attrait pour la polyvalence et capacité à gérer plusieurs projets de front.",2024-01-08,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/data-engineer-h-f-stage_puteaux?q=4312f2244a62de3032cd18401125b56f&o=3eaedd8a-c8c2-4093-9378-47d37efa32f8,wttj
Data Engineer (H/F) | CDI,"{'name': 'DATASCIENTEST', 'sector': 'SaaS / Cloud Services, EdTech, Formation', 'employees': '130 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}",CDI,Puteaux,Non spécifié,Télétravail occasionnel,01 septembre 2023,> 6 mois,Bac +5 / Master,"Descriptif du poste
En tant que Data Engineer, vous maîtrisez les technologies d’acquisition, de traitement, et d’extraction de données et avez des connaisisances scientifiques qui vous permettent de dialoguer avec des équipes Data.
Missions et activités principales :
Création et développement de contenus
Création environnement de formation et contribution au développement de notre plateforme de formation
Accompagnement et mentorat sur des sujet d’engineering
Participation et organisation d’évènements data
Participation à la stratégie R&D du département Tech","Profil recherché
Chez Datascientest, nous valorisons la diversité des profils et sommes convaincus par la force du collectif. Cette offre d’emploi est ouverte à tous, quel que soit votre niveau d’expérience.
Compétences requises :
Excellente maitrise de Python
Bonne maitrise de la programmation orienté objet
La maitrise de Scala (Spark) est un +
Attrait pour l’actualité relative au machine learning, l’engineering et à l’open-source.
Bon niveau en Anglais.
La connaissance d’un provider cloud est très appréciée (AWS, Azure, GCP)
ETL
Bonne connaissance des différents Systèmes de Gestion de Bases de Données
Bonnes connaissances en script Bash
Attrait pour l’actualité relative au machine learning
Outils de mise en production: Docker, Kubernetes, FastAPI, Airflow
Voir plus",2024-01-08,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/data-engineer-h-f-cdi_puteaux_DATAS_ZMLPerq?q=4312f2244a62de3032cd18401125b56f&o=81fff68e-df19-4459-bc12-65247a81fb50,wttj
Stage -Cloud Data Engineer Junior (H/F),"{'name': 'DATASCIENTEST', 'sector': 'SaaS / Cloud Services, EdTech, Formation', 'employees': '130 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '31 ans'}","Stage
(6 mois)",Puteaux,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
Nous proposons un stage passionnant de Cloud Data Engineer Junior spécialisé dans l’écosystème Azure, d’une durée de 6 mois minimum. Ce stage vous permettra de développer vos compétences en Data Engineering sur le cloud tout en étant intégré(e) au sein d’une équipe dynamique et expérimentée. En tant que stagiaire Cloud Data Engineer Junior, vous serez impliqué(e) dans le développement de cours de Cloud Data Engineering sur Azure, ainsi que dans l’animation de travaux dirigés pour promouvoir les technologies du Data Engineer Azure.
Responsabilités principales :
Participer à la création de cours et de supports de formation sur les technologies de Data Engineering sur Azure.
Animer des travaux dirigés et des sessions de formation pour les apprenants afin de promouvoir les compétences en Cloud Data Engineering.
Collaborer avec les Data Scientists et les équipes métiers pour comprendre leurs besoins en matière de données et apporter des solutions appropriées.
Assister le développement et le déploiement de pipelines ETL/ELT performants sur Azure, selon les besoins et les opportunités.
Acquérir une expertise sur les principaux outils de Data Engineering tels qu’Apache Spark, Azure Data Factory, Azure Databricks, etc.
Contribuer à la mise en place de solutions de stockage et de gestion des données en utilisant les services cloud d’Azure.
Participer à l’optimisation des performances et de la scalabilité des pipelines pour traiter de grands volumes de données en temps réel ou en batch.
Assister à la mise en place de mécanismes de contrôle et de validation pour assurer la qualité et la fiabilité des données.
Voir moins","Profil recherché
Formation en informatique, génie logiciel, génie des données ou domaine connexe.
Connaissances en programmation Python pour le développement de scripts et d’automatisations.
Intérêt pour les technologies de Data Engineering et le cloud computing, en particulier sur Azure.
Curiosité et volonté d’apprendre pour développer vos compétences en Data Engineering sur le cloud Azure.
Bonnes compétences en communication, en français et en anglais, pour travailler en équipe et échanger avec des collaborateurs multilingues.
Ce stage vous offrira une expérience pratique précieuse dans le domaine du Cloud Data Engineering sur Azure, avec des opportunités uniques d’implication dans le développement de cours et de travaux dirigés. Vous serez encadré(e) par des experts du domaine, et vos contributions joueront un rôle essentiel dans la réussite des projets de formation sur les technologies du Data Engineer Azure. Vous aurez également la possibilité de vous impliquer dans le développement et le déploiement de pipelines ETL/ELT en fonction des besoins de l’équipe et des projets en cours. Votre motivation, votre implication et votre adaptabilité seront des atouts essentiels pour tirer le meilleur parti de cette opportunité de stage enrichissante.
Voir plus",2024-01-08,https://www.welcometothejungle.com/fr/companies/datascientest/jobs/stage-cloud-data-engineer-junior-h-f_puteaux?q=4312f2244a62de3032cd18401125b56f&o=3749dcc8-e537-4b92-8849-f66e96f614cd,wttj
Data Engineer,"{'name': 'EP STUDIO', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, Incubateur / Accélérateur', 'employees': '45 collaborateurs', 'creation_year': '2007', 'turnover': None, 'mean_age': '33 ans'}",CDI,Nantes,Non spécifié,Télétravail non autorisé,,> 2 ans,,"Descriptif du poste
EP recherche un(e) Data Engineer en CDI !
Notre Pôle Data conçoit, développe et supervise une architecture transverse à nos plateformes, optimisée pour la la collecte, le stockage et le traitement de données. Dans une démarche scientifique, des modèles sont entraînés, permettant de créer des connaissances actionnables que nous mettons à disposition de nos utilisateurs et de nos Produits. Dans le cadre du développement du pôle, nous recherchons aujourd’hui un(e) Data Engineer prêt(e) à rejoindre EP, en CDI, à Nantes.
Votre day-to-day
Rattaché(e) au CDO, au sein d’une équipe Data Engineering, vous travaillez avec nos Data Scientists mais aussi nos DevOps et nos Product Managers, pour réaliser les missions suivantes :
Être le référent technique de l’architecture Data, pour toutes nos plateformes
Contribuer à l’animation technique, la veille technologique et l’innovation de la roadmap Data Engineering.
Concevoir et développer des pipelines scalables de données, pour de l’ingestion ou de la transformation.
Être garant des schémas des bases de données au sein de notre architecture Produit micro-services.
Industrialiser les modèles d’IA développés avec les Data Scientists.
Veiller à l’intégrité et la sécurité des données.
Tester, recetter, rédiger et transmettre de la documentation.
Voir moins","Profil recherché
Vous tel que nous vous imaginons
Vous avez évolué dans un environnement Cloud, idéalement Azure : Data Factory, Databricks, Functions.
Vous maîtrisez au moins l’un des langages de programmation suivants : Python, R, Scala, Spark.
Vous savez requêter dans des bases SQL et NoSQL : SQL Server, PostgreSQL, MongoDB, Elastic.
Vous avez déjà travaillé avec l’une des technologies suivantes : Airflow, Kafka, Salesforce.
Petit plus si vous avez une appétence pour les systèmes d’informations géographiques : QGIS, Geo Server
Votre profil
Vous disposez d’une expérience réussie d’au moins 2 ans en tant que Data Engineer.
Vous aimez travailler en feature team agile, avec une bonne culture du développement, portant attention au code, à la qualité et aux tests.
Voir plus",2024-01-08,https://www.welcometothejungle.com/fr/companies/ep/jobs/data-engineer-junior_nantes?q=4312f2244a62de3032cd18401125b56f&o=9e3edbf2-eba6-440a-a7e9-f48dbc682b8d,wttj
Data Engineer expérimenté,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,,Non spécifié,Télétravail occasionnel,,,,"Descriptif du poste
MP DATA, recrute un Data Engineer afin de travailler pour nos clients au cœur de l’industrie française.
Vos missions seront les suivantes :
Proposer des architectures et orienter le choix des technologies adaptées aux besoins de différents projets Data,
Établir le développement de solutions d’ingestion de données et de Data Ingénierie,
Concevoir et mettre en œuvre les traitements et transformations des données,
Création de pipelines de données, traitement et transformation de la donnée,
Garantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats,
Identifier, collecter, explorer, comprendre et intégrer les données nécessaires à la résolution de problématiques métier et opérationnelles,
Assurer le suivi de la production.","Profil recherché
De formation Bac+5 (ou plus) en développement informatique / Data Engineering, vous justifiez d’une expérience professionnelle significative au cours de laquelle vous avez pu développer les compétences techniques suivantes :
Ecosystème Big Data:
Cloudera
Hadoop
Spark
Kafka
PySpark
Bases de données relationnelles (SQL Server…).
Compétences ou connaissances qui seraient un plus :
Secteur de la métallurgie et de l’environnement (Air, CO2…)
Data visualisation
Talend
Maitrise de l’anglais",2024-01-08,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-experimente_dunkerque?q=4312f2244a62de3032cd18401125b56f&o=9d814094-b3cc-427f-874b-a9d785abde3f,wttj
Data Engineer Expérimenté,"{'name': 'CASTLE BEE - DATA, CLOUD & CYBER FOUNDRY', 'sector': 'Intelligence artificielle / Machine Learning, Big Data, Cybersécurité', 'employees': '25 collaborateurs', 'creation_year': '2021', 'turnover': '1M€', 'mean_age': '27 ans'}",CDI,,45K à 56K €,Télétravail occasionnel,29 janvier 2024,> 2 ans,Bac +5 / Master,"Descriptif du poste
L’environnement data vous anime, vous êtes sensibles par les enjeux de transitions énergétiques et environnementaux ? ce poste est fait pour vous.
Castle Bee recrute un Data Engineer expérimenté pour travailler sur un projet data de forte envergure pour le compte de l’un de nos clients.
Les missions sont les suivantes :
Spécifications techniques de flux de données (ingestion, transformation…)
Développement de solutions d’ingestion de données
Accès aux différentes sources de données et veille sur la qualité des données
Contribution à la mise en place des meilleures pratiques, outils et procédures sur un Cluster Big Data
Accompagné(e) par un programme de formation personnalisée de Castle Bee, vous monterez en compétences sur le management des flux de données et l’industrialisation de vos modèles, et sur les sujets qui vous passionnent le plus.","Profil recherché
Ingénieur d’une grande école (Centrale, Mines, Supaero, Supelec, …), vous êtes expérimenté de deux ans minimum en Data Engineering, notamment sur les technologies suivantes :
Écosystème Big Data
Base de données relationnelles
Spark, Kafka, Pyspark
Talend
Une première expérience en data visualisation serait un plus
Vous êtes autonome, vous vous adaptez rapidement à différents secteurs d’activités et vous communiquez aisément avec les différents interlocuteurs
Vous êtes mobile sur Haut de France
Rencontrons-nous prochainement pour échanger de nos opportunités et vos projets !",2024-01-08,https://www.welcometothejungle.com/fr/companies/castle-bee-data-cloud-cyber-foundry/jobs/data-engineer?q=4312f2244a62de3032cd18401125b56f&o=5b545faf-0c16-405c-b6f9-b0cdd2a00eca,wttj
Senior Data Engineer R&I - L'Oréal France,"{'name': ""L'ORÉAL FRANCE"", 'sector': 'Luxe, Cosmétique, E-commerce', 'employees': '88000 collaborateurs', 'creation_year': '1909', 'turnover': '27,99 Mds €', 'mean_age': None}",CDI,Clichy,Non spécifié,Télétravail fréquent,,> 4 ans,Bac +5 / Master,"Descriptif du poste
As a Senior Data Engineer inside the R&I Beauty Tech Data Team, you will build the end-to-end data integration pipeline from input layer to exposition layer in respecting the best practices. With other members of the team, you guarantee an optimum functioning of the platform by always optimizing the existing and proposing adapted architecture design for the new needs. You will also cooperate with the experts from the Global Beauty Tech Data Team and our partners like Google, Microsoft, Databricks to leverage the most updated knowledge. 
In addition, for a concrete data product development lifecycle, you will be in contact with the delivery team to ensure the delivery roadmap, work with the métier to understand their requirement and support the Data Analyst or Data Scientist for their data consumption. 
IF YOU WANT TO GO FURTHER IN DETAILS, THIS IS WHAT YOU COULD EXPECT TO DO 
Build the data pipeline with existing template to ingest data with the best practices (CI/CD, Code Quality, Test coverage etc.) and monitor the production environment once deployed. 
Design the data modelling and data exposition to use case with Data Architect and ensure the security of data with AmaaS (Access Management As A Service) 
Optimize in continual improvement of the architecture using serverless or managed services on top of Google Cloud Platform 
Participate in the workshops with the different stakeholders: Data Product Owner, Data Analyst, Data Scientist to promote the data usage and to leverage the value of data 
Work in an international environment and cooperate with hubs based in China, US, Brazil, Japan and India 
Pilot the project implementation with externals resources: contractor, nearshore outsourcing 
Aware of new technology innovation and realize them with the PoC project.
Voir moins","Profil recherché
First and foremost, we love people that are curious, collaborative, eager to have an impact and who value innovation, autonomy, and team spirit. 
Requirements: 
4+ years IT technical experience in Data Engineering or Software Engineering with a first experience in architecture design in Cloud environment GCP 
Experience designing data models and data warehouses and using SQL and NoSQL database management systems 
Good Experience with one general purpose programming language (e.g., Python, Java, C#, TypeScript, etc) and success in implementing applications or APIs 
Good understanding of the DevSecOPS
Ability to communicate with both technical and non-technical audiences. 
Curiosity to new technologies with good ability to learn quickly 
Good resilience to face the challenge and resolve the difficulty 
Engineer’s degree (Bac+5) or equivalent  
Verbal and written communications skills (French and English) 
Voir plus",2024-01-06,https://www.welcometothejungle.com/fr/companies/l-oreal/jobs/senior-data-engineer-r-i-l-oreal-france_clichy?q=4312f2244a62de3032cd18401125b56f&o=0ed794e7-0e95-4996-b679-9bd089c206b7,wttj
Data Engineer - Madonne Core (H/F),"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards € de PNB', 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous rejoignez l'équipe Core en charge de la maintenance évolutive des applications Madonne (Récolte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiée au coeur de l'IT Risque).

Au quotidien vous avez pour missions de :

Participer à l'adaptation de nos applications en adéquation avec les besoins métiers (nouveaux produits, nouvelles règlementations, nouveaux SI Front) ;
Participer activement à la modernisation de nos outils, modernisation de notre chaîne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;
Monter en compétences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous développerez une compréhension globale des chaînes de traitements ;
Participer à tous les travaux de modernisation de notre SI, et être donc engagé dans la migration de nombreux process vers le DataLake Risk.





#TransformativeFinance
Ce poste est basé à Paris avec la possibilité de télétravailler.
En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours.
Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.
Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise.
A propos du processus de recrutement
Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier).
Voir moins","Profil recherché
Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : Vous souhaitez bénéficier d'une première expérience significative en développement Spark et Scala. Vous maitrisez : * Les méthodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appétence pour la manipulation de la data. Vous êtes : * Reconnu par votre esprit d'équipe ; * Capable de communiquer avec des publics différents, notamment avec le métier ; * Autonome et ntéressé par l'environnement finance de marché. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous êtes intéressé en répondant à cette annonce.",2024-01-04,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-madonne-core-h-f_paris_NATIX_22ygGpM?q=4312f2244a62de3032cd18401125b56f&o=9d88976b-4324-4030-82f6-cd712acada51,wttj
Lead Data Engineer - F/H,"{'name': 'NIJI', 'sector': 'IT / Digital', 'employees': '1000 collaborateurs', 'creation_year': '2001', 'turnover': '98 millions', 'mean_age': None}",CDI,Lyon,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Nous sommes plus qu’un simple cabinet de conseil, qu'une agence de design et qu'une société de mise en œuvre technologique. Nous sommes le partenaire de la transformation digitale de nos clients grands-comptes et ETI, que nous accompagnons de l’idée à la réalité.
Nous associons, dans une même chaîne de valeur, conseil en stratégie, design de service et design émotionnel, management et valorisation de la donnée, ingénierie et conseil technologique, réalisation logicielle et expertise en cybersécurité.
Notre singularité repose sur les talents pluriels de nos équipes, au service de la satisfaction et de la performance de nos clients.
Le pôle Data de Niji c'est avant tout une équipe à taille humaine et pluridisciplinaire, composée de consultants et experts qui conseillent et appuient nos clients sur toutes les étapes du cycle des données :
de la collecte à la valorisation dans des services innovants,
en passant par les architectures de stockage et de services.
Nos consultants sont basés en Ile-de-France et en régions (Nantes, Rennes, Lille, Lyon et Bordeaux).
Nos 3 directeurs : experts confirmés de la gouvernance des données, de la data science de l'IA et des méthodologies d'industrialisation de l'IA (MLOps, DataOps), recherchent de nouveaux talents tous complémentaires avec plusieurs niveaux de qualification et séniorité, qui travailleront en synergie avec la large palette de compétences de Niji en développement, communication, cybersécurité et en conseil.
Intégrer le Pôle Data de Niji c'est avoir l'assurance d'être accompagné dans sa progression et le développement rapide de ses compétences ,vous suivez un parcours de formation riche et diversifié, visant à vous faire rapidement monter en expertise et à vous certifier. 
En tant que Data Engineer, vos principales missions seront les suivantes :
Concevoir, développer et maintenir une architecture de données robuste, évolutive et sécurisée, en tenant compte des besoins spécifiques des clients.
Participer activement à la rédaction de propositions commerciales, en contribuant aux aspects techniques (outils, make or buy …) et en fournissant des estimations de projet.
Gérer et optimiser les pipelines de données, en assurant la collecte, le stockage, le traitement et la mise à disposition des données de manière fiable et performante.
Assurer la qualité des données en mettant en place des contrôles de qualité, des tests et des processus de validation, conformément aux exigences des clients.
Encadrer les projets de bout en bout, en veillant à ce qu'ils soient livrés à temps, dans les limites du budget afin d’assurer la satisfaction des clients.
Assurer la documentation technique, les bonnes pratiques et les standards de développement au sein de l'équipe.

 Profil recherché
Si vous :
Avez obtenu un diplôme en université, école de commerce ou équivalent type bac +5
Maîtrisez l'anglais à l'écrit comme à l'oral
Avez de solides connaissances en architecture et en modélisation des données
Maîtrisez des technologies et des outils liés au Big Data (Hadoop, Spark, Hive, etc.)
Maîtrisez les outils d’industrialisation des pipelines data tel que docker, kubernetes, Dataiku, Jenkins…
Avez une expérience avec les langages de programmation utilisés dans le domaine des données, tels que : Python,R, Scala, SQL, etc.
Avez une expérience dans la conception et la mise en œuvre de pipelines de données
Avez des compétences en gestion d'équipe et en leadership technique
Avez des capacités à rédiger des propositions commerciales convaincantes
Alors… Venez participer au dynamisme de notre site en rejoignant notre Team Data Lyonnaise !

L'aventure Niji :
Process de recrutement : premier contact RH puis rencontre avec nos opérationnels.
Rejoindre l'expérience Niji c'est avoir l'assurance de participer à une aventure humaine dans un environnement de travail motivant, challengeant et innovant.
NijiU: notre plateforme de formation digital learning contenant près de 3 000 modules en accès libre.
Nos valeurs : Audace - Bienveillance - Performance – Talent. 
Si ces mots vous parlent, venez faire la différence chez Niji !
En rejoignant Niji, vous intégrez une entreprise dont la politique RSE contribue à la promotion de la diversité et de l’égalité des chances, notamment pour les personnes en situation de handicap.
Voir moins",,2024-01-04,https://www.welcometothejungle.com/fr/companies/niji/jobs/lead-data-engineer-f-h_lyon?q=4312f2244a62de3032cd18401125b56f&o=fedd0d8a-579a-4743-89c7-a61baf8ce1d2,wttj
DATA ENGINEER (F/H),"{'name': 'RS2I', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '160 collaborateurs', 'creation_year': '1992', 'turnover': '23 millions €', 'mean_age': '33 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Nous recrutons un Consultant Data / Data Engineer qui évoluera au sein d’un environnement Data & Analytics, d’une culture DevOps et des contextes fonctionnant en mode Agile.
En tant que Consultant Data, vous intervenez sur des problématiques métiers autour de la gestion des données. En collaboration avec les architectes data, les data analysts, les teams DevSecOps, infra et cloud, vous serez amené à mettre en place des solutions et des plateformes data (datahub, datalake, streaming platform, event-driven pipeline, …), développer, déployer et maintenir des chaines de transformations data.
La règle d’or : collecte et intégration, stockage, traitement et stockage, mise à disposition pour analyse et reporting.
Vous maitrisez java, python et/ou scala et avez une expérience significative sur un projet data. Véritable adepte des pratiques devops et cloud, la maitrise de kafka serait un atout.","Profil recherché
BAC+5 de type Ecole d’Ingénieur ou Universitaire,
De nature curieuse avec une soif d’apprendre,
Capacité à s’adapter et à travailler en équipe,
Bonne aisance technique et relationnelle,
Etre force de proposition de solutions techniquement innovantes et fiables.",2024-01-04,https://www.welcometothejungle.com/fr/companies/rs2i/jobs/data-engineer-f-h_levallois-perret_RS2I_lOd847N?q=4312f2244a62de3032cd18401125b56f&o=74fe298b-825b-4948-9905-e71b3fc54aa0,wttj
Data Engineer (H/F),"{'name': 'POSITIVE THINKING COMPANY', 'sector': 'Logiciels, IT / Digital, SaaS / Cloud Services', 'employees': '490 collaborateurs', 'creation_year': '2014', 'turnover': None, 'mean_age': '33 ans'}",CDI,Lyon,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
En tant que Data Engineer de 3 ans d’expérience significative, passionné par l’ingénierie des données et possédant une solide expérience en conception, développement et maintenance de pipelines de données robustes et évolutifs, tu participeras à un ou plusieurs projets pour nos clients et à toutes les phases de mise en œuvre d’un projet DATA.
Nous cherchons quelqu’un qui a des compétences techniques solides dans les domaines suivants :
Conception et développement de solutions de stockage de données, telles que des data warehouses et des data lakes
Mise en place de flux de travail pour l’extraction, la transformation et le chargement de données (ETL)
Maîtrise d’au moins un langage de programmation couramment utilisé dans l’ingénierie des données, tels que Python ou Scala
Connaissance de l’utilisation de technologies de traitement de données distribuées, telles que Hadoop, Spark
Compréhension des principes fondamentaux des bases de données relationnelles et non relationnelles
Capacité à travailler avec des outils d’automatisation et de gestion de code, tels que Git, Jenkins ou Ansible
Veiller à ce que les pipelines de données déployés soient sécurisés et clairs pour être analysés et transformés
💡 Tu travailleras au sein d’une équipe 100% agile
🤝 Tu auras l’occasion de collaborer sur des projets te permettant d’évoluer sur les bonnes pratiques. L’opportunité, pour toi, d’évoluer dans divers secteurs d’activité comme dans les milieux des médias, de l’énergie, du luxe, ect.
Voir moins","Profil recherché
Tu es issu(e) d’une formation d’ingénieur en Informatique Grandes Ecoles, ou troisième cycle universitaire – niveau Master 2 (Bac +5), ou Licence/Bac+2
Tu es un(e) passionné(e) des technologies web et architectures orientées services, aux processus d’intégration continue et de déploiement continu, et bien sûr de la big data,
Tu as une expérience réussie de plus de 3 ans,
Tu as un état d’esprit collaboratif et travailler en équipe est essentiel pour toi,
Tu es à l’aise en communication pour t’exprimer en français et tu disposes d’un niveau B2 en anglais minimum.",2024-01-03,https://www.welcometothejungle.com/fr/companies/positivethinkingcompany/jobs/data-engineer-h-f_lyon_PTC_yR8dVKb?q=4312f2244a62de3032cd18401125b56f&o=25886c68-c415-46a3-8fc0-2082caf31ba4,wttj
Senior Data Engineer (H/F),"{'name': 'RELEVANC', 'sector': 'SaaS / Cloud Services, Digital, AdTech / MarTech', 'employees': '150 collaborateurs', 'creation_year': '2017', 'turnover': None, 'mean_age': '30 ans'}",CDI,Paris,60K à 70K €,Télétravail occasionnel,,> 5 ans,Bac +5 / Master,"Descriptif du poste
En tant que Data Engineer tu auras accès aux données de nos clients internes (enseignes du groupe Casino) et externes à traiter au sein de notre data warehouse. Tes missions seront les suivantes :
travailler en étroite collaboration avec tous les autres membres de la squad
écrire / relire du code en respectant les bonnes pratiques de développement ainsi que les tests unitaires et participer
assurer la co-responsabilité du déroulement des déploiements, des mises en production et du bon fonctionnement des applications avec les autres membres de la squad
rédiger la documentation technique quand cela est nécessaire
mettre en œuvre les bonnes pratiques relatives au RGPD telles que définies par le tech lead
Ce CDI basé à Paris centre (1er arrondissement) débutera dès que possible.
Faire partie de relevanC, qu’est-ce que ça signifie ?
Travailler sur une stack technologique de pointe (Python, PySpark, Google BigQuery, Apache, Airflow…)
Être membre à part entière d’une équipe dynamique et passionnée aux profils très variés (chefs de projets, développeurs, designers, animations commerciales)
Travailler dans un environnement stimulant et relever des nouveaux défis chaque jour
Rejoindre une entreprise en pleine expansion avec des opportunités fortes de développements et d’innovation
Voir moins","Profil recherché
Diplômé(e) d’une grande école d’ingénieur ou profil universitaire spécialisé en Data / Informatique / Math / Stats.
5 ans (et plus) d’expérience en Data Engineering
Appétence forte pour le marketing digital et le retail, force de proposition, business oriented et moteur d’innovation
Une maitrise parfaites des bonnes pratiques de développement
Solides compétences en Python, Spark et SQL
Une expérience sur Google Cloud Platform est un plus",2024-01-02,https://www.welcometothejungle.com/fr/companies/relevan/jobs/head-of-data-engineering-lead-data-engineer_paris?q=4312f2244a62de3032cd18401125b56f&o=f4685cd6-af24-4e79-a744-f006883d0af4,wttj
Data Engineer (H/F) « Empreinte biodiversité »,"{'name': 'CDC BIODIVERSITÉ', 'sector': 'Environnement / Développement durable, Stratégie, Finance', 'employees': '82 collaborateurs', 'creation_year': '2008', 'turnover': None, 'mean_age': '35 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,08 janvier 2024,> 3 ans,,"Descriptif du poste
CONTEXTE
CDC Biodiversité recrute aujourd’hui un Ingénieur DevOps (H/F) pour contribuer au développement méthodologique du Global Biodiversity Score (GBS), un outil de mesure d’empreinte biodiversité.
Dans le cadre de sa mission de recherche et d’innovation, CDC Biodiversité a lancé en 2016 le projet Global Biodiversity Score (GBS), qui visait à construire un outil de mesure de l’empreinte biodiversité des entreprises. Depuis 2021, la Direction Mesure d’empreinte de CDC Biodiversité regroupe six pôles qui assurent le déploiement du GBS et l’accompagnement des acteurs économiques sur l’ensemble des questions relatives à l’empreinte biodiversité : Club des entreprises et institutions financières pour une biodiversité positive (Club B4B+), finance, Biodiversity Footprint Assessment (BFA), collectivités, formation et développement méthodologique.
La période actuelle est charnière pour la biodiversité avec l’émergence de nombreux cadres et initiatives : COP15, Taskforce on Nature-related Financial Disclosure (TNFD), révision du standard biodiversité de la Global Reporting Initiative (GRI), standard biodiversité européen pour la Corporate Sustainability Reporting Directive (CSRD), etc. L’équipe du département, constituée d’une vingtaine de personnes et en forte croissance, contribue à l’ensemble de ces initiatives et accompagne les acteurs économiques pour s’aligner avec les limites planétaires biodiversité.
En mai 2020, la première version de l’outil de mesure d’empreinte biodiversité des entreprises et institutions financières, le Global Biodiversity Score, est lancée. L’outil est à présent utilisé par une communauté d’entreprises, d’institutions financières, de consultants et de chercheurs. Le GBS est en constant développement et fonctionne à l’heure actuelle sur RStudio.
MISSIONS CONFIÉES
Sous la responsabilité de la cheffe du pôle Développement et méthodologie au sein de la Direction Mesure d’Empreinte, le Data Engineer (H/F) contribuera aux travaux de l’équipe pour mettre en œuvre les tâches suivantes :
Développer l’outil GBS
a)       Implémenter les développements méthodologiques dans le code
Créer et maintenir le code back-end (packages R) ;
Effectuer la revue du code et améliorer le processus de test ;
Assurer le versionning (GitHub) ;
Améliorer l’architecture et le pipeline des données en vue des évolutions de l’outil (compatibilité avec les standards de reporting émergents) ;
Améliorer les data visualisations de l’outil et participer à l’amélioration de l’interface utilisateur.
b)      Contribuer aux méthodologies d’empreinte biodiversité
Participer à la veille continue sur les données et modèles disponibles ;
Participer aux réflexions méthodologiques (e.g. sur l’impact de la production minière ou du tourisme sur la biodiversité, impacts sur la biodiversité marine, etc.)
Assurer le support technique externe et interne
Traiter les tickets des utilisateurs du GBS et participer aux webinaires ou réunions de support technique ;
Appuyer les développements techniques des autres pôles du GBS (entreprises, institutions financières et collectivités) ;
Partager les bonnes pratiques code au sein de la communauté de développeurs.
Contribuer au fonctionnement du pôle Développement et méthodologie
Encadrer des stages sur le développement de l’outil ;
Co-construire la stratégie du pôle Développement et améliorer en continu le workflow du développement
La liste des tâches n’étant pas exhaustive, le Data Engineer (H/F) pourra se voir confier d’autres tâches suivant les besoins.
POURQUOI NOUS REJOINDRE ?
Être au cœur d‘un projet à impact positif sur la biodiversité à l’heure de plusieurs grands rendez-vous internationaux sur le sujet ;
Prendre part directement au développement de l’empreinte des entreprises sur la biodiversité, au sein d’une équipe jeune, dynamique, engagée et experte ;
Être pionnier dans la recherche sur la mesure d’empreinte biodiversité et sa mise en œuvre dans un outil d’évaluation de l’impact sur la biodiversité.
Une formation de 3 jours au GBS sera fournie à le Data Engineer (H/F) mais aussi des formations relatives aux compétences requises pour le poste (e.g. Datacamp pour R).
Voir moins","Profil recherché
Vous avez au moins 3 ans d’expérience en développement d’outils et/ou data sciences ;
Vous êtes diplômé(e) Bac + 5 dans les domaines de data science, et/ou applications et services web ;
Vous avez des connaissances en R, python (jupyter notebook) ou SQL. Des expériences en code collaboratif, versionning, architecture des données, tests et revue de code, analyse de données (packages tidyverse, RMarkdown), création de package, Systèmes d’Information Géographique (SIG – terra, sf), data visualization (shiny, ggplot, plotly), et méthode Agile seront appréciées ;
Vous avez des connaissances ou une appétence pour les enjeux environnementaux et la biodiversité ;
Vous maîtrisez la suite Office (Word, Excel et Power Point) ;
Votre niveau d’anglais est courant (C1 sur l’échelle européenne CECRL) ;
Vous êtes apprécié(e) pour vos excellentes capacités d’analyse, rigueur, autonomie, votre sens de l’innovation et de travail en équipe.",2024-01-02,https://www.welcometothejungle.com/fr/companies/cdc-biodiversite/jobs/ingenieur-devops-h-f-empreinte-biodiversite-methodologie-et-evaluation-des-entreprises_paris?q=4312f2244a62de3032cd18401125b56f&o=898ee0be-4ec2-4a14-9cce-de7d21943e44,wttj
Stage Data-engineer / data-science,"{'name': 'NETDEVICES', 'sector': 'Application mobile, Intelligence artificielle / Machine Learning, Big Data', 'employees': '15 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': '29 ans'}","Stage
(6 mois)",Paris,Non spécifié,Télétravail total,01 janvier 2023,,Bac +5 / Master,"Descriptif du poste
Au sein de l’équipe de R&D de Data4Risk, vous interviendrez sur la conception et le développement de la partie Big Data de nos solutions.
Vous travaillerez sur la modélisation de systèmes d’alertes et d’analyse de risques
Vous serez rattaché(e) au directeur technique dans une équipe au total de 15 personnes.
Rémunération selon profil","Profil recherché
• Ingénieur ou docteur en informatique et/ou en statistique
• Analyse de données, apprentissage automatique et modélisation probabiliste
• ML computer vision ou NLP
• Bases de données
• Scripting/prototypage rapide",2023-12-21,https://www.welcometothejungle.com/fr/companies/netdevices/jobs/stage-data-scientist-pre-embauche_paris?q=4312f2244a62de3032cd18401125b56f&o=ab793b5e-40f9-484e-9084-1423a2ad64cb,wttj
Data Engineer,"{'name': 'BIAL-X', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '72 collaborateurs', 'creation_year': '2007', 'turnover': '8 millions €', 'mean_age': '37 ans'}",CDI,,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous serez amené(e) à vous impliquer sur l’ensemble de la chaine de valorisation des données depuis leur collecte en mode batch ou via une speed layer, leur stockage dans des datalakes leur transformation et leur structuration dans des environnements décisionnels ou leur mise à disposition en vue d’analyses propres à la data science. Vous interviendrez dans différents types d’environnements : Modern Data Platforms, OnPremise ou hybride. Vos savoir-faire et savoir-être feront la différence.
Vos missions seront de différentes natures : audit, conseil, expertise ponctuelle, avant-vente, projet de mise en œuvre.
Vous pourrez intervenir dans toutes les phases des projets, réaliser des chiffrages, animer des ateliers avec les utilisateurs, définir des architectures, modéliser, concevoir des environnements (Datalake, Datalakehouse et Datamart), spécifier et mettre en place des flux ETL/ELT, réaliser des pipelines.
Pour développer et partager vos compétences, vous serez amené(e) à suivre des formations puis à passer des certifications qualifiantes prises en charge par l’entreprise. Vous contribuerez activement au centre d’expertise qui vous permettra de développer votre cœur de compétences, mais également de vous ouvrir sur d’autres domaines.
Vous pourrez aussi coacher et encadrer des consultants plus juniors.
Voir moins","Profil recherché
Conception et réalisation de visualisations et tableaux de bords (PowerBI, Tableau, QlikSense)
De formation Bac+5 en informatique, vous justifiez d’au moins 3 années d’expériences dans un poste similaire.
Compétences techniques requises
Maîtrise du SQL
Maîtrise des principes de modélisation décisionnelle
Maîtrise du cycle de valorisation de la donnée (expériences avérées exigées)
Maîtrise d’une technologie ETL/ELT : Talend, Azure Datafactory, Databricks, PDI…
Maîtrise d’une base de données (SQL Server, Snowflake,..)
Connaissance d’une Modern Data Plateform : AZURE, AWS…
Compétences techniques appréciées
Connaissance d’une solution de Dataviz : Power BI / Tableau Software / QlikSense
Connaissance de Python
Voir plus",2023-12-20,https://www.welcometothejungle.com/fr/companies/bial-x/jobs/data-engineering_BIALX_wJlwbe1?q=4312f2244a62de3032cd18401125b56f&o=7c88257a-109e-49ac-a206-983120a9a004,wttj
STAGIAIRE DATA ENGINEER SNOWFLAKE (H/F),"{'name': 'HARDIS GROUP', 'sector': 'IT / Digital, Supply Chain, SaaS / Cloud Services', 'employees': '1500 collaborateurs', 'creation_year': '1984', 'turnover': ""156 millions d'euros en 2022"", 'mean_age': '38 ans'}","Stage
(6 mois)",Puteaux,Non spécifié,Télétravail occasionnel,,< 6 mois,Bac +5 / Master,"Descriptif du poste
En tant que Data Engineer SNOWFLAKE, nous vous proposons de participer à nos projets CLOUD en utilisant cette Data Platform.
Avec l’appui de l’un de nos architectes Data, vous validez les choix technologiques appropriés au besoin du projet et les orientations à suivre. Les validations se font en mode « POC » sous le contrôle de notre comité d’architectes et notre CTO.
Vos missions sont :
Vous souhaitez appréhender un projet concret et implémenter la plateforme SNOWFLAKE pour valoriser sa donnée.
- Vous avez eu une première approche sur les services Data d’un Cloud Provider
- Vous avez des connaissances en conception et mise en place d’ingestions et transformation de données
- Vous avez des connaissances en Modélisation de données : Star Schéma, DataVault, DataMesh, Virtualisation
- Vous avez des connaissances et utilisez les différentes solutions de stockage (SQL, NoSQL,…).
- Vous avec des connaissances sur les principes du développement Cloud
Technos utilisées :
- SNOWFLAKE
- GCP,
- Snowpipe, Kafka
- SQL, Python, Java, Scala
Voir moins","Profil recherché
En formation de niveau Bac+5 en Ecole d’Ingénieurs, vous recherchez votre stage de fin d’études. 
Les plus du stage :
- Solutions innovantes
- Equipe à la pointe technologiquement
- Liberté totale sur le choix des technologies pour la réalisation
- Stage de pré-embauche",2023-12-20,https://www.welcometothejungle.com/fr/companies/hardis-group/jobs/stagiaire-data-engineer-snowflake-h-f_puteaux?q=4312f2244a62de3032cd18401125b56f&o=e4e243c6-aef4-4751-90ca-96e87b40607a,wttj
STAGIAIRE DATA ENGINEER GCP (H/F),"{'name': 'HARDIS GROUP', 'sector': 'IT / Digital, Supply Chain, SaaS / Cloud Services', 'employees': '1500 collaborateurs', 'creation_year': '1984', 'turnover': ""156 millions d'euros en 2022"", 'mean_age': '38 ans'}","Stage
(6 mois)",Puteaux,Non spécifié,Télétravail occasionnel,,< 6 mois,Bac +5 / Master,"Descriptif du poste
En tant que Data Engineer GCP , nous vous proposons de participer à nos projets CLOUD utilisant les services DATA de Google Cloud Platform (Cloud Storage, Dataflow, Big Query, Cloud Functions, Looker Studio,…)
Avec l’appui de l’un de nos architectes Data, vous validez les choix technologiques appropriés au besoin du projet et les orientations à suivre. Les validations se font en mode « POC » sous le contrôle de notre comité d’architectes et notre CTO.
Vos missions sont :
Vous souhaitez appréhender un projet concret et implémenter une plateforme pour valoriser sa donnée.
- Vous avez eu une première approche sur les services Data d’un Cloud Provider
- Vous avez des connaissances des langages suivants  : Python, Java, JavaScript
- Vous avez connaissance d’un Framework de calculs distribué (Spark, Beam, …)
- Vous avez des connaissances et utilisez les différentes solutions de stockage (SQL, NoSQL, Search Engine…)
- Vous avec des connaissances les principes du développement Cloud
- Vous avez des connaissances en Machine Learning
Technos utilisées :
GCP
Python,
Spark, Beam,
Kafka, Airflow, ELK
Java
JavaScript
Voir moins","Profil recherché
De formation Bac+5 en Ecole d’Ingénieurs, vous recherchez un stage de fin d’études. 
Les plus du stage :
- Solutions innovantes
- Equipe à la pointe technologiquement
- Liberté totale sur le choix des technologies pour la réalisation
- Stage de pré-embauche",2023-12-20,https://www.welcometothejungle.com/fr/companies/hardis-group/jobs/stagiaire-data-engineer-gcp-h-f_puteaux?q=4312f2244a62de3032cd18401125b56f&o=a4fdfce7-4169-4fe4-8e24-ee2e036eb79d,wttj
STAGIAIRE DATA ENGINEER ETL/ELT (H/F),"{'name': 'HARDIS GROUP', 'sector': 'IT / Digital, Supply Chain, SaaS / Cloud Services', 'employees': '1500 collaborateurs', 'creation_year': '1984', 'turnover': ""156 millions d'euros en 2022"", 'mean_age': '38 ans'}","Stage
(6 mois)",Puteaux,Non spécifié,Télétravail occasionnel,,< 6 mois,Bac +5 / Master,"Descriptif du poste
En tant que Data Engineer ETL/ELT, nous vous proposons de participer à nos projets CLOUD en utilisant GCP et TALEND.
Avec l’appui de l’un de nos architectes Data, vous validez les choix technologiques appropriés au besoin du projet et les orientations à suivre. Les validations se font en mode « POC » sous le contrôle de notre comité d’architectes et notre CTO.
Vos missions sont :
Vous souhaitez appréhender un projet concret et implémenter la plateforme GCP et TALEND pour valoriser sa donnée.
- Vous avez eu une première approche sur les services Data d’un Cloud Provider.
- Vous avez des connaissances en conception et mise en place d’ingestions et transformation de données
- Vous avez des connaissances et utilisez les différentes solutions de stockage (SQL, NoSQL,…).
- Vous avec des connaissances sur les principes du développement Cloud.
Technos utilisées :
- GCP,
-TALEND,
- SQL, Python, Java, Scala
Voir moins","Profil recherché
De formation Bac+5 en Ecole d’Ingénieurs, vous recherchez votre stage de fin d’études. 
Les plus du stage :
- Solutions innovantes
- Equipe à la pointe technologiquement
- Liberté totale sur le choix des technologies pour la réalisation
- Stage de pré-embauche",2023-12-20,https://www.welcometothejungle.com/fr/companies/hardis-group/jobs/stagiaire-data-engineer-etl-elt-h-f_puteaux?q=869a38b87064c2fba5413f455cbe1d45&o=b49d5aad-182d-44a5-bbad-4c28547f0917,wttj
STAGIAIRE DATA ENGINEER ETL/ELT (H/F),"{'name': 'HARDIS GROUP', 'sector': 'IT / Digital, Supply Chain, SaaS / Cloud Services', 'employees': '1500 collaborateurs', 'creation_year': '1984', 'turnover': ""156 millions d'euros en 2022"", 'mean_age': '38 ans'}","Stage
(6 mois)",Puteaux,Non spécifié,Télétravail occasionnel,,< 6 mois,Bac +5 / Master,"Descriptif du poste
En tant que Data Engineer ETL/ELT, nous vous proposons de participer à nos projets CLOUD en utilisant GCP et TALEND.
Avec l’appui de l’un de nos architectes Data, vous validez les choix technologiques appropriés au besoin du projet et les orientations à suivre. Les validations se font en mode « POC » sous le contrôle de notre comité d’architectes et notre CTO.
Vos missions sont :
Vous souhaitez appréhender un projet concret et implémenter la plateforme GCP et TALEND pour valoriser sa donnée.
- Vous avez eu une première approche sur les services Data d’un Cloud Provider.
- Vous avez des connaissances en conception et mise en place d’ingestions et transformation de données
- Vous avez des connaissances et utilisez les différentes solutions de stockage (SQL, NoSQL,…).
- Vous avec des connaissances sur les principes du développement Cloud.
Technos utilisées :
- GCP,
-TALEND,
- SQL, Python, Java, Scala
Voir moins","Profil recherché
De formation Bac+5 en Ecole d’Ingénieurs, vous recherchez votre stage de fin d’études. 
Les plus du stage :
- Solutions innovantes
- Equipe à la pointe technologiquement
- Liberté totale sur le choix des technologies pour la réalisation
- Stage de pré-embauche",2023-12-20,https://www.welcometothejungle.com/fr/companies/hardis-group/jobs/stagiaire-data-engineer-etl-elt-h-f_puteaux_HG_8pOqrJ8?q=869a38b87064c2fba5413f455cbe1d45&o=4323dd2e-c0b4-448b-b8f9-4b535cee208e,wttj
Senior Data Engineer e-santé dans l'une de nos startups partenaire,"{'name': 'MY MAJOR', 'sector': 'Santé, Média, Recrutement', 'employees': '14 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '26 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
La startup
Notre partenaire a créé une plateforme communautaire permettant à chacun de trouver le praticien qui lui correspond grâce aux données et recommandations des autres utilisateurs.
Avec cette plateforme :
👋 Bye bye l’angoisse de devoir choisir un praticien au hasard et de se rendre compte après coup pourquoi son agenda était si peu rempli !
✌️ Hello l’entraide et les réponses personnalisées à chaque situation (médecin qui part à la retraite, déménagement nécessitant de se refaire un carnet d’adresse, urgence en vacances, etc.)
Avec plus de 1 million de membres dans la communauté et une croissance mensuelle moyenne de 20%, ils sont à la recherche d’un Data Analyst pour les accompagner dans leur développement.
Le poste et ses missions
Amélioration et optimisation de la base de données (20 millions de données)
Identification des incohérences
Mise en place de routines de cleaning
Intelligence autour de la donnée
Réflexion et amélioration des scripts et algorithmes
Création et amélioration de parcours personnalisés
Concevoir et mettre en place des tableaux de bord pour suivre les indicateurs clés de performance
Voir moins","Profil recherché
Minimum 5 ans d’expérience
Bonne connaissance de Python, SQL (Maria DB), Elasticsearch et Docker
En mesure de convertir une problématique business en question technique et de vulgariser son approche en interne
Autonomie, pro-activité, curiosité
Bonus : expérience dans le secteur de la santé
Les conditions de travail
Poste basé à Paris
Mode de travail hybride, présentiel et télétravailMin",2023-12-15,https://www.welcometothejungle.com/fr/companies/my-major/jobs/data-analyst-e-sante-cdi_paris?q=869a38b87064c2fba5413f455cbe1d45&o=7f1a5b2d-9e1e-43f9-82f7-4c298271488b,wttj
Finance Data Engineer,"{'name': 'WEEFIN', 'sector': 'Stratégie, Transformation, FinTech / InsurTech', 'employees': '42 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '29 ans'}",CDI,Paris,Non spécifié,Télétravail total,,,,"Descriptif du poste
ESG Connect a pour vocation de faciliter la validation, l’exploitation et l’enrichissement des données fournisseurs dans le contexte particulier de chacun de nos clients ; la donnée est donc au cœur des problématiques adressées par l’équipe Tech de WeeFin.
Cela conduit notre équipe de développeurs à mettre en place des pipelines data, des mécanismes de notification, et des features permettant d’encadrer les processus ESG.
Les challenges de l’équipe Tech :
Normaliser les données provenant des différents fournisseurs
Proposer des moyens innovants de présenter la donnée normalisée, sa qualité et l’intégration de ces informations dans des calculs à disposition des différents métiers gravitant autour du produit
Gérer la donnée et les résultats dans le temps pour satisfaire des besoins de simulation, d’audit…
Au sein de l’équipe Tech, les responsabilités du pôle Implémentation :
Intégrer les données des clients et providers dans ESG Connect et garantir leur fiabilité
Optimiser la structuration de ces données
Les enjeux du poste
Le.la futur.e Finance Data Engineer viendra renforcer le pôle Implémentation dans un contexte de fort développement, avec un nombre grandissant de demandes et dans une démarche de renforcement des process.
Les interlocuteurs principaux
L’équipe DevOps
L’équipe Produit
L’équipe Customer Success
L’équipe R&D
Les missions
Au sein du pôle Implémentation de l’équipe Tech, et rattaché.e directement au Lead Implémentation, le.la futur.e Data Engineer aura les missions suivantes :
1 - Intégrer les données de différentes sources vers des formats normalisés sur ESG Connect
Analyser, traiter, reformater la data à intégrer dans la plateforme
Garantir la qualité des données qualifiées disponibles
2 - Gérer les demandes d’implémentation de données des différentes équipes
Analyser les demandes d’implémentation en ayant en tête les enjeux métiers et les fonctionnalités d’ESG Connect
Etudier la faisabilité et les implications des demandes d’implémentation (temps de développement, ressources nécessaires)
3 - Contribuer à renforcer les processus actuels
Adopter une démarche d’amélioration continue pour gagner en efficacité dans l’intégration des données
Documenter les process en garantissant la pédagogie des supports
Les + de l’équipe
Une position transverse, entre enjeux clients et environnement technique
Un environnement stimulant pour apprendre rapidement !
Voir moins","Profil recherché
Tu as au moins 3 ans d’expérience sur des missions similaires, en banques ou dans la gestion d’actifs
Tu maîtrises Python et SQL
On dit de toi que tu fais preuve d’esprit critique, de pédagogie et de débrouillardise
Tu as un esprit analytique affuté et es orienté.e solution
Tu es prêt.e à rejoindre une équipe en plein développement !",2023-12-14,https://www.welcometothejungle.com/fr/companies/weefin/jobs/finance-data-engineer_paris?q=869a38b87064c2fba5413f455cbe1d45&o=e7ae1464-95d6-4a35-8c67-6f5e39fdde7c,wttj
Lead Data Engineer F/H,"{'name': 'BPIFRANCE.IO', 'sector': 'FinTech / InsurTech', 'employees': '300 collaborateurs', 'creation_year': '2012', 'turnover': None, 'mean_age': '35 ans'}",CDI,Maisons-Alfort,Non spécifié,Télétravail fréquent,15 janvier 2024,> 5 ans,Bac +5 / Master,"Descriptif du poste
Vos missions au service de l’économie française

Au sein de la Digital Factory, la Data Factory a pour objectifs de piloter, définir, déployer et opérer les meilleurs solutions Data permettant de répondre aux enjeux Business & Stratégiques de Bpifrance.Afin de renforcer son collectif, la Digital Factory est à la recherche d’un. e Lead Data Engineer.


La/le lead data engineer :

Contribue à la rédaction de la feuille de route de l’équipe Core Data de la Data Factory
Prend en charge la supervision, l’organision et l’animation des Data Engineers de la Data Factory 
Conçoit, met en œuvre et monitore les traitements d’alimentation et de transformation des données
Garanti la gouvernance des données (Data quality, lineage & Data cataloging) en mettant en place les outils et Kpi de suivi adéquats 
Met en place les bonnes pratiques de code et devX 
Participe à la formation et au coaching des équipes
Voir moins","Profil recherché
Prêts à rejoindre notre équipe ?

Profil de candidat recherché :

Vous êtes diplômé(e) d’un master 2 ou d’une école d’ingénieur ou de commerce.
Vous êtes doté(e) d’une expérience concrète et réussie de plus de 5 ans dans des environnements complexes. Une expérience en startup est un plus.
Vous êtes rigoureux (se), organisé(e) et avez une très forte envie de progresser, de challenger et d’être challengé. Vous êtes motivé(e) par la recherche de solutions permettant d’atteindre vos objectifs.
 

Compétences requises :

Vous avez une expérience significative dans la data et maitrisez l’écosystème des solutions ainsi que l’ensemble des étapes de réalisation de data product : Storage, Engineering, Analytics, Reporting
Vous avez une expertise technique solide en python, spark, SQL et maitrisez les outils  snowflake et dbt.
Vous comprenez les enjeux business et savez les traduire dans un environnement Tech.
Vous avez une culture entrepreneuriale et savez faire bouger les lignes. 
Toujours à la recherche d’axe d’amélioration, vous avez le sens du détail afin d’identifier les pain points récurrents et trouvez les solutions adéquates.
 










Travailler chez Bpifrance, c’est intégrer une banque pas comme les autres, un projet d’entreprise ambitieux et tourné vers l’avenir. C’est plus qu’un métier : c’est une mission, une équipe, un réseau et un écosystème.

Pour découvrir nos autres opportunités et tout savoir de la vie au sein du groupe, rendez-vous  !



Bpifrance est une banque citoyenne dotée d’un code de déontologie et d’une politique anti-corruption.
Avant de postuler, nous vous invitons à consulter  relative à la gestion des données à caractère personnel disponible sur notre site.
Voir plus",2023-12-13,https://www.welcometothejungle.com/fr/companies/bpi-france-digital/jobs/lead-data-engineer-f-h_maisons-alfort?q=869a38b87064c2fba5413f455cbe1d45&o=bd5499d5-d96a-42bf-a925-8152ec36da01,wttj
Data Engineer - Madonne Core (H/F),"{'name': 'NATIXIS', 'sector': 'Banque, Transformation, Assurance', 'employees': '13600 collaborateurs', 'creation_year': '2006', 'turnover': '25,7 milliards € de PNB', 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Vous rejoignez l'équipe Core en charge de la maintenance évolutive des applications Madonne (Récolte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiée au coeur de l'IT Risque).

Au quotidien vous avez pour missions de :

Participer à l'adaptation de nos applications en adéquation avec les besoins métiers (nouveaux produits, nouvelles règlementations, nouveaux SI Front) ;
Participer activement à la modernisation de nos outils, modernisation de notre chaîne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;
Monter en compétences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous développerez une compréhension globale des chaînes de traitements ;
Participer à tous les travaux de modernisation de notre SI, et être donc engagé dans la migration de nombreux process vers le DataLake Risk.





#TransformativeFinance
Ce poste est basé à Paris avec la possibilité de télétravailler.
En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours.
Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.
Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise.
A propos du processus de recrutement
Vous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier).
Voir moins","Profil recherché
Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous : Vous souhaitez bénéficier d'une première expérience significative en développement Spark et Scala. Vous maitrisez : * Les méthodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appétence pour la manipulation de la data. Vous êtes : * Reconnu par votre esprit d'équipe ; * Capable de communiquer avec des publics différents, notamment avec le métier ; * Autonome et ntéressé par l'environnement finance de marché. Vous maitrisez l'anglais avec un niveau B1. Dites-nous que vous êtes intéressé en répondant à cette annonce.",2023-12-07,https://www.welcometothejungle.com/fr/companies/natixis/jobs/data-engineer-madonne-core-h-f_paris_NATIX_o1MYbgA?q=869a38b87064c2fba5413f455cbe1d45&o=ca1a2594-2e80-417f-958c-1acc9a524e4a,wttj
Data Engineer H/F,"{'name': 'GROUPE CRÉDIT AGRICOLE', 'sector': 'Banque, Assurance', 'employees': '142000 collaborateurs', 'creation_year': '1885', 'turnover': None, 'mean_age': None}",CDI,Guyancourt,Non spécifié,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
En tant qu’ingénieur data au sein du pôle Data Engineering, vous aurez pour principales missions :
1. La prise en charge de la chaîne CI / CD
Conception / Paramétrage / Pilotage et suivi de l’implémentation
Intégration de la chaîne dans les processus existants
Accompagnement du changement auprès des utilisateurs
2. Le développement de traitements de flux de données
Conception générique, développement ETL (dans un premier temps sur les outils on premise puis évolution vers les fonctionnalités natives des cloud providers)
Maintenance et évolutions applicatives
Intégration et suivi de bout en bout via la chaîne CI/CD
3. D’assurer la qualité et le fonctionnement de la plateforme Data
Suivi de la production, gestion et analyse des incidents
Rédaction de mode opératoire, documentation de production
Support N2
Ce poste est soumis à un régime d’astreinte de nuit et week-end ainsi qu’à des interventions ponctuelles et planifiées de nuit, week-end et jours fériés.
Pourquoi nous rejoindre ?
CAPS est une entreprise dynamique, portée par les innovations technologiques
De nombreuses opportunités professionnelles vous attendent chez CAPS et au sein du Groupe CA
Vous bénéficiez également d’un plan de formation et de développement adapté à vos besoins
Au sein de nos différents Campus, de nombreux services vous facilitent le quotidien : conciergerie, espaces de travail collaboratifs, choix de restauration variés, équipements digitaux, parkings…
Agir chaque jour dans l’intérêt de nos collaborateurs et de la société, cela signifie aussi être attentifs aux sujets de mixité, de handicap, d’engagement solidaire, autant d’axes forts de notre politique RSE et facteurs de performance et d’innovation.
Quelques raisons supplémentaires…
Un package de rémunération attractif (primes sur objectifs, intéressement et participation)
De nombreux avantages sociaux (CSE, offre bancaire groupe, remboursement des transports à 90% etc.)
2 jours de télétravail par semaine en moyenne
Un partenariat avec Vivrou.com pour aider nos (futurs) collaborateurs à trouver leur lieu de vie idéal.
Voir moins","Profil recherché
Formation : Bac +5 / M2 - Spécialisation Ingénieur, Business Intelligence, Data
Expérience : 6 à 10 ans d’expérience dont 5 ans dans des fonctions similaires
Compétences :
Programmation avançée (algorithmique / conception de modèles de données)
Méthodologie projet (Agile + Bout en bout / CI CD)
Connaissances fonctionnelles des paiements (monétiques, fiduciaire, flux) serait un plus
Capacité à réaliser des conceptions détaillées de traitements et à concevoir des traitements génériques
Monitoring et suivi d’environnements multiples (dev, intégration, homologation, production)
Autonomie et sens de l’initiative
Outils informatiques :
Excellente maîtrise d’un outil ETL (Datastage, Informatica, Talend)
Excellente maîtrise des Systèmes de gestion de base de données (Vertica serait un plus)
Voir plus",2023-12-06,https://www.welcometothejungle.com/fr/companies/groupe-credit-agricole/jobs/data-engineer-h-f_guyancourt?q=869a38b87064c2fba5413f455cbe1d45&o=9b171abe-3d7b-4f9b-9294-99552e2c7a86,wttj
Lead Data Engineer H/F,"{'name': 'SOLUTION BI', 'sector': 'IT / Digital, Transformation, Finance', 'employees': '292 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': '33 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 5 ans,Bac +5 / Master,"Descriptif du poste
En tant que Lead Data Engineer, ton rôle sera clé sur les domaines suivants : 
Concevoir, construire et déployer de nouvelles data platforms à l’état de l’art pour nos clients, 
Collaborer avec les équipes métiers et techniques de nos clients pour identifier toutes les exigences attendues, 
Maîtriser les technologies d’infra-as-code et de CI/CD, 
Développer des flux de données de haut niveau de qualité, 
Concevoir et recommander la meilleure modélisation de données possibles (dans le respect du Keep It Simple), 
Fédérer une communauté de passionnés autour de toi, 
Apporter ta bonne humeur et t’éclater sur les projets.","Profil recherché
Nous recherchons avant tout de la passion et de la curiosité. Les compétences technologiques qui te seront les plus utiles sont :  
Expertise sur un cloud data warehouse comme Snowflake, 
Maîtrise du langage de programmation Python et d’un framework comme Spark ou Pandas, 
Maîtrise avancée du SQL (optimisation de requête, bonnes pratiques) 
Maîtrise d’un langage d’infra-as-code comme Terraform et d’un outil de CI/CD, 
Maîtrise avancée de Git. 
Mais avant tout, ce sont tes compétences humaines qui seront tes principaux atouts :  
Ta capacité à animer une équipe, 
Ton envie de partager tes connaissances, 
Le sens du service et la passion de la tech qui t’animent. 
Pour un Lead Data Engineer, voici nos attentes :  
Au moins 5 années d’expérience pendant lesquelles tu as joué un rôle clé dans la mise en production de plateformes de données modernes, 
Voir plus",2023-12-01,https://www.welcometothejungle.com/fr/companies/solution-bi/jobs/lead-data-engineer-h-f_paris?q=869a38b87064c2fba5413f455cbe1d45&o=64c81b1a-fb49-4cfd-b7c7-afe2e38d2b99,wttj
Data Engineer H/F - Lyon,"{'name': 'SOLUTION BI', 'sector': 'IT / Digital, Transformation, Finance', 'employees': '292 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': '33 ans'}",CDI,Lyon,Non spécifié,Télétravail occasionnel,,> 2 ans,,"Descriptif du poste
En tant que Data Engineer, ton rôle sera clé sur les domaines suivants : 
Comprendre les attentes métiers des clients pour développer des data pipelines simples et efficaces, 
Prendre une part au DevOps sur les technologies d’infra-as-code et de CI/CD, 
Développer en équipe avec des outils tels que Git, 
Construire et déployer de nouvelles data platforms à l’état de l’art pour nos clients en collaboration avec nos data architects et lead data engineers, 
Apporter ta bonne humeur et t’éclater sur les projets.","Profil recherché
Nous recherchons avant tout de la passion et de la curiosité. Les compétences technologiques qui te seront les plus utiles sont :
Maîtrise du SQL (optimisation de requête, bonnes pratiques),
Bonne connaissance d’un ou plusieurs outils ETL (DBT, Matillion, etc.),
Expérience sur une cloud data platform (par ex. Snowflake, Databricks, BigQuery, …)
Expérience en Python et sur un framework comme Spark ou Pandas,
Expérience sur Git.
Mais avant tout, ce sont tes compétences humaines qui seront tes principaux atouts :
Ta capacité à travailler une équipe,
Ton envie d’acquérir et partager des nouvelles connaissances,
Le sens du service et la passion de la tech qui t’animent.
Tes qualifications
Pour un Lead Data Engineer, voici nos attentes :
Au moins 2 années d’expérience pendant lesquelles tu as joué un rôle dans le développement de piplines de données,
Voir plus",2023-12-01,https://www.welcometothejungle.com/fr/companies/solution-bi/jobs/data-engineer-h-f_paris?q=869a38b87064c2fba5413f455cbe1d45&o=c5606ab7-45c4-4320-868e-ad36ed231e13,wttj
Data Engineer - H/F,"{'name': 'CLS – COLLECTE LOCALISATION SATELLITES', 'sector': 'Ingénieries Spécialisées, Aéronautique / Spatiale', 'employees': '900 collaborateurs', 'creation_year': '1986', 'turnover': '173M€', 'mean_age': '42 ans'}",CDI,Ramonville-Saint-Agne,Non spécifié,Télétravail non autorisé,,,Bac +5 / Master,"Descriptif du poste
Nous renforçons nos équipes et recherchons un ou une :
 Data Engineer H/F
 Ce que nous attendons de vous :
Participer à la réalisation des projets innovants
Collaborer avec l’ensemble des interlocuteurs concernés, transverses et métier
Manipuler des volumes de données importants, et leur croisement (pipelines de données, ETL)
Développer jusqu'à la mise en production les traitements Big Data
Aider les équipes en charge de développement de modèles ML à leur montée en maturité industrielle.","Profil recherché
Vous aimez la techno mais également comprendre le métier et les applications, ingénieur de formation, vous détenez de solides bases techniques en base de données et systèmes Big Data.
Le candidat idéal maitrisera :
Java (J2EE / Jdk 17 / SpringBoot)
Scala
Spark (SQL /DataFrame)
Parquet
Impala / Kudu / Hive / SQL
Redis
Kafka
Docker – Kubernetes – Helm
Web Services Rest
TU (JUnit / Mockito / PowerMock / ScalaMock)
Une appétence Machine Learning est un plus. Une connaissance de Git et Maven est requise.
Voir plus",2023-07-11,https://www.welcometothejungle.com/fr/companies/cls-group/jobs/data-engineer-h-f_ramonville-saint-agne_CCLS_jb3Oy0J?q=869a38b87064c2fba5413f455cbe1d45&o=15757626-1deb-409b-aeb3-a4a6492bf390,wttj
Data Analyst / Data Scientist (H/F),"{'name': 'STAGO', 'sector': 'Pharmaceutique / Biotechnologique, IT / Digital, Santé', 'employees': '2600 collaborateurs', 'creation_year': '1945', 'turnover': None, 'mean_age': '40 ans'}",CDI,Gennevilliers,Non spécifié,Télétravail non autorisé,,> 1 an,Bac +5 / Master,"Descriptif du poste
Présentation STAGO :
Choisir Stago c’est contribuer à la santé, dans une entreprise à taille humaine et à dimension internationale. 
Référence mondiale en diagnostic in vitro et partenaire privilégié des laboratoires de biologie médicale, Stago conçoit, fabrique et commercialise, à travers le monde, la plus large gamme de réactifs et d’instruments d’analyses en hémostase.
Venez participer à une aventure unique au sein d’une société reconnue pour son expertise et avec des valeurs humaines fortes !
A la recherche de nouveaux défis ?
Vous souhaitez contribuer à la performance de nos applications logicielles en apportant votre expertise métier ?
Ne cherchez plus, nous avons un poste pour vous ! 
Descriptif du poste :
Nous recherchons pour notre département R&D Instruments Plateformes Systèmes, un Data Analyst / Data Scientist (H/F) pour un contrat en CDI.
Vous êtes en charge de participer à l’exploitation des données des instruments Stago en réalisant des explorations de données basées sur des indicateurs statistiques.
Vous rejoindrez une équipe de trois personnes, pour assurer les missions suivantes : 
Explorer les données disponibles dans le lac de données, faire le lien avec les interventions techniques pour mettre en place des algorithmes de détection d’anomalies et identifier les tendances révélatrices de problématiques instruments.
Mettre en place des tables prototypes afin d’enrichir les exploitations de données actuelles.
Vérifier la qualité des données, mettre en place des indicateurs de suivi, s’assurer de leur exploitation par les clients internes et réaliser les évolutions demandées.
Participer à la mise en place de manipulations  de reproduction de défaillance sur instrument au sein du Lab R2S Connect et à leur analyse.
Vous travaillerez en interaction régulière avec les différentes équipes amont et aval oeuvrant sur le projet. Votre curiosité et votre esprit d’analyse et de synthèse contribuera à identifier les indicateurs les plus pertinents afin de les partager avec les clients internes.
Une formation à l’hémostase et à nos produits sera assurée dès votre intégration. 
 Voir moins","Profil recherché
Profil recherché :
Ce que nous recherchons : 
Diplôme : Bac + 5 en data science, data engineering, informatique ou statistique
Nombre d’expérience : une expérience dans le domaine de la data (stage ou apprentissage accepté) en tant que Data Scientist, Data Analyst ou Data Engineer   
Compétences techniques : Vous disposez de compétences techniques en SQL, en Python 3 ainsi que des compétences en statistiques et dans la manipulation des données. Des notions de pyspark et Power BI sont un plus. La maîtrise de l’anglais (lu, écrit, parlé) est demandée.
Compétences comportementales : L’organisation, la rigueur, l’autonomie, la curiosité associée à votre capacité de synthèse et de communication seront les qualités essentielles à la réussite de vos missions.
Ce poste, à pourvoir dès à présent, est basé à Gennevilliers (RER C station Les Grésillons / Gennevilliers).
Rejoindre STAGO c’est :
Voir plus",2024-02-23,https://www.welcometothejungle.com/fr/companies/stago/jobs/data-analyst-data-scientist-h-f_gennevilliers_STAGO_j2P1XYJ?q=869a38b87064c2fba5413f455cbe1d45&o=eb802708-a5c0-4f44-95c6-70b05abcb914,wttj
BigData Engineer Cloudera H/F ,"{'name': 'BTI ADVISORY', 'sector': 'Application mobile, IT / Digital, Transformation', 'employees': '36 collaborateurs', 'creation_year': '2016', 'turnover': '4 millions en 2022', 'mean_age': '34 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
BigData Engineer Cloudera H/F  
Contexte : 
BTI-Advisory est un cabinet de conseil en IT fondé en 2016, 100% indépendant, qui a pour vocation de co-construire avec des entreprises leurs transformations digitales afin de mettre en lumière et d’optimiser leurs potentiels tout en ayant un impact sociétal positif et durable. 
Pour apporter des réponses durables et adaptées aux besoins particuliers de nos clients, nous avons développé une offre de services augmentée qui s’articule de la manière suivante : 
Notre expertise métier permettant d’accompagner nos clients de la construction de la vision numérique à l’implémentation de celle-ci. 
Des centres d’excellences qui portent nos convictions et réunissent des expertises de haut niveau pour assister nos clients à adresser des problématiques technologiques et métiers. 
Et enfin une offre de services augmentée avec notre écosystème de partenaires ciblés. 
Ce poste est fait pour vous si :  
Vous êtes diplômé(e) d’une école d’ingénieur ou d’une formation universitaire de premier rang en informatique ou domaine connexe. 
Vous avez une expertise avérée au moins 3 ans minimum dans les infrastructures Big Data, idéalement avec Cloudera Data Platform. 
Vous possédez une solide expérience en gestion de projet Agile, avec la capacité de prendre en charge les rôles de Product Owner et Scrum Master au besoin. 
Vous maîtrisez les technologies clés telles que Hadoop, Spark, Kafka, ainsi que les langages de script (ksh, bash, python…). 
Vous êtes compétent(e) dans la gestion de la sécurité des données et des systèmes, avec une expérience dans la mise en œuvre de solutions de cyber-sécurité.
Voir moins","Profil recherché
Pour rejoindre une équipe dynamique et en charge d’apporter une expertise transverse, nous recherchons plusieurs Big Data Engineer expérimenté.es pour concevoir, déployer et gérer les solutions Big Data de nos clients. 
Votre rôle consistera à définir l’orientation technique de la plateforme de Big Data en collaboration étroite avec notre client et l’éditeur pour assurer l’optimisation, la sécurité, et la scalabilité de nos solutions Big Data, notamment sur Cloudera Data Platform. 
Vous serez en charge d’une équipe agile et vos principales missions seront de : 
Préparer les installations et les montées de versions des composants logiciels Big Data, en automatisant les processus quand cela est possible. 
Rédiger les Procédures Techniques d’Installation et contribuer à la mise à jour des dossiers d’architecture et d’exploitation. 
Assurer la scalabilité des environnements de développement et de recette, et concevoir des outils pour le suivi de la capacité des composants logiciels Big Data. 
Prendre en charge la recette et les Tests de Non Régression. 
Renforcer la cyber-sécurité et la robustesse des composants logiciels Big Data à travers toutes les phases de développement et sur tous les environnements. 
Voir plus",2024-02-23,https://www.welcometothejungle.com/fr/companies/bti-advisory/jobs/bigdata-engineer-cloudera-h-f_paris?q=869a38b87064c2fba5413f455cbe1d45&o=bf69bb32-d8ff-487c-99ef-a2c44b19b95c,wttj
DataOps 3 ans EXP MINI - IA Générative,"{'name': 'MP DATA', 'sector': 'Intelligence artificielle / Machine Learning, IT / Digital, Big Data', 'employees': '100 collaborateurs', 'creation_year': '2015', 'turnover': None, 'mean_age': '27 ans'}",CDI,,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
Dans le cadre de sa forte croissance, MP DATA, recrute un Consultant DataOps pour travailler avec un de ses clients du secteur de la Défense pour la création custom d’un modèle d’IA Générative inspiré de ChatGPT et entraîné sur des données sécurisées.
Responsabilités:
Déployer la solution (inférence, et éventuellement entraînement) dans un environnement sécurisé.
Mettre en place des rapports sur la surveillance des modèles d’IA pour l’utilisation et les performances
Créer une campagne de test pour le déploiement automatisé des modèles
Diagnostiquer et résoudre les incidents de déploiement
Documenter la solution automatisée de déploiement
Adapter la solution automatisée aux nouveaux cas d’utilisation et aux contraintes spécifiques qui se présentent
Synchroniser avec d’autres équipes travaillant sur l’IA générative
Gérer la relation avec les équipes IS/IT hébergeant l’infrastructure sécurisée","Profil recherché
De formation ingénieur Grande École (groupe Centrale, Mines & Telecom, ENSIMAG, Phelma, N7, …) ou docteur vous justifiez de plusieurs expériences professionnelles au cours desquelles vous avez pu développer les compétences techniques suivantes :
Connaissances des modèles LLM
Fortes expériences techniques en Kubernetes, Docker
Maîtrise des concepts et outil DevOps
Connaissances du DevOps dans des environnements contraints / sécurisés
MLOps (MLFlow, Kubeflow, DVC, …)
En plus : langages frontend (Streamlit, Flask)
Un intérêt particulier pour les sujets d’IA générative est le bienvenu.
Nous recherchons quelqu’un d’expérimenté sur ce poste, au minimum 3 ans au global dont des expériences en tant que : DevOps, Data Engineer et Tech Lead.
Type d’emploi : Temps plein, CDI
Localisation : Paris (centre)
Télétravail : 3 jours par semaine",2024-02-21,https://www.welcometothejungle.com/fr/companies/mp-data/jobs/dataops-3-ans-exp-mini-ia-generative?q=869a38b87064c2fba5413f455cbe1d45&o=8b44237e-a44b-4674-b97c-9e97d95a3b37,wttj
Engineering Manager - Data and AI platforms,"{'name': 'EVANEOS', 'sector': 'Tourisme, SocialTech / GreenTech', 'employees': '165 collaborateurs', 'creation_year': '2009', 'turnover': None, 'mean_age': '32 ans'}",CDI,Paris,60 à 70 €,Télétravail fréquent,,> 5 ans,,"Descriptif du poste
L’équipe Data Tech chez Evaneos 📊
Chez Evaneos, notre activité Data est un pilier essentiel. L’équipe data tech fournit les plateformes et l’expertise technique Data et IA. Elle se compose de :
Data Platform : cette partie de l’équipe comprend 1 Data Engineer et 1 Analytics Engineer, qui fournissent les ressources nécessaires (pipelines de données, ressources cloud, …) à nos 8 Data Analysts B2B et B2C qui accompagnent tous les départements dans leurs prises de décision.
AI Platform : cette partie de l’équipe comprend 1 Data/ML Engineer, 1 Data Scientist et 1 Technical Product Manager. Ils et elles soutiennent nos équipes produit (impact teams) en leur fournissant une plateforme d’intelligence artificielle (outillage, ressources cloud, APIs, expertise).
En ce qui concerne notre stack, nous utilisons Google Cloud, Looker, Amplitude, Airflow, DBT et Git pour la partie Data platform, ainsi que pour l’instant VertexAI, Python pour l’AI platform.","Profil recherché
Ton rôle en tant qu’Engineering Manager dans l’équipe Data Tech 👋
1️⃣ En tant que référent⸱e technique :
Tu as une bonne compréhension des enjeux techniques, grâce à quoi tu guides notre équipe et la stratégie en matière de Data et IA. Il reste encore des choix techniques à faire, et nous sommes impatient⸱e⸱s de voir où tu nous mèneras !
Tu accompagnes ton équipe dans leur montée en compétences et encourages leur autonomie, la prise de responsabilité et l’initiative pour qu’ils et elles soient fier⸱e⸱s de leurs accomplissements.
Manager/manageuse plutôt “hands on”, ton expérience et ton bagage technique te permettent également de participer à la résolution de problèmes complexes.
2️⃣ En tant qu’Engineering Manager :
Tes missions consisteront à garantir une équipe efficace, concrètement cela signifie :
Qui délivre : de l’IA pragmatique “en prod” qui apporte de la valeur aux voyageurs et agents dans nos produits, et pas seulement de la recherche et développement
Voir plus",2024-02-19,https://www.welcometothejungle.com/fr/companies/evaneos/jobs/engineering-manager-data-and-ia-platforms_paris?q=869a38b87064c2fba5413f455cbe1d45&o=3dadaaf8-53df-429d-816f-6d99bb1561fe,wttj
Consultant(e) Senior Data Product Manager - WiTADA,"{'name': 'WIVOO', 'sector': 'IT / Digital, Organisation / Management, Digital', 'employees': '120 collaborateurs', 'creation_year': '2018', 'turnover': '10M€', 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail occasionnel,25 septembre 2023,,,"Descriptif du poste
Dans le cadre du lancement de notre nouvelle entité data WiTADA, nous recherchons nos premiers pionniers pour rejoindre l’aventure ! Nous recrutons Un.e Senior Data Product Manager afin de d’accompagner nos clients sur des problématiques techniques et business liées à la data et nous accompagner dans la co-construction de l’entreprise en interne.
En tant que Consultant(e) Senior Data PM chez WiTADA, tu interviendras sur des projets Data pour challenger et cadrer les besoins, et pour faire la liaison entre les besoins clients, l’équipe Data Science et la DSI.
Tu interviendras au sein d’équipes pluridisciplinaires et expérimentées dans le cadre de projet de réflexion, conception et exploitation de plateformes data !
Innovation et pragmatisme te permettrons de franchir toutes les étapes des projets que nous menons.
Tes principales responsabilités sont :
Cadrer, challenger, prioriser les projets Data dès leur initiation
Animer les ateliers avec le client et/ou les utilisateurs finaux afin de comprendre précisément leurs besoins
Définir la vision produit en accord avec les parties prenantes du projet, et la communiquer aux équipes à travers la roadmap produit
Ecrire les User Stories et les critères d’acceptance
Gérer et prioriser le Product Backlog
Animer les cérémonies agiles SCRUM (Sprint Planning, Backlog Refinement, …)
Assurer les recettes fonctionnelles
Piloter le projet, en coordination avec le client, l’équipe data et l’IT et assurer la communication entre les parties prenantes tout au long du projet
Effectuer le suivi des projets du POC à leur industrialisation éventuelle
Voir moins","Profil recherché
Les données indiquent que nous avons tendance à hésiter à postuler pour un poste si nous pensons ne pas avoir toutes les compétences requises.
Notre équipe WiTADA tient à souligner que même si tu as toutes les compétences requises, mais qu’il ne t’en manque qu’une, n’hésites pas à postuler !
Ce que nous attendons de toi :
Tu as un profil hybride entre compréhension des enjeux business/métiers et la maîtrise de la Data Science.
Tu auras en charge un ou des projets Data de la définition des besoins jusqu’à la mise en œuvre avec l’IT puis de leur amélioration continue.
Tu auras la charge de la détection des problématiques utilisateurs et l’identification des solutions appropriées au besoin, avec éléments de faisabilité / alternatives sur toute la chaîne de production de valeur.
Et pour mener à bien ces responsabilités, tu disposes des compétences suivantes :
Capacité à traduire des besoins clients en usages et fonctionnalités produit
Maîtrise des enjeux du Big Data
Voir plus",2024-02-12,https://www.welcometothejungle.com/fr/companies/wivoo/jobs/consultant-data-product-manager_paris?q=869a38b87064c2fba5413f455cbe1d45&o=1f86dc6b-f338-4800-a0fe-f64f44b84148,wttj
"Jobdating Micropole - Recrutement de Consultants et Managers Data, Cloud et EPM","{'name': 'MICROPOLE', 'sector': 'IT / Digital', 'employees': '1200 collaborateurs', 'creation_year': '1987', 'turnover': ""122 millions d'€"", 'mean_age': '36 ans'}",CDI,Levallois-Perret,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Micropole vous invite à sa soirée de recrutement [Retrogaming Night]
Nous avons le plaisir de vous convier à la soirée de recrutement de Micropole qui aura lieu le mardi 12 mars 2024 à partir de 18h30 dans nos locaux au 91 rue Carnot à Levallois (Métro ligne 3, arrêt Anatole France).
Vous pourrez rencontrer nos Consultants et Managers, participer à des jeux d'arcade autour d'un bon cocktail dînatoire et profiter de plusieurs surprises prévues au cours de la soirée. Toutes les entités de Micropole seront  présentes au jobdating : Cloud4Data, Data Experience, Data Science, Data Gouvernance, Digital, EPM/FT&P, Data Thinking, etc.
=> Si vous êtes prêt(e) à booster votre carrière et à rejoindre une entreprise qui va vous aider à décupler votre potentiel, cliquez sur ce lien Eventbrite pour récupérer votre invitation : https://shorturl.at/kvLUY 
=> Si vous avez une personne de votre entourage en recherche active d'un nouveau poste dans l'EPM, le conseil ou la data, vous pouvez venir ensemble la soirée. Nous serions ravis de vous accueillir.
PS. N’hésitez pas à venir accompagné en prenant plusieurs billets. ^__^
_ _ _Micropole en bref : https://www.micropole.com/micropole-en-bref/Micropole est accélérateur de la transformation des entreprises par la Data. Notre mission est d’aider nos clients à garder un temps d’avance en exploitant tout le potentiel de la Data pour avoir un impact business positif, grâce à l’innovation, qu’elle soit technologique, de process ou de méthode. Du conseil à la mise en œuvre opérationnelle, nous accompagnons les entreprises dans leur stratégie Data, et les transformations organisationnelles, humaines et technologiques associées. Le groupe réunit à travers ses 1200 talents (en Europe et en Chine) l’ensemble des expertises de conseil et technologies autour de la Data, dans ses différents métiers : Stratégie Data, Cloud Acceleration, Digital Business, pour mener à bien les transformations “data driven”.
Voir moins","Profil recherché
Vous êtes Consultant ou Manager dans un cabinet de conseil et vous souhaitez découvrir un nouvel environnement de travail et évoluer sur des projets plus valorisants ?  Que vous soyez jeune diplômé, junior, confirmé, senior ou Manager, Micropole a un plan de carrière clair et des projets sur lesquels vous pourrez vous épanouir.
Découvrez les profils que nous recrutons :
Entité Data Expérience :  
Profils : Data Analyst, Product Owner, Chef de projet, Business Analyst, Ingénieur d'études
Outils : Power BI, Tableau, Qlik, Power Platform, Power Apps, Power Automate, Alteryx, Dataiku
Entité CLOUD4DATA :
Profils : Data Engineer, Data Cloud Analytics Engineer, Chef de projet, Product Owner, Data Analyst, Architecte Data Cloud
Outils : AWS, Databricks, Snowflake, DBT, GCP
Entité Data Gouvernance :
Voir plus",2024-02-09,https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/jobdating-micropole-recrutement-en-cdi-de-consultants-et-managers-data-et-epm_levallois-perret?q=869a38b87064c2fba5413f455cbe1d45&o=41acd581-2453-43a8-a9d6-962a20e520f2,wttj
Product Owner Data,"{'name': 'WEWYSE', 'sector': 'Digital Marketing / Data Marketing, IT / Digital, Transformation', 'employees': '60 collaborateurs', 'creation_year': '2019', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 2 ans,Bac +5 / Master,"Descriptif du poste
Être Product Owner Data chez Wewyse c’est :
intégrer une communauté d’experts Data passionnés,
recevoir et partager de la connaissance et des savoirs-faire lors de nombreux évènements,
participer à des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires académiques et des start up,
bénéficier des outils et du support de la communauté Wewyse pour mener à bien tous les projets,
être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles,
faire partie de la famille Wemanity avec ses évènements et ses multiples opportunités de carrière,
combiner expertise Data et méthodes agiles pour un maximum d’impact,
intervenir sur des projets aux enjeux sans cesse renouvelés (diversité de secteur, de métier, de maturité Data, …),
mettre la Data au cœur des processus de création de valeur de nos clients,
maximiser la valeur des données de nos clients,
renforcer la confiance des utilisateurs dans la donnée.
Voir moins","Profil recherché
Ce que nous aimons chez Wewyse :
Les personnalités ouvertes, curieuses, ambitieuses, audacieuses
Des compétences en communication (équipe, métier/client, …)
Une volonté de s’investir dans un projet (travail quotidien avec les équipes et les clients, présence à toutes les cérémonies)
Les certifications Scrum, SAFE
Une approche UX
Appréhender les différents rôles d’une équipe Data (Data Analyst, Data Scientist, Data Engineer, Data Architect, …)
Savoir dire non (besoin client, sujets d’équipe, nécessaire à la priorisation des sujets)
L’expérience sur le requêtage de la donnée (SQL, NoSQL), le traitement de la donnée, et la modélisation et la spécification de la donnée autour de dimensions et de KPI (étoile, flocon, …)
Les connaissances sur les architectures présentes autour de la donnée (Data Lake/Delta Lake, Data Warehouse, Pipeline) et les différentes solutions du marché (Cloud, Data visualisation, ETL, Gouvernance, …)
Voir plus",2024-02-06,https://www.welcometothejungle.com/fr/companies/wewyse/jobs/product-owner-data_paris_WEWYS_O7KZ4QD?q=869a38b87064c2fba5413f455cbe1d45&o=9fc9e7ed-8c03-4eb2-b4b3-b968676bf04e,wttj
Data Ingénieur HF,"{'name': 'BUT', 'sector': 'Grande distribution, Aménagement / Design, E-commerce', 'employees': '9000 collaborateurs', 'creation_year': '1972', 'turnover': ""2,2 milliards d'euros"", 'mean_age': '38 ans'}",CDI,Émerainville,Non spécifié,Télétravail non autorisé,,> 2 ans,Bac +5 / Master,"Descriptif du poste
BUT est une enseigne en action, animée par des hommes et des femmes pour qui aucun jour ne ressemble au précédent.

Au sein de la direction CRM, Trafic et data et dans le cadre du plan de transformation digitale et data de BUT et de la structuration de l'architecture de données clients, le data ingénieur sera amené à contribuer à développer et valoriser l'ensemble des données en prenant part à des projets et uses cases métiers innovants. Vous participerez aux études et phases exploratoires des projets Data client


Vos principales missions :

Gérer, maintenir et documenter de multiples bases de données
Collecter, consolider, modéliser et documenter de gros volumes de données (Big Data, Data Warehouse, DataLakes)
Cartographier des données et des flux de données
Développer l'industrialisation de modèles statistiques ou de machine learning
S'assurer de la scalabilité, la sécurité, la stabilité et la disponibilité des données de la plateforme
Développer, automatiser et monitorer des flux de collecte de données via fichier ou API
Construire des Datamarts à partir d'expression de besoin métier pour visualisation en dashboards, reporting
Vous avez de bonnes connaissances particulièrement :



Dans l'écosystème Data et IA
Sur les environnements GCP, Terraform, dbt, Airflow
Sur les technologies informatiques pour manipuler des bases de données (Oracle, Postgres, Big Query,...) et sur les Framework
Sur les langages informatiques (SQL, Python, Java) vous permettant d'être autonome sur la manipulation des données
Sur les outils BI et data visualisation (Tableau, power BI, Qlik ...)
En agilité et sur les outils associés (scrum, confluence, Jira,...)
Et être capable de rédiger de la documentation technique.
Voir moins","Profil recherché
De formation Bac +5, vous justifiez d'une expérience en tant que Data Engineer dans le domaine du Big Data, et vous êtes passionné(e) par les nouvelles technologies.

Dynamique, curieux(se), adaptable et force de proposition, vous êtes capable et avez envie de travailler aussi bien avec des équipes techniques que des équipes métiers et dans des contextes agiles

Vous possédez également d'excellentes qualités relationnelles, et avez le sens du délai et des résultats et un gout pour l'innovation.

Chez BUT, nous sommes engagés pour la diversité des équipes et la mixité des emplois. N'hésitez pas à nous faire part de votre situation de handicap, nous étudierons vos éventuels besoins spécifiques.

Être Data Ingénieur ou Ingénieure chez BUT, ça ne se raconte pas, ça se vit !",2024-01-31,https://www.welcometothejungle.com/fr/companies/but-1/jobs/data-ingenieur-hf_emerainville_BUT_eg8oGlZ?q=869a38b87064c2fba5413f455cbe1d45&o=fa917678-ec99-4207-b428-3b32fb9c2331,wttj
Project Lead Data Consultant (H/F) Paris,"{'name': 'FIFTY-FIVE', 'sector': 'Digital Marketing / Data Marketing', 'employees': '400 collaborateurs', 'creation_year': '2010', 'turnover': None, 'mean_age': '31 ans'}",CDI,Paris,Non spécifié,Télétravail fréquent,,> 3 ans,Bac +5 / Master,"Descriptif du poste
A propos de fifty-five :
fifty-five est une data-company d’un genre nouveau qui aide les marques à exploiter les données pour améliorer le marketing, les médias et l’expérience client grâce à une combinaison de services de conseil et de technologie spécialisés.
En tant que pilier data et marketing du Brandtech Group, nous offrons des services qui combinent le conseil en stratégie, les services de cloud, le conseil en média et l’expérience client.
fifty-five, c’est plus de 400 experts du numérique. Des digital consultants, des spécialistes du tracking et du média, des ingénieurs et des data scientists, travaillent tous en étroite collaboration pour fournir des conseils marketing de haut niveau et une assistance technique aux marques, dans tout type d’industrie, partout dans le monde.
Partenaire des annonceurs de la collecte à l’activation et l’exploitation des données, nous aidons les organisations à devenir de véritables entités omnicanales maîtrisant l’efficacité de leur écosystème digital et ses synergies avec le monde physique.
Basé à Paris, nous opérons sur 3 fuseaux horaires depuis nos 10 bureaux, situés à Paris, Londres, Genève, Milan, Shanghai, Hong Kong, Shenzhen, Taipei, Singapour et New York. fifty-five attache une importance particulière au bien-être de ses collaborateurs, ce qui lui a permis de figurer dans le classement Best Workplaces France en 2018.
Nous croyons fermement que l’environnement de travail est un élément clé du bien-être des employés et nous avons l’intention d’offrir d’excellentes conditions de travail à nos Fifty Fivers. L’humilité, le sens de l’humour et les qualités humaines sont des valeurs communes partagées par tous !
Contexte :
Au sein de l’équipe Conseil, vous supervisez et participerez activement aux missions effectuées par fifty-five pour le compte de ses clients et serez acteur majeur du développement de l’offre Data Science.
Ces missions couvrent des problématiques de mise en place d’activations marketing avancées, afin de délivrer des cas d’usage Marketing orientés Machine Learning & IA tout en intégrant les exigences business dans un objectif d’activation pertinente.
Vous rapporterez au managing director d’une des équipes conseil de 55 et travaillerez en étroite collaboration avec les experts et autres consultants de l’entreprise.
Missions :
Vous encadrerez une équipe et vos missions seront les suivantes (liste non exhaustive) :
Répondre aux besoins client,
Participer, en collaboration avec l’équipe, à l’élaboration de l’offre Data Science de fifty-five, tant sur le plan marketing que sur le plan technique ou opérationnel ;
Participer au business development de l’équipe
Apporter une expertise technique dans l’élaboration de projets Data d’envergure
Assurer la transmission d’informations entre les clients et les équipes techniques internes de 55, coordonner les activités des profils sollicités
Manager de façon projet et également RH des consultants junior/senior
Voir moins","Profil recherché
Diplômé(e) d’un bac +5 d’une grande école. Vous avez 3 à 6 années d’expérience en gestion de projet et en Data Science au sein de structures telles que : cabinets de conseil annonceurs (ex. gestion de projets online au sein d’acteurs économiques majeurs du CAC 40) ou pure players Internet de premier plan (ex. Google, Facebook, etc.).
Une bonne connaissance des technologies digitales vous permettra de vous intégrer rapidement. La maîtrise de l’anglais est indispensable.
Compétences requises :
Vous avez des compétences en analyse, en résolution de problèmes et en réflexion structurée.
Vous êtes doté(e) d’une excellente communication orale et écrite ainsi que d’un esprit commercial (développement commercial en support du MD pour les prospects et moteur pour identifier et convertir les opportunités d’upsell pour les clients existants).
Vous avez une expérience confirmée en gestion de projet : en termes de planification, encadrement interne, relation client, gestion des délais et des risques, contrôle de la qualité des livrables et de la profitabilité.






Voir plus",2024-01-29,https://www.welcometothejungle.com/fr/companies/fifty-five/jobs/project-lead-data-consultant-h-f-paris_paris?q=869a38b87064c2fba5413f455cbe1d45&o=2431c7b1-c303-4a36-bd5c-04454f6d5adb,wttj
Chef de projet Data Flux et API,"{'name': 'INSEPTI', 'sector': 'Big Data', 'employees': '19 collaborateurs', 'creation_year': '2010', 'turnover': None, 'mean_age': '29 ans'}",CDI,Villeneuve-d'Ascq,Non spécifié,Télétravail occasionnel,03 octobre 2023,> 5 ans,Bac +5 / Master,,,2024-01-22,https://www.welcometothejungle.com/fr/companies/insepti/jobs/chef-de-projet-data-flux-et-api_villeneuve-d-ascq?q=869a38b87064c2fba5413f455cbe1d45&o=b96fca71-367d-441d-928a-4e074d6461ee,wttj
Ingénieur(e) Data - Aeroline - Toulon,"{'name': 'SOPRA STERIA', 'sector': 'IT / Digital, Organisation / Management', 'employees': '50000 collaborateurs', 'creation_year': '1968', 'turnover': '5,1 Mds', 'mean_age': '37 ans'}",CDI,Six-Fours-les-Plages,Non spécifié,Télétravail non autorisé,,,,"Descriptif du poste
Votre futur environnement de travail :
Vous intervenez au sein d’une équipe multi-projets autour des technologies Big Data pour un constructeur de la défense. Ces projets visent à améliorer l’expérience utilisateur en opérant la transformation digitale de l’entreprise.
Votre rôle et vos missions :
Vous rejoindrez une équipe dynamique et serez amené(e) à contribuer de la construction au déploiement de solutions permettant de traiter des enjeux comme :
Le remplacement d’outils clients par des solutions plus adaptées et plus efficaces,
Le développement d’outils d’aide à la décision,
La digitalisation de chaines de traitement,
La mise en place d’indicateurs sur des équipements spécifiques,
Etc.
Vous aurez également l’occasion de participer à différents ateliers directement au contact du client afin de mieux cibler ses enjeux et ses attentes, dans le but de répondre au mieux à ses besoins tout en vous adaptant aux différentes contraintes inhérentes à son métier.
Environnement technologique : Architecture Spark, Apache Spark, Hadoop, Nifi, Qlick/Tableau,
Environnement fonctionnel : Au sein d’une plateforme Big Data, l’équipe projet intervient, pour le compte d’un grand constructeur de la défense de la région, sur le traitement et la mise à disposition au client d’un grand volume de données dans le cadre d’une stratégie de transformation numérique.
Informations supplémentaires
Les avantages à nous rejoindre :
Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. 
Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.
Un accompagnement individualisé avec un mentor.
Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.
Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.
La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».
L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).
Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.
https://www.soprasteria.fr/nous-connaitre/nos-engagements
 Voir moins","Profil recherché
Votre profil :
Vous êtes diplômé(eà d’une école d'Ingénieur ou Master 2 Informatique, ou équivalent. Vous êtes curieux(se), logique et vous appréciez le travail collaboratif. Vous êtes passionné(e) par les enjeux induits par la transformation digitale en cours et à venir et vous voulez en être un acteur / une actrice.
Vous avez idéalement une première expérience significative d'au moins 2 ans en tant que Data Engineer ou Data analyste. ",2024-01-17,https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/ingenieur-data-aeroline-toulon_six-fours-les-plages_SS_xxq3k5M?q=869a38b87064c2fba5413f455cbe1d45&o=593fb0d8-52d1-4e50-bb57-3204e50bac84,wttj
,,,,,,,,,,,,https://www.welcometothejungle.com/fr/companies/accor-tech-and-digital/jobs/data-tech-lead-h-f-x_issy-les-moulineaux_ATD_yPb224g?q=869a38b87064c2fba5413f455cbe1d45&o=24bfeba4-548d-4e17-ae86-8bf5fa462113,wttj
Consultant(e) Cloud Data Azure,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 M€', 'mean_age': '34 ans'}",CDI,Saint-Herblain,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Vous avez une expérience en développement stratégique et vous êtes passionné par les nouvelles technologies et la mise en place de solutions applicatives ?
Vous aimez aider les clients et partager vos connaissances ? Analyser et comprendre les besoins des utilisateurs en termes de collecte, stockage, valorisation de la donnée, mise en œuvre, teste puis déploiement ? Cette opportunité est sûrement faite pour vous !
Au sein de notre agence nantaise, votre rôle sera de créer et faire évoluer des applications hébergées dans le cloud Azure, répondant aux besoins de nos clients. Pour cela vous réalisez et mettez en place des solutions applicatives sur mesure dans une démarche agile .
Vos principales missions :
Identifier et challenger les besoins métier de nos clients ;
Veiller à la satisfaction client et la bonne communication avec les autres services ;
Assurer une veille technologique permanente et à l’évolution des bonnes pratiques KPC ;
Concevoir et développer les architectures Data sous Azure ;
Sourcer les données pertinentes et les collecter ;
Tester les architectures et les développements ;
Vérifier la cohérence fonctionnelle des données en collaboration avec les métiers ;
Réaliser les composants logiciels, les assembler, les mettre à disposition pour mise en production, s assurer de leur comportement et leur pertinence dans le temps ;
Contribuer à l analyse et préparer les données ;
Déployer la solution  dans les environnements adéquats ;
Effectuer une veille technologique sur les azure Data.
Voir moins","Profil recherché
Vous avez une expérience d’au moins 3 ans sur le Big Data/Business Intelligence : Azure Cloud DataPlatform, Azure Data Factory, Azure Data Lake, Azure Databricks, Azure SQL DB, Azure Synapse Analytics, Azure ML, DataBricks, Azure service Bus, Azure Stream Analytics.
Une connaissance des patterns d architecture data (bronze, silver, gold)
Traitement de la données, mise en place de l’intégration du mode Delta
De l’expérience dans le développement de projets dans le Cloud
Vous êtes : 
Passionné et de curieux 
Persévérant dans la réalisation des solutions
Vous tenez à votre excellence technique et méthodologique
Vous avez le sens du service, le partage et collaboration sont vos maîtres-mots !
Une certification Azure du type “Microsoft Azure Data Engineer Associate” serait un plus",2024-01-15,https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-cloud-data-azure_saint-herblain_KC_xVkgQpA?q=869a38b87064c2fba5413f455cbe1d45&o=62a29273-c974-418d-9629-ea3931011b53,wttj
Consultant(e) Cloud Data Azure,"{'name': 'KPC', 'sector': 'IT / Digital, Organisation / Management, Big Data', 'employees': '300 collaborateurs', 'creation_year': '2010', 'turnover': '40 M€', 'mean_age': '34 ans'}",CDI,Saint-Herblain,Non spécifié,Télétravail fréquent,,,,"Descriptif du poste
Vous avez une expérience en développement stratégique et vous êtes passionné par les nouvelles technologies et la mise en place de solutions applicatives ?
Vous aimez aider les clients et partager vos connaissances ? Analyser et comprendre les besoins des utilisateurs en termes de collecte, stockage, valorisation de la donnée, mise en œuvre, teste puis déploiement ? Cette opportunité est sûrement faite pour vous !
Au sein de notre agence nantaise, votre rôle sera de créer et faire évoluer des applications hébergées dans le cloud Azure, répondant aux besoins de nos clients. Pour cela vous réalisez et mettez en place des solutions applicatives sur mesure dans une démarche agile .
Vos principales missions :
Identifier et challenger les besoins métier de nos clients ;
Veiller à la satisfaction client et la bonne communication avec les autres services ;
Assurer une veille technologique permanente et à l’évolution des bonnes pratiques KPC ;
Concevoir et développer les architectures Data sous Azure ;
Sourcer les données pertinentes et les collecter ;
Tester les architectures et les développements ;
Vérifier la cohérence fonctionnelle des données en collaboration avec les métiers ;
Réaliser les composants logiciels, les assembler, les mettre à disposition pour mise en production, s assurer de leur comportement et leur pertinence dans le temps ;
Contribuer à l analyse et préparer les données ;
Déployer la solution  dans les environnements adéquats ;
Effectuer une veille technologique sur les azure Data.
Voir moins","Profil recherché
Vous avez une expérience d’au moins 3 ans sur le Big Data/Business Intelligence : Azure Cloud DataPlatform, Azure Data Factory, Azure Data Lake, Azure Databricks, Azure SQL DB, Azure Synapse Analytics, Azure ML, DataBricks, Azure service Bus, Azure Stream Analytics.
Une connaissance des patterns d architecture data (bronze, silver, gold)
Traitement de la données, mise en place de l’intégration du mode Delta
De l’expérience dans le développement de projets dans le Cloud
Vous êtes : 
Passionné et de curieux 
Persévérant dans la réalisation des solutions
Vous tenez à votre excellence technique et méthodologique
Vous avez le sens du service, le partage et collaboration sont vos maîtres-mots !
Une certification Azure du type “Microsoft Azure Data Engineer Associate” serait un plus",2024-01-15,https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-cloud-data-azure_saint-herblain?q=869a38b87064c2fba5413f455cbe1d45&o=c58004c4-593c-4239-93a8-7564ba4b6607,wttj
Data Product Owner H/F - CDI,"{'name': 'SIAXPERIENCE', 'sector': 'Design, Organisation / Management, Digital', 'employees': '120 collaborateurs', 'creation_year': 'Âge moyen : 29 ans', 'turnover': None, 'mean_age': None}",CDI,Paris,Non spécifié,Télétravail fréquent,,,Bac +5 / Master,"Descriptif du poste
Description de l’entreprise :
SiaXperience est l’écosystème qui développe la connectivité entre les marques et les consommateurs avec un parti pris analytique puissant mis au service des meilleures pratiques en matière de créativité et de design. SiaXperience réalise 20 millions d’euros de chiffre d’affaires avec 120 collaborateurs designers, consultants en marketing et experts du digital répartis dans 10 design centers : Paris, Lyon, Londres, Amsterdam, Montreal, Los Angeles, New York, San Francisco Bay, Seattle, Hong Kong. SiaXperience est au cœur de la stratégie de développement des activités de design, de créativité et d’expérience client de Sia Partners, aux côtés du conseil en management et stratégie ainsi que de l’intelligence artificielle.
Pionnier du Consulting 4.0, Sia Partners réinvente le métier du conseil et apporte un regard innovant et des résultats concrets à ses clients. Nous avons développé des solutions basées sur l’Intelligence Artificielle et le design pour augmenter l’impact de nos missions de conseil. Notre présence globale et notre expertise dans plus de 30 secteurs et services nous permettent d’accompagner nos clients dans le monde entier. A travers notre démarche “Consulting for Good”, nous mettons notre expertise au service des objectifs RSE de nos clients et faisons du développement durable un levier de performance pour nos clients.
Description du poste :
SiaXperience recherche un(e) Data Product Owner afin de renforcer ses équipes. Sous la responsabilité des managers, vous interviendrez sur des projets Data pour challenger et cadrer les besoins, et pour faire la liaison entre les besoins clients, l’équipe Data Science et la DSI.
Vous interviendrez au sein d’équipes pluridisciplinaires et expérimentées dans le cadre de projet de réflexion, conception et exploitation de plateformes data !
Innovation et pragmatisme vous permettront de franchir toutes les étapes des projets que nous menons.
Vos principales responsabilités sont :
Cadrer, challenger, prioriser les projets Data dès leur initiation
Animer les ateliers avec le client et/ou les utilisateurs finaux afin de comprendre précisément leurs besoins
Définir la vision produit en accord avec les parties prenantes du projet, et la communiquer aux équipes à travers la roadmap produit
Ecrire les User Stories et les critères d’acceptance
Gérer et prioriser le Product Backlog
Animer les cérémonies agiles SCRUM (Sprint Planning, Backlog Refinement, …)
Assurer les recettes fonctionnelles
Piloter le projet, en coordination avec le client, l’équipe data et l’IT et assurer la communication entre les parties prenantes tout au long du projet
Effectuer le suivi des projets du POC à leur industrialisation éventuelle
Voir moins","Profil recherché
Qualifications :
Diplômé(e) d’une école d’ingénieur ou d’une formation de haut niveau dans le domaine des technologies de l’information, vous avez un profil hybride entre compréhension des enjeux business/métiers et la maîtrise de la Data Science.
Vous prendrez en charge un ou des projets Data de la définition des besoins jusqu’à la mise en œuvre avec l’IT puis de leur amélioration continue.
Vous aurez la charge de la détection des problématiques utilisateurs et l’identification des solutions appropriées au besoin, avec éléments de faisabilité / alternatives sur toute la chaîne de production de valeur.
Et pour mener à bien ces responsabilités, vous disposez des compétences suivantes :
Capacité à traduire des besoins clients en usages et fonctionnalités produit
Maîtrise des enjeux du Big Data
Capacité à comprendre les principes et pratiques de l’analyse de données et des dernières avancées du Machine Learning pour identifier les applications produit potentielles
Voir plus",2024-01-04,https://www.welcometothejungle.com/fr/companies/siaxperience/jobs/data-product-owner-h-f_paris?q=869a38b87064c2fba5413f455cbe1d45&o=6d3e8e72-083b-41cd-b472-71d968e7cab9,wttj
Talent Acquisition Manager - Tech & Produit,"{'name': 'INDY', 'sector': 'FinTech / InsurTech', 'employees': '266 collaborateurs', 'creation_year': '2016', 'turnover': None, 'mean_age': '29 ans'}",CDI,,45K à 53K €,Télétravail fréquent,04 mars 2024,> 1 an,,"Descriptif du poste
Notre mission dans l’équipe recrutement : offrir une expérience de recrutement bienveillante et ambitieuse. 
L’équipe Technique et Produit continue de grandir et a toujours besoin de nouveaux talents pour développer nos futurs projets. Cette croissance va s’accélérer dans les mois à venir et sur l’année 2024. Pour recruter tous les nouveaux Indies, l’équipe People a besoin du renfort d’un·e Talent Acquisition Manager (TAM) Tech & Produit.
Dans l’équipe recrutement tu trouveras :
Baptiste, Head of Talent Acquisition (ton manager)
Manon D et Josselain tous les 2 Talent Acquisition Manager Tech & Produit
Manon R, Wendy et Valentine, toutes les 3 Talent Acquisition Manager Business
Notre rôle ne s’arrête pas au recrutement mais il englobe énormément d’autres sujets comme la marque employeur. Tu participeras à toute l’expérience d’un·e candidat·e, du premier contact jusqu’à son premier jour chez Indy. 
Plus concrètement sur tes missions
Sur la partie recrutement tu participeras à :
Savoir lancer un poste : discussion avec les hiring managers, établir une stratégie de recrutement
Identifier et approcher des candidats via des canaux originaux : github, meetup, stackoverflow, twitter...
La réalisation des premiers entretiens de qualification
Suivre tes candidats·es tout au long du processus en garantissant une expérience candidat exceptionnelle
Sur la Marque employeur on attendra de toi que :
Tu participes activement à l’animation de nos différents médias de communication
Apporter tes idées pour faire rayonner Indy et nos valeurs
Organiser des meet-up, événements, site carrière…
Sur l’onboarding tu seras garant·e de :
Suivre tes candidats·es pendant leur période de préavis
L’accueil des nouveau Indies
Le suivi de leur intégration dans les premières semaines
Le poste est à pourvoir à Lyon ou à Paris. 
Voir moins","Profil recherché
Le·a candidat·e idéal·e pour rejoindre notre équipe People
Tu justifies d’au moins une première expérience en start-up ou dans un environnement innovant sur le recrutement de profils tech (développeur, data engineer) et produit (Product Manager, Product designer)
Tu n’attends pas que les candidats·es postulent à tes offres mais tu aimes aller les contacter toi-même d’une quelconque façon
Tu es passionné·e par le contact humain. Créer du relationnel est ton plaisir quotidien. Ton ambition : créer des rencontres qui créent de la valeur et du bonheur !
Tu sais déceler les leviers de motivations de tes candidat·es et les mettre en adéquation avec les atouts et les valeurs d’Indy. Tu es curieux·se de comprendre l’univers de tes candidats·es
Tu comprends la phrase suivante ⇒ “Je suis dev backend NodeJS avec une surcouche Fastify. J’aime développer en TDD avec la philosophie clean code et des design KISS.”
Nous portons une attention particulière à la diversité dans notre processus de recrutement. Nous savons que certaines personnes n’osent parfois pas répondre sans cocher toutes les cases : Venez nous en parler. De même dans le cadre de nos valeurs d’inclusions, nous accordons chez Indy une attention particulière aux personnes en situation de handicap.
Voir plus",2024-02-19,https://www.welcometothejungle.com/fr/companies/indy/jobs/talent-acquisition-manager-tech-produit?q=869a38b87064c2fba5413f455cbe1d45&o=03161d05-def5-469b-a603-dd963bcbfc81,wttj
Architecte Cloud Azure H/F,"{'name': 'CAPGEMINI', 'sector': 'IT / Digital, Organisation / Management, Stratégie, Transformation', 'employees': '360000 collaborateurs', 'creation_year': '1967', 'turnover': '18 Mds €', 'mean_age': '37 ans'}",CDI,Paris,Non spécifié,Télétravail non autorisé,,> 7 ans,Bac +5 / Master,"Descriptif du poste
Description de l’entreprise
Capgemini recherche pour sa practice CCA Cloud Custom Application, un Architecte CLOUD Azure pour rejoindre ses équipes d’Architecte. Rejoindre CCA c’est intervenir au cœur du métier d’intégrateur de Capgemini pour le développement des systèmes et programmes critiques dans le cadre des transformations AGILES, DIGITALEs et DATA de nos clients.
Être ADVISOR CLOUD c’est être à la pointe de la plateforme AZURE pour identifier et concevoir les trajectoires de migration ou construire les nouvelles architecture SI en utilisant efficacement les solutions CAAS, PAAS, SAAS de Microsoft. C’est aussi travailler dans et avec une communauté d’architectes et d’ingénieurs multi CLOUD permettant de développer une expérience reconnue sur l’application modernisation, la data intégration, l’industrialisation DevSecOps, et les pratiques de citizen développement. Être ADVISOR CLOUD, c’est enfin ré-écrire l’informatique de nos clients vers une IT plus durable et responsable vis-à-vis de l’environnement.
Capgemini est le partenaire 1 de Microsoft en France. Nous rejoindre c’est bénéficier de l’appui de notre partenaire dans le développement de votre savoir faire et de votre réseau.
Description de la mission
En tant qu’Architecte Advisor Cloud Azure votre rôle sera de :
Accompagner et conseiller des CxO dans l’adoption et le déploiement des services Microsoft Azure (Stratégie IT, Etude d’opportunités, Audit, Cadrage et Roadmap)
Concevoir des plateformes solution intégrant les services de référence AZURE (IOT Hub, DataBricks, Event Hub, AKS, Functions, API Man) dans des contextes CLOUD Natif et CLOUD Hybrid
Construire avec les référents DevSecOps l’industrialisation du développement et déploiement d’applications avec AzureDevOps et TerraForm
Prendre en main et défendre l’approche solution des dossiers d’avant-vente
Evangéliser le Cloud en interne et auprès de nos clients (meetups, workshops, …)
Voir moins","Profil recherché
Description du profil :

Profil
Qui êtes-vous ?
Vous avez une expérience en conception et mise en œuvre de plateformes dans le CLOUD
Vous avez construit une compétence autour des services managés Azure
Vous êtes certifié Microsoft Azure Solution Architect ou Developper ou Data Engineer
Vous avez une connaissance de certains frameworks d’architecture (TOGAF, IAF etc…) 
Vous êtes orienté service client, avec une très bonne communication et une envie de progresser
Vous êtes un Team Player AGILE qui voyez l’architecture comme un enabler inclusif",2024-02-17,https://www.welcometothejungle.com/fr/companies/capgemini/jobs/architecte-cloud-azure-h-f_paris_CAPGE_N9exNe3?q=869a38b87064c2fba5413f455cbe1d45&o=371cc000-3e3e-469b-8494-c570c0943970,wttj
Talent Acquisition Specialist,"{'name': 'STRANGEBEE', 'sector': 'Cybersécurité', 'employees': '37 collaborateurs', 'creation_year': '2018', 'turnover': None, 'mean_age': '35 ans'}",Temps partiel,Paris,Non spécifié,Télétravail fréquent,19 février 2024,,,"Descriptif du poste
Dans le cadre de notre croissance, nous sommes à la recherche de notre futur Talent acquisition Specialist.
Rattaché(e) à la Head of People, vous gérez l’ensemble du processus de recrutement dans son intégralité depuis la recherche du candidat jusqu’à son intégration :
• Recueil et analyse des besoins en recrutement en interaction avec les équipes.
• Gestion des annonces : rédaction, mise en ligne et traitement des candidatures,
• Entretiens de validation (physiques ou Visio)
• Préparation des réunions hebdomadaires (présentation des candidats, participation à la prise de décision sur les recrutements…)
• Embauche des candidats en collaboration avec la Head Of People (proposition salariale, élaboration des contrats, suivi de signatures)
• Participation à la bonne intégration et à la fidélisation des profils recrutés, onboarding réalisé par L’Office Manager.
• Reporting de l’activité et suivi de l’intégration.
Vous serez également amené à participer aux différents projets organisationnels de l’entreprise :
• Incitation à la cooptation,
• Promotion de la société sur les réseaux sociaux.
Voir moins","Profil recherché
De formation supérieure (bac +4 / +5), vous avez une 1ère expérience réussie en recrutement idéalement en ESN (anciennement SSII), dans une société de conseil ou encore en cabinet de recrutement spécialisé en IT / Digital.
Vous avez déjà recruté des profils d’ingénieurs études et développement (Scala, C#, C++, python, Angular, data engineer), Devops, Testeurs recetteurs, PMO ainsi que des profils fonctionnels (MOA Finance).
Nous souhaitons intégrer une personne sur un un mi-temps ou un poste à 80%, avec au minimum 1 jour par semaine en présentiel dans nos bureaux à Paris ( Gare de Lyon )
Il est important pour nous que vous soyez une personne optimiste et enjouée. Vous serez le premier visage que les candidats verront de StrangeBee.",2024-02-12,https://www.welcometothejungle.com/fr/companies/strangebee/jobs/talent-acquisition-specialist_paris?q=869a38b87064c2fba5413f455cbe1d45&o=33b297fd-96b7-4e68-b9fc-57e5043cd160,wttj
,,,,,,,,,,,,https://www.welcometothejungle.com/fr/companies/accor-tech-and-digital/jobs/candidature-spontanee-pour-la-digital-business-factory_issy-les-moulineaux_ATD_Lyz64XR?q=869a38b87064c2fba5413f455cbe1d45&o=40c3f0cd-9697-4d62-938e-b844d4ea0f59,wttj
